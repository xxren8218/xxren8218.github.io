<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>逻辑回归实战--信用卡诈骗检测 | X.X.Ren的个人博客</title>
  <meta name="description" content="信用卡诈骗预测——二分类的问题12345import pandas as pdimport matplotlib.pyplot as pltimport numpy as np%matplotlib inline 先来看看数据长什么样子吧12data &#x3D; pd.read_csv(&quot;creditcard.csv&quot;)data.head()">
<meta property="og:type" content="article">
<meta property="og:title" content="逻辑回归实战--信用卡诈骗检测">
<meta property="og:url" content="https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html">
<meta property="og:site_name" content="X.X.Ren">
<meta property="og:description" content="信用卡诈骗预测——二分类的问题12345import pandas as pdimport matplotlib.pyplot as pltimport numpy as np%matplotlib inline 先来看看数据长什么样子吧12data &#x3D; pd.read_csv(&quot;creditcard.csv&quot;)data.head()">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/5_11.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/22_1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/24_1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/28_1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/31_1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/40_1png">
<meta property="article:published_time" content="2021-04-17T17:26:48.000Z">
<meta property="article:modified_time" content="2021-04-17T18:53:58.904Z">
<meta property="article:author" content="任晓雄">
<meta property="article:tag" content="机器学习基础实战">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/5_11.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html">
  
    <link rel="alternate" href="/atom.xml" title="X.X.Ren" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" rel="stylesheet">
  
  
  
  
<meta name="generator" content="Hexo 5.4.0"></head>


<body class="main-center theme-purple# 主题颜色 theme-black theme-blue theme-green theme-purple" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://xxren888.gitee.io" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">任晓雄</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">机器学习 &amp; 人工智能</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> 陕西, 西安</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/xxren8218/xxren8218.github.io" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://weibo.com/u/5824042330" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="/" target="_blank" title="Facebook" data-toggle=tooltip data-placement=top><i class="icon icon-facebook"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-stackexchange"></i>公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-folder-open"></i>分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/">二分查找</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/">传统算法</a><span class="category-list-count">38</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">动态规划</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%9E%E6%BA%AF%E6%B3%95/">回溯法</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">53</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/">大数据的lambda架构</a><span class="category-list-count">22</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/">机器学习基础实战</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-tags"></i>标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/python%E5%9F%BA%E7%A1%80/" style="font-size: 13.9px; color: #fff">python基础</a> <a href="/tags/vim/" style="font-size: 13px; color: #fff">vim</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 13.1px; color: #fff">二分法</a> <a href="/tags/%E4%BC%AA%E5%A4%B4%E8%8A%82%E7%82%B9/" style="font-size: 13px; color: #fff">伪头节点</a> <a href="/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/" style="font-size: 13.2px; color: #fff">位运算</a> <a href="/tags/%E5%85%B6%E4%BB%96/" style="font-size: 13.1px; color: #fff">其他</a> <a href="/tags/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/" style="font-size: 13px; color: #fff">内置函数</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 13px; color: #fff">动态规划</a> <a href="/tags/%E5%8D%95%E8%B0%83%E6%A0%88/" style="font-size: 13px; color: #fff">单调栈</a> <a href="/tags/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97/" style="font-size: 13px; color: #fff">单调队列</a> <a href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/" style="font-size: 13.5px; color: #fff">双指针</a> <a href="/tags/%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97/" style="font-size: 13px; color: #fff">双端队列</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 13.4px; color: #fff">哈希表</a> <a href="/tags/%E5%A4%9A%E6%8C%87%E9%92%88/" style="font-size: 13.4px; color: #fff">多指针</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 13.1px; color: #fff">字符串</a> <a href="/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" style="font-size: 13px; color: #fff">归并排序</a> <a href="/tags/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88/" style="font-size: 13.1px; color: #fff">快慢指针</a> <a href="/tags/%E5%BF%AB%E9%80%9F%E5%B9%82/" style="font-size: 13px; color: #fff">快速幂</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 13.3px; color: #fff">排序</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/" style="font-size: 14px; color: #fff">推荐系统基础</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 13.3px; color: #fff">数学</a> <a href="/tags/%E6%95%B0%E7%BB%84/" style="font-size: 13.7px; color: #fff">数组</a> <a href="/tags/%E6%9C%80%E5%B0%8F%E5%A0%86/" style="font-size: 13.1px; color: #fff">最小堆</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" style="font-size: 13.8px; color: #fff">机器学习基础</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/" style="font-size: 13.1px; color: #fff">机器学习基础实战</a> <a href="/tags/%E6%9F%A5%E6%89%BE/" style="font-size: 13px; color: #fff">查找</a> <a href="/tags/%E6%A0%88/" style="font-size: 13px; color: #fff">栈</a> <a href="/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/" style="font-size: 13px; color: #fff">滑动窗口</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E5%88%97%E8%A1%A8/" style="font-size: 13.1px; color: #fff">辅助列表</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E6%A0%88/" style="font-size: 13.1px; color: #fff">辅助栈</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E7%B4%A0%E7%BB%84/" style="font-size: 13px; color: #fff">辅助素组</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E9%98%9F%E5%88%97/" style="font-size: 13px; color: #fff">辅助队列</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 13.3px; color: #fff">递归</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 13.6px; color: #fff">链表</a>
    </div>
  </div>

<script type="text/javascript">
    var everytag=document.getElementsByClassName("widget-body tagcloud")[0].children;
    for (var i = everytag.length - 1; i >= 0; i--) {
        var r= Math.floor(Math.random()*255);
        var g= Math.floor(Math.random()*255);
        var b= Math.floor(Math.random()*255);
        everytag[i].style.background = "rgb("+r+","+g+","+b+")";
    }
</script>

    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-archives-fill"></i>归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">七月 2021</a><span class="archive-list-count">38</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">六月 2021</a><span class="archive-list-count">51</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a><span class="archive-list-count">36</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a><span class="archive-list-count">18</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-shu-fill"></i>最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled ">
        
          <li>
            
            <div class="item-thumb">
              <a href="/20210716/07-%E6%B1%82%E7%BB%84%E5%92%8C%E6%80%BB%E5%92%8C%E4%B8%89.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210302194723.jpeg)" alt="07-求组和总和三" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%9B%9E%E6%BA%AF%E6%B3%95/">回溯法</a>
              </p>
              <p class="item-title">
                <a href="/20210716/07-%E6%B1%82%E7%BB%84%E5%92%8C%E6%80%BB%E5%92%8C%E4%B8%89.html" class="title">07-求组和总和三</a>
              </p>
              <p class="item-date">
                <time datetime="2021-07-16T14:26:03.000Z" itemprop="datePublished">2021-07-16 22:26:03</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210716/06-%E6%B1%82%E7%BB%84%E5%92%8C%E6%80%BB%E5%92%8C%E4%BA%8C.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210302194723.jpeg)" alt="06-求组和总和二" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%9B%9E%E6%BA%AF%E6%B3%95/">回溯法</a>
              </p>
              <p class="item-title">
                <a href="/20210716/06-%E6%B1%82%E7%BB%84%E5%92%8C%E6%80%BB%E5%92%8C%E4%BA%8C.html" class="title">06-求组和总和二</a>
              </p>
              <p class="item-date">
                <time datetime="2021-07-16T14:23:43.000Z" itemprop="datePublished">2021-07-16 22:23:43</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210716/18-%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88%E9%97%AE%E9%A2%98.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210302194723.jpeg)" alt="18-最近公共祖先问题" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a>
              </p>
              <p class="item-title">
                <a href="/20210716/18-%E6%9C%80%E8%BF%91%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88%E9%97%AE%E9%A2%98.html" class="title">18-最近公共祖先问题</a>
              </p>
              <p class="item-date">
                <time datetime="2021-07-16T14:20:27.000Z" itemprop="datePublished">2021-07-16 22:20:27</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210715/05-%E7%94%B5%E8%AF%9D%E5%8F%B7%E7%A0%81%E7%9A%84%E5%AD%97%E6%AF%8D%E7%BB%84%E5%90%88.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210302194723.jpeg)" alt="05-电话号码的字母组合" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E5%9B%9E%E6%BA%AF%E6%B3%95/">回溯法</a>
              </p>
              <p class="item-title">
                <a href="/20210715/05-%E7%94%B5%E8%AF%9D%E5%8F%B7%E7%A0%81%E7%9A%84%E5%AD%97%E6%AF%8D%E7%BB%84%E5%90%88.html" class="title">05-电话号码的字母组合</a>
              </p>
              <p class="item-date">
                <time datetime="2021-07-15T13:57:48.000Z" itemprop="datePublished">2021-07-15 21:57:48</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210715/17-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A0%E6%A0%91%E7%9A%84%E4%BC%97%E6%95%B0.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210302194723.jpeg)" alt="17-二叉搜素树的众数" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a>
              </p>
              <p class="item-title">
                <a href="/20210715/17-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A0%E6%A0%91%E7%9A%84%E4%BC%97%E6%95%B0.html" class="title">17-二叉搜素树的众数</a>
              </p>
              <p class="item-date">
                <time datetime="2021-07-15T13:56:03.000Z" itemprop="datePublished">2021-07-15 21:56:03</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <nav id="toc" class="article-toc">
      <h3 class="toc-title">文章目录</h3>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E9%A2%84%E6%B5%8B%E2%80%94%E2%80%94%E4%BA%8C%E5%88%86%E7%B1%BB%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">信用卡诈骗预测——二分类的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E6%9D%A5%E7%9C%8B%E7%9C%8B%E6%95%B0%E6%8D%AE%E9%95%BF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90%E5%90%A7"><span class="toc-text">先来看看数据长什么样子吧</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E6%9D%A5%E7%9C%8B%E7%9C%8B%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%88%86%E5%B8%83%E6%83%85%E5%86%B5%E5%90%A7%EF%BC%81"><span class="toc-text">先来看看正负样本的分布情况吧！</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E6%9E%81%E5%BA%A6%E4%B8%8D%E5%9D%87%E5%8C%80%EF%BC%8C%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-text">样本数据极度不均匀，应该怎么做？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Amount%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E4%B8%8D%E5%9D%87%E8%A1%A1%EF%BC%8C%E4%B8%BA%E4%BA%86%E4%BF%9D%E8%AF%81%E7%89%B9%E5%BE%81%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E6%98%AF%E5%B7%AE%E4%B8%8D%E5%A4%9A%E7%9A%84%E3%80%82%E2%80%94%E2%80%94%E5%8D%B3%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%E4%B8%80%E6%A0%B7%E3%80%82"><span class="toc-text">Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E6%9D%A5%E8%BF%9B%E8%A1%8C%E4%B8%8B%E9%87%87%E6%A0%B7%E5%90%A7%EF%BC%81"><span class="toc-text">先来进行下采样吧！</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E9%87%87%E6%A0%B7%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B0%91%E4%BA%86%EF%BC%8C%E4%BC%9A%E5%87%BA%E7%8E%B0%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%E5%91%A2%EF%BC%9F-%E5%90%8E%E9%9D%A2%E8%AF%B4%E3%80%82"><span class="toc-text">下采样的数据少了，会出现什么问题呢？ 后面说。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E6%9D%A5%E8%BF%9B%E8%A1%8C%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%87%E5%88%86%E3%80%82%E2%80%94%E2%80%94%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%EF%BC%8C%E8%AF%B4%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%BA%E4%BA%86%E9%80%89%E5%8F%82%EF%BC%81"><span class="toc-text">先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%B0%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%88%87%E5%88%86%E5%AE%8C%E4%BA%86%EF%BC%8C%E5%B7%B2%E7%BB%8F%E6%9C%89%E6%95%B0%E6%8D%AE%E4%BA%86%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%BF%9B%E8%A1%8C%E5%BB%BA%E6%A8%A1%E4%BA%86%EF%BC%81%E2%80%94%E2%80%94%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-text">现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E5%AE%B9%E6%98%93%E5%BB%BA%E7%AB%8B%EF%BC%88%E5%A6%82%E7%94%A8sklearn%EF%BC%89%EF%BC%8C%E4%BD%86%E6%98%AF%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%A0%87%E5%87%86%E5%92%8B%E6%A0%B7%E5%91%A2%EF%BC%9F%E2%80%94%E2%80%94%E7%B2%BE%E5%BA%A6%E9%AA%97%E4%BA%BA"><span class="toc-text">模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人!</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E5%87%86%E7%8E%87%E4%B8%8E%E6%9F%A5%E5%85%A8%E7%8E%87%EF%BC%88%E5%8F%AC%E5%9B%9E%E7%8E%87%EF%BC%89"><span class="toc-text">查准率与查全率（召回率）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-text">交叉验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E4%B8%8B%E9%87%87%E6%A0%B7%E7%9A%84%E6%B5%8B%E8%AF%95%E9%9B%86%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E5%8F%AC%E5%9B%9E%E7%8E%87%E7%BA%A6%E4%B8%BA-137-10-137%E2%89%8890"><span class="toc-text">从下采样的测试集，可以看到召回率约为(137+10)&#x2F;137≈90%</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E4%B8%8B%E9%87%87%E6%A0%B7%E7%9A%84%E9%A2%84%E6%B5%8B%E5%BA%94%E7%94%A8%E5%88%B0%E6%95%B4%E4%BD%93%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%B5%8B%E8%AF%95%E9%9B%86%EF%BC%8C%E8%99%BD%E7%84%B6%E5%8F%AC%E5%9B%9E%E7%8E%87%E7%BA%A6%E4%B8%BA90-%EF%BC%8C%E4%BD%86%E6%9C%898581%E4%B8%AA%E8%AF%AF%E6%9D%80%E5%80%BC%EF%BC%8C%E4%B8%8D%E6%98%AF%E6%88%91%E4%BB%AC%E6%89%80%E5%B8%8C%E6%9C%9B%E7%9A%84%E3%80%82"><span class="toc-text">可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90%，但有8581个误杀值，不是我们所希望的。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E9%AA%8C%E8%AF%81%E3%80%82%E4%BC%9A%E5%BE%97%E5%88%B0%E4%BB%80%E4%B9%88%E7%BB%93%E6%9E%9C%E5%91%A2%EF%BC%9F%E2%80%94%E2%80%94%E4%B8%8D%E8%BF%9B%E8%A1%8C%E4%B8%8A-%E4%B8%8B-%E9%87%87%E6%A0%B7"><span class="toc-text">对于原始数据集进行验证。会得到什么结果呢？——不进行上(下)采样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E6%8B%BF%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B%E5%BE%97%E5%88%B0%E7%9A%84%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%98%AF%E6%AF%94%E8%BE%83%E4%BD%8E%E7%9A%84%E3%80%82"><span class="toc-text">可以看到拿原始数据进行预测得到的召回率是比较低的。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A5%E4%B8%8B%E6%9D%A5%E7%9C%8B%E7%9C%8B%E4%B8%8D%E5%90%8C%E7%9A%84%E9%98%88%E5%80%BC%E5%AF%B9%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E5%93%8D%E2%80%94%E2%80%94%E5%88%92%E5%88%86%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%A0%87%E5%87%86%E4%B8%8D%E6%98%AF%E9%BB%98%E8%AE%A4%E7%9A%840-5%E4%BA%86"><span class="toc-text">接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0.5了</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E9%9A%8F%E7%9D%80%E9%98%88%E5%80%BC%E7%9A%84%E4%B8%8A%E5%8D%87%EF%BC%8C%E8%AF%AF%E6%9D%80%E5%80%BC%E5%87%8F%E5%B0%8F%EF%BC%8C%E4%BD%86%E6%98%AF%E5%8F%AC%E5%9B%9E%E7%8E%87%E4%B9%9F%E6%98%AF%E5%87%8F%E5%B0%8F%E4%BA%86%E3%80%82%E2%80%94%E2%80%94%E5%AE%9E%E9%99%85%E5%BB%BA%E6%A8%A1%E6%97%B6%EF%BC%8C%E5%BA%94%E8%AF%A5%E6%A0%B9%E6%8D%AE%E5%AE%9E%E9%99%85%E6%83%85%E5%86%B5%E6%9D%A5%E9%80%89%E6%8B%A9%E9%98%88%E5%80%BC%EF%BC%81"><span class="toc-text">可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9C%8B%E5%AE%8C%E4%B8%8B%E9%87%87%E6%A0%B7%E7%9A%84%E5%88%86%E6%9E%90%EF%BC%8C%E6%88%91%E4%BB%AC%E6%9D%A5%E7%9C%8B%E7%9C%8B%E4%B8%8A%E9%87%87%E6%A0%B7%E7%9A%84%E7%BB%93%E6%9E%9C%E5%90%A7%EF%BC%81"><span class="toc-text">看完下采样的分析，我们来看看上采样的结果吧！</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AC%E5%9B%9E%E7%8E%87%E8%BF%98%E5%8F%AF%E4%BB%A5%EF%BC%8C%E8%AF%AF%E6%9D%80%E7%8E%87%E9%99%8D%E4%B8%8B%E6%9D%A5%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%B2%BE%E5%BA%A6%E5%8F%98%E9%AB%98%E3%80%82-56344-91-569344-91-517-10"><span class="toc-text">召回率还可以，误杀率降下来——模型的精度变高。(56344+91)&#x2F;(569344+91+517+10)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E4%B9%8B%EF%BC%8C%E8%83%BD%E7%94%A8%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E6%96%B9%E5%BC%8F%E5%B0%BD%E9%87%8F%E7%94%A8%EF%BC%8C%E4%B8%8A%E9%87%87%E6%A0%B7%E7%9A%84%E7%BB%93%E6%9E%9C%E6%9B%B4%E5%A5%BD%EF%BC%81"><span class="toc-text">总之，能用数据生成方式尽量用，上采样的结果更好！</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-text">案例流程总结：</span></a></li></ol>
    </nav>
  </div>
</aside>

<main class="main" role="main">
  <div class="content">
  <article id="post-逻辑回归基础实战" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      逻辑回归实战--信用卡诈骗检测
    </h1>
  


      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar"></i>
    <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html" class="article-date">
        发布于<time datetime="2021-04-17T17:26:48.000Z" itemprop="datePublished">
            2021-04-18 01:26:48
        </time>
    </a>
</span>

<span class="article-date">
    <i class="icon icon-calendar-check"></i>
    <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html" class="article-date">
        更新于<time datetime="2021-04-17T18:53:58.904Z" itemprop="dateUpdated">
            2021-04-18 02:53:58
        </time>
    </a>
</span>


        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/">机器学习基础实战</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/" rel="tag">机器学习基础实战</a>
  </span>


        

	<span class="article-read hidden-xs">
    	<i class="icon icon-eye-fill" aria-hidden="true"></i>
    	<span id="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html" class="leancloud_visitors"  data-flag-title="逻辑回归实战--信用卡诈骗检测">0</span>
    </span>

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
	<div style="background-color:#D7BDE2;border:1px solid #D7BDE2;border-radius:10px;padding:5px">
    		<b>温馨提示</b>：点击页面下方<i style="color:red" class="icon icon-anchor"></i>以展开或折叠目录~
	</div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h1 id="信用卡诈骗预测——二分类的问题"><a href="#信用卡诈骗预测——二分类的问题" class="headerlink" title="信用卡诈骗预测——二分类的问题"></a>信用卡诈骗预测——二分类的问题</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h2 id="先来看看数据长什么样子吧"><a href="#先来看看数据长什么样子吧" class="headerlink" title="先来看看数据长什么样子吧"></a>先来看看数据长什么样子吧</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;creditcard.csv&quot;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<div style="overflow: scroll;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>



<h2 id="先来看看正负样本的分布情况吧！"><a href="#先来看看正负样本的分布情况吧！" class="headerlink" title="先来看看正负样本的分布情况吧！"></a>先来看看正负样本的分布情况吧！</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">count_classes = pd.value_counts(data[<span class="string">&#x27;Class&#x27;</span>], sort = <span class="literal">True</span>).sort_index()  <span class="comment"># values_counts可以根据值进行计数。sort_index()按行索引排序</span></span><br><span class="line">count_classes.plot(kind = <span class="string">&#x27;bar&#x27;</span>)    <span class="comment"># 除了plt，pd也可以做一些简单的图</span></span><br><span class="line">plt.title(<span class="string">&quot;Fraud class histogram&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Class&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.text.Text at 0x216366d8860&gt;
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/5_11.png" alt=""></p>
<h2 id="样本数据极度不均匀，应该怎么做？"><a href="#样本数据极度不均匀，应该怎么做？" class="headerlink" title="样本数据极度不均匀，应该怎么做？"></a>样本数据极度不均匀，应该怎么做？</h2><ul>
<li><strong>下采样</strong>——对于不均衡的数据，让 1 和 0 的数据一样少</li>
<li><strong>过采样</strong>——对于不均衡的数据，生成一些数据，让生成的数据与 0 样本一样多</li>
</ul>
<h3 id="Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。"><a href="#Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。" class="headerlink" title="Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。"></a>Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。</h3><ul>
<li><strong>标准化</strong> </li>
<li><strong>归一化</strong>  </li>
</ul>
<p>可以使用sklearn的预处理模块进行标准化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;normAmount&#x27;</span>] = StandardScaler().fit_transform(data[<span class="string">&#x27;Amount&#x27;</span>].reshape(-<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># reshape(-1,1)</span></span><br><span class="line">                                                                                   <span class="comment"># -1表示让python给它行数</span></span><br><span class="line">data = data.drop([<span class="string">&#x27;Time&#x27;</span>,<span class="string">&#x27;Amount&#x27;</span>],axis=<span class="number">1</span>)  <span class="comment"># 有了新特征后，将没用的特征去掉。</span></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>
<div style="overflow: scroll;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Class</th>
      <th>normAmount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>0.090794</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>0</td>
      <td>0.244964</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>-0.166974</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>0</td>
      <td>-0.342475</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>0.207643</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>0</td>
      <td>1.160686</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>-0.054952</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>0</td>
      <td>0.140534</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>0.753074</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>0</td>
      <td>-0.073403</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 30 columns</p>
</div>



<h2 id="先来进行下采样吧！"><a href="#先来进行下采样吧！" class="headerlink" title="先来进行下采样吧！"></a>先来进行下采样吧！</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">X = data.ix[:, data.columns != <span class="string">&#x27;Class&#x27;</span>] <span class="comment"># loc[标签] iloc[索引数字] 取值 ，ix[都可以]  </span></span><br><span class="line">y = data.ix[:, data.columns == <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of data points in the minority class</span></span><br><span class="line">number_records_fraud = <span class="built_in">len</span>(data[data.Class == <span class="number">1</span>])  <span class="comment"># 计算异常样本的数目——采用bool索引的方式进行</span></span><br><span class="line">fraud_indices = np.array(data[data.Class == <span class="number">1</span>].index) <span class="comment"># 通过.index函数拿出来异常样本的索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Picking the indices of the normal classes</span></span><br><span class="line">normal_indices = data[data.Class == <span class="number">0</span>].index  <span class="comment"># 拿出来所有正常样本的index，为了下面的随机选择。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Out of the indices we picked, randomly select &quot;x&quot; number (number_records_fraud)</span></span><br><span class="line">random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = <span class="literal">False</span>)<span class="comment">#  np.random.choice(样本，选择数目)进行随机选择</span></span><br><span class="line">random_normal_indices = np.array(random_normal_indices)  <span class="comment"># 将拿出来的索引转化为np.array的类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Appending the 2 indices  ##合并两个样本的index进行合并</span></span><br><span class="line">under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Under sample dataset  ## 经过下采样以后拿到的数据</span></span><br><span class="line">under_sample_data = data.iloc[under_sample_indices,:]</span><br><span class="line"></span><br><span class="line">X_undersample = under_sample_data.ix[:, under_sample_data.columns != <span class="string">&#x27;Class&#x27;</span>]  <span class="comment"># 下采样的数据分成两部分</span></span><br><span class="line">y_undersample = under_sample_data.ix[:, under_sample_data.columns == <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing ratio</span></span><br><span class="line">print(<span class="string">&quot;Percentage of normal transactions: &quot;</span>, <span class="built_in">len</span>(under_sample_data[under_sample_data.Class == <span class="number">0</span>])/<span class="built_in">len</span>(under_sample_data))</span><br><span class="line">print(<span class="string">&quot;Percentage of fraud transactions: &quot;</span>, <span class="built_in">len</span>(under_sample_data[under_sample_data.Class == <span class="number">1</span>])/<span class="built_in">len</span>(under_sample_data))</span><br><span class="line">print(<span class="string">&quot;Total number of transactions in resampled data: &quot;</span>, <span class="built_in">len</span>(under_sample_data))</span><br></pre></td></tr></table></figure>
<pre><code>Percentage of normal transactions:  0.5
Percentage of fraud transactions:  0.5
Total number of transactions in resampled data:  984
</code></pre><h3 id="下采样的数据少了，会出现什么问题呢？-后面说。"><a href="#下采样的数据少了，会出现什么问题呢？-后面说。" class="headerlink" title="下采样的数据少了，会出现什么问题呢？ 后面说。"></a>下采样的数据少了，会出现什么问题呢？ 后面说。</h3><h2 id="先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！"><a href="#先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！" class="headerlink" title="先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！"></a>先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split  <span class="comment"># sklearn有交叉验证的工具，能镜像数据的划分。</span></span><br><span class="line"><span class="comment"># from sklearn.model_selection import train_test_split</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Whole dataset  #【1】对原始的数据进行切分——（为了使用它的测试集进行测试）</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>) <span class="comment">## 注意顺序！ 数据洗牌</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Number transactions train dataset: &quot;</span>, <span class="built_in">len</span>(X_train))</span><br><span class="line">print(<span class="string">&quot;Number transactions test dataset: &quot;</span>, <span class="built_in">len</span>(X_test))</span><br><span class="line">print(<span class="string">&quot;Total number of transactions: &quot;</span>, <span class="built_in">len</span>(X_train)+<span class="built_in">len</span>(X_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Undersampled dataset  # 【2】 对下采样的数据进行切分。（下采样的测试集小，不具备原始数据的分布规则。）</span></span><br><span class="line">X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample</span><br><span class="line">                                                                                                   ,y_undersample</span><br><span class="line">                                                                                                   ,test_size = <span class="number">0.3</span></span><br><span class="line">                                                                                                   ,random_state = <span class="number">0</span>)</span><br><span class="line">print(<span class="string">&quot;&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;Number transactions train dataset: &quot;</span>, <span class="built_in">len</span>(X_train_undersample))</span><br><span class="line">print(<span class="string">&quot;Number transactions test dataset: &quot;</span>, <span class="built_in">len</span>(X_test_undersample))</span><br><span class="line">print(<span class="string">&quot;Total number of transactions: &quot;</span>, <span class="built_in">len</span>(X_train_undersample)+<span class="built_in">len</span>(X_test_undersample))</span><br></pre></td></tr></table></figure>
<pre><code>C:\Anaconda3\lib\site-packages\sklearn\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  &quot;This module will be removed in 0.20.&quot;, DeprecationWarning)


Number transactions train dataset:  199364
Number transactions test dataset:  85443
Total number of transactions:  284807

Number transactions train dataset:  688
Number transactions test dataset:  296
Total number of transactions:  984
</code></pre><h2 id="现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归"><a href="#现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归" class="headerlink" title="现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归"></a>现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归</h2><h4 id="模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人"><a href="#模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人" class="headerlink" title="模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人!"></a>模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人!</h4><ul>
<li>样本数目不均衡时，类偏移现象。100个人，99个正常(0)，1个得癌症(1)。那如果我的模型是y = 0,我的准确率是 99 %,但是检测不出来一个患有癌症的人。——所以希望我们的模型查的全一点。</li>
</ul>
<h3 id="查准率与查全率（召回率）"><a href="#查准率与查全率（召回率）" class="headerlink" title="查准率与查全率（召回率）"></a>查准率与查全率（召回率）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Recall = TP/(TP+FN)  # 我判断得癌症的人/实际得癌症的人</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold, cross_val_score   <span class="comment"># KFold 做几倍的交叉验证， cross_val_score交叉验证的结果</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,recall_score,classification_report </span><br></pre></td></tr></table></figure>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><ul>
<li>正则化惩罚项——解决<strong>高偏差</strong>（<strong>欠拟合</strong>，数据误差大）&amp; <strong>高方差</strong>（<strong>过拟合</strong>，泛化能力差）<ul>
<li>L1 惩罚项</li>
<li>L2 惩罚项</li>
</ul>
</li>
</ul>
<ul>
<li><p>直接使用sklearn的逻辑回归库进行拟合 </p>
<ul>
<li>先实例化一个逻辑回归对象（传入正则化参数C，惩罚方式即可）</li>
<li>然后进行fit拟合</li>
<li>sklearn会返回预测结果</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_Kfold_scores</span>(<span class="params">x_train_data,y_train_data</span>):</span></span><br><span class="line">    fold = KFold(<span class="number">5</span>,shuffle=<span class="literal">False</span>)   <span class="comment"># 对（训练的）测试集的五倍交叉验证。</span></span><br><span class="line">                                                      <span class="comment">### 返回值是一个列表是[[train1,test1],[train2,test2],...]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Different C parameters   # C越大惩罚力度越大，即heta的权重就越小。可以用交叉验证来检测到底等于多少好。</span></span><br><span class="line">    c_param_range = [<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1</span>,<span class="number">10</span>,<span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">    results_table = pd.DataFrame(index = <span class="built_in">range</span>(<span class="built_in">len</span>(c_param_range),<span class="number">2</span>), columns = [<span class="string">&#x27;C_parameter&#x27;</span>,<span class="string">&#x27;Mean recall score&#x27;</span>])</span><br><span class="line">    results_table[<span class="string">&#x27;C_parameter&#x27;</span>] = c_param_range</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]  </span></span><br><span class="line">    <span class="comment">## k-fold会分成两个索引的列表：train_indices = indices[0], test_indices = indices[1]  </span></span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">&quot;&quot;&quot;来看哪个C好&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> c_param <span class="keyword">in</span> c_param_range:</span><br><span class="line">        print(<span class="string">&#x27;-------------------------------------------&#x27;</span>)</span><br><span class="line">        print(<span class="string">&#x27;C parameter: &#x27;</span>, c_param)</span><br><span class="line">        print(<span class="string">&#x27;-------------------------------------------&#x27;</span>)</span><br><span class="line">        print(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        recall_accs = []</span><br><span class="line">        <span class="string">&quot;&quot;&quot;来进行交叉验证，1 3 训练 2验证，1 2 训练，3验证...&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> iteration, indices <span class="keyword">in</span> <span class="built_in">enumerate</span>(fold,start=<span class="number">1</span>):  <span class="comment">## 一般情况下，如果要对一个列表或者数组既要遍历索引又要遍历元素时，可以用enumerate</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Call the logistic regression model with a certain C parameter</span></span><br><span class="line">            lr = LogisticRegression(C = c_param, penalty = <span class="string">&#x27;l1&#x27;</span>)  <span class="comment">## C正则化，惩罚方式 L1惩罚。</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Use the training data to fit the model. In this case, we use the portion of the fold to train the model</span></span><br><span class="line">            <span class="comment"># with indices[0]. We then predict on the portion assigned as the &#x27;test cross validation&#x27; with indices[1]</span></span><br><span class="line">            <span class="comment"># 进行数据的拟合</span></span><br><span class="line">            lr.fit(x_train_data.iloc[indices[<span class="number">0</span>],:],y_train_data.iloc[indices[<span class="number">0</span>],:].values.ravel())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Predict values using the test indices in the training data</span></span><br><span class="line">            <span class="comment">## 比如在C = 0.01情况下，效果咋样</span></span><br><span class="line">            y_pred_undersample = lr.predict(x_train_data.iloc[indices[<span class="number">1</span>],:].values)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Calculate the recall score and append it to a list for recall scores representing the current c_parameter</span></span><br><span class="line">            recall_acc = recall_score(y_train_data.iloc[indices[<span class="number">1</span>],:].values,y_pred_undersample)  <span class="comment">## 召回率库自己生成 recall_score(实际值，预测值)</span></span><br><span class="line">            recall_accs.append(recall_acc)</span><br><span class="line">            print(<span class="string">&#x27;Iteration &#x27;</span>, iteration,<span class="string">&#x27;: recall score = &#x27;</span>, recall_acc)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The mean value of those recall scores is the metric we want to save and get hold of.</span></span><br><span class="line">        results_table.ix[j,<span class="string">&#x27;Mean recall score&#x27;</span>] = np.mean(recall_accs)</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">        print(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        print(<span class="string">&#x27;Mean recall score &#x27;</span>, np.mean(recall_accs))</span><br><span class="line">        print(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    best_c = results_table.loc[results_table[<span class="string">&#x27;Mean recall score&#x27;</span>].idxmax()][<span class="string">&#x27;C_parameter&#x27;</span>]  <span class="comment"># 定义能取到最大值得索引位置，</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Finally, we can check which C parameter is the best amongst the chosen.</span></span><br><span class="line">    print(<span class="string">&#x27;*********************************************************************************&#x27;</span>)</span><br><span class="line">    print(<span class="string">&#x27;Best model to choose from cross validation is with C parameter = &#x27;</span>, best_c)</span><br><span class="line">    print(<span class="string">&#x27;*********************************************************************************&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_c</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)</span><br></pre></td></tr></table></figure>
<pre><code>-------------------------------------------
C parameter:  0.01
-------------------------------------------

Iteration  1 : recall score =  0.958904109589
Iteration  2 : recall score =  0.917808219178
Iteration  3 : recall score =  1.0
Iteration  4 : recall score =  0.972972972973
Iteration  5 : recall score =  0.954545454545

Mean recall score  0.960846151257

-------------------------------------------
C parameter:  0.1
-------------------------------------------

Iteration  1 : recall score =  0.835616438356
Iteration  2 : recall score =  0.86301369863
Iteration  3 : recall score =  0.915254237288
Iteration  4 : recall score =  0.932432432432
Iteration  5 : recall score =  0.878787878788

Mean recall score  0.885020937099

-------------------------------------------
C parameter:  1
-------------------------------------------

Iteration  1 : recall score =  0.835616438356
Iteration  2 : recall score =  0.86301369863
Iteration  3 : recall score =  0.966101694915
Iteration  4 : recall score =  0.945945945946
Iteration  5 : recall score =  0.893939393939

Mean recall score  0.900923434357

-------------------------------------------
C parameter:  10
-------------------------------------------

Iteration  1 : recall score =  0.849315068493
Iteration  2 : recall score =  0.86301369863
Iteration  3 : recall score =  0.966101694915
Iteration  4 : recall score =  0.959459459459
Iteration  5 : recall score =  0.893939393939

Mean recall score  0.906365863087

-------------------------------------------
C parameter:  100
-------------------------------------------

Iteration  1 : recall score =  0.86301369863
Iteration  2 : recall score =  0.86301369863
Iteration  3 : recall score =  0.966101694915
Iteration  4 : recall score =  0.959459459459
Iteration  5 : recall score =  0.893939393939

Mean recall score  0.909105589115

*********************************************************************************
Best model to choose from cross validation is with C parameter =  0.01
*********************************************************************************
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span>(<span class="params">cm, classes,</span></span></span><br><span class="line"><span class="function"><span class="params">                          title=<span class="string">&#x27;Confusion matrix&#x27;</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                          cmap=plt.cm.Blues</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function prints and plots the confusion matrix.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    plt.imshow(cm, interpolation=<span class="string">&#x27;nearest&#x27;</span>, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(<span class="built_in">len</span>(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=<span class="number">0</span>)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    thresh = cm.<span class="built_in">max</span>() / <span class="number">2.</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(<span class="built_in">range</span>(cm.shape[<span class="number">0</span>]), <span class="built_in">range</span>(cm.shape[<span class="number">1</span>])):</span><br><span class="line">        plt.text(j, i, cm[i, j],</span><br><span class="line">                 horizontalalignment=<span class="string">&quot;center&quot;</span>,</span><br><span class="line">                 color=<span class="string">&quot;white&quot;</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">&quot;black&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred_undersample = lr.predict(X_test_undersample.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Recall metric in the testing dataset:  0.931972789116
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/22_1.png" alt=""></p>
<h3 id="从下采样的测试集，可以看到召回率约为-137-10-137≈90"><a href="#从下采样的测试集，可以看到召回率约为-137-10-137≈90" class="headerlink" title="从下采样的测试集，可以看到召回率约为(137+10)/137≈90%"></a>从下采样的测试集，可以看到召回率约为(137+10)/137≈90%</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred = lr.predict(X_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test,y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Recall metric in the testing dataset:  0.918367346939
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/24_1.png" alt=""></p>
<h3 id="可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90-，但有8581个误杀值，不是我们所希望的。"><a href="#可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90-，但有8581个误杀值，不是我们所希望的。" class="headerlink" title="可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90%，但有8581个误杀值，不是我们所希望的。"></a>可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90%，但有8581个误杀值，不是我们所希望的。</h3><h2 id="对于原始数据集进行验证。会得到什么结果呢？——不进行上-下-采样"><a href="#对于原始数据集进行验证。会得到什么结果呢？——不进行上-下-采样" class="headerlink" title="对于原始数据集进行验证。会得到什么结果呢？——不进行上(下)采样"></a>对于原始数据集进行验证。会得到什么结果呢？——不进行上(下)采样</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_c = printing_Kfold_scores(X_train,y_train)</span><br></pre></td></tr></table></figure>
<pre><code>-------------------------------------------
C parameter:  0.01
-------------------------------------------

Iteration  1 : recall score =  0.492537313433
Iteration  2 : recall score =  0.602739726027
Iteration  3 : recall score =  0.683333333333
Iteration  4 : recall score =  0.569230769231
Iteration  5 : recall score =  0.45

Mean recall score  0.559568228405

-------------------------------------------
C parameter:  0.1
-------------------------------------------

Iteration  1 : recall score =  0.567164179104
Iteration  2 : recall score =  0.616438356164
Iteration  3 : recall score =  0.683333333333
Iteration  4 : recall score =  0.584615384615
Iteration  5 : recall score =  0.525

Mean recall score  0.595310250644

-------------------------------------------
C parameter:  1
-------------------------------------------

Iteration  1 : recall score =  0.55223880597
Iteration  2 : recall score =  0.616438356164
Iteration  3 : recall score =  0.716666666667
Iteration  4 : recall score =  0.615384615385
Iteration  5 : recall score =  0.5625

Mean recall score  0.612645688837

-------------------------------------------
C parameter:  10
-------------------------------------------

Iteration  1 : recall score =  0.55223880597
Iteration  2 : recall score =  0.616438356164
Iteration  3 : recall score =  0.733333333333
Iteration  4 : recall score =  0.615384615385
Iteration  5 : recall score =  0.575

Mean recall score  0.61847902217

-------------------------------------------
C parameter:  100
-------------------------------------------

Iteration  1 : recall score =  0.55223880597
Iteration  2 : recall score =  0.616438356164
Iteration  3 : recall score =  0.733333333333
Iteration  4 : recall score =  0.615384615385
Iteration  5 : recall score =  0.575

Mean recall score  0.61847902217

*********************************************************************************
Best model to choose from cross validation is with C parameter =  10.0
*********************************************************************************
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train,y_train.values.ravel())</span><br><span class="line">y_pred_undersample = lr.predict(X_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test,y_pred_undersample)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Recall metric in the testing dataset:  0.619047619048
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/28_1.png" alt=""></p>
<h3 id="可以看到拿原始数据进行预测得到的召回率是比较低的。"><a href="#可以看到拿原始数据进行预测得到的召回率是比较低的。" class="headerlink" title="可以看到拿原始数据进行预测得到的召回率是比较低的。"></a>可以看到拿原始数据进行预测得到的召回率是比较低的。</h3><h2 id="接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0-5了"><a href="#接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0-5了" class="headerlink" title="接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0.5了"></a>接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0.5了</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = <span class="number">0.01</span>, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values) <span class="comment">## 之前拿的是predict()现在是另外一个函数了</span></span><br><span class="line">                                                                       <span class="comment"># 之前预测是类别的值，现在预测是概率值</span></span><br><span class="line"></span><br><span class="line">thresholds = [<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">j = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> thresholds:</span><br><span class="line">    y_test_predictions_high_recall = y_pred_undersample_proba[:,<span class="number">1</span>] &gt; i  <span class="comment">## 这是关键，拿到概率后直接拿它与设定阈值比较</span></span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,j)</span><br><span class="line">    j += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute confusion matrix</span></span><br><span class="line">    cnf_matrix = confusion_matrix(y_test_undersample,y_test_predictions_high_recall)</span><br><span class="line">    np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">    class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    plot_confusion_matrix(cnf_matrix</span><br><span class="line">                          , classes=class_names</span><br><span class="line">                          , title=<span class="string">&#x27;Threshold &gt;= %s&#x27;</span>%i) </span><br></pre></td></tr></table></figure>
<pre><code>Recall metric in the testing dataset:  1.0
Recall metric in the testing dataset:  1.0
Recall metric in the testing dataset:  1.0
Recall metric in the testing dataset:  0.986394557823
Recall metric in the testing dataset:  0.931972789116
Recall metric in the testing dataset:  0.884353741497
Recall metric in the testing dataset:  0.836734693878
Recall metric in the testing dataset:  0.748299319728
Recall metric in the testing dataset:  0.571428571429
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/31_1.png" alt=""></p>
<h3 id="可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！"><a href="#可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！" class="headerlink" title="可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！"></a>可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！</h3><h2 id="看完下采样的分析，我们来看看上采样的结果吧！"><a href="#看完下采样的分析，我们来看看上采样的结果吧！" class="headerlink" title="看完下采样的分析，我们来看看上采样的结果吧！"></a>看完下采样的分析，我们来看看上采样的结果吧！</h2><ul>
<li>上采样需要额外的数据，这里我们采用 <strong><code>SMOTE</code></strong> 方法来生成少数样本的数据。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE   <span class="comment"># 需要安装 imblearn 库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">credit_cards=pd.read_csv(<span class="string">&#x27;creditcard.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">columns=credit_cards.columns</span><br><span class="line"><span class="comment"># The labels are in the last column (&#x27;Class&#x27;). Simply remove it to obtain features columns</span></span><br><span class="line">features_columns=columns.delete(<span class="built_in">len</span>(columns)-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">features=credit_cards[features_columns]</span><br><span class="line">labels=credit_cards[<span class="string">&#x27;Class&#x27;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">features_train, features_test, labels_train, labels_test = train_test_split(features, </span><br><span class="line">                                                                            labels, </span><br><span class="line">                                                                            test_size=<span class="number">0.2</span>, </span><br><span class="line">                                                                            random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oversampler=SMOTE(random_state=<span class="number">0</span>)  <span class="comment"># 每次生辰的随机数一样。</span></span><br><span class="line">os_features,os_labels=oversampler.fit_sample(features_train,labels_train)  <span class="comment"># 注意传入的是训练的x和y的值。没有测试部分的</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(os_labels[os_labels==<span class="number">1</span>])  <span class="comment"># 自动会进行平衡。1:1平衡</span></span><br></pre></td></tr></table></figure>
<pre><code>227454
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">os_features = pd.DataFrame(os_features)</span><br><span class="line">os_labels = pd.DataFrame(os_labels)</span><br><span class="line">best_c = printing_Kfold_scores(os_features,os_labels)</span><br></pre></td></tr></table></figure>
<pre><code>-------------------------------------------
C parameter:  0.01
-------------------------------------------

Iteration  1 : recall score =  0.890322580645
Iteration  2 : recall score =  0.894736842105
Iteration  3 : recall score =  0.968861347792
Iteration  4 : recall score =  0.957595541926
Iteration  5 : recall score =  0.958430881173

Mean recall score  0.933989438728

-------------------------------------------
C parameter:  0.1
-------------------------------------------

Iteration  1 : recall score =  0.890322580645
Iteration  2 : recall score =  0.894736842105
Iteration  3 : recall score =  0.970410534469
Iteration  4 : recall score =  0.959980655302
Iteration  5 : recall score =  0.960178498807

Mean recall score  0.935125822266

-------------------------------------------
C parameter:  1
-------------------------------------------

Iteration  1 : recall score =  0.890322580645
Iteration  2 : recall score =  0.894736842105
Iteration  3 : recall score =  0.970454796946
Iteration  4 : recall score =  0.96014552489
Iteration  5 : recall score =  0.960596168431

Mean recall score  0.935251182603

-------------------------------------------
C parameter:  10
-------------------------------------------

Iteration  1 : recall score =  0.890322580645
Iteration  2 : recall score =  0.894736842105
Iteration  3 : recall score =  0.97065397809
Iteration  4 : recall score =  0.960343368396
Iteration  5 : recall score =  0.960530220596

Mean recall score  0.935317397966

-------------------------------------------
C parameter:  100
-------------------------------------------

Iteration  1 : recall score =  0.890322580645
Iteration  2 : recall score =  0.894736842105
Iteration  3 : recall score =  0.970543321899
Iteration  4 : recall score =  0.960211472725
Iteration  5 : recall score =  0.960903924995

Mean recall score  0.935343628474

*********************************************************************************
Best model to choose from cross validation is with C parameter =  100.0
*********************************************************************************
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(os_features,os_labels.values.ravel())</span><br><span class="line">y_pred = lr.predict(features_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(labels_test,y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Recall metric in the testing dataset:  0.90099009901
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/40_1png" alt=""></p>
<h3 id="召回率还可以，误杀率降下来——模型的精度变高。-56344-91-569344-91-517-10"><a href="#召回率还可以，误杀率降下来——模型的精度变高。-56344-91-569344-91-517-10" class="headerlink" title="召回率还可以，误杀率降下来——模型的精度变高。(56344+91)/(569344+91+517+10)"></a>召回率还可以，误杀率降下来——模型的精度变高。(56344+91)/(569344+91+517+10)</h3><h3 id="总之，能用数据生成方式尽量用，上采样的结果更好！"><a href="#总之，能用数据生成方式尽量用，上采样的结果更好！" class="headerlink" title="总之，能用数据生成方式尽量用，上采样的结果更好！"></a>总之，能用数据生成方式尽量用，上采样的结果更好！</h3><h1 id="案例流程总结："><a href="#案例流程总结：" class="headerlink" title="案例流程总结："></a>案例流程总结：</h1><ul>
<li><p><strong>1. 数据的观察。</strong></p>
<ul>
<li>1.1 数据浮动情况：<ul>
<li>归一化</li>
<li>标准化<ul>
<li>1.2 数据分布均匀情况：</li>
</ul>
</li>
<li>下采样</li>
<li>上采样<ul>
<li>1.3 此处的案例的特征是处理过的，纯净的特征，不需要额外处理。很多时候需要特种工程处理特征数据—后面讲</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>2. 对于不同的模型有不同的参数，需要自己进行选择。</strong></p>
<ul>
<li>比如逻辑回归的正则化参数C的选择(解决过拟合【高方差】和欠拟合【高偏差】)。<ul>
<li>采用交叉验证的方式来确定参数C（交叉验证多次来确定C的合适大小）</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>3. 混淆矩阵，召回率——解决类偏移问题</strong></p>
<ul>
<li>预测模型为 y=1 ,准确率达到90%这类问题。</li>
</ul>
</li>
<li><p><strong>4. 不同的阈值（评判分类的不概率标准）</strong></p>
<ul>
<li>对结果有一定的影响。如此题。阈值越大，误杀率越高，召回率降低。——实际建模的时候，根据需要来确定。</li>
</ul>
</li>
</ul>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
<!--  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html" title="逻辑回归实战--信用卡诈骗检测" target="_blank" rel="external">https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul> -->
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://xxren888.gitee.io" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://xxren888.gitee.io" target="_blank"><span class="text-dark">任晓雄</span><small class="ml-1x">机器学习 &amp; 人工智能</small></a></h3>
        <div>西安交通大学19级研究生一枚，研究计算机纯属兴趣。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/20210429/%E5%86%B3%E7%AD%96%E6%A0%91.html" title="决策树基础"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html" title="逻辑回归基础"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
    <li class="toggle-toc">
      <a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button">
        <span>[&nbsp;</span><span>文章目录</span>
        <i class="text-collapsed icon icon-anchor"></i>
        <i class="text-in icon icon-close"></i>
        <span>]</span>
      </a>
    </li>
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>感谢您的支持，我会继续努力的!</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>




</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/xxren8218/xxren8218.github.io" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://weibo.com/u/5824042330" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="/" target="_blank" title="Facebook" data-toggle=tooltip data-placement=top><i class="icon icon-facebook"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/xxren8218" target="_blank"> xxren </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>

  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: 'q31vlhOeBIWHbSnIN669vDYF-gzGzoHsz',
    appKey: 'r0sWX8dHj6ThrIus2L589jr9',
    placeholder: '说点什么吧...',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: true
  });
  </script>

     







<div id="go-top"></div>

<style type="text/css">
#go-top {
 width:40px;height:36px;
 background-color:#DDA0DD;
 position:relative;
 border-radius:2px;
 position:fixed;right:10px;bottom:60px;
 cursor:pointer;display:none;
}
#go-top:after {
 content:" ";
 position:absolute;left:14px;top:14px;
 border-top:2px solid #fff;border-right:2px solid #fff;
 width:12px;height:12px;
 transform:rotate(-45deg);
}
#go-top:hover {
 background-color:#8A2BE2;
}
</style>
<script>
$(function () {
  var top=$("#go-top");
  $(window).scroll(function () {
    ($(window).scrollTop() > 300) ? top.show(300) : top.hide(200);
    $("#go-top").click(function () {
      $('body,html').animate({scrollTop:0});
      return false();
    })
  });
});
</script>


  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
      z-index: 2;
    }

    .highlight-wrap:hover .copy-btn,
        .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  
  <script>
    addLoadEvent(()=>{
      $('.highlight').each(function (i, e) {
        var $wrap = $('<div>').addClass('highlight-wrap')
        $(e).after($wrap)
        $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
          var code = $(this).parent().find(".code")[0].innerText
          
          var ta = document.createElement('textarea')
          document.body.appendChild(ta)
          ta.style.position = 'absolute'
          ta.style.top = '0px'
          ta.style.left = '0px'
          ta.value = code
          ta.select()
          ta.focus()
          var result = document.execCommand('copy')
          document.body.removeChild(ta)
          
            if(result)$(this).text('复制成功')
            else $(this).text('复制失败')
          
          $(this).blur()
        })).on('mouseleave', function (e) {
          var $b = $(this).find('.copy-btn')
          setTimeout(function () {
            $b.text('复制')
          }, 300)
        }).append(e)
      })
    })
  </script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>



</body>
</html>
