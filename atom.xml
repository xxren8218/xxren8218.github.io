<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>X.X.Ren</title>
  
  <subtitle>个人博客</subtitle>
  <link href="https://xxren8218.github.io/atom.xml" rel="self"/>
  
  <link href="https://xxren8218.github.io/"/>
  <updated>2021-06-24T16:54:48.314Z</updated>
  <id>https://xxren8218.github.io/</id>
  
  <author>
    <name>任晓雄</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>21-MapReduce原理详解</title>
    <link href="https://xxren8218.github.io/20210625/21-MapReduce%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3.html"/>
    <id>https://xxren8218.github.io/20210625/21-MapReduce%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3.html</id>
    <published>2021-06-24T16:49:11.000Z</published>
    <updated>2021-06-24T16:54:48.314Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-MapReduce原理详解"><a href="#1-MapReduce原理详解" class="headerlink" title="1.MapReduce原理详解"></a>1.MapReduce原理详解</h3><p><strong>单机程序计算流程</strong></p><p>输入数据—-&gt;读取数据—-&gt;处理数据—-&gt;写入数据—-&gt;输出数据</p><p><strong>Hadoop计算流程</strong></p><p>input data：输入数据</p><p>InputFormat：对数据进行切分，格式化处理</p><p>map：将前面切分的数据做map处理(将数据进行分类，输出(k,v)键值对数据)</p><p>shuffle&amp;sort:将相同的数据放在一起，并对数据进行排序处理</p><p>reduce：将map输出的数据进行hash计算，对每个map数据进行统计计算</p><ul><li>hash的目的：如英文单词中y,z的单词开头比较少。再次词频统计时，少的统计完了，但是多的并没有进行统计完，少的需要等待。——hash能使得均匀的进行统计。</li></ul><p>OutputFormat：格式化输出数据</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625005045.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625005103.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625005121.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625005205.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625005240.png" alt=""></p><p>map：将数据进行处理</p><p>buffer in memory：达到80%数据时，将数据锁在内存上，将这部分输出到磁盘上</p><p>partitions：在磁盘上有很多”小的数据”，将这些数据进行归并排序。</p><p>merge on disk：将所有的”小的数据”进行合并。</p><p>reduce：不同的reduce任务，会从map中对应的任务中copy数据</p><p>​        在reduce中同样要进行merge操作</p><ul><li><p>MR慢的原因：内存和磁盘之间频繁的数据IO交换。基于当时限制，内存比较贵。</p><p>但是Spark是基于内存的计算，速度快很多。</p></li></ul><h3 id="2-MapReduce架构"><a href="#2-MapReduce架构" class="headerlink" title="2 MapReduce架构"></a>2 MapReduce架构</h3><ul><li>MapReduce架构 1.X（没有YARN之前，计算与分配都在一起。）<ul><li>JobTracker:负责接收客户作业提交，负责任务到作业节点上运行，检查作业的状态</li><li>TaskTracker：由JobTracker指派任务，定期向JobTracker汇报状态，在每一个工作节点上永远只会有一个TaskTracker</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625005406.png" alt=""></p><ul><li><p>MapReduce2.X架构</p><ul><li>ResourceManager：负责资源的管理，负责提交任务到NodeManager所在的节点运行，检查节点的状态</li><li>NodeManager：由ResourceManager指派任务，定期向ResourceManager汇报状态</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625005425.png" alt=""></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-MapReduce原理详解&quot;&gt;&lt;a href=&quot;#1-MapReduce原理详解&quot; class=&quot;headerlink&quot; title=&quot;1.MapReduce原理详解&quot;&gt;&lt;/a&gt;1.MapReduce原理详解&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;单机程序计算流程&lt;/</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>20-MapReduce实战——基于MRJob</title>
    <link href="https://xxren8218.github.io/20210625/20-MapReduce%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8EMRJob.html"/>
    <id>https://xxren8218.github.io/20210625/20-MapReduce%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8EMRJob.html</id>
    <published>2021-06-24T16:41:37.000Z</published>
    <updated>2021-06-24T16:43:51.781Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MapReduce实战"><a href="#MapReduce实战" class="headerlink" title="MapReduce实战"></a>MapReduce实战</h2><h3 id="1-利用MRJob编写和运行MapReduce代码"><a href="#1-利用MRJob编写和运行MapReduce代码" class="headerlink" title="1 利用MRJob编写和运行MapReduce代码"></a>1 利用MRJob编写和运行MapReduce代码</h3><p><strong>mrjob 简介</strong></p><ul><li>提出背景<ul><li>若要写MapReduce，一般也不会用hadoop streaming,它没有任何封装，是自己写脚本，通过指令上传。</li><li>实际上有很多步骤有优化的余地。——出现了MRJob的库</li></ul></li><li>使用python开发在Hadoop上运行的程序, mrjob是最简单的方式</li><li>mrjob程序可以在本地测试运行也可以部署到Hadoop集群上运行</li><li>如果不想成为hadoop专家, 但是需要利用Hadoop写MapReduce代码,mrJob是很好的选择</li><li>优点：<ul><li>如果涉及多个map和多个reduce，或上个MR的输出作为下一个MR的输入的话。若用hadoop-streaming，需要写多个脚本。而MRJob可以通过一个类对其进行解决。——MRStep。——应用：TOPN统计</li></ul></li></ul><p><strong>mrjob 安装</strong></p><ul><li>使用pip安装<ul><li>pip install mrjob</li></ul></li></ul><p><strong>mrjob实现WordCount</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MRWordFrequencyCount</span>(<span class="params">MRJob</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, _, line</span>):</span></span><br><span class="line">        <span class="comment"># 得到三个生成器，需next</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="string">&quot;chars&quot;</span>, <span class="built_in">len</span>(line)</span><br><span class="line">        <span class="keyword">yield</span> <span class="string">&quot;words&quot;</span>, <span class="built_in">len</span>(line.split())</span><br><span class="line">        <span class="keyword">yield</span> <span class="string">&quot;lines&quot;</span>, <span class="number">1</span></span><br><span class="line">        </span><br><span class="line"><span class="comment"># key 相同的会走到同一个reducer中</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span>(<span class="params">self, key, values</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> key, <span class="built_in">sum</span>(values)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    调用run以后，他会自己调用mapper,和reducer方法。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    MRWordFrequencyCount.run() </span><br></pre></td></tr></table></figure><ul><li>每个单词词频的统计。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MRWordCount</span>(<span class="params">MRJob</span>):</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 每一行从line中输入</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, key, line</span>):</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> line.split():</span><br><span class="line">            <span class="keyword">yield</span> word,<span class="number">1</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># word相同的 会走到同一个reduce</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span>(<span class="params">self, word, counts</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> word, <span class="built_in">sum</span>(counts)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    MRWordCount.run()</span><br></pre></td></tr></table></figure><p><strong>运行WordCount代码</strong></p><p>打开命令行, 找到一篇文本文档, 敲如下命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python mr_word_count.py my_file.txt</span><br></pre></td></tr></table></figure><h3 id="2-运行MRJOB的不同方式"><a href="#2-运行MRJOB的不同方式" class="headerlink" title="2 运行MRJOB的不同方式"></a>2 运行MRJOB的不同方式</h3><p>1、内嵌(-r inline)方式</p><p>特点是调试方便，启动单一进程模拟任务执行状态和结果，默认(-r inline)可以省略，输出文件使用 &gt; output-file 或-o output-file，比如下面两种运行方式是等价的</p><p>python word_count.py -r inline input.txt &gt; output.txt<br>python word_count.py input.txt &gt; output.txt</p><p>2、本地(-r local)方式</p><p>用于本地模拟Hadoop调试，与内嵌(inline)方式的区别是启动了多进程执行每一个任务。如：</p><p>python word_count.py -r local input.txt &gt; output1.txt</p><p>3、Hadoop(-r hadoop)方式</p><p>用于hadoop环境，支持Hadoop运行调度控制参数，如：</p><p>1)指定Hadoop任务调度优先级(VERY_HIGH|HIGH),如：—jobconf mapreduce.job.priority=VERY_HIGH。</p><p>2)Map及Reduce任务个数限制，如：—jobconf mapreduce.map.tasks=2  —jobconf mapreduce.reduce.tasks=5</p><p><strong>python word_count.py -r hadoop hdfs:///test.txt -o  hdfs:///output </strong></p><ul><li>要求输出的hadoop不能有内容——删掉output。</li></ul><p><strong>遇到的坑——code127错误</strong></p><p>在后面加 -python-bin /miniconda2/envs/py365/bin/python就行。因为在虚拟机运行为py3.x，而本机环境为2.x！</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625004312.PNG" alt=""></p><h3 id="3-mrjob-实现-topN统计（实验）"><a href="#3-mrjob-实现-topN统计（实验）" class="headerlink" title="3 mrjob 实现 topN统计（实验）"></a>3 mrjob 实现 topN统计（实验）</h3><ul><li>上个MR的输出作为下一个MR的输入的话。MRJob.MRStep</li></ul><p>统计数据中出现次数最多的前n个数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob,MRStep</span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TopNWords</span>(<span class="params">MRJob</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, _, line</span>):</span></span><br><span class="line">        <span class="keyword">if</span> line.strip() != <span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> line.strip().split():</span><br><span class="line">                <span class="keyword">yield</span> word,<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 介于mapper和reducer之间，用于临时的将mapper输出的数据进行统计</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combiner</span>(<span class="params">self, word, counts</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> word,<span class="built_in">sum</span>(counts)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer_sum</span>(<span class="params">self, word, counts</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> <span class="literal">None</span>,(<span class="built_in">sum</span>(counts),word) </span><br><span class="line">        <span class="comment"># key为None，只有value有值。</span></span><br><span class="line"><span class="comment"># 调换位置原因——后面的取最大的N个值是按key进行取值的。</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 利用heapq将数据进行排序，将最大的2个取出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">top_n_reducer</span>(<span class="params">self,_,word_cnts</span>):</span></span><br><span class="line">        <span class="keyword">for</span> cnt,word <span class="keyword">in</span> heapq.nlargest(<span class="number">2</span>,word_cnts):</span><br><span class="line">            <span class="keyword">yield</span> word,cnt <span class="comment"># 再调换一次。</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 实现steps方法用于指定自定义的mapper，comnbiner和reducer方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">steps</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 这里有两个MR。不过第二个没有mapper</span></span><br><span class="line">        <span class="keyword">return</span> [</span><br><span class="line">            MRStep(mapper=self.mapper,</span><br><span class="line">                   combiner=self.combiner,</span><br><span class="line">                   reducer=self.reducer_sum),</span><br><span class="line">            MRStep(reducer=self.top_n_reducer)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    TopNWords.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><ul><li>本地运行实例：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625004332.PNG" alt=""></p><h3 id="4-MRJOB-文件合并"><a href="#4-MRJOB-文件合并" class="headerlink" title="4 MRJOB 文件合并"></a>4 MRJOB 文件合并</h3><p><strong>需求描述</strong></p><ul><li>两个文件合并 类似于数据库中的两张表合并</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">uid uname</span><br><span class="line">01 user1 </span><br><span class="line">02 user2</span><br><span class="line">03 user3</span><br><span class="line">uid orderid order_price</span><br><span class="line">01   01     80</span><br><span class="line">01   02     90</span><br><span class="line">02   03    82</span><br><span class="line">02   04    95</span><br></pre></td></tr></table></figure><p><strong>mrjob 实现</strong></p><p>实现对两个数据表进行join操作，显示效果为每个用户的所有订单信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;01:user1&quot;&quot;01:80,02:90&quot;</span><br><span class="line">&quot;02:user2&quot;&quot;03:82,04:95&quot;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserOrderJoin</span>(<span class="params">MRJob</span>):</span></span><br><span class="line">    SORT_VALUES = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 二次排序参数：http://mrjob.readthedocs.io/en/latest/job.html</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, _, line</span>):</span></span><br><span class="line">        fields = line.strip().split(<span class="string">&#x27;\t&#x27;</span>) <span class="comment"># 用制表符进行拆分</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(fields) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># user data</span></span><br><span class="line">            source = <span class="string">&#x27;A&#x27;</span></span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            user_name = fields[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">yield</span>  user_id,[source,user_name] <span class="comment"># 01 [A,user1]</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(fields) == <span class="number">3</span>:</span><br><span class="line">            <span class="comment"># order data</span></span><br><span class="line">            source =<span class="string">&#x27;B&#x27;</span></span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            order_id = fields[<span class="number">1</span>]</span><br><span class="line">            price = fields[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">yield</span> user_id,[source,order_id,price] <span class="comment">#01 [&#x27;B&#x27;,01,80][&#x27;B&#x27;,02,90]</span></span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span>(<span class="params">self,user_id,values</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        每个用户的订单列表</span></span><br><span class="line"><span class="string">        &quot;01:user1&quot;&quot;01:80,02:90&quot;</span></span><br><span class="line"><span class="string">        &quot;02:user2&quot;&quot;03:82,04:95&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param user_id:</span></span><br><span class="line"><span class="string">        :param values:[A,user1]  [&#x27;B&#x27;,01,80]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        values = [v <span class="keyword">for</span> v <span class="keyword">in</span> values]  <span class="comment"># 加了 &quot;A&quot;&quot;&quot;B&quot;以后保证先过来的是两个元素值。</span></span><br><span class="line">          <span class="comment"># 首行SORT_VALUES = True</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(values)&gt;<span class="number">1</span> :</span><br><span class="line">            user_name = values[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">            order_info = [<span class="string">&#x27;:&#x27;</span>.join([v[<span class="number">1</span>],v[<span class="number">2</span>]]) <span class="keyword">for</span> v <span class="keyword">in</span> values[<span class="number">1</span>:]] <span class="comment">#[01:80,02:90]</span></span><br><span class="line">            <span class="keyword">yield</span> <span class="string">&#x27;:&#x27;</span>.join([user_id,user_name]),<span class="string">&#x27;,&#x27;</span>.join(order_info)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    UserOrderJoin.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>实现对两个数据表进行join操作，显示效果为每个用户所下订单的订单总量和累计消费金额</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;01:user1&quot;[2, 170]</span><br><span class="line">&quot;02:user2&quot;[2, 177]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mrjob.job <span class="keyword">import</span> MRJob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserOrderJoin</span>(<span class="params">MRJob</span>):</span></span><br><span class="line">    <span class="comment"># 二次排序参数：http://mrjob.readthedocs.io/en/latest/job.html</span></span><br><span class="line">    SORT_VALUES = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mapper</span>(<span class="params">self, _, line</span>):</span></span><br><span class="line">        fields = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(fields) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># user data</span></span><br><span class="line">            source = <span class="string">&#x27;A&#x27;</span> </span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            user_name = fields[<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">yield</span>  user_id,[source,user_name]</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(fields) == <span class="number">3</span>:</span><br><span class="line">            <span class="comment"># order data</span></span><br><span class="line">            source =<span class="string">&#x27;B&#x27;</span></span><br><span class="line">            user_id = fields[<span class="number">0</span>]</span><br><span class="line">            order_id = fields[<span class="number">1</span>]</span><br><span class="line">            price = fields[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">yield</span> user_id,[source,order_id,price]</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reducer</span>(<span class="params">self,user_id,values</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        统计每个用户的订单数量和累计消费金额</span></span><br><span class="line"><span class="string">        :param user_id:</span></span><br><span class="line"><span class="string">        :param values:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        values = [v <span class="keyword">for</span> v <span class="keyword">in</span> values]</span><br><span class="line">        user_name = <span class="literal">None</span></span><br><span class="line">        order_cnt = <span class="number">0</span></span><br><span class="line">        order_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(values)&gt;<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> values:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(v) ==  <span class="number">2</span> :</span><br><span class="line">                    user_name = v[<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">len</span>(v) == <span class="number">3</span>:</span><br><span class="line">                    order_cnt += <span class="number">1</span></span><br><span class="line">                    order_sum += <span class="built_in">int</span>(v[<span class="number">2</span>])</span><br><span class="line">            <span class="keyword">yield</span> <span class="string">&quot;:&quot;</span>.join([user_id,user_name]),(order_cnt,order_sum)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    UserOrderJoin().run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;MapReduce实战&quot;&gt;&lt;a href=&quot;#MapReduce实战&quot; class=&quot;headerlink&quot; title=&quot;MapReduce实战&quot;&gt;&lt;/a&gt;MapReduce实战&lt;/h2&gt;&lt;h3 id=&quot;1-利用MRJob编写和运行MapReduce代码&quot;&gt;&lt;a</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>05-动态规划之高楼扔鸡蛋进阶版</title>
    <link href="https://xxren8218.github.io/20210625/05-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E9%AB%98%E6%A5%BC%E6%89%94%E9%B8%A1%E8%9B%8B%E8%BF%9B%E9%98%B6%E7%89%88.html"/>
    <id>https://xxren8218.github.io/20210625/05-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E9%AB%98%E6%A5%BC%E6%89%94%E9%B8%A1%E8%9B%8B%E8%BF%9B%E9%98%B6%E7%89%88.html</id>
    <published>2021-06-24T16:36:48.000Z</published>
    <updated>2021-06-24T16:40:09.855Z</updated>
    
    <content type="html"><![CDATA[<h2 id="动态规划之高楼扔鸡蛋（进阶）"><a href="#动态规划之高楼扔鸡蛋（进阶）" class="headerlink" title="动态规划之高楼扔鸡蛋（进阶）"></a>动态规划之高楼扔鸡蛋（进阶）</h2><p>前面一篇文章的所讲的动态规划的效率不是饿很高，在力扣的用例通过率50%左右。但是是较为容易理解的动态规划解法。今天来讲两种思路，来优化一下这个问题。分别是  <code>二分查找优化</code>  和  <code>重新定义状态转移</code></p><p>二分搜索的优化思路也许是我们可以尽力尝试写出的，而修改状态转移的解法可能是不容易想到的，可以借此见识一下动态规划算法设计的玄妙，当做思维拓展。</p><blockquote><h3 id="一、二分搜索优化"><a href="#一、二分搜索优化" class="headerlink" title="一、二分搜索优化"></a>一、二分搜索优化</h3></blockquote><p>之前提到过这个解法，核心是因为状态转移方程的单调性，这里可以具体展开看看。</p><p>题目要求最坏情况下至少需要扔几次鸡蛋才能测出鸡蛋恰好摔不碎的楼层<code>F</code>。首先简述一下原始动态规划的思路：</p><p><strong>1</strong>、暴力穷举尝试在所有楼层<code>1 &lt;= i &lt;= N</code>扔鸡蛋，每次选择尝试次数<strong>最少</strong>的那一层；</p><p><strong>2</strong>、每次扔鸡蛋有两种可能，要么碎，要么没碎；</p><p><strong>3</strong>、如果鸡蛋碎了，<code>F</code>应该在第<code>i</code>层下面，否则，<code>F</code>应该在第<code>i</code>层上面；</p><p><strong>4</strong>、鸡蛋是碎了还是没碎，取决于哪种情况下尝试次数<strong>更多</strong>，因为我们想求的是最坏情况下的结果。</p><p>核心的状态转移代码是这段：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当前状态为 K 个鸡蛋，面对 N 层楼</span></span><br><span class="line"><span class="comment"># 返回这个状态下的最优结果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">K, N</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, N):</span><br><span class="line">        <span class="comment"># 最坏情况下的最少扔鸡蛋次数</span></span><br><span class="line">        res = <span class="built_in">min</span>(res, </span><br><span class="line">                  <span class="built_in">max</span>( </span><br><span class="line">                        dp(K - <span class="number">1</span>, i - <span class="number">1</span>), <span class="comment"># 碎</span></span><br><span class="line">                        dp(K, N - i)      <span class="comment"># 没碎</span></span><br><span class="line">                     ) + <span class="number">1</span> <span class="comment"># 在第 i 楼扔了一次</span></span><br><span class="line">                 )</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>这个 for 循环就是下面这个状态转移方程的具体代码实现：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625003842.jpg" alt=""></p><p>如果能够理解这个状态转移方程，那么就很容易理解二分查找的优化思路。</p><p>首先我们根据<code>dp(K, N)</code>数组的定义（有<code>K</code>个鸡蛋面对<code>N</code>层楼，最少需要扔 dp(K, N) 次），<strong>很容易知道<code>K</code>固定时，这个函数随着<code>N</code>的增加一定是单调递增的</strong>，无论你策略多聪明，楼层增加的话，测试次数一定要增加。</p><p>那么注意<code>dp(K - 1, i - 1)</code>和<code>dp(K, N - i)</code>这两个函数，其中<code>i</code>是从 1 到<code>N</code>单增的，如果我们固定<code>K</code>和<code>N</code>，<strong>把这两个函数看做关于<code>i</code>的函数，前者随着<code>i</code>的增加应该也是单调递增的，而后者随着<code>i</code>的增加应该是单调递减的</strong>：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625003902.jpg" alt=""></p><p>这时候求二者的较大值，再求这些最大值之中的最小值，其实就是求这两条直线交点，也就是红色折线的最低点嘛。</p><p>二分查找的运用很广泛，形如下面这种形式的 for 循环代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">if</span> (isOK(i)):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> i</span><br></pre></td></tr></table></figure><p>都很有可能可以运用二分查找来优化线性搜索的复杂度，回顾这两个<code>dp</code>函数的曲线，我们要找的最低点其实就是这种情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, N)</span><br><span class="line">    <span class="keyword">if</span> dp(K - <span class="number">1</span>, i - <span class="number">1</span>) == dp(K, N - i):</span><br><span class="line">        <span class="keyword">return</span> dp(K, N - i);</span><br></pre></td></tr></table></figure><p>熟悉二分搜索的同学肯定敏感地想到了，这不就是相当于求 Valley（山谷）值嘛，可以用二分查找来快速寻找这个点的，直接看代码吧，整体的思路还是一样，只是加快了搜索速度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">superEggDrop</span>(<span class="params">self, K: <span class="built_in">int</span>, N: <span class="built_in">int</span></span>) -&gt; int:</span></span><br><span class="line"></span><br><span class="line">    memo = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">K, N</span>):</span></span><br><span class="line">        <span class="keyword">if</span> K == <span class="number">1</span>: <span class="keyword">return</span> N</span><br><span class="line">        <span class="keyword">if</span> N == <span class="number">0</span>: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> (K, N) <span class="keyword">in</span> memo:</span><br><span class="line">            <span class="keyword">return</span> memo[(K, N)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># for 1 &lt;= i &lt;= N:</span></span><br><span class="line">        <span class="comment">#     res = min(res, </span></span><br><span class="line">        <span class="comment">#             max( </span></span><br><span class="line">        <span class="comment">#                 dp(K - 1, i - 1), </span></span><br><span class="line">        <span class="comment">#                 dp(K, N - i)      </span></span><br><span class="line">        <span class="comment">#                 ) + 1 </span></span><br><span class="line">        <span class="comment">#             )</span></span><br><span class="line"></span><br><span class="line">        res = <span class="built_in">float</span>(<span class="string">&#x27;INF&#x27;</span>)</span><br><span class="line">        <span class="comment"># 用二分搜索代替线性搜索</span></span><br><span class="line">        low, high = <span class="number">1</span>, N</span><br><span class="line">        <span class="keyword">while</span> low &lt;= high:</span><br><span class="line">            mid = (low + high) // <span class="number">2</span></span><br><span class="line">            broken = dp(K - <span class="number">1</span>, mid - <span class="number">1</span>) <span class="comment"># 碎</span></span><br><span class="line">            not_broken = dp(K, N - mid) <span class="comment"># 没碎</span></span><br><span class="line">            <span class="comment"># res = min(max(碎，没碎) + 1)</span></span><br><span class="line">            <span class="keyword">if</span> broken &gt; not_broken:</span><br><span class="line">                high = mid - <span class="number">1</span></span><br><span class="line">                res = <span class="built_in">min</span>(res, broken + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                low = mid + <span class="number">1</span></span><br><span class="line">                res = <span class="built_in">min</span>(res, not_broken + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        memo[(K, N)] = res</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp(K, N)</span><br></pre></td></tr></table></figure><p>这个算法的时间复杂度是多少呢？<strong>动态规划算法的时间复杂度就是子问题个数 × 函数本身的复杂度</strong>。</p><p>函数本身的复杂度就是忽略递归部分的复杂度，这里<code>dp</code>函数中用了一个二分搜索，所以函数本身的复杂度是 O(logN)。</p><p>子问题个数也就是不同状态组合的总数，显然是两个状态的乘积，也就是 O(KN)。</p><p>所以算法的总时间复杂度是 O(K<em>N</em>logN), 空间复杂度 O(KN)。效率上比之前的算法 O(KN^2) 要高效不少。</p><blockquote><h3 id="二、重写状态转移"><a href="#二、重写状态转移" class="headerlink" title="二、重写状态转移"></a>二、重写状态转移</h3></blockquote><p>找动态规划的状态转移本就是见仁见智，比较玄学的事情。不同的状态定义可以衍生出不同的解法，其解法和复杂程度都可能有巨大差异。这里就是一个很好的例子。</p><p>再回顾一下我们之前定义的<code>dp</code>数组含义：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">k, n</span>) -&gt; int</span></span><br><span class="line"><span class="function"># 当前状态为 k 个鸡蛋，面对 n 层楼</span></span><br><span class="line"><span class="function"># 返回这个状态下最少的扔鸡蛋次数</span></span><br></pre></td></tr></table></figure><p>用 dp 数组表示的话也是一样的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dp[k][n] = m</span><br><span class="line"><span class="comment"># 当前状态为 k 个鸡蛋，面对 n 层楼</span></span><br><span class="line"><span class="comment"># 这个状态下最少的扔鸡蛋次数为 m</span></span><br></pre></td></tr></table></figure><p>按照这个定义，就是<strong>确定当前的鸡蛋个数和面对的楼层数，就知道最小扔鸡蛋次数</strong>。最终我们想要的答案就是<code>dp(K, N)</code>的结果。</p><p>这种思路下，肯定要穷举所有可能的扔法的，用二分搜索优化也只是做了「剪枝」，减小了搜索空间，但本质思路没有变，只不过是更聪明的穷举。</p><p>现在，我们稍微修改<code>dp</code>数组的定义，<strong>确定当前的鸡蛋个数和最多允许的扔鸡蛋次数，就知道能够确定<code>F</code>的最高楼层数</strong>。</p><p>有点绕口，具体来说是这个意思：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dp[k][m] = n</span><br><span class="line"><span class="comment"># 当前有 k 个鸡蛋，可以尝试扔 m 次鸡蛋</span></span><br><span class="line"><span class="comment"># 这个状态下，最坏情况下最多能确切测试一栋 n 层的楼</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 比如说 dp[1][7] = 7 表示：</span></span><br><span class="line"><span class="comment"># 现在有 1 个鸡蛋，允许你扔 7 次;</span></span><br><span class="line"><span class="comment"># 这个状态下最多给你 7 层楼，</span></span><br><span class="line"><span class="comment"># 使得你可以确定楼层 F 使得鸡蛋恰好摔不碎</span></span><br><span class="line"><span class="comment"># （一层一层线性探查嘛）</span></span><br></pre></td></tr></table></figure><p>这其实就是我们原始思路的一个「反向」版本，我们先不管这种思路的状态转移怎么写，先来思考一下这种定义之下，最终想求的答案是什么？</p><p>我们最终要求的其实是扔鸡蛋次数<code>m</code>，但是这时候<code>m</code>在状态之中而不是<code>dp</code>数组的结果，可以这样处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">superEggDrop</span>(<span class="params">K, N</span>):</span></span><br><span class="line">    m = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> dp[K][m] &lt; N </span><br><span class="line">        m += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 状态转移...</span></span><br><span class="line">    <span class="keyword">return</span> m;</span><br></pre></td></tr></table></figure><p>题目不是<strong>给你<code>K</code>鸡蛋，<code>N</code>层楼，让你求最坏情况下最少的测试次数<code>m</code></strong> 吗？<code>while</code>循环结束的条件是<code>dp[K][m] == N</code>，也就是<strong>给你<code>K</code>个鸡蛋，允许测试<code>m</code>次，最坏情况下最多能测试<code>N</code>层楼</strong>。</p><p>注意看这两段描述，是完全一样的！所以说这样组织代码是正确的，关键就是状态转移方程怎么找呢？还得从我们原始的思路开始讲。之前的解法配了这样图帮助大家理解状态转移思路：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625003925.jpg" alt=""></p><p>这个图描述的仅仅是某一个楼层<code>i</code>，原始解法还得线性或者二分扫描所有楼层，要求最大值、最小值。但是现在这种<code>dp</code>定义根本不需要这些了，基于下面两个事实：</p><p><strong>1、无论你在哪层楼扔鸡蛋，鸡蛋只可能摔碎或者没摔碎，碎了的话就测楼下，没碎的话就测楼上</strong>。</p><p><strong>2、无论你上楼还是下楼，总的楼层数 = 楼上的楼层数 + 楼下的楼层数 + 1（当前这层楼）</strong>。</p><p>根据这个特点，可以写出下面的状态转移方程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dp[k][m] = dp[k][m-<span class="number">1</span>] + dp[k-<span class="number">1</span>][m-<span class="number">1</span>] + <span class="number">1</span></span><br></pre></td></tr></table></figure><p><strong><code>dp[k][m - 1]</code>就是楼上的楼层数</strong>，因为鸡蛋个数<code>k</code>不变，也就是鸡蛋没碎，扔鸡蛋次数<code>m</code>减一；</p><p><strong><code>dp[k - 1][m - 1]</code>就是楼下的楼层数</strong>，因为鸡蛋个数<code>k</code>减一，也就是鸡蛋碎了，同时扔鸡蛋次数<code>m</code>减一。</p><p>PS：这个<code>m</code>为什么要减一而不是加一？之前定义得很清楚，这个<code>m</code>是一个允许的次数上界，而不是扔了几次。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210625003951.jpg" alt=""></p><p>至此，整个思路就完成了，只要把状态转移方程填进框架即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">superEggDrop</span>(<span class="params">K, N</span>):</span></span><br><span class="line">    <span class="comment"># m 最多不会超过 N 次（线性扫描）</span></span><br><span class="line">    dp = [[<span class="number">0</span>]*(N + <span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K + <span class="number">1</span>)]</span><br><span class="line">    <span class="comment"># base case:</span></span><br><span class="line">    <span class="comment"># dp[0][..] = 0</span></span><br><span class="line">    <span class="comment"># dp[..][0] = 0</span></span><br><span class="line">    m = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> dp[K][m] &lt; N:</span><br><span class="line">        m += <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, K):</span><br><span class="line">            dp[k][m] = dp[k][m - <span class="number">1</span>] + dp[k - <span class="number">1</span>][m - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> m</span><br></pre></td></tr></table></figure><p>如果你还觉得这段代码有点难以理解，其实它就等同于这样写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, dp[K][m] &lt; N):</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, K):</span><br><span class="line">        dp[k][m] = dp[k][m - <span class="number">1</span>] + dp[k - <span class="number">1</span>][m - <span class="number">1</span>] + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>看到这种代码形式就熟悉多了吧，因为我们要求的不是<code>dp</code>数组里的值，而是某个符合条件的索引<code>m</code>，所以用<code>while</code>循环来找到这个<code>m</code>而已。</p><p>这个算法的时间复杂度是多少？很明显就是两个嵌套循环的复杂度 O(KN)。</p><p>另外注意到<code>dp[m][k]</code>转移只和左边和左上的两个状态有关，所以很容易优化成一维<code>dp</code>数组，这里就不写了。</p><blockquote><h3 id="三、进一步思考"><a href="#三、进一步思考" class="headerlink" title="三、进一步思考"></a>三、进一步思考</h3></blockquote><p>再往下就要用一些数学方法了，不具体展开，就简单提一下思路吧。</p><p>在刚才的思路之上，<strong>注意函数<code>dp(m, k)</code>是随着<code>m</code>单增的，因为鸡蛋个数<code>k</code>不变时，允许的测试次数越多，可测试的楼层就越高。</strong></p><p>这里又可以借助二分搜索算法快速逼近<code>dp[K][m] == N</code>这个终止条件，时间复杂度进一步下降为 O(KlogN)，我们可以设<code>g(k,m)</code>等于……</p><p>算了算了，打住吧。我觉得我们能够写出 O(K<em>N</em>logN) 的二分优化算法就行了，后面的这些解法呢，听个响鼓个掌就行了，把欲望限制在能力的范围之内才能拥有快乐！</p><p>不过可以肯定的是，根据二分搜索代替线性扫描 m 的取值，代码的大致框架肯定是修改穷举 m 的 for 循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把线性搜索改成二分搜索</span></span><br><span class="line"><span class="comment"># for m in range(1, dp[K][m] &lt; N):</span></span><br><span class="line">low, high = <span class="number">1</span>, N</span><br><span class="line"><span class="keyword">while</span> low &lt; high:</span><br><span class="line">    mid = (low + high) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> ... &lt; N:</span><br><span class="line">        low = ...</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        high = ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, K):</span><br><span class="line">        <span class="comment"># 状态转移方程</span></span><br></pre></td></tr></table></figure><p>简单总结一下吧，<strong>第一个二分优化是利用了<code>dp</code>函数的单调性</strong>，用二分查找技巧快速搜索答案；<strong>第二种优化是巧妙地修改了状态转移方程</strong>，简化了求解了流程，但相应的，解题逻辑比较难以想到；</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;动态规划之高楼扔鸡蛋（进阶）&quot;&gt;&lt;a href=&quot;#动态规划之高楼扔鸡蛋（进阶）&quot; class=&quot;headerlink&quot; title=&quot;动态规划之高楼扔鸡蛋（进阶）&quot;&gt;&lt;/a&gt;动态规划之高楼扔鸡蛋（进阶）&lt;/h2&gt;&lt;p&gt;前面一篇文章的所讲的动态规划的效率不是饿很高</summary>
      
    
    
    
    <category term="动态规划" scheme="https://xxren8218.github.io/categories/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
  </entry>
  
  <entry>
    <title>19-hadoop之YARN &amp; MapReduce</title>
    <link href="https://xxren8218.github.io/20210623/19-hadoop%E4%B9%8BYARN-MapReduce.html"/>
    <id>https://xxren8218.github.io/20210623/19-hadoop%E4%B9%8BYARN-MapReduce.html</id>
    <published>2021-06-23T04:50:39.000Z</published>
    <updated>2021-06-24T16:45:55.515Z</updated>
    
    <content type="html"><![CDATA[<h1 id="YARN-amp-MapReduce"><a href="#YARN-amp-MapReduce" class="headerlink" title="YARN&amp;MapReduce"></a>YARN&amp;MapReduce</h1><p>掌握目标：</p><ul><li>了解YARN概念和产生背景</li><li>了解MapReduce概念</li><li>说出YARN执行流程</li><li>说出MapReduce原理</li><li>独立完成Mrjob实现wordcount</li><li>完成提交作业到YARN上执行</li></ul><h2 id="1-资源调度框架-YARN"><a href="#1-资源调度框架-YARN" class="headerlink" title="1.资源调度框架 YARN"></a>1.资源调度框架 YARN</h2><h3 id="1-1-什么是YARN"><a href="#1-1-什么是YARN" class="headerlink" title="1.1 什么是YARN"></a>1.1 什么是YARN</h3><ul><li>Yet Another Resource Negotiator, 另一种资源协调者</li><li>通用资源管理系统</li><li>为上层应用提供统一的资源管理和调度，为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处</li></ul><h3 id="1-2-YARN产生背景"><a href="#1-2-YARN产生背景" class="headerlink" title="1.2 YARN产生背景"></a>1.2 YARN产生背景</h3><ul><li><p>通用资源管理系统</p><ul><li>Hadoop数据分布式存储（数据分块，冗余存储）</li><li>当多个MapReduce任务要用到相同的hdfs数据， 需要进行资源调度管理</li><li>Hadoop1.x时并没有YARN，MapReduce 既负责进行计算作业又处理服务器集群资源调度管理</li></ul></li><li><p>服务器集群资源调度管理和MapReduce执行过程耦合在一起带来的问题</p><ul><li><p>Hadoop早期, 技术只有Hadoop, 这个问题不明显</p></li><li><p>随着大数据技术的发展，Spark Storm … 计算框架都要用到服务器集群资源 </p></li><li><p>如果没有通用资源管理系统，只能为多个集群分别提供数据</p><ul><li>资源利用率低 运维成本高</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125202.png" alt=""></p></li><li><p>Yarn (Yet Another Resource Negotiator) 另一种资源调度器</p><ul><li>Mesos 大数据资源管理产品</li></ul></li></ul></li><li><p>不同计算框架可以共享同一个HDFS集群上的数据，享受整体的资源调度</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125235.png" alt=""></p></li></ul><h3 id="1-3-YARN的架构和执行流程"><a href="#1-3-YARN的架构和执行流程" class="headerlink" title="1.3 YARN的架构和执行流程"></a>1.3 YARN的架构和执行流程</h3><ul><li>ResourceManager: RM 资源管理器<br>​    整个集群同一时间提供服务的RM只有一个，负责集群资源的统一管理和调度<br>​    处理客户端的请求： submit, kill<br>​    监控我们的NM，一旦某个NM挂了，那么该NM上运行的任务需要告诉我们的AM来如何进行处理</li><li>NodeManager: NM 节点管理器<br>​    整个集群中有多个，负责自己本身节点资源管理和使用<br>​    定时向RM汇报本节点的资源使用情况<br>​    接收并处理来自RM的各种命令：启动Container<br>​    处理来自AM的命令</li><li>ApplicationMaster: AM<br>​    每个应用程序对应一个：MR、Spark，负责应用程序的管理<br>​    为应用程序向RM申请资源（core、memory），分配给内部task<br>​    需要与NM通信：启动/停止task，task是运行在container里面，AM也是运行在container里面</li><li>Container 容器: 封装了CPU、Memory等资源的一个容器,是一个任务运行环境的抽象</li><li>Client: 提交作业 查询作业的运行进度,杀死作业</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125255.png" alt=""></p><p>1，Client提交作业请求</p><p>2，ResourceManager 进程和 NodeManager 进程通信，根据集群资源，为用户程序分配第一个Container(容器)，并将 ApplicationMaster 分发到这个容器上面</p><p>3，在启动的Container中创建ApplicationMaster</p><p>4，ApplicationMaster启动后向ResourceManager注册进程,申请资源</p><p>5，ApplicationMaster申请到资源后，向对应的NodeManager申请启动Container,将要执行的程序分发到NodeManager上</p><p>6，Container启动后，执行对应的任务</p><p>7，Tast执行完毕之后，向ApplicationMaster返回结果</p><p>8，ApplicationMaster向ResourceManager汇报任务结束。 请求kill</p><h3 id="1-4-YARN环境搭建"><a href="#1-4-YARN环境搭建" class="headerlink" title="1.4 YARN环境搭建"></a>1.4 YARN环境搭建</h3><p>1）mapred-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>2）yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>3) 启动YARN相关的进程<br>sbin/start-yarn.sh</p><p>4）验证<br>​    jps<br>​        ResourceManager<br>​        NodeManager<br>​    <a href="http://192,168.19.137:8088">http://192,168.19.137:8088</a></p><p>5）停止YARN相关的进程<br>​    sbin/stop-yarn.sh</p><h2 id="2-分布式处理框架-MapReduce"><a href="#2-分布式处理框架-MapReduce" class="headerlink" title="2.分布式处理框架 MapReduce"></a>2.分布式处理框架 MapReduce</h2><h3 id="2-1-什么是MapReduce"><a href="#2-1-什么是MapReduce" class="headerlink" title="2.1 什么是MapReduce"></a>2.1 什么是MapReduce</h3><ul><li>源于Google的MapReduce论文(2004年12月)</li><li>Hadoop的MapReduce是Google论文的开源实现</li><li>MapReduce优点: 海量数据离线处理&amp;易开发</li><li>MapReduce缺点: 不能实时流式计算</li></ul><h3 id="2-2-MapReduce编程模型"><a href="#2-2-MapReduce编程模型" class="headerlink" title="2.2 MapReduce编程模型"></a>2.2 MapReduce编程模型</h3><ul><li><p>MapReduce分而治之的思想</p><ul><li>数钱实例：一堆钞票，各种面值分别是多少<ul><li>单点策略<ul><li>一个人数所有的钞票，数出各种面值有多少张</li></ul></li><li>分治策略<ul><li>每个人分得一堆钞票，数出各种面值有多少张</li><li>汇总，每个人负责统计一种面值</li></ul></li><li>解决数据可以切割进行计算的应用</li></ul></li></ul></li><li><p>MapReduce编程分Map和Reduce阶段——还是过于简单了（相比于Spark,不能进行求平均操作，得自己写。）</p><ul><li>将作业拆分成Map阶段和Reduce阶段</li><li>Map阶段 Map Tasks 分：把复杂的问题分解为若干”简单的任务”</li><li>Reduce阶段: Reduce Tasks 合：reduce</li></ul></li><li><p>MapReduce编程执行步骤</p><ul><li>准备MapReduce的输入数据</li><li>准备Mapper数据，进行Mapper操作</li><li>Shuffle</li><li>Reduce处理</li><li>结果输出</li></ul></li><li><p><strong>编程模型</strong></p></li><li><p>借鉴函数式编程方式</p></li><li><p>用户只需要实现两个函数接口：</p><ul><li><p>Map(in_key,in_value)</p><p>—-&gt;(out_key,intermediate_value) list</p></li><li><p>Reduce(out_key,intermediate_value) list</p><p>—-&gt;out_value list</p></li></ul></li><li><p>Word Count 词频统计案例</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125322.png" alt=""></p></li></ul><h3 id="2-3-Hadoop-Streaming-实现wordcount"><a href="#2-3-Hadoop-Streaming-实现wordcount" class="headerlink" title="2.3 Hadoop Streaming 实现wordcount"></a>2.3 Hadoop Streaming 实现wordcount</h3><ul><li><p>提供了python的API，写完以后翻译成java去执行的。——此处用了虚拟环境（source activate py365）</p><ul><li>Mapper</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入为标准输入stdin</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="comment"># 删除开头和结尾的空行</span></span><br><span class="line">    line = line.strip()</span><br><span class="line">    <span class="comment"># 以默认空格分隔单词到words列表</span></span><br><span class="line">    words = line.split()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="comment"># 输出所有单词，格式为“单词 1”以便作为Reduce的输入</span></span><br><span class="line">        print(<span class="string">&quot;%s %s&quot;</span>%(word,<span class="number">1</span>))</span><br></pre></td></tr></table></figure><ul><li>Reducer</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">current_count = <span class="number">0</span></span><br><span class="line">word = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取标准输入，即mapper.py的标准输出</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    <span class="comment"># 删除开头和结尾的空行</span></span><br><span class="line">    line = line.strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解析mapper.py输出作为程序的输入，以tab作为分隔符</span></span><br><span class="line">    word, count = line.split()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 转换count从字符型到整型</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        count = <span class="built_in">int</span>(count)</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="comment"># count非数字时，忽略此行</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 要求mapper.py的输出做排序（sort）操作，以便对连续的word做判断</span></span><br><span class="line">    <span class="keyword">if</span> current_word == word:</span><br><span class="line">        current_count += count</span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="comment"># 出现了一个新词</span></span><br><span class="line">        <span class="comment"># 输出当前word统计结果到标准输出</span></span><br><span class="line">        <span class="keyword">if</span> current_word :</span><br><span class="line">            print(<span class="string">&#x27;%s\t%s&#x27;</span> % (current_word, current_count))</span><br><span class="line">        <span class="comment"># 开始对新词的统计</span></span><br><span class="line">        current_count = count</span><br><span class="line">        current_word = word</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最后一个word统计</span></span><br><span class="line"><span class="keyword">if</span> current_word == word:</span><br><span class="line">    print(<span class="string">&quot;%s\t%s&quot;</span>% (current_word, current_count))</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>本地实现</p><p>​     <code>cat xxx.txt</code>|<code>python3 map.py</code>|<code>sort|python3 red.py</code></p><p>得到最终的输出</p><p><strong>注：hadoop-streaming会主动将map的输出数据进行字典排序</strong></p></li></ul><ul><li><p>通过Hadoop Streaming 提交作业到Hadoop集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">STREAM_JAR_PATH=&quot;/root/bigdata/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.9.1.jar&quot;    # hadoop streaming jar包所在位置</span><br><span class="line">INPUT_FILE_PATH_1=&quot;/The_Man_of_Property.txt&quot;  #要进行词频统计的文档在hdfs中的路径</span><br><span class="line">OUTPUT_PATH=&quot;/output&quot;                         #MR作业后结果的存放路径</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r -skipTrash $OUTPUT_PATH    #输出路径如果之前存在 先删掉否则会报错</span><br><span class="line"></span><br><span class="line">hadoop jar $STREAM_JAR_PATH \   </span><br><span class="line">-input $INPUT_FILE_PATH_1 \ # 指定输入文件位置</span><br><span class="line">-output $OUTPUT_PATH \      #指定输出结果位置</span><br><span class="line">-mapper &quot;python map.py&quot; \   #指定mapper执行的程序</span><br><span class="line">-reducer &quot;python red.py&quot; \  #指定reduce阶段执行的程序</span><br><span class="line">-file ./map.py \            #通过-file 把python源文件分发到集群的每一台机器上  </span><br><span class="line">-file ./red.py</span><br></pre></td></tr></table></figure></li><li><p>到Hadoop集群查看运行结果</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125354.png" alt=""></p><h3 id="文档说明"><a href="#文档说明" class="headerlink" title="文档说明"></a>文档说明</h3></li><li><p>对于java而言，.java编译-&gt;.class文件（多个打包）-&gt;.jar-&gt; 在JVM虚拟机上运行。对于JVM而言，.jar是其可执行文件。相当于windows的.exe。</p></li><li><p>通过hadoop-streaming-2.9.1.ja可执行文件将python的可执行文件翻译成java。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125413.PNG" alt=""></p><p>结果如图</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125427.PNG" alt=""></p><h2 id="注意！"><a href="#注意！" class="headerlink" title="注意！"></a>注意！</h2><p>得开启YARN才可以</p><p>也可以去YARN去看：端口号8088</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210623125443.PNG" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;YARN-amp-MapReduce&quot;&gt;&lt;a href=&quot;#YARN-amp-MapReduce&quot; class=&quot;headerlink&quot; title=&quot;YARN&amp;amp;MapReduce&quot;&gt;&lt;/a&gt;YARN&amp;amp;MapReduce&lt;/h1&gt;&lt;p&gt;掌握目标：&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>04-动态规划之高楼扔鸡蛋</title>
    <link href="https://xxren8218.github.io/20210622/04-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E9%AB%98%E6%A5%BC%E6%89%94%E9%B8%A1%E8%9B%8B.html"/>
    <id>https://xxren8218.github.io/20210622/04-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B%E9%AB%98%E6%A5%BC%E6%89%94%E9%B8%A1%E8%9B%8B.html</id>
    <published>2021-06-22T10:24:57.000Z</published>
    <updated>2021-06-22T11:26:11.752Z</updated>
    
    <content type="html"><![CDATA[<h2 id="动态规划之高楼扔鸡蛋"><a href="#动态规划之高楼扔鸡蛋" class="headerlink" title="动态规划之高楼扔鸡蛋"></a>动态规划之高楼扔鸡蛋</h2><p>今天要聊一个很经典的算法问题，若干层楼，若干个鸡蛋，让你算出最少的尝试次数，找到鸡蛋恰好摔不碎的那层楼。国内大厂以及谷歌脸书面试都经常考察这道题，只不过他们觉得扔鸡蛋太浪费，改成扔杯子，扔破碗什么的。</p><p>具体的问题等会再说，但是这道题的解法技巧很多，光动态规划就好几种效率不同的思路，最后还有一种极其高效数学解法。秉承我们一贯的作风，拒绝奇技淫巧，拒绝过于诡异的技巧，因为这些技巧无法举一反三，学了不太划算。</p><p>下面就来用我们一直强调的动态规划通用思路来研究一下这道题。</p><blockquote><h3 id="一、解析题目"><a href="#一、解析题目" class="headerlink" title="一、解析题目"></a>一、解析题目</h3></blockquote><p>题目是这样：你面前有一栋从 1 到<code>N</code>共<code>N</code>层的楼，然后给你<code>K</code>个鸡蛋（<code>K</code>至少为 1）。现在确定这栋楼存在楼层<code>0 &lt;= F &lt;= N</code>，在这层楼将鸡蛋扔下去，鸡蛋<strong>恰好没摔碎</strong>（高于<code>F</code>的楼层都会碎，低于<code>F</code>的楼层都不会碎）。现在问你，<strong>最坏</strong>情况下，你<strong>至少</strong>要扔几次鸡蛋，才能<strong>确定</strong>这个楼层<code>F</code>呢？</p><p>PS：F 可以为 0，比如说鸡蛋在 1 层都能摔碎，那么 F = 0。</p><p>也就是让你找摔不碎鸡蛋的最高楼层<code>F</code>，但什么叫「最坏情况」下「至少」要扔几次呢？我们分别举个例子就明白了。</p><p>比方说<strong>现在先不管鸡蛋个数的限制</strong>，有 7 层楼，你怎么去找鸡蛋恰好摔碎的那层楼？</p><p>最原始的方式就是线性扫描：我先在 1 楼扔一下，没碎，我再去 2 楼扔一下，没碎，我再去 3 楼……</p><p>以这种策略，<strong>最坏</strong>情况应该就是我试到第 7 层鸡蛋也没碎（<code>F = 7</code>），也就是我扔了 7 次鸡蛋。</p><p>现在你应该理解什么叫做「最坏情况」下了，<strong>鸡蛋破碎一定发生在搜索区间穷尽时</strong>，不会说你在第 1 层摔一下鸡蛋就碎了，这是你运气好，不是最坏情况。</p><p>现在再来理解一下什么叫「至少」要扔几次。依然不考虑鸡蛋个数限制，同样是 7 层楼，我们可以优化策略。</p><p>最好的策略是使用二分查找思路，我先去第<code>(1 + 7) / 2 = 4</code>层扔一下：</p><p>如果碎了说明<code>F</code>小于 4，我就去第<code>(1 + 3) / 2 = 2</code>层试……</p><p>如果没碎说明<code>F</code>大于等于 4，我就去第<code>(5 + 7) / 2 = 6</code>层试……</p><p>以这种策略，<strong>最坏</strong>情况应该是试到第 7 层鸡蛋还没碎（<code>F = 7</code>），或者鸡蛋一直碎到第 1 层（<code>F = 0</code>）。然而无论那种最坏情况，只需要试<code>log7</code>向上取整等于 3 次，比刚才的 7 次要少，这就是所谓的<strong>至少</strong>要扔几次。</p><p>实际上，如果不限制鸡蛋个数的话，二分思路显然可以得到最少尝试的次数，但问题是，<strong>现在给你了鸡蛋个数的限制<code>K</code>，直接使用二分思路就不行了</strong>。</p><p>比如说只给你 1 个鸡蛋，7 层楼，你敢用二分吗？你直接去第 4 层扔一下，如果鸡蛋没碎还好，但如果碎了你就没有鸡蛋继续测试了，无法确定鸡蛋恰好摔不碎的楼层<code>F</code>了。这种情况下只能用线性扫描的方法，算法返回结果应该是 7。</p><p>有的读者也许会有这种想法：二分查找排除楼层的速度无疑是最快的，那干脆先用二分查找，等到只剩 1 个鸡蛋的时候再执行线性扫描，这样得到的结果是不是就是最少的扔鸡蛋次数呢？</p><p>很遗憾，并不是，比如说把楼层变高一些，100 层，给你 2 个鸡蛋，你在 50 层扔一下，碎了，那就只能线性扫描 1～49 层了，最坏情况下要扔 50 次。</p><p>如果不要「二分」，变成「五分」「十分」都会大幅减少最坏情况下的尝试次数。比方说第一个鸡蛋每隔十层楼扔，在哪里碎了第二个鸡蛋一个个线性扫描，总共不会超过 20 次。</p><p>最优解其实是 14 次。最优策略非常多，而且并没有什么规律可言。</p><p>说了这么多废话，就是确保大家理解了题目的意思，而且认识到这个题目确实复杂，就连我们手算都不容易，如何用算法解决呢？</p><blockquote><h3 id="二、思路分析"><a href="#二、思路分析" class="headerlink" title="二、思路分析"></a>二、思路分析</h3></blockquote><p>对动态规划问题，直接套我们以前多次强调的框架即可：这个问题有什么「状态」，有什么「选择」，然后穷举。</p><p><strong>「状态」很明显，就是当前拥有的鸡蛋数<code>K</code>和需要测试的楼层数<code>N</code></strong>。随着测试的进行，鸡蛋个数可能减少，楼层的搜索范围会减小，这就是状态的变化。</p><p><strong>「选择」其实就是去选择哪层楼扔鸡蛋</strong>。回顾刚才的线性扫描和二分思路，二分查找每次选择到楼层区间的中间去扔鸡蛋，而线性扫描选择一层层向上测试。不同的选择会造成状态的转移。</p><p>现在明确了「状态」和「选择」，<strong>动态规划的基本思路就形成了</strong>：肯定是个二维的<code>dp</code>数组或者带有两个状态参数的<code>dp</code>函数来表示状态转移；外加一个 for 循环来遍历所有选择，择最优的选择更新结果 ：</p><p><code>dp（）</code> 函数的含义：鸡蛋数目为k，可选楼层数为N时的最小扔鸡蛋次数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 伪代码</span></span><br><span class="line"><span class="comment"># 当前状态为 (K 个鸡蛋，N 层楼)</span></span><br><span class="line"><span class="comment"># 返回这个状态下的最优结果</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">K, N</span>):</span></span><br><span class="line">    res = <span class="built_in">float</span>(<span class="string">&#x27;INF&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> <span class="number">1</span> &lt;= i &lt;= N:</span><br><span class="line">        res = <span class="built_in">min</span>(res, 这次在第 i 层楼扔鸡蛋)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>这段伪码还没有展示递归和状态转移，不过大致的算法框架已经完成了。</p><p>我们在第<code>i</code>层楼扔了鸡蛋之后，可能出现两种情况：鸡蛋碎了，鸡蛋没碎。<strong>注意，这时候状态转移就来了</strong>：</p><p><strong>如果鸡蛋碎了</strong>，那么鸡蛋的个数<code>K</code>应该减一，搜索的楼层区间应该从<code>[1..N]</code>变为<code>[1..i-1]</code>共<code>i-1</code>层楼；</p><p><strong>如果鸡蛋没碎</strong>，那么鸡蛋的个数<code>K</code>不变，搜索的楼层区间应该从 <code>[1..N]</code>变为<code>[i+1..N]</code>共<code>N-i</code>层楼。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210622192232.jpg" alt=""></p><p>PS：细心的读者可能会问，在第<code>i</code>层楼扔鸡蛋如果没碎，楼层的搜索区间缩小至上面的楼层，是不是应该包含第<code>i</code>层楼呀？不必，因为已经包含了。开头说了 F 是可以等于 0 的，向上递归后，第<code>i</code>层楼其实就相当于第 0 层，可以被取到，所以说并没有错误。</p><p>因为我们要求的是<strong>最坏情况</strong>下扔鸡蛋的次数，所以鸡蛋在第<code>i</code>层楼碎没碎，取决于那种情况的结果<strong>更大</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">K, N</span>):</span></span><br><span class="line">    <span class="keyword">for</span> <span class="number">1</span> &lt;= i &lt;= N:</span><br><span class="line">        <span class="comment"># 最坏情况下的最少扔鸡蛋次数</span></span><br><span class="line">        res = <span class="built_in">min</span>(res, </span><br><span class="line">                  <span class="built_in">max</span>( </span><br><span class="line">                        dp(K - <span class="number">1</span>, i - <span class="number">1</span>), <span class="comment"># 碎</span></span><br><span class="line">                        dp(K, N - i)      <span class="comment"># 没碎</span></span><br><span class="line">                     ) + <span class="number">1</span> <span class="comment"># 在第 i 楼扔了一次</span></span><br><span class="line">                 )</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>递归的 base case 很容易理解：当楼层数<code>N</code>等于 0 时，显然不需要扔鸡蛋；当鸡蛋数<code>K</code>为 1 时，显然只能线性扫描所有楼层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">K, N</span>):</span></span><br><span class="line">    <span class="keyword">if</span> K == <span class="number">1</span>: <span class="keyword">return</span> N</span><br><span class="line">    <span class="keyword">if</span> N == <span class="number">0</span>: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p>至此，其实这道题就解决了！只要添加一个备忘录消除重叠子问题即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">superEggDrop</span>(<span class="params">K: <span class="built_in">int</span>, N: <span class="built_in">int</span></span>):</span></span><br><span class="line"></span><br><span class="line">    memo = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dp</span>(<span class="params">K, N</span>) -&gt; int:</span></span><br><span class="line">        <span class="comment"># base case</span></span><br><span class="line">        <span class="keyword">if</span> K == <span class="number">1</span>: <span class="keyword">return</span> N</span><br><span class="line">        <span class="keyword">if</span> N == <span class="number">0</span>: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 避免重复计算</span></span><br><span class="line">        <span class="keyword">if</span> (K, N) <span class="keyword">in</span> memo:</span><br><span class="line">            <span class="keyword">return</span> memo[(K, N)]</span><br><span class="line"></span><br><span class="line">        res = <span class="built_in">float</span>(<span class="string">&#x27;INF&#x27;</span>)</span><br><span class="line">        <span class="comment"># 穷举所有可能的选择</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, N + <span class="number">1</span>):</span><br><span class="line">            res = <span class="built_in">min</span>(res, </span><br><span class="line">                      <span class="built_in">max</span>(</span><br><span class="line">                            dp(K, N - i), </span><br><span class="line">                            dp(K - <span class="number">1</span>, i - <span class="number">1</span>)</span><br><span class="line">                         ) + <span class="number">1</span></span><br><span class="line">                  )</span><br><span class="line">        <span class="comment"># 记入备忘录</span></span><br><span class="line">        memo[(K, N)] = res</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp(K, N)</span><br></pre></td></tr></table></figure><p>这个算法的时间复杂度是多少呢？<strong>动态规划算法的时间复杂度就是子问题个数 × 函数本身的复杂度</strong>。</p><p>函数本身的复杂度就是忽略递归部分的复杂度，这里<code>dp</code>函数中有一个 for 循环，所以函数本身的复杂度是 O(N)。</p><p>子问题个数也就是不同状态组合的总数，显然是两个状态的乘积，也就是 O(KN)。</p><p>所以算法的总时间复杂度是 O(K*N^2), 空间复杂度为子问题个数，即 O(KN)。</p><blockquote><h3 id="三、疑难解答"><a href="#三、疑难解答" class="headerlink" title="三、疑难解答"></a>三、疑难解答</h3></blockquote><p>这个问题很复杂，但是算法代码却十分简洁，这就是动态规划的特性，穷举加备忘录/DP table 优化，真的没啥新意。</p><p>首先，有读者可能不理解代码中为什么用一个 for 循环遍历楼层<code>[1..N]</code>，也许会把这个逻辑和之前探讨的线性扫描混为一谈。其实不是的，<strong>这只是在做一次「选择」</strong>。</p><p>比方说你有 2 个鸡蛋，面对 10 层楼，你得拿一个鸡蛋去某一层楼扔对吧？那选择去哪一层楼扔呢？不知道，那就把这 10 层楼全试一遍。至于鸡蛋碎没碎，下次怎么选择不用你操心，有正确的状态转移，递归会算出每个选择的代价，我们取最优的那个就是最优解。</p><p>其实，这个问题还有更好的解法，比如修改代码中的 for 循环为二分搜索，可以将时间复杂度降为 O(K<em>N</em>logN)；再改进动态规划解法可以进一步降为 O(KN)；使用数学方法解决，时间复杂度达到最优 O(K*logN)，空间复杂度达到 O(1)。</p><p>二分的解法也有点误导性，你很可能以为它跟我们之前讨论的二分思路扔鸡蛋有关系，实际上没有半毛钱关系。能用二分搜索是因为状态转移方程的函数图像具有单调性，可以快速找到最小值。</p><p>我觉得吧，我们这种解法就够了：<strong>找状态，做选择</strong>，足够清晰易懂，可流程化，可举一反三。掌握这套框架学有余力的话，二分查找的优化应该可以看懂，之后的优化也就随缘吧。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;动态规划之高楼扔鸡蛋&quot;&gt;&lt;a href=&quot;#动态规划之高楼扔鸡蛋&quot; class=&quot;headerlink&quot; title=&quot;动态规划之高楼扔鸡蛋&quot;&gt;&lt;/a&gt;动态规划之高楼扔鸡蛋&lt;/h2&gt;&lt;p&gt;今天要聊一个很经典的算法问题，若干层楼，若干个鸡蛋，让你算出最少的尝试次数，</summary>
      
    
    
    
    <category term="动态规划" scheme="https://xxren8218.github.io/categories/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
  </entry>
  
  <entry>
    <title>18-hadoop之分布式文件系统 HDFS</title>
    <link href="https://xxren8218.github.io/20210622/18-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS.html"/>
    <id>https://xxren8218.github.io/20210622/18-%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-HDFS.html</id>
    <published>2021-06-21T16:38:13.000Z</published>
    <updated>2021-06-24T16:47:54.127Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式文件系统-HDFS"><a href="#分布式文件系统-HDFS" class="headerlink" title="分布式文件系统 HDFS"></a>分布式文件系统 HDFS</h1><p>掌握目标：</p><ul><li>知道什么是hdfs</li><li>说出hdfs的架构</li><li>能够掌握hdfs的环境搭建</li><li>能够掌握hdfs shell的基本使用</li><li>知道hdfs shell的优缺点</li></ul><h3 id="1-HDFS的使用"><a href="#1-HDFS的使用" class="headerlink" title="1 HDFS的使用"></a>1 HDFS的使用</h3><ul><li><p>启动HDFS</p><ul><li>来到$HADOOP_HOME/sbin目录下</li><li>执行start-dfs.sh</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ ./start-dfs.sh</span><br></pre></td></tr></table></figure><ul><li>可以看到 namenode和 datanode启动的日志信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Starting namenodes on [hadoop00]</span><br><span class="line">hadoop00: starting namenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-namenode-hadoop00.out</span><br><span class="line">localhost: starting datanode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-datanode-hadoop00.out</span><br><span class="line">Starting secondary namenodes [0.0.0.0]</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /home/hadoop/app/hadoop-2.6.0-cdh5.7.0/logs/hadoop-hadoop-secondarynamenode-hadoop00.out</span><br></pre></td></tr></table></figure><ul><li>通过jps命令查看当前运行的进程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop00 sbin]$ jps</span><br><span class="line">4416 DataNode</span><br><span class="line">4770 Jps</span><br><span class="line">4631 SecondaryNameNode</span><br><span class="line">4251 NameNode</span><br></pre></td></tr></table></figure><ul><li>可以看到 NameNode DataNode 以及 SecondaryNameNode 说明启动成功</li></ul></li><li><p>通过可视化界面查看HDFS的运行情况</p><ul><li>通过浏览器查看 主机ip:50070端口 </li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210622004022.png" alt=""></p><ul><li>Overview界面查看整体情况</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210622004044.png" alt=""></p><ul><li>Datanodes界面查看datanode的情况</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210622004102.png" alt=""></p></li></ul><h3 id="2-HDFS-shell操作"><a href="#2-HDFS-shell操作" class="headerlink" title="2 HDFS shell操作"></a>2 HDFS shell操作</h3><ul><li><p>调用文件系统(FS)Shell命令应使用 bin/hadoop fs <args>的形式</p><ul><li><h3 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h3><p>使用方法：hadoop fs -ls <args></p><p>如果是文件，则按照如下格式返回文件信息：<br>文件名 &lt;副本数&gt; 文件大小 修改日期 修改时间 权限 用户ID 组ID<br>如果是目录，则返回它直接子文件的一个列表，就像在Unix中一样。目录返回列表的信息如下：<br>目录名 <dir> 修改日期 修改时间 权限 用户ID 组ID<br>示例：<br>hadoop fs -ls /user/hadoop/file1 /user/hadoop/file2 hdfs://host:port/user/hadoop/dir1 /nonexistentfile<br>返回值：<br>成功返回0，失败返回-1。 </p></li><li><h3 id="text"><a href="#text" class="headerlink" title="text"></a>text</h3><p>使用方法：hadoop fs -text <src> </p><p>将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream。</p></li><li><h3 id="mv"><a href="#mv" class="headerlink" title="mv"></a>mv</h3><p>使用方法：hadoop fs -mv URI [URI …] <dest></p><p>将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。<br>示例：</p><ul><li>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</li><li>hadoop fs -mv hdfs://host:port/file1 hdfs://host:port/file2 hdfs://host:port/file3 hdfs://host:port/dir1</li></ul><p>返回值：</p><p>成功返回0，失败返回-1。</p></li><li><h3 id="put"><a href="#put" class="headerlink" title="put"></a>put</h3><p>使用方法：hadoop fs -put <localsrc> … <dst></p><p>从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。</p><ul><li>hadoop fs -put localfile /user/hadoop/hadoopfile</li><li>hadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdir</li><li>hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile</li><li>hadoop fs -put - hdfs://host:port/hadoop/hadoopfile<br>从标准输入中读取输入。</li></ul><p>返回值：</p><p>成功返回0，失败返回-1。</p></li><li><h3 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h3><p>使用方法：hadoop fs -rm URI [URI …]</p><p>删除指定的文件。只删除非空目录和文件。请参考rmr命令了解递归删除。<br>示例：</p><ul><li>hadoop fs -rm hdfs://host:port/file /user/hadoop/emptydir</li></ul><p>返回值：</p><p>成功返回0，失败返回-1。</p></li></ul></li><li><p><a href="http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html">http://hadoop.apache.org/docs/r1.0.4/cn/hdfs_shell.html</a></p></li></ul><h3 id="3-HDFS-shell操作练习"><a href="#3-HDFS-shell操作练习" class="headerlink" title="3 HDFS shell操作练习"></a>3 HDFS shell操作练习</h3><ul><li><p>在centos 中创建 test.txt  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch test.txt</span><br></pre></td></tr></table></figure></li><li><p>在centos中为test.txt 添加文本内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi test.txt</span><br></pre></td></tr></table></figure></li><li><p>在HDFS中创建 hadoop001/test 文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /hadoop001/test</span><br></pre></td></tr></table></figure></li><li><p>把text.txt文件上传到HDFS中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put test.txt /hadoop001/test/</span><br></pre></td></tr></table></figure></li><li><p>查看hdfs中 hadoop001/test/test.txt 文件内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /hadoop001/test/test.txt</span><br></pre></td></tr></table></figure></li><li><p>将hdfs中 hadoop001/test/test.txt文件下载到centos</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get /hadoop001/test/test.txt test.txt</span><br></pre></td></tr></table></figure></li><li><p>删除HDFS中 hadoop001/test/</p><p>hadoop fs -rm -r /hadoop001</p></li></ul><h3 id="4-HDFS设计思路"><a href="#4-HDFS设计思路" class="headerlink" title="4 HDFS设计思路"></a>4 HDFS设计思路</h3><ul><li><p>分布式文件系统的设计思路：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210622004151.png" alt=""></p></li></ul><ul><li>HDFS的设计目标<ul><li>适合运行在通用硬件(commodity hardware)上的分布式文件系统</li><li>高度容错性的系统，适合部署在廉价的机器上</li><li>HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用</li><li>容易扩展，为用户提供性能不错的文件存储服务</li></ul></li></ul><h3 id="5-HDFS架构"><a href="#5-HDFS架构" class="headerlink" title="5 HDFS架构"></a>5 HDFS架构</h3><ul><li>1个NameNode/NN(Master)  带 DataNode/DN(Slaves) (Master-Slave结构)</li><li>1个文件会被拆分成多个Block</li><li>NameNode(NN)<ul><li>负责客户端请求的响应</li><li>负责元数据（文件的名称、副本系数、Block存放的DN）的管理<ul><li>元数据 MetaData 描述数据的数据</li></ul></li><li>监控DataNode健康状况 10分钟 <code>心跳</code> 没有收到DataNode报告认为Datanode死掉了。将数据再存储一份。</li></ul></li><li>DataNode(DN)<ul><li>存储用户的文件对应的数据块(Block)</li><li>要定期向NN发送心跳信息，汇报本身及其所有的block信息，健康状况</li></ul></li><li>分布式集群NameNode和DataNode部署在不同机器上</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210622004230.jpg" alt=""></p><ul><li>HDFS优缺点<ul><li>优点<ul><li>数据冗余 硬件容错</li><li>适合存储大文件</li><li>处理流式数据</li><li>可构建在廉价机器上</li></ul></li><li>缺点<ul><li>高延迟的数据访问。——在各个机器之间通讯，延迟高。</li><li>小文件存储。即使文件大小小于128M，它也会占128M的空间。</li></ul></li></ul></li></ul><h3 id="6-HDFS环境搭建"><a href="#6-HDFS环境搭建" class="headerlink" title="6 HDFS环境搭建"></a>6 HDFS环境搭建</h3><ul><li><p>下载jdk（java development kit,） 和 hadoop 放到 ~/software目录下 然后解压到 ~/app目录下</p><ul><li>因为大数据Hadoop等是用 java 开发的，java 需要在JVM上运行，而JDK就包含了JVM（JVM：java的虚拟机）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf 压缩包名字 -C ~/app/</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile</span><br><span class="line">export JAVA_HOME=/home/hadoop/app/jdk1.8.0_91</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export HADOOP_HOME=/home/hadoop/app/hadoop......</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">保存退出后</span></span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure></li><li><p>进入到解压后的hadoop目录 修改配置文件</p><ul><li><p>配置文件作用</p><ul><li>core-site.xml  指定hdfs的访问方式</li><li>hdfs-site.xml  指定namenode 和 datanode 的数据存储位置</li><li>mapred-site.xml 配置mapreduce</li><li>yarn-site.xml  配置yarn</li></ul></li><li><p>修改hadoop-env.sh</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd etc/hadoop</span><br><span class="line">vi hadoop-env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash">找到下面内容添加java home</span></span><br><span class="line">export_JAVA_HOME=/home/hadoop/app/jdk1.8.0_91</span><br></pre></td></tr></table></figure><ul><li>修改 core-site.xml 在 <configuration>节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop000:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改hdfs-site.xml 在 configuration节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/app/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/app/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改 mapred-site.xml </li><li>默认没有这个 从模板文件复制 </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure><p>​    在mapred-site.xml  的configuration 节点中添加</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改yarn-site.xml configuration 节点中添加</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>来到hadoop的bin目录——格式化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./hadoop namenode -format (这个命令只运行一次)</span><br></pre></td></tr></table></figure></li><li><p>启动hdfs 进入到  sbin</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-dfs.sh</span><br></pre></td></tr></table></figure></li><li><p>启动启动yarn 在sbin中</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;分布式文件系统-HDFS&quot;&gt;&lt;a href=&quot;#分布式文件系统-HDFS&quot; class=&quot;headerlink&quot; title=&quot;分布式文件系统 HDFS&quot;&gt;&lt;/a&gt;分布式文件系统 HDFS&lt;/h1&gt;&lt;p&gt;掌握目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;知道什么是hdfs&lt;/</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>17-Hadoop概述</title>
    <link href="https://xxren8218.github.io/20210621/17-Hadoop%E6%A6%82%E8%BF%B0.html"/>
    <id>https://xxren8218.github.io/20210621/17-Hadoop%E6%A6%82%E8%BF%B0.html</id>
    <published>2021-06-21T10:21:17.000Z</published>
    <updated>2021-06-24T16:48:20.361Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hadoop概述"><a href="#Hadoop概述" class="headerlink" title="Hadoop概述"></a>Hadoop概述</h2><p>掌握目标：</p><ul><li>知道Hadoop的概念及发展历史</li><li>说出hadoop的核心组件</li><li>知道hadoop的优势</li></ul><h3 id="1-什么是Hadoop"><a href="#1-什么是Hadoop" class="headerlink" title="1 什么是Hadoop"></a>1 什么是Hadoop</h3><ul><li><p>Hadoop名字的由来</p><ul><li>作者：Doug cutting</li><li>Hadoop项目作者的孩子给一个棕黄色的大象样子的填充玩具的命名</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181835.png" alt=""></p></li><li><p>Hadoop的概念:</p><ul><li>Apache™ Hadoop®  是一个开源的, <strong>可靠的</strong>(reliable), <strong>可扩展</strong>的(scalable)<strong>分布式计算框架</strong><ul><li>允许使用简单的编程模型跨计算机集群分布式处理大型数据集</li><li><strong>可扩展</strong>: 从单个服务器扩展到数千台计算机，每台计算机都提供本地计算和存储</li><li><strong>可靠的</strong>: 不依靠硬件来提供高可用性(high-availability)，而是在应用层检测和处理故障，从而在计算机集群之上提供高可用服务</li></ul></li></ul></li><li><p>Hadoop能做什么?</p><ul><li><p>搭建大型数据仓库</p></li><li><p>PB级数据的存储 处理 分析 统计等业务</p><ul><li><p>搜索引擎</p></li><li><p>日志分析</p></li><li><p>数据挖掘</p></li><li><p>商业智能(Business Intelligence，简称：BI)</p></li></ul></li></ul></li></ul><pre><code>  商业智能通常被理解为将企业中现有的数据(订单、库存、交易账目、客户和供应商等数据)转化为知识，帮助企业做出明智的业务经营决策的工具。从技术层面上讲，是数据仓库、数据挖掘等技术的综合运用。</code></pre><ul><li><p>Hadoop发展史</p><ul><li><p>2003-2004年 Google发表了三篇论文</p><ul><li>GFS：Google的分布式文件系统Google File System </li><li><a href="https://en.wikipedia.org/wiki/MapReduce">MapReduce</a>: Simplified Data Processing on Large Clusters </li><li>BigTable：一个大型的分布式数据库</li></ul></li><li>2006年2月Hadoop成为Apache的独立开源项目( Doug Cutting等人实现了DFS和MapReduce机制)。</li><li>2006年4月— 标准排序(10 GB每个节点)在188个节点上运行47.9个小时。 </li><li>2008年4月— 赢得世界最快1TB数据排序在900个节点上用时209秒。 </li><li>2008年— <strong>淘宝开始投入研究基于Hadoop的系统–云梯</strong>。云梯总容量约9.3PB，共有1100台机器，每天处理18000道作业，扫描500TB数据。 </li><li>2009年3月— <strong>Cloudera推出CDH（Cloudera’s Dsitribution Including Apache Hadoop）</strong></li><li>2009年5月— Yahoo的团队使用Hadoop对1 TB的数据进行排序只花了62秒时间。 </li><li>2009年7月— <strong>Hadoop Core项目更名为Hadoop Common;</strong> </li><li>2009年7月— <strong>MapReduce和Hadoop Distributed File System (HDFS)成为Hadoop项目的独立子项目。</strong></li><li>2012年11月— Apache Hadoop 1.0 Available</li><li>2018年4月— Apache Hadoop 3.1 Available</li><li>搜索引擎时代<ul><li>有保存大量网页的需求(单机  集群)</li><li>词频统计 <strong>【word count】</strong>  <strong>【PageRank】</strong></li></ul></li><li>数据仓库时代<ul><li>FaceBook推出Hive（Hive是基于<a href="https://baike.baidu.com/item/Hadoop/3526507">Hadoop</a>的一个<a href="https://baike.baidu.com/item/数据仓库/381916">数据仓库</a>工具）</li><li>曾经进行数分析与统计时, 仅限于数据库,受数据量和计算能力的限制, 我们只能对最重要的数据进行统计和分析(决策数据,财务相关)</li><li>Hive可以在Hadoop上运行SQL操作, 可以把运行日志, 应用采集数据,数据库数据放到一起分析</li></ul></li><li>数据挖掘时代<ul><li>啤酒尿不湿</li><li>关联分析</li><li>用户画像/物品画像</li></ul></li><li>机器学习时代  广义大数据<ul><li>大数据提高数据存储能力, 为机器学习提供燃料</li><li>alpha go</li><li>siri 小爱 天猫精灵</li></ul></li></ul></li></ul><h3 id="2-Hadoop核心组件"><a href="#2-Hadoop核心组件" class="headerlink" title="2 Hadoop核心组件"></a>2 Hadoop核心组件</h3><ul><li><p>Hadoop是所有搜索引擎的共性问题的廉价解决方案</p><ul><li>如何存储持续增长的海量网页:  单节点 V.S. 分布式存储</li><li>如何对持续增长的海量网页进行排序: 超算 V.S. 分布式计算</li><li>HDFS 解决分布式存储问题</li><li>MapReduce 解决分布式计算问题</li></ul></li><li><p><strong>Hadoop Common</strong>: The common utilities that support the other Hadoop modules.(hadoop的公共组件)—（如将HDFS和MapReduce串起来）</p></li><li><strong>Hadoop Distributed File System (HDFS™)</strong>: A distributed file system that provides high-throughput access to application data.(分布式文件系统)<ul><li>源自于Google的GFS论文, 论文发表于2003年10月</li><li>HDFS是GFS的开源实现</li><li>HDFS的特点:扩展性&amp;容错性&amp;海量数量存储</li><li>将文件切分成指定大小的数据块, 并在多台机器上保存多个副本（冗余、切割）</li><li>数据切分、多副本、容错等操作对用户是透明的——系统自动给用户拆分</li></ul></li><li>下面这张图是数据块多份复制存储的示意<ul><li>图中对于文件 /users/sameerp/data/part-0，其复制备份数设置为2, 存储的BlockID分别为1、3。</li><li>Block1的两个备份存储在DataNode0和DataNode2两个服务器上</li><li>Block3的两个备份存储在DataNode4和DataNode6两个服务器上</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181916.png" alt=""></p><ul><li><p><strong>Hadoop MapReduce</strong>: A YARN-based system for parallel processing of large data sets.</p><ul><li>分布式计算框架</li><li>源于Google的MapReduce论文，论文发表于2004年12月</li><li>MapReduce是GoogleMapReduce的开源实现</li><li>MapReduce特点:扩展性&amp;容错性&amp;海量数据离线处理（得等）</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181942.png" alt=""></p></li><li><p><strong>Hadoop YARN</strong>: A framework for job scheduling and cluster resource management.(资源调度系统)</p><ul><li><p>YARN: Yet Another Resource Negotiator</p></li><li><p>负责整个集群资源的管理和调度</p></li><li><p>YARN特点:扩展性&amp;容错性&amp;多框架资源统一调度</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621182008.jpg" alt=""></p></li></ul></li></ul><h3 id="3-Hadoop优势"><a href="#3-Hadoop优势" class="headerlink" title="3 Hadoop优势"></a>3 Hadoop优势</h3><ul><li>高可靠<ul><li>数据存储: 数据块多副本</li><li>数据计算: 某个节点崩溃, 会自动重新调度作业计算</li></ul></li><li>高扩展性<ul><li>存储/计算资源不够时，可以横向的线性扩展机器</li><li>一个集群中可以包含数以千计的节点</li><li>集群可以使用廉价机器，成本低</li></ul></li><li>Hadoop生态系统成熟</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Hadoop概述&quot;&gt;&lt;a href=&quot;#Hadoop概述&quot; class=&quot;headerlink&quot; title=&quot;Hadoop概述&quot;&gt;&lt;/a&gt;Hadoop概述&lt;/h2&gt;&lt;p&gt;掌握目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;知道Hadoop的概念及发展历史&lt;/li&gt;
&lt;li&gt;说</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>03-动态规划之 KMP 算法详解</title>
    <link href="https://xxren8218.github.io/20210621/03-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B-KMP-%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3.html"/>
    <id>https://xxren8218.github.io/20210621/03-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B9%8B-KMP-%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3.html</id>
    <published>2021-06-21T10:05:59.000Z</published>
    <updated>2021-06-21T10:14:07.647Z</updated>
    
    <content type="html"><![CDATA[<h2 id="动态规划之-KMP-算法详解"><a href="#动态规划之-KMP-算法详解" class="headerlink" title="动态规划之 KMP 算法详解"></a>动态规划之 KMP 算法详解</h2><p>KMP 算法（Knuth-Morris-Pratt 算法）是一个著名的字符串匹配算法，效率很高，但是确实有点复杂。</p><p>KMP 算法比较难理解。有一些优秀的同学通过手推 KMP 算法的过程来辅助理解该算法，这是一种办法，不过本文要从逻辑层面帮助读者理解算法的原理。十行代码之间，KMP 灰飞烟灭。</p><p><strong>先在开头约定，本文用<code>pat</code>表示模式串，长度为<code>M</code>，<code>txt</code>表示文本串，长度为<code>N</code>。KMP 算法是在<code>txt</code>中查找子串<code>pat</code>，如果存在，返回这个子串的起始索引，否则返回 -1</strong>。</p><p>为什么我认为 KMP 算法就是个动态规划问题呢，等会有解释。对于动态规划，之前多次强调了要明确<code>dp</code>数组的含义，而且同一个问题可能有不止一种定义<code>dp</code>数组含义的方法，不同的定义会有不同的解法。</p><p>常见的 KMP 算法应该是，一波诡异的操作处理<code>pat</code>后形成一个一维的数组<code>next</code>，然后根据这个数组经过又一波复杂操作去匹配<code>txt</code>。时间复杂度 O(N)，空间复杂度 O(M)。其实它这个<code>next</code>数组就相当于<code>dp</code>数组，其中元素的含义跟<code>pat</code>的前缀和后缀有关，判定规则比较复杂，不太好理解。</p><p>本文则用一个<strong>二维</strong>的<code>dp</code>数组（但空间复杂度还是 O(M)），重新定义其中元素的含义，使得代码长度大大减少，可解释性大大提高。</p><p>PS：原代码使用的数组名称是<code>dfa</code>（确定有限状态机），本文还是沿用<code>dp</code>数组的名称。</p><blockquote><h3 id="一、KMP-算法概述"><a href="#一、KMP-算法概述" class="headerlink" title="一、KMP 算法概述"></a>一、KMP 算法概述</h3></blockquote><p>首先还是简单介绍一下 KMP 算法和暴力匹配算法的不同在哪里，难点在哪里，和动态规划有啥关系。</p><p>暴力的字符串匹配算法很容易写，看一下它的运行逻辑：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 暴力匹配</span></span><br><span class="line">def search(pat, txt):(pat-&gt;string, txt-&gt;string)</span><br><span class="line">    M = <span class="built_in">len</span>(pat)</span><br><span class="line">    N = <span class="built_in">len</span>(txt)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N - M + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 记录每次匹配成功的字串的元素个数</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">            <span class="keyword">if</span> pat[j] != txt[i + j]:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># pat 全部匹配了</span></span><br><span class="line">        <span class="keyword">if</span> (count == M): <span class="keyword">return</span> i</span><br><span class="line"></span><br><span class="line">    <span class="comment"># txt 中不存在 pat 子串</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure><p>对于暴力算法，如果出现不匹配字符，同时回退<code>txt</code>和<code>pat</code>的指针，嵌套 for 循环，时间复杂度 <em>O</em>(MN)，空间复杂度<em>O</em>(1)。最主要的问题是，如果字符串中重复的字符比较多，该算法就显得很蠢。</p><p>比如 txt = “aaacaaab” pat = “aaab”：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180706.gif" alt=""></p><center>暴力算法</center><p>很明显，<code>pat</code>中根本没有字符 c，根本没必要回退指针<code>i</code>，暴力解法明显多做了很多不必要的操作。</p><p>KMP 算法的不同之处在于，它会花费空间来记录一些信息，在上述情况中就会显得很聪明：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180728.gif" alt=""></p><center>KMP算法</center><p>再比如类似的 txt = “aaaaaaab” pat = “aaab”，暴力解法还会和上面那个例子一样蠢蠢地回退指针<code>i</code>，而 KMP 算法又会耍聪明：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180744.gif" alt=""></p><center>KMP算法</center><p>因为 KMP 算法知道字符 b 之前的字符 a 都是匹配的，所以每次只需要比较字符 b 是否被匹配就行了。</p><p><strong>KMP 算法永不回退<code>txt</code>的指针<code>i</code>，不走回头路（不会重复扫描<code>txt</code>），而是借助<code>dp</code>数组中储存的信息把<code>pat</code>移到正确的位置继续匹配</strong>，时间复杂度只需 O(N)，用空间换时间，所以我认为它是一种动态规划算法。</p><p>KMP 算法的难点在于，如何计算<code>dp</code>数组中的信息？如何根据这些信息正确地移动<code>pat</code>的指针？这个就需要<strong>确定有限状态自动机</strong>来辅助了，别怕这种高大上的文学词汇，其实和动态规划的<code>dp</code>数组如出一辙，等你学会了也可以拿这个词去吓唬别人。</p><p>还有一点需要明确的是：<strong>计算这个<code>dp</code>数组，只和<code>pat</code>串有关</strong>。意思是说，只要给我个<code>pat</code>，我就能通过这个模式串计算出<code>dp</code>数组，然后你可以给我不同的<code>txt</code>，我都不怕，利用这个<code>dp</code>数组我都能在 O(N) 时间完成字符串匹配。</p><p>具体来说，比如上文举的两个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">txt1 = <span class="string">&quot;aaacaaab&quot;</span> </span><br><span class="line">pat = <span class="string">&quot;aaab&quot;</span></span><br><span class="line">txt2 = <span class="string">&quot;aaaaaaab&quot;</span> </span><br><span class="line">pat = <span class="string">&quot;aaab&quot;</span></span><br></pre></td></tr></table></figure><p>我们的<code>txt</code>不同，但是<code>pat</code>是一样的，所以 KMP 算法使用的<code>dp</code>数组是同一个。只不过对于<code>txt1</code>的下面这个即将出现的未匹配情况：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180840.png" alt=""></p><p><code>dp</code>数组指示<code>pat</code>这样移动：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180857.jpg" alt=""></p><p>PS：这个<code>j</code>不要理解为索引，它的含义更准确地说应该是<strong>状态</strong>（state），所以它会出现这个奇怪的位置，后文会详述。</p><p>而对于<code>txt2</code>的下面这个即将出现的未匹配情况：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180910.jpg" alt=""></p><p><code>dp</code>数组指示<code>pat</code>这样移动：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180932.jpg" alt=""></p><p>明白了<code>dp</code>数组只和<code>pat</code>有关，那么我们这样设计 KMP 算法就会比较漂亮：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMP</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, pat</span>):</span></span><br><span class="line">        self.pat = pat</span><br><span class="line">        <span class="comment"># 通过 pat 构建 dp 数组</span></span><br><span class="line">        <span class="comment"># 需要 O(N) 时间</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, txt</span>):</span></span><br><span class="line">        <span class="comment"># 借助 dp 数组去匹配 txt</span></span><br><span class="line">        <span class="comment"># 需要 O(N) 时间</span></span><br></pre></td></tr></table></figure><p>这样，当我们需要用同一<code>pat</code>去匹配不同<code>txt</code>时，就不需要浪费时间构造<code>dp</code>数组了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kmp = KMP(<span class="string">&quot;aaab&quot;</span>)</span><br><span class="line">pos1 = kmp.search(<span class="string">&quot;aaacaaab&quot;</span>) <span class="comment"># 4</span></span><br><span class="line">pos2 = kmp.search(<span class="string">&quot;aaaaaaab&quot;</span>) <span class="comment"># 4</span></span><br></pre></td></tr></table></figure><blockquote><h3 id="二、状态机概述"><a href="#二、状态机概述" class="headerlink" title="二、状态机概述"></a>二、状态机概述</h3></blockquote><p>为什么说 KMP 算法和状态机有关呢？是这样的，我们可以认为<code>pat</code>的匹配就是状态的转移。比如当 pat = “ABABC”：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180945.jpg" alt=""></p><p>如上图，圆圈内的数字就是状态，状态 0 是起始状态，状态 5（<code>pat.length</code>）是终止状态。开始匹配时<code>pat</code>处于起始状态，一旦转移到终止状态，就说明在<code>txt</code>中找到了<code>pat</code>。</p><p>比如说如果当前处于状态 2，就说明字符 “AB” 被匹配：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621180959.jpg" alt=""></p><p>另外，处于某个状态时，遇到不同的字符，<code>pat</code>状态转移的行为也不同。比如说假设现在匹配到了状态 4，如果遇到字符 A 就应该转移到状态 3，遇到字符 C 就应该转移到状态 5，如果遇到字符 B 就应该转移到状态 0：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181013.jpg" alt=""></p><p>具体什么意思呢，举例解释一下。用变量<code>j</code>表示指向当前状态的指针，当前<code>pat</code>匹配到了状态 4</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181025.jpg" alt=""></p><p>如果遇到了字符 “A”，根据箭头指示，转移到状态 3 是最聪明的：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181040.jpg" alt=""></p><p>如果遇到了字符 “B”，根据箭头指示，只能转移到状态 0（一夜回到解放前）：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181054.jpg" alt=""></p><p>如果遇到了字符 “C”，根据箭头指示，应该转移到终止状态 5，这也就意味着匹配完成：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181109.jpg" alt=""></p><p>当然了，还可能遇到其他字符，比如 Z，但是显然应该转移到起始状态 0，因为<code>pat</code>中根本都没有字符 Z：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181128.jpg" alt=""></p><p>这里为了清晰起见，我们画状态图时就把其他字符转移到状态 0 的箭头省略，只画<code>pat</code>中出现的字符的状态转移：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181141.jpg" alt=""></p><p>KMP 算法最关键的步骤就是构造这个状态转移图。<strong>要确定状态转移的行为，得明确两个变量，一个是当前的匹配状态，另一个是遇到的字符</strong>；确定了这两个变量后，就可以知道这个情况下应该转移到哪个状态。</p><p>下面看一下 KMP 算法根据这幅状态转移图匹配字符串<code>txt</code>的过程：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181156.gif" alt=""></p><p><strong>请记住这个 GIF 的匹配过程，这就是 KMP 算法的核心逻辑</strong>！</p><p>为了描述状态转移图，我们定义一个二维 dp 数组，它的含义如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">dp[j][c] = <span class="built_in">next</span></span><br><span class="line"><span class="number">0</span> &lt;= j &lt; M，代表当前的状态</span><br><span class="line"><span class="number">0</span> &lt;= c &lt; <span class="number">256</span>，代表遇到的字符（ASCII 码）</span><br><span class="line"><span class="number">0</span> &lt;= <span class="built_in">next</span> &lt;= M，代表下一个状态</span><br><span class="line"></span><br><span class="line">dp[<span class="number">4</span>][<span class="string">&#x27;A&#x27;</span>] = <span class="number">3</span> 表示：</span><br><span class="line">当前是状态 <span class="number">4</span>，如果遇到字符 A，</span><br><span class="line">pat 应该转移到状态 <span class="number">3</span></span><br><span class="line"></span><br><span class="line">dp[<span class="number">1</span>][<span class="string">&#x27;B&#x27;</span>] = <span class="number">2</span> 表示：</span><br><span class="line">当前是状态 <span class="number">1</span>，如果遇到字符 B，</span><br><span class="line">pat 应该转移到状态  <span class="number">2</span></span><br></pre></td></tr></table></figure><p>根据我们这个 dp 数组的定义和刚才状态转移的过程，我们可以先写出 KMP 算法的 search 函数代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">String txt</span>):</span></span><br><span class="line">    M = <span class="built_in">len</span>(pat)</span><br><span class="line">    N = <span class="built_in">len</span>(txt)</span><br><span class="line">    <span class="comment"># pat 的初始态为 0</span></span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        <span class="comment"># 当前是状态 j，遇到字符 txt[i]，</span></span><br><span class="line">        <span class="comment"># pat 应该转移到哪个状态？</span></span><br><span class="line">        j = dp[j][<span class="built_in">ord</span>(txt[i])]</span><br><span class="line">        <span class="comment"># 如果达到终止态，返回匹配开头的索引</span></span><br><span class="line">        <span class="keyword">if</span> j == M: <span class="keyword">return</span> i - M + <span class="number">1</span></span><br><span class="line">   </span><br><span class="line">    <span class="comment"># 没到达终止态，匹配失败</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li>注意：python的内置函数ord(“a”) 输出字符串的ASCII编码</li><li>python的内置函数chr(67) 输出ASCII编码对应的字符串</li></ul><p>到这里，应该还是很好理解的吧，<code>dp</code>数组就是我们刚才画的那幅状态转移图，如果不清楚的话回去看下 GIF 的算法演进过程。</p><p>下面讲解：如何通过<code>pat</code>构建这个<code>dp</code>数组？</p><blockquote><h3 id="三、构建状态转移图"><a href="#三、构建状态转移图" class="headerlink" title="三、构建状态转移图"></a>三、构建状态转移图</h3></blockquote><p>回想刚才说的：<strong>要确定状态转移的行为，必须明确两个变量，一个是当前的匹配状态，另一个是遇到的字符</strong>，而且我们已经根据这个逻辑确定了<code>dp</code>数组的含义，那么构造<code>dp</code>数组的框架就是这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="number">0</span> &lt;= j &lt; M: <span class="comment"># 状态</span></span><br><span class="line">    <span class="keyword">for</span> <span class="number">0</span> &lt;= c &lt; <span class="number">256</span>: <span class="comment"># 字符</span></span><br><span class="line">        dp[j][c] = <span class="built_in">next</span></span><br></pre></td></tr></table></figure><p>这个 next 状态应该怎么求呢？显然，<strong>如果遇到的字符<code>c</code>和<code>pat[j]</code>匹配的话</strong>，状态就应该向前推进一个，也就是说<code>next = j + 1</code>，我们不妨称这种情况为<strong>状态推进</strong>：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181226.jpg" alt=""></p><p><strong>如果遇到的字符<code>c</code>和<code>pat[j]</code>不匹配的话</strong>，状态就要回退（或者原地不动），我们不妨称这种情况为<strong>状态重启</strong></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181239.jpg" alt=""></p><p>那么，如何得知在哪个状态重启呢？解答这个问题之前，我们再定义一个名字：<strong>影子状态</strong>（我编的名字），用变量<code>X</code>表示。<strong>所谓影子状态，就是和当前状态具有相同的前缀</strong>。比如下面这种情况：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181254.jpg" alt=""></p><p>当前状态<code>j = 4</code>，其影子状态为<code>X = 2</code>，它们都有相同的前缀 “AB”。因为状态<code>X</code>和状态<code>j</code>存在相同的前缀，所以当状态<code>j</code>准备进行状态重启的时候（遇到的字符<code>c</code>和<code>pat[j]</code>不匹配），可以通过<code>X</code>的状态转移图来获得<strong>最近的重启位置</strong>。</p><p>比如说刚才的情况，如果状态<code>j</code>遇到一个字符 “A”，应该转移到哪里呢？首先状态 4 只有遇到 “C” 才能推进状态，遇到 “A” 显然只能进行状态重启。<strong>状态<code>j</code>会把这个字符委托给状态<code>X</code>处理，也就是<code>dp[j][&#39;A&#39;] = dp[X][&#39;A&#39;]</code></strong>：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181306.jpg" alt=""></p><p>为什么这样可以呢？因为：既然<code>j</code>这边已经确定字符 “A” 无法推进状态，<strong>只能回退</strong>，而且 KMP 算法就是要<strong>尽可能少的回退</strong>，以免多余的计算。那么<code>j</code>就可以去问问和自己具有相同前缀的<code>X</code>，如果<code>X</code>遇见 “A” 可以进行「状态推进」，那就转移过去，因为这样回退最少：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181317.gif" alt=""></p><p>当然，如果遇到的字符是 “B”，状态<code>X</code>也不能进行「状态推进」，只能回退，<code>j</code>只要跟着<code>X</code>指引的方向回退就行了：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181335.jpg" alt=""></p><p>你也许会问，这个<code>X</code>怎么知道遇到字符 “B” 要回退到状态 0 呢？因为<code>X</code>永远跟在<code>j</code>的身后，状态<code>X</code>如何转移，在之前就已经算出来了。动态规划算法不就是利用过去的结果解决现在的问题吗？</p><p>这样，我们就可以细化一下刚才的框架代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(M):</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">256</span>):</span><br><span class="line">        <span class="keyword">if</span> c == <span class="built_in">ord</span>(pat[j]):</span><br><span class="line">            <span class="comment"># 状态推进</span></span><br><span class="line">            dp[j][c] = j + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 状态重启</span></span><br><span class="line">            <span class="comment"># 委托 X 计算重启位置</span></span><br><span class="line">            dp[j][c] = dp[X][c]</span><br></pre></td></tr></table></figure><blockquote><h3 id="四、代码实现"><a href="#四、代码实现" class="headerlink" title="四、代码实现"></a>四、代码实现</h3><ul><li>注意python如何生成二维矩阵</li></ul></blockquote><p>如果之前的内容你都能理解，恭喜你，现在就剩下一个问题：影子状态<code>X</code>是如何得到的呢？下面先直接看完整代码吧。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMP</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, pat</span>):</span></span><br><span class="line">        self.pat = pat</span><br><span class="line">        M = <span class="built_in">len</span>(pat)</span><br><span class="line">        <span class="comment"># dp[状态][字符] = 下个状态</span></span><br><span class="line">        self.dp = [[<span class="number">0</span>] * <span class="number">256</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(M)]</span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="comment">#     二维矩阵的生成    #</span></span><br><span class="line">        <span class="comment">#      M 行 256 列    #      </span></span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="comment"># base case</span></span><br><span class="line">        self.dp[<span class="number">0</span>][<span class="built_in">ord</span>(pat[<span class="number">0</span>])] = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 影子状态 X 初始为 0</span></span><br><span class="line">        X = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 当前状态 j 从 1 开始</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, M):</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">256</span>):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">ord</span>(pat[j]) == c:</span><br><span class="line">                    self.dp[j][c] = j + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.dp[j][c] = self.dp[X][c]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新影子状态</span></span><br><span class="line">            X = self.dp[X][<span class="built_in">ord</span>(pat[j])]</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self</span>):</span></span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p>先解释一下这一行代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># base case</span></span><br><span class="line">dp[<span class="number">0</span>][<span class="built_in">ord</span>(pat[<span class="number">0</span>])] = <span class="number">1</span></span><br></pre></td></tr></table></figure><p>这行代码是 base case，只有遇到 pat[0] 这个字符才能使状态从 0 转移到 1，遇到其它字符的话还是停留在状态 0。</p><p>影子状态<code>X</code>是先初始化为 0，然后随着<code>j</code>的前进而不断更新的。下面看看到底应该<strong>如何更新影子状态<code>X</code></strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, M)</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># 更新影子状态</span></span><br><span class="line">    <span class="comment"># 当前是状态 X，遇到字符 pat[j],</span></span><br><span class="line">    <span class="comment"># pat 应该转移到哪个状态？</span></span><br><span class="line">    X = dp[X][<span class="built_in">ord</span>(pat[J])]</span><br></pre></td></tr></table></figure><p>更新<code>X</code>其实和<code>search</code>函数中更新状态<code>j</code>的过程是非常相似的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">j = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">    <span class="comment"># 当前是状态 j，遇到字符 txt[i]，</span></span><br><span class="line">    <span class="comment"># pat 应该转移到哪个状态？</span></span><br><span class="line">    j = dp[j][<span class="built_in">ord</span>(txt[i])]</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><p><strong>其中的原理非常微妙</strong>，注意代码中 for 循环的变量初始值，可以这样理解：后者是在<code>txt</code>中匹配<code>pat</code>，前者是在<code>pat</code>中匹配<code>pat[1:]</code>，状态<code>X</code>总是落后状态<code>j</code>一个状态，与<code>j</code>具有最长的相同前缀。所以我把<code>X</code>比喻为影子状态，似乎也有一点贴切。</p><p>另外，构建 dp 数组是根据 base case<code>dp[0][..]</code>向后推演。这就是我认为 KMP 算法就是一种动态规划算法的原因。</p><p>下面来看一下状态转移图的完整构造过程，你就能理解状态<code>X</code>作用之精妙了：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210621181353.gif" alt=""></p><p>至此，KMP 算法就已经再无奥妙可言了！看下 KMP 算法的完整代码吧：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMP</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, pat</span>):</span></span><br><span class="line">        self.pat = pat</span><br><span class="line">        M = <span class="built_in">len</span>(pat)</span><br><span class="line">        <span class="comment"># dp[状态][字符] = 下个状态</span></span><br><span class="line">        self.dp = [[<span class="number">0</span>] * <span class="number">256</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(M)]</span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="comment">#     二维矩阵的生成    #</span></span><br><span class="line">        <span class="comment">#      M 行 256 列    #</span></span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="comment"># base case</span></span><br><span class="line">        self.dp[<span class="number">0</span>][<span class="built_in">ord</span>(pat[<span class="number">0</span>])] = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 影子状态 X 初始为 0</span></span><br><span class="line">        X = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 当前状态 j 从 1 开始</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, M):</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">256</span>):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">ord</span>(pat[j]) == c:</span><br><span class="line">                    self.dp[j][c] = j + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.dp[j][c] = self.dp[X][c]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 更新影子状态</span></span><br><span class="line">            X = self.dp[X][<span class="built_in">ord</span>(pat[j])]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, txt</span>):</span></span><br><span class="line">        M = <span class="built_in">len</span>(self.pat)</span><br><span class="line">        N = <span class="built_in">len</span>(txt)</span><br><span class="line">        <span class="comment"># pat 的初始态为 0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">            <span class="comment"># 当前是状态 j，遇到字符 txt[i]，</span></span><br><span class="line">            <span class="comment"># pat 应该转移到哪个状态？</span></span><br><span class="line">            j = self.dp[j][<span class="built_in">ord</span>(txt[i])]</span><br><span class="line">            <span class="comment"># 如果达到终止态，返回匹配开头的索引</span></span><br><span class="line">            <span class="keyword">if</span> j == M: <span class="keyword">return</span> i - M + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 没到达终止态，匹配失败</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure><p>经过之前的详细举例讲解，你应该可以理解这段代码的含义了，当然你也可以把 KMP 算法写成一个函数。核心代码也就是两个函数中 for 循环的部分，数一下有超过十行吗？</p><blockquote><h3 id="五、最后总结"><a href="#五、最后总结" class="headerlink" title="五、最后总结"></a>五、最后总结</h3></blockquote><p>传统的 KMP 算法是使用一个一维数组<code>next</code>记录前缀信息，而本文是使用一个二维数组<code>dp</code>以状态转移的角度解决字符匹配问题，但是空间复杂度仍然是 O(256M) = O(M)。</p><p>在<code>pat</code>匹配<code>txt</code>的过程中，只要明确了「<strong>当前处在哪个状态</strong>」和「<strong>遇到的字符是什么</strong>」这两个问题，就可以确定应该转移到哪个状态（推进或回退）。</p><p>对于一个模式串<code>pat</code>，其总共就有 M 个状态，对于 ASCII 字符，总共不会超过 256 种。所以我们就构造一个数组<code>dp[M][256]</code>来包含所有情况，并且明确<code>dp</code>数组的含义：</p><p><strong><code>dp[j][c] = next</code>表示，当前是状态<code>j</code>，遇到了字符<code>c</code>，应该转移到状态<code>next</code>。</strong></p><p>明确了其含义，就可以很容易写出 search 函数的代码。</p><p>对于如何构建这个<code>dp</code>数组，需要一个辅助状态<code>X</code>，它永远比当前状态<code>j</code>落后一个状态，拥有和<code>j</code>最长的相同前缀，我们给它起了个名字叫「影子状态」。</p><p>在构建当前状态<code>j</code>的转移方向时，只有字符<code>pat[j]</code>才能使状态推进（<code>dp[j][pat[j]] = j+1</code>）；而对于其他字符只能进行状态回退，应该去请教影子状态<code>X</code>应该回退到哪里（<code>dp[j][other] = dp[X][other]</code>，其中<code>other</code>是除了<code>pat[j]</code>之外所有字符）。</p><p>对于影子状态<code>X</code>，我们把它初始化为 0，并且随着<code>j</code>的前进进行更新，更新的方式和 search 过程更新<code>j</code>的过程非常相似（<code>X = dp[X][pat[j]]</code>）。</p><p>KMP 算法也就是动态规划的思路，是按照一套框架来的，无非就是描述问题逻辑，明确<code>dp</code>数组含义，定义 base case 这点破事。</p><p>希望这篇文章能让大家对动态规划有更深的理解，并摆脱被 KMP 算法支配的恐惧。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;动态规划之-KMP-算法详解&quot;&gt;&lt;a href=&quot;#动态规划之-KMP-算法详解&quot; class=&quot;headerlink&quot; title=&quot;动态规划之 KMP 算法详解&quot;&gt;&lt;/a&gt;动态规划之 KMP 算法详解&lt;/h2&gt;&lt;p&gt;KMP 算法（Knuth-Morris-Pr</summary>
      
    
    
    
    <category term="动态规划" scheme="https://xxren8218.github.io/categories/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
    
  </entry>
  
  <entry>
    <title>剑指Offer（五十六）：删除排序链表中重复的结点—2</title>
    <link href="https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E7%BB%93%E7%82%B9%E2%80%942.html"/>
    <id>https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E7%BB%93%E7%82%B9%E2%80%942.html</id>
    <published>2021-06-17T10:04:34.000Z</published>
    <updated>2021-06-17T10:05:39.292Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h1><p>在一个排序的[链表)中，存在重复的结点，请删除该[链表]中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;3-&gt;4-&gt;5。</p><h1 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h1><p>由于给定的链表是排好序的，因此重复的元素在链表中出现的位置是连续的，因此我们只需要对链表进行一次遍历，就可以删除重复的元素。</p><p>具体地，我们从指针cur 指向链表的头节点，随后开始对链表进行遍历。如果当前 cur 与 cur.next 对应的元素相同，那么我们就将 cur.next 从链表中移除；否则说明链表中已经不存在其它与 cur 对应的元素相同的节点，因此可以将 cur 指向 cur.next。</p><p>当遍历完整个链表之后，我们返回链表的头节点即可。</p><p><strong>细节</strong></p><p>当我们遍历到链表的最后一个节点时，cur.next 为空节点，如果不加以判断，访问 cur.next 对应的元素会产生运行错误。因此我们只需要遍历到链表的最后一个节点，而不需要遍历完整个链表。</p><h1 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span>(<span class="params">self, head</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head: <span class="keyword">return</span> head</span><br><span class="line">        cur = head</span><br><span class="line">        <span class="keyword">while</span> cur.<span class="built_in">next</span>:</span><br><span class="line">            <span class="keyword">if</span> cur.val == cur.<span class="built_in">next</span>.val:</span><br><span class="line">                cur.<span class="built_in">next</span> = cur.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cur = cur.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h1&gt;&lt;p&gt;在一个排序的[链表)中，存在重复的结点，请删除该[链表]中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&amp;g</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="链表" scheme="https://xxren8218.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（五十六）：删除排序链表中重复的结点</title>
    <link href="https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E7%BB%93%E7%82%B9.html"/>
    <id>https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E9%87%8D%E5%A4%8D%E7%9A%84%E7%BB%93%E7%82%B9.html</id>
    <published>2021-06-17T10:03:30.000Z</published>
    <updated>2021-06-17T10:04:03.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h1><p>在一个排序的[链表)中，存在重复的结点，请删除该[链表]中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5 处理后为 1-&gt;2-&gt;5。</p><h1 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h1><p>由于给定的链表是排好序的，因此重复的元素在链表中出现的位置是连续的，因此我们只需要对链表进行一次遍历，就可以删除重复的元素。由于链表的头节点可能会被删除，因此我们需要额外使用一个哑节点（dum node）指向链表的头节点。</p><p>具体地，我们从指针 cur 指向链表的哑节点，随后开始对链表进行遍历。如果当前cur.next 与 cur.next.next 对应的元素相同，那么我们就需要将 cur.next 以及所有后面拥有相同元素值的链表节点全部删除。我们记下这个元素值 x，随后不断将 cur.next 从链表中移除，直到 cur.next 为空节点或者其元素值不等于 x 为止。此时，我们将链表中所有元素值为 x 的节点全部删除。</p><p>如果当前 cur.next 与 cur.next.next 对应的元素不相同，那么说明链表中只有一个元素值为 cur.next 的节点，那么我们就可以将 cur 指向 cur.next。</p><p>当遍历完整个链表之后，我们返回链表的的哑节点的下一个节点 dum.next 即可。</p><p><strong>细节</strong></p><p>需要注意 cur.next 以及cur.next.next 可能为空节点，如果不加以判断，可能会产生运行错误。</p><h1 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        </span><br><span class="line">        dum = ListNode(<span class="number">0</span>, head)</span><br><span class="line"></span><br><span class="line">        cur = dum</span><br><span class="line">        <span class="keyword">while</span> cur.<span class="built_in">next</span> <span class="keyword">and</span> cur.<span class="built_in">next</span>.<span class="built_in">next</span>:</span><br><span class="line">            <span class="keyword">if</span> cur.<span class="built_in">next</span>.val == cur.<span class="built_in">next</span>.<span class="built_in">next</span>.val:</span><br><span class="line">                x = cur.<span class="built_in">next</span>.val</span><br><span class="line">                <span class="keyword">while</span> cur.<span class="built_in">next</span> <span class="keyword">and</span> cur.<span class="built_in">next</span>.val == x:</span><br><span class="line">                    cur.<span class="built_in">next</span> = cur.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cur = cur.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dum.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h1&gt;&lt;p&gt;在一个排序的[链表)中，存在重复的结点，请删除该[链表]中重复的结点，重复的结点不保留，返回链表头指针。 例如，链表1-&amp;g</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="链表" scheme="https://xxren8218.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（五十五）：链表中环的入口结点</title>
    <link href="https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9A%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%8E%AF%E7%9A%84%E5%85%A5%E5%8F%A3%E7%BB%93%E7%82%B9.html"/>
    <id>https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9A%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%8E%AF%E7%9A%84%E5%85%A5%E5%8F%A3%E7%BB%93%E7%82%B9.html</id>
    <published>2021-06-17T10:01:28.000Z</published>
    <updated>2021-06-17T10:02:40.423Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h1><p>一个 <code>[链表]</code> 中包含环，请找出该链表的环的入口结点。</p><h1 id="2-思路一：快慢指针"><a href="#2-思路一：快慢指针" class="headerlink" title="2.思路一：快慢指针"></a>2.思路一：快慢指针</h1><p>可以用两个指针来解决这个问题。先定义两个指针P1和P2指向链表的头结点。如果链表中的环有n个结点，指针P1先在链表上向前移动n步，然后两个指针以相同的速度向前移动。当第二个指针指向的入口结点时，第一个指针已经围绕着揍了一圈又回到了入口结点。</p><p>以下图为例，指针P1和P2在初始化时都指向链表的头结点。由于环中有4个结点，指针P1先在链表上向前移动4步。接下来两个指针以相同的速度在链表上向前移动，直到它们相遇。它们相遇的结点正好是环的入口结点。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617180225.png" alt=""></p><p><strong>现在的关键问题是如何知道环中有几点节点呢？</strong></p><p>可以使用快慢指针，一个每次走一步，一个每次走两步。如果两个指针相遇，表明链表中存在环，并且两个指针相遇的结点一定在环中。</p><p>随后，我们就从相遇的这个环中结点出发，一边继续向前移动一边计数，当再次回到这个结点时，就可以得到环中结点数目了。</p><h1 id="3-思路二：辅助列表"><a href="#3-思路二：辅助列表" class="headerlink" title="3.思路二：辅助列表"></a>3.思路二：辅助列表</h1><p>可以直接建立一个列表来存放每个node，若不存在node,则添加进去，若存在，直接返回即可。</p><h1 id="4-代码一："><a href="#4-代码一：" class="headerlink" title="4.代码一："></a>4.代码一：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">EntryNodeOfLoop</span>(<span class="params">self, pHead</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        meetingnode = self.MeetingNode(pHead)</span><br><span class="line">        <span class="keyword">if</span> meetingnode == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        nodeslop = <span class="number">1</span></span><br><span class="line">        node1 = meetingnode</span><br><span class="line">        <span class="keyword">while</span> node1.<span class="built_in">next</span> != meetingnode:</span><br><span class="line">            node1 = node1.<span class="built_in">next</span></span><br><span class="line">            nodeslop += <span class="number">1</span></span><br><span class="line">        node1 = pHead</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(nodeslop):</span><br><span class="line">            node1 = node1.<span class="built_in">next</span></span><br><span class="line">        node2 = pHead</span><br><span class="line">        <span class="keyword">while</span> node1 != node2:</span><br><span class="line">            node1 = node1.<span class="built_in">next</span></span><br><span class="line">            node2 = node2.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> node1</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">MeetingNode</span>(<span class="params">self, pHead</span>):</span></span><br><span class="line">        slow = pHead.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">if</span> slow == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        fast = slow.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">while</span> fast != <span class="literal">None</span> <span class="keyword">and</span> slow != <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> slow == fast:</span><br><span class="line">                <span class="keyword">return</span> fast</span><br><span class="line">            slow = slow.<span class="built_in">next</span></span><br><span class="line">            fast = fast.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> fast != <span class="literal">None</span>:</span><br><span class="line">                fast = fast.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h1 id="5-代码二："><a href="#5-代码二：" class="headerlink" title="5.代码二："></a>5.代码二：</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">EntryNodeOfLoop</span>(<span class="params">self, pHead</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> pHead:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        p1 = pHead</span><br><span class="line">        l = []</span><br><span class="line">        <span class="keyword">while</span> p1:</span><br><span class="line">            <span class="keyword">if</span> p1 <span class="keyword">in</span> l:</span><br><span class="line">                <span class="keyword">return</span> p1</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l.append(p1)</span><br><span class="line">                p1 = p1.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h1&gt;&lt;p&gt;一个 &lt;code&gt;[链表]&lt;/code&gt; 中包含环，请找出该链表的环的入口结点。&lt;/p&gt;
&lt;h1 id=&quot;2-思路一：快慢指</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="链表" scheme="https://xxren8218.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
    <category term="快慢指针" scheme="https://xxren8218.github.io/tags/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88/"/>
    
    <category term="辅助列表" scheme="https://xxren8218.github.io/tags/%E8%BE%85%E5%8A%A9%E5%88%97%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（三十六）：两个链表的第一个公共结点</title>
    <link href="https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E4%B8%A4%E4%B8%AA%E9%93%BE%E8%A1%A8%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%85%AC%E5%85%B1%E7%BB%93%E7%82%B9.html"/>
    <id>https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%89%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E4%B8%A4%E4%B8%AA%E9%93%BE%E8%A1%A8%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%85%AC%E5%85%B1%E7%BB%93%E7%82%B9.html</id>
    <published>2021-06-17T09:59:38.000Z</published>
    <updated>2021-06-17T10:00:48.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h1><p>输入两个<code>[链表]</code>，找出它们的第一个公共结点.</p><h1 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h1><p>公共结点的样子：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617180033.png" alt=""></p><p>上图就是一个有公共结点的例子，在公共结点之后，两个链表指针指向的地址是相同的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入：intersectVal = <span class="number">8</span>, listA = [<span class="number">4</span>,<span class="number">1</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>], listB = [<span class="number">5</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>], skipA = <span class="number">2</span>, skipB = <span class="number">3</span></span><br><span class="line">输出：Reference of the node <span class="keyword">with</span> value = <span class="number">8</span></span><br><span class="line">输入解释：相交节点的值为 <span class="number">8</span> （注意，如果两个列表相交则不能为 <span class="number">0</span>）。从各自的表头开始算起，链表 A 为 [<span class="number">4</span>,<span class="number">1</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>]，链表 B 为 [<span class="number">5</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>]。在 A 中，相交节点前有 <span class="number">2</span> 个节点；在 B 中，相交节点前有 <span class="number">3</span> 个节点</span><br></pre></td></tr></table></figure><p>我们可以把两个链表拼接起来，一个 <code>headA</code> 在前  <code>headB</code> 在后，一个 <code>headB</code> 在前 <code>headA</code> 在后。这样，生成了两个相同长度的链表，那么我们只要同时遍历这两个表，就一定能找到公共结点。时间复杂度O(m+n)，空间复杂度O(m+n)。</p><h1 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getIntersectionNode</span>(<span class="params">self, headA, headB</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type head1, head1: ListNode</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> headA <span class="keyword">or</span> <span class="keyword">not</span> headB:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        cur1, cur2 = headA, headB</span><br><span class="line">        <span class="keyword">while</span> cur1 != cur2:</span><br><span class="line">            cur1 = cur1.<span class="built_in">next</span> <span class="keyword">if</span> cur1 != <span class="literal">None</span> <span class="keyword">else</span> headB</span><br><span class="line">            cur2 = cur2.<span class="built_in">next</span> <span class="keyword">if</span> cur2 != <span class="literal">None</span> <span class="keyword">else</span> headA</span><br><span class="line">        <span class="keyword">return</span> cur1</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h1&gt;&lt;p&gt;输入两个&lt;code&gt;[链表]&lt;/code&gt;，找出它们的第一个公共结点.&lt;/p&gt;
&lt;h1 id=&quot;2-思路&quot;&gt;&lt;a href=</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="链表" scheme="https://xxren8218.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（二十五）：复杂链表的复制</title>
    <link href="https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9A%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6.html"/>
    <id>https://xxren8218.github.io/20210617/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9A%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6.html</id>
    <published>2021-06-17T09:55:35.000Z</published>
    <updated>2021-06-17T09:59:09.941Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h1><p>请实现 <code>copyRandomList</code> 函数，复制一个复杂链表。在复杂链表中，每个节点除了有一个 <code>next</code> 指针指向下一个节点，还有一个 <code>random</code> 指针指向链表中的任意节点或者 <code>null</code>。</p><p>示例 1：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617175717.PNG" alt=""></p><p>输入：<code>head = [[7,null],[13,0],[11,4],[10,2],[1,0]]</code><br>输出：<code>[[7,null],[13,0],[11,4],[10,2],[1,0]]</code></p><h1 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h1><p>普通链表的节点定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a Node.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x: <span class="built_in">int</span>, <span class="built_in">next</span>: <span class="string">&#x27;Node&#x27;</span> = <span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = <span class="built_in">int</span>(x)</span><br><span class="line">        self.<span class="built_in">next</span> = <span class="built_in">next</span></span><br></pre></td></tr></table></figure><p>本题链表的节点定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a Node.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x: <span class="built_in">int</span>, <span class="built_in">next</span>: <span class="string">&#x27;Node&#x27;</span> = <span class="literal">None</span>, random: <span class="string">&#x27;Node&#x27;</span> = <span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = <span class="built_in">int</span>(x)</span><br><span class="line">        self.<span class="built_in">next</span> = <span class="built_in">next</span></span><br><span class="line">        self.random = random</span><br></pre></td></tr></table></figure><p>给定链表的头节点 head ，复制普通链表很简单，只需遍历链表，每轮建立新节点 + 构建前驱节点 pre 和当前节点 node 的引用指向即可。</p><p>本题链表的节点新增了 <code>random</code> 指针，指向链表中的 任意节点 或者 <code>null</code> 。这个 <code>random</code> 指针意味着在复制过程中，除了构建前驱节点和当前节点的引用指向 <code>pre.next</code> ，还要构建前驱节点和其随机节点的引用指向 <code>pre.random</code> 。</p><p><strong>本题难点：</strong> 在复制链表的过程中构建新链表各节点的 <code>random</code> 引用指向。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617175740.PNG" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">copyRandomList</span>(<span class="params">self, head: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; &#x27;Node&#x27;:</span></span><br><span class="line">        cur = head</span><br><span class="line">        dum = pre = Node(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            node = Node(cur.val) <span class="comment"># 复制节点 cur</span></span><br><span class="line">            pre.<span class="built_in">next</span> = node      <span class="comment"># 新链表的 前驱节点 -&gt; 当前节点</span></span><br><span class="line">            <span class="comment"># pre.random = &#x27;???&#x27; # 新链表的 「 前驱节点 -&gt; 当前节点 」 无法确定</span></span><br><span class="line">            cur = cur.<span class="built_in">next</span>       <span class="comment"># 遍历下一节点</span></span><br><span class="line">            pre = node           <span class="comment"># 保存当前新节点</span></span><br><span class="line">        <span class="keyword">return</span> dum.<span class="built_in">next</span></span><br></pre></td></tr></table></figure><p>本文介绍 <code>「哈希表」</code> ，<code>「拼接 + 拆分」</code> 两种方法。哈希表方法比较直观；拼接 + 拆分方法的空间复杂度更低。</p><h4 id="方法一：哈希表"><a href="#方法一：哈希表" class="headerlink" title="方法一：哈希表"></a>方法一：哈希表</h4><p>利用哈希表的查询特点，考虑构建 <strong>原链表节点</strong> 和 <strong>新链表对应节点</strong> 的键值对映射关系，再遍历构建新链表各节点的 <code>next</code> 和 <code>random</code> 引用指向即可。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617175800.PNG" alt=""></p><h4 id="方法二：拼接-拆分"><a href="#方法二：拼接-拆分" class="headerlink" title="方法二：拼接 + 拆分"></a>方法二：拼接 + 拆分</h4><p>考虑构建 <code>原节点 1 -&gt; 新节点 1 -&gt; 原节点 2 -&gt; 新节点 2 -&gt; …… 的拼接链表</code>，如此便可在访问原节点的 <code>random</code> 指向节点的同时找到新对应新节点的 <code>random</code> 指向节点。</p><p>如下图将 <code>B.random.next -&gt; B&#39;.random</code>，即实现了<code>B&#39;到A‘</code>的指向</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617175817.jpg" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617175835.PNG" alt=""></p><h1 id="3-代码一：哈希表"><a href="#3-代码一：哈希表" class="headerlink" title="3.代码一：哈希表"></a>3.代码一：哈希表</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">copyRandomList</span>(<span class="params">self, head: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; &#x27;Node&#x27;:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head: <span class="keyword">return</span></span><br><span class="line">        dic = &#123;&#125;</span><br><span class="line">        <span class="comment"># 1. 复制各节点，并建立 “原节点 -&gt; 新节点” 的 Map 映射</span></span><br><span class="line">        cur = head</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            dic[cur] = Node(cur.val)</span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        </span><br><span class="line">        cur = head</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 构建新节点的 next 和 random 指向</span></span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            dic[cur].<span class="built_in">next</span> = dic.get(cur.<span class="built_in">next</span>)</span><br><span class="line">            dic[cur].random = dic.get(cur.random)</span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        <span class="comment"># 3. 返回新链表的头节点</span></span><br><span class="line">        <span class="keyword">return</span> dic[head]</span><br></pre></td></tr></table></figure><h1 id="4-代码二：拼接-拆分"><a href="#4-代码二：拼接-拆分" class="headerlink" title="4.代码二：拼接 + 拆分"></a>4.代码二：拼接 + 拆分</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">copyRandomList</span>(<span class="params">self, head: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; &#x27;Node&#x27;:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head: <span class="keyword">return</span></span><br><span class="line">        cur = head</span><br><span class="line">        <span class="comment"># 1. 复制各节点，并构建拼接链表</span></span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            tmp = Node(cur.val)</span><br><span class="line">            tmp.<span class="built_in">next</span> = cur.<span class="built_in">next</span></span><br><span class="line">            cur.<span class="built_in">next</span> = tmp</span><br><span class="line">            cur = tmp.<span class="built_in">next</span></span><br><span class="line">        <span class="comment"># 2. 构建各新节点的 random 指向</span></span><br><span class="line">        cur = head</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            <span class="keyword">if</span> cur.random:</span><br><span class="line">                cur.<span class="built_in">next</span>.random = cur.random.<span class="built_in">next</span></span><br><span class="line">            cur = cur.<span class="built_in">next</span>.<span class="built_in">next</span> <span class="comment"># 注意位置</span></span><br><span class="line">        <span class="comment"># 3. 拆分两链表</span></span><br><span class="line">        cur = res = head.<span class="built_in">next</span></span><br><span class="line">        pre = head</span><br><span class="line">        <span class="keyword">while</span> cur.<span class="built_in">next</span>: <span class="comment"># 注意是cur.next，倒数第二个cur节点，不然下面的cur.next.next不成立。</span></span><br><span class="line">            pre.<span class="built_in">next</span> = pre.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            cur.<span class="built_in">next</span> = cur.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            pre = pre.<span class="built_in">next</span></span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        pre.<span class="built_in">next</span> = <span class="literal">None</span> <span class="comment"># 单独处理原链表尾节点</span></span><br><span class="line">        <span class="keyword">return</span> res      <span class="comment"># 返回新链表头节点</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h1&gt;&lt;p&gt;请实现 &lt;code&gt;copyRandomList&lt;/code&gt; 函数，复制一个复杂链表。在复杂链表中，每个节点除了有一个 &lt;</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="链表" scheme="https://xxren8218.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
    <category term="哈希表" scheme="https://xxren8218.github.io/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>16-电影推荐(ContentBased)_物品画像</title>
    <link href="https://xxren8218.github.io/20210617/16-%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90-ContentBased-%E7%89%A9%E5%93%81%E7%94%BB%E5%83%8F.html"/>
    <id>https://xxren8218.github.io/20210617/16-%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90-ContentBased-%E7%89%A9%E5%93%81%E7%94%BB%E5%83%8F.html</id>
    <published>2021-06-16T16:53:27.000Z</published>
    <updated>2021-06-16T16:55:00.782Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于内容的电影推荐：物品画像"><a href="#基于内容的电影推荐：物品画像" class="headerlink" title="基于内容的电影推荐：物品画像"></a>基于内容的电影推荐：物品画像</h2><p>物品画像构建步骤：</p><ul><li>利用tags.csv中每部电影的标签作为电影的候选关键词</li><li>利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</li><li>将电影的分类词直接作为每部电影的画像标签</li></ul><h2 id="基于TF-IDF的特征提取技术"><a href="#基于TF-IDF的特征提取技术" class="headerlink" title="基于TF-IDF的特征提取技术"></a>基于TF-IDF的特征提取技术</h2><p>前面提到，物品画像的特征标签主要都是指的如电影的导演、演员、图书的作者、出版社等结构话的数据，也就是他们的特征提取，尤其是体征向量的计算是比较简单的，如直接给作品的分类定义0或者1的状态。</p><p>但另外一些特征，比如电影的内容简介、电影的影评、图书的摘要等文本数据，这些被称为<strong>非结构化数据</strong>，首先他们本应该也属于物品的一个特征标签，但是这样的特征标签进行量化时，也就是计算它的特征向量时是很难去定义的。</p><p>因此这时就需要借助一些<strong>自然语言处理、信息检索等技术</strong>，将如用户的文本评论或其他文本内容信息的非结构化数据进行量化处理，从而实现更加完善的物品画像/用户画像。</p><p>TF-IDF算法便是其中一种在自然语言处理领域中应用比较广泛的一种算法。可用来提取目标文档中，并得到关键词用于计算对于目标文档的权重，并将这些权重组合到一起得到特征向量。</p><h4 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h4><p>TF-IDF自然语言处理领域中计算文档中词或短语的权值的方法，是<strong>词频</strong>（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）的乘积。TF指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被正规化，以防止它偏向长的文件（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。IDF是一个词语普遍重要性的度量，某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。</p><p>TF-IDF算法基于一个这样的假设：若一个词语在目标文档中出现的频率高而在其他文档中出现的频率低，那么这个词语就可以用来区分出目标文档。这个假设需要掌握的有两点：</p><ul><li>在本文档出现的频率高；</li><li>在其他文档出现的频率低。</li></ul><p>因此，TF-IDF算法的计算可以分为词频（Term Frequency，TF）和逆转文档频率（Inverse Document Frequency，IDF）两部分，由TF和IDF的乘积来设置文档词语的权重。</p><p>TF指的是一个词语在文档中的出现频率。假设文档集包含的文档数为<script type="math/tex">N</script>，文档集中包含关键词<script type="math/tex">k_i</script>的文档数为<script type="math/tex">n_i</script>，<script type="math/tex">f_{ij}</script>表示关键词<script type="math/tex">k_i</script>在文档<script type="math/tex">d_j</script>中出现的次数，<script type="math/tex">f_{dj}</script>表示文档<script type="math/tex">d_j</script>中出现的词语总数，<script type="math/tex">k_i</script>在文档dj中的词频<script type="math/tex">TF_{ij}</script>定义为：<script type="math/tex">TF_{ij}=\frac {f_{ij}}{f_{dj}}</script>。并且注意，这个数字通常会被正规化，以防止它偏向长的文件（指同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。</p><p>IDF是一个词语普遍重要性的度量。表示某一词语在整个文档集中出现的频率，由它计算的结果取对数得到关键词<script type="math/tex">k_i</script>的逆文档频率<script type="math/tex">IDF_i</script>：<script type="math/tex">IDF_i=log\frac {N}{n_i}</script></p><p>由TF和IDF计算词语的权重为：<script type="math/tex">w_{ij}=TF_{ij}</script><strong>·</strong><script type="math/tex">IDF_{i}=\frac {f_{ij}}{f_{dj}}</script><strong>·</strong><script type="math/tex">log\frac {N}{n_i}</script></p><p><strong>结论：TF-IDF与词语在文档中的出现次数成正比，与该词在整个文档集中的出现次数成反比。</strong></p><p><strong>用途：在目标文档中，提取关键词(特征标签)的方法就是将该文档所有词语的TF-IDF计算出来并进行对比，取其中TF-IDF值最大的k个数组成目标文档的特征向量用以表示文档。</strong></p><p>注意：文档中存在的停用词（Stop Words），如“是”、“的”之类的，对于文档的中心思想表达没有意义的词，在分词时需要先过滤掉再计算其他词语的TF-IDF值。</p><h4 id="算法举例"><a href="#算法举例" class="headerlink" title="算法举例"></a>算法举例</h4><p>对于计算影评的TF-IDF，以电影“加勒比海盗：黑珍珠号的诅咒”为例，假设它总共有1000篇影评，其中一篇影评的总词语数为200，其中出现最频繁的词语为“海盗”、“船长”、“自由”，分别是20、15、10次，并且这3个词在所有影评中被提及的次数分别为1000、500、100，就这3个词语作为关键词的顺序计算如下。</p><ol><li><p>将影评中出现的停用词过滤掉，计算其他词语的词频。以出现最多的三个词为例进行计算如下：</p><ul><li>“海盗”出现的词频为20/200＝0.1</li><li>“船长”出现的词频为15/200=0.075</li><li>“自由”出现的词频为10/200=0.05；</li></ul></li><li><p>计算词语的逆文档频率如下：</p><ul><li>“海盗”的IDF为：log(1000/1000)=0</li><li>“船长”的IDF为：log(1000/500)=0.3<br>“自由”的IDF为：log(1000/100)=1</li></ul></li><li>由1和2计算的结果求出词语的TF-IDF结果，“海盗”为0，“船长”为0.0225，“自由”为0.05。</li></ol><p>通过对比可得，该篇影评的关键词排序应为：“自由”、“船长”、“海盗”。把这些词语的TF-IDF值作为它们的权重按照对应的顺序依次排列，就得到这篇影评的特征向量，我们就用这个向量来代表这篇影评，向量中每一个维度的分量大小对应这个属性的重要性。</p><p>将总的影评集中所有的影评向量与特定的系数相乘求和，得到这部电影的综合影评向量，与电影的基本属性结合构建视频的物品画像，同理构建用户画像，可采用多种方法计算物品画像和用户画像之间的相似度，为用户做出推荐。</p><h4 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">- 利用tags.csv中每部电影的标签作为电影的候选关键词</span></span><br><span class="line"><span class="string">- 利用TF·IDF计算每部电影的标签的tfidf值，选取TOP-N个关键词作为电影画像标签</span></span><br><span class="line"><span class="string">- 并将电影的分类词直接作为每部电影的画像标签</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie_dataset</span>():</span></span><br><span class="line">    <span class="comment"># 加载基于所有电影的标签</span></span><br><span class="line">    <span class="comment"># all-tags.csv来自ml-latest数据集中</span></span><br><span class="line">    <span class="comment"># 由于ml-latest-small中标签数据太多，因此借助其来扩充</span></span><br><span class="line">    _tags = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/all-tags.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)).dropna()</span><br><span class="line">    tags = _tags.groupby(<span class="string">&quot;movieId&quot;</span>).agg(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载电影列表数据集</span></span><br><span class="line">    movies = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/movies.csv&quot;</span>, index_col=<span class="string">&quot;movieId&quot;</span>)</span><br><span class="line">    <span class="comment"># 将类别词分开</span></span><br><span class="line">    movies[<span class="string">&quot;genres&quot;</span>] = movies[<span class="string">&quot;genres&quot;</span>].apply(<span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">    <span class="comment"># 为每部电影匹配对应的标签数据，如果没有将会是NAN</span></span><br><span class="line">    movies_index = <span class="built_in">set</span>(movies.index) &amp; <span class="built_in">set</span>(tags.index)</span><br><span class="line">    new_tags = tags.loc[<span class="built_in">list</span>(movies_index)]</span><br><span class="line">    ret = movies.join(new_tags)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建电影数据集，包含电影Id、电影名称、类别、标签四个字段</span></span><br><span class="line">    <span class="comment"># 如果电影没有标签数据，那么就替换为空列表</span></span><br><span class="line">    <span class="comment"># map(fun,可迭代对象)--将标签和分类进行合并以便后面的TF-IDF的分析。</span></span><br><span class="line">    movie_dataset = pd.DataFrame(</span><br><span class="line">        <span class="built_in">map</span>(</span><br><span class="line">            <span class="keyword">lambda</span> x: (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], x[<span class="number">2</span>]+x[<span class="number">3</span>]) <span class="keyword">if</span> x[<span class="number">3</span>] <span class="keyword">is</span> <span class="keyword">not</span> np.nan <span class="keyword">else</span> (x[<span class="number">0</span>], x[<span class="number">1</span>], x[<span class="number">2</span>], []), ret.itertuples())</span><br><span class="line">        , columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tags&quot;</span>]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    movie_dataset.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_dataset</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">print(movie_dataset)</span><br></pre></td></tr></table></figure><h4 id="基于TF·IDF提取TOP-N关键词，构建电影画像"><a href="#基于TF·IDF提取TOP-N关键词，构建电影画像" class="headerlink" title="基于TF·IDF提取TOP-N关键词，构建电影画像"></a>基于TF·IDF提取TOP-N关键词，构建电影画像</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset: </span></span><br><span class="line"><span class="string">    :return: </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    movie_profile = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, mid <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.index):</span><br><span class="line">        <span class="comment"># 根据每条数据返回，向量</span></span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        <span class="comment"># 按照TF-IDF值得到top-n的关键词</span></span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        <span class="comment"># 根据关键词提取对应的名称</span></span><br><span class="line">        movie_profile[mid] = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br></pre></td></tr></table></figure><h4 id="完善画像关键词"><a href="#完善画像关键词" class="headerlink" title="完善画像关键词"></a>完善画像关键词</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> TfidfModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_movie_profile</span>(<span class="params">movie_dataset</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    使用tfidf，分析提取topn关键词</span></span><br><span class="line"><span class="string">    :param movie_dataset:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = movie_dataset[<span class="string">&quot;tags&quot;</span>].values</span><br><span class="line"></span><br><span class="line">    <span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line">    <span class="comment"># 根据数据集建立词袋，并统计词频，将所有词放入一个词典，使用索引进行获取</span></span><br><span class="line">    dct = Dictionary(dataset)</span><br><span class="line">    <span class="comment"># 根据将每条数据，返回对应的词索引和词频</span></span><br><span class="line">    corpus = [dct.doc2bow(line) <span class="keyword">for</span> line <span class="keyword">in</span> dataset]</span><br><span class="line">    <span class="comment"># 训练TF-IDF模型，即计算TF-IDF值</span></span><br><span class="line">    model = TfidfModel(corpus)</span><br><span class="line"></span><br><span class="line">    _movie_profile = []</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(movie_dataset.itertuples()):</span><br><span class="line">        mid = data[<span class="number">0</span>]</span><br><span class="line">        title = data[<span class="number">1</span>]</span><br><span class="line">        genres = data[<span class="number">2</span>]</span><br><span class="line">        vector = model[corpus[i]]</span><br><span class="line">        movie_tags = <span class="built_in">sorted</span>(vector, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)[:<span class="number">30</span>]</span><br><span class="line">        topN_tags_weights = <span class="built_in">dict</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (dct[x[<span class="number">0</span>]], x[<span class="number">1</span>]), movie_tags))</span><br><span class="line">        <span class="comment"># 将类别词的添加进去，并设置权重值为1.0</span></span><br><span class="line">        <span class="keyword">for</span> g <span class="keyword">in</span> genres:</span><br><span class="line">            topN_tags_weights[g] = <span class="number">1.0</span></span><br><span class="line">        topN_tags = [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> topN_tags_weights.items()]</span><br><span class="line">        _movie_profile.append((mid, title, topN_tags, topN_tags_weights))</span><br><span class="line"></span><br><span class="line">    movie_profile = pd.DataFrame(_movie_profile, columns=[<span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;title&quot;</span>, <span class="string">&quot;profile&quot;</span>, <span class="string">&quot;weights&quot;</span>])</span><br><span class="line">    movie_profile.set_index(<span class="string">&quot;movieId&quot;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> movie_profile</span><br><span class="line"></span><br><span class="line">movie_dataset = get_movie_dataset()</span><br><span class="line">pprint(create_movie_profile(movie_dataset))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了根据指定关键词迅速匹配到对应的电影，因此需要对物品画像的标签词，建立<strong>倒排索引</strong></p><p><strong>倒排索引介绍</strong></p><p>通常数据存储数据，都是以物品的ID作为索引，去提取物品的其他信息数据</p><p>而倒排索引就是用物品的其他数据作为索引，去提取它们对应的物品的ID列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">建立tag-物品的倒排索引</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inverted_table</span>(<span class="params">movie_profile</span>):</span></span><br><span class="line">    inverted_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> mid, weights <span class="keyword">in</span> movie_profile[<span class="string">&quot;weights&quot;</span>].iteritems():</span><br><span class="line">        <span class="keyword">for</span> tag, weight <span class="keyword">in</span> weights.items():</span><br><span class="line">            <span class="comment">#到inverted_table dict 用tag作为Key去取值 如果取不到就返回[]</span></span><br><span class="line">            _ = inverted_table.get(tag, [])</span><br><span class="line">            _.append((mid, weight))</span><br><span class="line">            inverted_table.setdefault(tag, _)</span><br><span class="line">    <span class="keyword">return</span> inverted_table</span><br><span class="line"></span><br><span class="line">inverted_table = create_inverted_table(movie_profile)</span><br><span class="line">pprint(inverted_table)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于内容的电影推荐：物品画像&quot;&gt;&lt;a href=&quot;#基于内容的电影推荐：物品画像&quot; class=&quot;headerlink&quot; title=&quot;基于内容的电影推荐：物品画像&quot;&gt;&lt;/a&gt;基于内容的电影推荐：物品画像&lt;/h2&gt;&lt;p&gt;物品画像构建步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>15-基于内容的推荐算法</title>
    <link href="https://xxren8218.github.io/20210617/15-%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95.html"/>
    <id>https://xxren8218.github.io/20210617/15-%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95.html</id>
    <published>2021-06-16T16:51:30.000Z</published>
    <updated>2021-06-16T16:54:18.765Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于内容的推荐算法（Content-Based）"><a href="#基于内容的推荐算法（Content-Based）" class="headerlink" title="基于内容的推荐算法（Content-Based）"></a>基于内容的推荐算法（Content-Based）</h2><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>基于内容的推荐方法是非常直接的，它以物品的内容描述信息为依据来做出的推荐，本质上是基于对物品和用户自身的特征或属性的直接分析和计算。</p><p>例如，假设已知电影A是一部喜剧，而恰巧我们得知某个用户喜欢看喜剧电影，那么我们基于这样的已知信息，就可以将电影A推荐给该用户。</p><h4 id="基于内容的推荐实现步骤"><a href="#基于内容的推荐实现步骤" class="headerlink" title="基于内容的推荐实现步骤"></a>基于内容的推荐实现步骤</h4><ul><li><p><strong>画像构建</strong>。顾名思义，画像就是刻画物品或用户的特征。本质上就是给用户或物品贴标签。</p><ul><li><p><strong>物品画像</strong>：例如给电影《战狼2》贴标签，可以有哪些？</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617005246.png" alt=""></p><p>“动作”、”吴京”、”吴刚”、”张翰”、”大陆电影”、”国产”、”爱国”、”军事”等等一系列标签是不是都可以贴上</p></li><li><p><strong>用户画像</strong>：例如已知用户的观影历史是：”《战狼1》”、”《战狼2》”、”《建党伟业》”、”《建军大业》”、”《建国大业》”、”《红海行动》”、”《速度与激情1-8》”等，我们是不是就可以分析出该用户的一些兴趣特征如：”爱国”、”战争”、”赛车”、”动作”、”军事”、”吴京”、”韩三平”等标签。</p></li></ul></li></ul><h6 id="问题：物品的标签来自哪儿？"><a href="#问题：物品的标签来自哪儿？" class="headerlink" title="问题：物品的标签来自哪儿？"></a>问题：物品的标签来自哪儿？</h6><ol><li>PGC    物品画像—冷启动<ul><li>物品自带的属性（物品一产生就具备的）：如电影的标题、导演、演员、类型等等</li><li>服务提供方设定的属性（服务提供方为物品附加的属性）：如短视频话题、微博话题（平台拟定）</li><li>其他渠道：如爬虫</li></ul></li><li>UGC    冷启动问题<ul><li>用户在享受服务过程中提供的物品的属性：如用户评论内容，微博话题（用户拟定）</li></ul></li></ol><p>根据PGC内容构建的物品画像的可以解决物品的冷启动问题</p><h6 id="基于内容推荐的算法流程："><a href="#基于内容推荐的算法流程：" class="headerlink" title="基于内容推荐的算法流程："></a>基于内容推荐的算法流程：</h6><ul><li>根据PGC/UGC内容构建物品画像</li><li>根据用户行为记录生成用户画像</li><li>根据用户画像从物品中寻找最匹配的TOP-N物品进行推荐</li></ul><h6 id="物品冷启动处理："><a href="#物品冷启动处理：" class="headerlink" title="物品冷启动处理："></a>物品冷启动处理：</h6><ul><li>根据PGC内容构建物品画像</li><li>利用物品画像计算物品间两两相似情况</li><li>为每个物品产生TOP-N最相似的物品进行相关推荐：如与该商品相似的商品有哪些？与该文章相似文章有哪些？</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于内容的推荐算法（Content-Based）&quot;&gt;&lt;a href=&quot;#基于内容的推荐算法（Content-Based）&quot; class=&quot;headerlink&quot; title=&quot;基于内容的推荐算法（Content-Based）&quot;&gt;&lt;/a&gt;基于内容的推荐算法（Cont</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>14-BiasSVD算法实现</title>
    <link href="https://xxren8218.github.io/20210617/14-BiasSVD%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0.html"/>
    <id>https://xxren8218.github.io/20210617/14-BiasSVD%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0.html</id>
    <published>2021-06-16T16:50:20.000Z</published>
    <updated>2021-06-16T16:50:52.584Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于矩阵分解的CF算法实现（二）：BiasSVD"><a href="#基于矩阵分解的CF算法实现（二）：BiasSVD" class="headerlink" title="基于矩阵分解的CF算法实现（二）：BiasSVD"></a>基于矩阵分解的CF算法实现（二）：BiasSVD</h2><p>BiasSvd其实就是前面提到的Funk SVD矩阵分解基础上加上了偏置项。</p><h4 id="BiasSvd"><a href="#BiasSvd" class="headerlink" title="BiasSvd"></a>BiasSvd</h4><p>利用BiasSvd预测用户对物品的评分，$k$表示隐含特征数量：</p><script type="math/tex; mode=display">\begin{split}\hat {r}_{ui} &=\mu + b_u + b_i + \vec {p_{uk}}\cdot \vec {q_{ki}}\\&=\mu + b_u + b_i + {\sum_{k=1}}^k p_{uk}q_{ik}\end{split}</script><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>同样对于评分预测我们利用平方差来构建损失函数：</p><script type="math/tex; mode=display">\begin{split}Cost &= \sum_{u,i\in R} (r_{ui}-\hat{r}_{ui})^2\\&=\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i -{\sum_{k=1}}^k p_{uk}q_{ik})^2\end{split}</script><p>加入L2正则化：</p><script type="math/tex; mode=display">Cost = \sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)</script><p>对损失函数求偏导：</p><script type="math/tex; mode=display">\begin{split}\cfrac {\partial}{\partial p_{uk}}Cost &= \cfrac {\partial}{\partial p_{uk}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}\\\\\cfrac {\partial}{\partial q_{ik}}Cost &= \cfrac {\partial}{\partial q_{ik}}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-p_{uk}) + 2\lambda q_{ik}\end{split}</script><script type="math/tex; mode=display">\begin{split}\cfrac {\partial}{\partial b_u}Cost &= \cfrac {\partial}{\partial b_u}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_u\\\\\cfrac {\partial}{\partial b_i}Cost &= \cfrac {\partial}{\partial b_i}[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{b_u}^2+\sum_I{b_i}^2+\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-1) + 2\lambda b_i\end{split}</script><h4 id="随机梯度下降法优化"><a href="#随机梯度下降法优化" class="headerlink" title="随机梯度下降法优化"></a>随机梯度下降法优化</h4><p>梯度下降更新参数$p_{uk}$：</p><script type="math/tex; mode=display">\begin{split}p_{uk}&:=p_{uk} - \alpha\cfrac {\partial}{\partial p_{uk}}Cost\\&:=p_{uk}-\alpha [2\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}]\\&:=p_{uk}+\alpha [\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda p_{uk}]\end{split}</script><p> 同理：</p><script type="math/tex; mode=display">\begin{split}q_{ik}&:=q_{ik} + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda q_{ik}]\end{split}</script><script type="math/tex; mode=display">b_u:=b_u + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_u]</script><script type="math/tex; mode=display">b_i:=b_i + \alpha[\sum_{u,i\in R} (r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda b_i]</script><p><strong>随机梯度下降：</strong></p><script type="math/tex; mode=display">\begin{split}&p_{uk}:=p_{uk}+\alpha [(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda_1 p_{uk}]\\&q_{ik}:=q_{ik} + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda_2 q_{ik}]\end{split}</script><script type="math/tex; mode=display">b_u:=b_u + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_3 b_u]</script><script type="math/tex; mode=display">b_i:=b_i + \alpha[(r_{ui}-\mu - b_u - b_i-{\sum_{k=1}}^k p_{uk}q_{ik}) - \lambda_4 b_i]</script><p>由于P矩阵和Q矩阵是两个不同的矩阵，通常分别采取不同的正则参数，如$\lambda_1$和$\lambda_2$</p><p><strong>算法实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">BiasSvd Model</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiasSvd</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha, reg_p, reg_q, reg_bu, reg_bi, number_LatentFactors=<span class="number">10</span>, number_epochs=<span class="number">10</span>, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        self.alpha = alpha <span class="comment"># 学习率</span></span><br><span class="line">        self.reg_p = reg_p</span><br><span class="line">        self.reg_q = reg_q</span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        self.number_LatentFactors = number_LatentFactors  <span class="comment"># 隐式类别数量</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        fit dataset</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.dataset = pd.DataFrame(dataset)</span><br><span class="line"></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.globalMean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line"></span><br><span class="line">        self.P, self.Q, self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化P和Q矩阵，同时为设置0，1之间的随机值作为初始值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># User-LF</span></span><br><span class="line">        P = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.users_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.users_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="comment"># Item-LF</span></span><br><span class="line">        Q = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.items_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.items_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        使用随机梯度下降，优化结果</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        P, Q = self._init_matrix()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span>%i)</span><br><span class="line">            error_list = []</span><br><span class="line">            <span class="keyword">for</span> uid, iid, r_ui <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                v_pu = P[uid]</span><br><span class="line">                v_qi = Q[iid]</span><br><span class="line">                err = np.float32(r_ui - self.globalMean - bu[uid] - bi[iid] - np.dot(v_pu, v_qi))</span><br><span class="line"></span><br><span class="line">                v_pu += self.alpha * (err * v_qi - self.reg_p * v_pu)</span><br><span class="line">                v_qi += self.alpha * (err * v_pu - self.reg_q * v_qi)</span><br><span class="line">                </span><br><span class="line">                P[uid] = v_pu </span><br><span class="line">                Q[iid] = v_qi</span><br><span class="line">                </span><br><span class="line">                bu[uid] += self.alpha * (err - self.reg_bu * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (err - self.reg_bi * bi[iid])</span><br><span class="line"></span><br><span class="line">                error_list.append(err ** <span class="number">2</span>)</span><br><span class="line">            print(np.sqrt(np.mean(error_list)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> P, Q, bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> uid <span class="keyword">not</span> <span class="keyword">in</span> self.users_ratings.index <span class="keyword">or</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">return</span> self.globalMean</span><br><span class="line"></span><br><span class="line">        p_u = self.P[uid]</span><br><span class="line">        q_i = self.Q[iid]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.globalMean + self.bu[uid] + self.bi[iid] + np.dot(p_u, q_i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bsvd = BiasSvd(<span class="number">0.02</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">    bsvd.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>)</span><br><span class="line">        iid = <span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>)</span><br><span class="line">        print(bsvd.predict(<span class="built_in">int</span>(uid), <span class="built_in">int</span>(iid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于矩阵分解的CF算法实现（二）：BiasSVD&quot;&gt;&lt;a href=&quot;#基于矩阵分解的CF算法实现（二）：BiasSVD&quot; class=&quot;headerlink&quot; title=&quot;基于矩阵分解的CF算法实现（二）：BiasSVD&quot;&gt;&lt;/a&gt;基于矩阵分解的CF算法实现（</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>13-LFM算法实现</title>
    <link href="https://xxren8218.github.io/20210617/13-LFM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0.html"/>
    <id>https://xxren8218.github.io/20210617/13-LFM%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0.html</id>
    <published>2021-06-16T16:46:16.000Z</published>
    <updated>2021-06-16T16:48:43.882Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于矩阵分解的CF算法实现（一）：LFM"><a href="#基于矩阵分解的CF算法实现（一）：LFM" class="headerlink" title="基于矩阵分解的CF算法实现（一）：LFM"></a>基于矩阵分解的CF算法实现（一）：LFM</h2><p>LFM也就是前面提到的Funk SVD矩阵分解</p><h4 id="LFM原理解析"><a href="#LFM原理解析" class="headerlink" title="LFM原理解析"></a>LFM原理解析</h4><p>LFM(latent factor model)隐语义模型核心思想是通过隐含特征联系用户和物品，如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004809.png" alt=""></p><ul><li>P矩阵是User-LF矩阵，即用户和隐含特征矩阵。LF有三个，表示共总有三个隐含特征。</li><li>Q矩阵是LF-Item矩阵，即隐含特征和物品的矩阵</li><li>R矩阵是User-Item矩阵，有P*Q得来</li><li><strong>能处理稀疏评分矩阵</strong></li></ul><p>利用矩阵分解技术，将原始User-Item的评分矩阵（稠密/稀疏）分解为P和Q矩阵，然后利用$P<em>Q$还原出User-Item评分矩阵$R$。整个过程相当于<em>*降维处理</em></em>，其中：</p><ul><li><p>矩阵值$P_{11}$表示用户1对隐含特征1的权重值</p></li><li><p>矩阵值$Q_{11}$表示隐含特征1在物品1上的权重值</p></li><li><p>矩阵值$R_{11}$就表示预测的用户1对物品1的评分，且$R_{11}=\vec{P_{1,k}}\cdot \vec{Q_{k,1}}$</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004828.png" alt=""></p><p>利用LFM预测用户对物品的评分，$k$表示隐含特征数量：</p><script type="math/tex; mode=display">\begin{split}\hat {r}_{ui} &=\vec {p_{uk}}\cdot \vec {q_{ik}}\\&={\sum_{k=1}}^k p_{uk}q_{ik}\end{split}</script><p>因此最终，我们的目标也就是要求出P矩阵和Q矩阵及其当中的每一个值，然后再对用户-物品的评分进行预测。</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>同样对于评分预测我们利用平方差来构建损失函数：</p><script type="math/tex; mode=display">\begin{split}Cost &= \sum_{u,i\in R} (r_{ui}-\hat{r}_{ui})^2\\&=\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2\end{split}</script><p>加入L2正则化：</p><script type="math/tex; mode=display">Cost = \sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)</script><p>对损失函数求偏导：</p><script type="math/tex; mode=display">\begin{split}\cfrac {\partial}{\partial p_{uk}}Cost &= \cfrac {\partial}{\partial p_{uk}}[\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}\\\\\cfrac {\partial}{\partial q_{ik}}Cost &= \cfrac {\partial}{\partial q_{ik}}[\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})^2 + \lambda(\sum_U{p_{uk}}^2+\sum_I{q_{ik}}^2)]\\&=2\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})(-p_{uk}) + 2\lambda q_{ik}\end{split}</script><h4 id="随机梯度下降法优化"><a href="#随机梯度下降法优化" class="headerlink" title="随机梯度下降法优化"></a>随机梯度下降法优化</h4><p>梯度下降更新参数$p_{uk}$：</p><script type="math/tex; mode=display">\begin{split}p_{uk}&:=p_{uk} - \alpha\cfrac {\partial}{\partial p_{uk}}Cost\\&:=p_{uk}-\alpha [2\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})(-q_{ik}) + 2\lambda p_{uk}]\\&:=p_{uk}+\alpha [\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda p_{uk}]\end{split}</script><p> 同理：</p><script type="math/tex; mode=display">\begin{split}q_{ik}&:=q_{ik} + \alpha[\sum_{u,i\in R} (r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda q_{ik}]\end{split}</script><p><strong>随机梯度下降：</strong> 向量乘法 每一个分量相乘 求和</p><script type="math/tex; mode=display">\begin{split}&p_{uk}:=p_{uk}+\alpha [(r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})q_{ik} - \lambda_1 p_{uk}]\\&q_{ik}:=q_{ik} + \alpha[(r_{ui}-{\sum_{k=1}}^k p_{uk}q_{ik})p_{uk} - \lambda_2 q_{ik}]\end{split}</script><p>由于P矩阵和Q矩阵是两个不同的矩阵，通常分别采取不同的正则参数，如$\lambda_1$和$\lambda_2$</p><p><strong>算法实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">LFM Model</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评分预测    1-5</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LFM</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha, reg_p, reg_q, number_LatentFactors=<span class="number">10</span>, number_epochs=<span class="number">10</span>, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        self.alpha = alpha <span class="comment"># 学习率</span></span><br><span class="line">        self.reg_p = reg_p    <span class="comment"># P矩阵正则</span></span><br><span class="line">        self.reg_q = reg_q    <span class="comment"># Q矩阵正则</span></span><br><span class="line">        self.number_LatentFactors = number_LatentFactors  <span class="comment"># 隐式类别数量</span></span><br><span class="line">        self.number_epochs = number_epochs    <span class="comment"># 最大迭代次数</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        fit dataset</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.dataset = pd.DataFrame(dataset)</span><br><span class="line"></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line"></span><br><span class="line">        self.globalMean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line"></span><br><span class="line">        self.P, self.Q = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化P和Q矩阵，同时为设置0，1之间的随机值作为初始值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># User-LF</span></span><br><span class="line">        P = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.users_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.users_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="comment"># Item-LF</span></span><br><span class="line">        Q = <span class="built_in">dict</span>(<span class="built_in">zip</span>(</span><br><span class="line">            self.items_ratings.index,</span><br><span class="line">            np.random.rand(<span class="built_in">len</span>(self.items_ratings), self.number_LatentFactors).astype(np.float32)</span><br><span class="line">        ))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        使用随机梯度下降，优化结果</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        P, Q = self._init_matrix()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span>%i)</span><br><span class="line">            error_list = []</span><br><span class="line">            <span class="keyword">for</span> uid, iid, r_ui <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                <span class="comment"># User-LF P</span></span><br><span class="line">                <span class="comment">## Item-LF Q</span></span><br><span class="line">                v_pu = P[uid] <span class="comment"># 用户向量</span></span><br><span class="line">                v_qi = Q[iid] <span class="comment"># 物品向量</span></span><br><span class="line">                err = np.float32(r_ui - np.dot(v_pu, v_qi))</span><br><span class="line"></span><br><span class="line">                v_pu += self.alpha * (err * v_qi - self.reg_p * v_pu)</span><br><span class="line">                v_qi += self.alpha * (err * v_pu - self.reg_q * v_qi)</span><br><span class="line">                </span><br><span class="line">                P[uid] = v_pu </span><br><span class="line">                Q[iid] = v_qi</span><br><span class="line"></span><br><span class="line">                <span class="comment"># for k in range(self.number_of_LatentFactors):</span></span><br><span class="line">                <span class="comment">#     v_pu[k] += self.alpha*(err*v_qi[k] - self.reg_p*v_pu[k])</span></span><br><span class="line">                <span class="comment">#     v_qi[k] += self.alpha*(err*v_pu[k] - self.reg_q*v_qi[k])</span></span><br><span class="line"></span><br><span class="line">                error_list.append(err ** <span class="number">2</span>)</span><br><span class="line">            print(np.sqrt(np.mean(error_list)))</span><br><span class="line">        <span class="keyword">return</span> P, Q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="comment"># 如果uid或iid不在，我们使用全剧平均分作为预测结果返回</span></span><br><span class="line">        <span class="keyword">if</span> uid <span class="keyword">not</span> <span class="keyword">in</span> self.users_ratings.index <span class="keyword">or</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">return</span> self.globalMean</span><br><span class="line"></span><br><span class="line">        p_u = self.P[uid]</span><br><span class="line">        q_i = self.Q[iid]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.dot(p_u, q_i)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    lfm = LFM(<span class="number">0.02</span>, <span class="number">0.01</span>, <span class="number">0.01</span>, <span class="number">10</span>, <span class="number">100</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    lfm.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>)</span><br><span class="line">        iid = <span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>)</span><br><span class="line">        print(lfm.predict(<span class="built_in">int</span>(uid), <span class="built_in">int</span>(iid)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于矩阵分解的CF算法实现（一）：LFM&quot;&gt;&lt;a href=&quot;#基于矩阵分解的CF算法实现（一）：LFM&quot; class=&quot;headerlink&quot; title=&quot;基于矩阵分解的CF算法实现（一）：LFM&quot;&gt;&lt;/a&gt;基于矩阵分解的CF算法实现（一）：LFM&lt;/h2&gt;&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>12-基于矩阵分解的协同过滤推荐</title>
    <link href="https://xxren8218.github.io/20210617/12-%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90.html"/>
    <id>https://xxren8218.github.io/20210617/12-%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90.html</id>
    <published>2021-06-16T16:42:37.000Z</published>
    <updated>2021-06-16T16:45:35.059Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于矩阵分解的CF算法"><a href="#基于矩阵分解的CF算法" class="headerlink" title="基于矩阵分解的CF算法"></a>基于矩阵分解的CF算法</h2><h4 id="矩阵分解发展史"><a href="#矩阵分解发展史" class="headerlink" title="矩阵分解发展史"></a>矩阵分解发展史</h4><p><strong>Traditional SVD:</strong></p><p>通常SVD矩阵分解指的是SVD（奇异值）分解技术，在这我们姑且将其命名为Traditional SVD（传统并经典着）其公式如下：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004337.jpg" alt=""></p><p>Traditional SVD分解的形式为3个矩阵相乘，中间矩阵为奇异值矩阵。如果想运用SVD分解的话，有一个前提是要求矩阵是<strong>稠密</strong>的，即矩阵里的元素要非空，否则就不能运用SVD分解。</p><p>很显然我们的数据其实绝大多数情况下都是稀疏的，因此如果要使用Traditional SVD，<strong>一般的做法是先用均值或者其他统计学方法来填充矩阵，然后再运用Traditional SVD分解降维，但这样做明显对数据的原始性造成一定影响。</strong></p><p><strong>FunkSVD（LFM）</strong></p><p>刚才提到的Traditional SVD首先需要填充矩阵，然后再进行分解降维，同时存在计算复杂度高的问题，因为要分解成3个矩阵，所以后来提出了Funk SVD的方法，<strong>它不在将矩阵分解为3个矩阵，而是分解为2个用户-隐含特征，项目-隐含特征的矩阵，</strong>Funk SVD也被称为<strong>最原始的</strong>LFM模型</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004354.jpg" alt=""></p><p>借鉴线性回归的思想，通过最小化观察数据的平方来寻求最优的用户和项目的隐含向量表示。同时为了避免过度拟合（Overfitting）观测数据，又提出了带有L2正则项的FunkSVD，上公式：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004440.jpg" alt=""></p><p>以上两种最优化函数都可以通过梯度下降或者随机梯度下降法来寻求最优解。</p><p><strong>BiasSVD:</strong></p><p>在FunkSVD提出来之后，出现了很多变形版本，其中一个相对成功的方法是BiasSVD，顾名思义，即带有偏置项的SVD分解：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004502.jpg" alt=""></p><p>它基于的假设和Baseline基准预测是一样的，但这里将Baseline的偏置引入到了矩阵分解中</p><p><strong>SVD++:</strong></p><p>人们后来又提出了改进的BiasSVD，被称为SVD++，该算法是在BiasSVD的基础上添加了用户的隐式反馈信息：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004524.jpg" alt=""></p><p>显示反馈指的用户的评分这样的行为，隐式反馈指用户的<strong>浏览记录、购买记录、收听记录</strong>等。</p><p>SVD++是基于这样的假设：在BiasSVD基础上，认为用户对于项目的历史浏览记录、购买记录、收听记录等可以从侧面反映用户的偏好。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于矩阵分解的CF算法&quot;&gt;&lt;a href=&quot;#基于矩阵分解的CF算法&quot; class=&quot;headerlink&quot; title=&quot;基于矩阵分解的CF算法&quot;&gt;&lt;/a&gt;基于矩阵分解的CF算法&lt;/h2&gt;&lt;h4 id=&quot;矩阵分解发展史&quot;&gt;&lt;a href=&quot;#矩阵分解发展史&quot; c</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>11-基于回归模型的协同过滤推荐</title>
    <link href="https://xxren8218.github.io/20210617/11-%E5%9F%BA%E4%BA%8E%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90.html"/>
    <id>https://xxren8218.github.io/20210617/11-%E5%9F%BA%E4%BA%8E%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90.html</id>
    <published>2021-06-16T16:37:54.000Z</published>
    <updated>2021-06-16T16:41:54.175Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于回归模型的协同过滤推荐"><a href="#基于回归模型的协同过滤推荐" class="headerlink" title="基于回归模型的协同过滤推荐"></a>基于回归模型的协同过滤推荐</h2><p>如果我们将评分看作是一个连续的值而不是离散的值，那么就可以借助线性回归思想来预测目标用户对某物品的评分。其中一种实现策略被称为Baseline（基准预测）。</p><h4 id="Baseline：基准预测"><a href="#Baseline：基准预测" class="headerlink" title="Baseline：基准预测"></a>Baseline：基准预测</h4><p>Baseline设计思想基于以下的假设：</p><ul><li>有些用户的评分普遍高于其他用户，有些用户的评分普遍低于其他用户。比如有些用户天生愿意给别人好评，心慈手软，比较好说话，而有的人就比较苛刻，总是评分不超过3分（5分满分）</li><li>一些物品的评分普遍高于其他物品，一些物品的评分普遍低于其他物品。比如一些物品一被生产便决定了它的地位，有的比较受人们欢迎，有的则被人嫌弃。</li></ul><p>这个用户或物品普遍高于或低于平均值的差值，我们称为偏置(bias)</p><p><strong>Baseline目标：</strong></p><ul><li>找出每个用户普遍高于或低于他人的偏置值$b_u$</li><li>找出每件物品普遍高于或低于其他物品的偏置值$b_i$</li><li>我们的目标也就转化为寻找最优的$b_u$和$b_i$</li></ul><p>使用Baseline的算法思想预测评分的步骤如下：</p><ul><li><p>计算所有电影的平均评分$\mu$（即全局平均评分）</p></li><li><p>计算每个用户评分与平均评分$\mu$的偏置值$b_u$</p></li><li><p>计算每部电影所接受的评分与平均评分$\mu$的偏置值$b_i$</p></li><li><p>预测用户对电影的评分：</p><script type="math/tex; mode=display">\hat{r}_{ui} = b_{ui} = \mu + b_u + b_i</script></li></ul><p>举例：</p><p>​    比如我们想通过Baseline来预测用户A对电影“阿甘正传”的评分，那么首先计算出整个评分数据集的平均评分$\mu$是3.5分；而用户A是一个比较苛刻的用户，他的评分比较严格，普遍比平均评分低0.5分，即用户A的偏置值$b_i$是-0.5；而电影“阿甘正传”是一部比较热门而且备受好评的电影，它的评分普遍比平均评分要高1.2分，那么电影“阿甘正传”的偏置值$b_i$是+1.2，因此就可以预测出用户A对电影“阿甘正传”的评分为：$3.5+(-0.5)+1.2$，也就是4.2分。</p><p>对于所有电影的平均评分$\mu$是直接能计算出的，因此问题在于要测出每个用户的$b_u$值和每部电影的$b_i$的值。对于线性回归问题，我们可以利用平方差构建损失函数如下：</p><script type="math/tex; mode=display">\begin{split}Cost &= \sum_{u,i\in R}(r_{ui}-\hat{r}_{ui})^2\\&=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2\end{split}</script><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004008.png" alt=""></p><p>加入L2正则化：</p><script type="math/tex; mode=display">Cost=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)</script><p>公式解析：</p><ul><li>公式第一部分$ \sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2$是用来寻找与已知评分数据拟合最好的$b_u$和$b_i$</li><li>公式第二部分$\lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)$是正则化项，用于避免过拟合现象</li></ul><p>对于最小过程的求解，我们一般采用<strong>随机梯度下降法</strong>或者<strong>交替最小二乘法</strong>来优化实现。</p><h4 id="方法一：随机梯度下降法优化"><a href="#方法一：随机梯度下降法优化" class="headerlink" title="方法一：随机梯度下降法优化"></a>方法一：随机梯度下降法优化</h4><p>使用随机梯度下降优化算法预测Baseline偏置值</p><h6 id="step-1：梯度下降法推导"><a href="#step-1：梯度下降法推导" class="headerlink" title="step 1：梯度下降法推导"></a>step 1：梯度下降法推导</h6><p>损失函数：</p><script type="math/tex; mode=display">\begin{split}&J(\theta)=Cost=f(b_u, b_i)\\\\&J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)\end{split}</script><p>梯度下降参数更新原始公式：</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\cfrac{\partial }{\partial \theta_j}J(\theta)</script><p>梯度下降更新$b_u$:</p><p>​    损失函数偏导推导：</p><script type="math/tex; mode=display">\begin{split}\cfrac{\partial}{\partial b_u} J(\theta)&=\cfrac{\partial}{\partial b_u} f(b_u, b_i)\\&=2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)(-1) + 2\lambda{b_u}\\&=-2\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda*b_u\end{split}</script><p>​    $b_u$更新(因为alpha可以人为控制，所以2可以省略掉)：</p><script type="math/tex; mode=display">\begin{split}b_u&:=b_u - \alpha*(-\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + \lambda * b_u)\\&:=b_u + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) - \lambda* b_u)\end{split}</script><p>同理可得，梯度下降更新$b_i$:</p><script type="math/tex; mode=display">b_i:=b_i + \alpha*(\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) -\lambda*b_i)</script><h6 id="step-2：随机梯度下降"><a href="#step-2：随机梯度下降" class="headerlink" title="step 2：随机梯度下降"></a>step 2：随机梯度下降</h6><p>由于<strong>随机梯度下降法</strong>本质上利用<strong>每个样本的损失</strong>来更新参数，而不用每次求出全部的损失和，因此使用SGD时：</p><p>单样本损失值：</p><script type="math/tex; mode=display">\begin{split}error &=r_{ui}-\hat{r}_{ui}\\&= r_{ui}-(\mu+b_u+b_i)\\&= r_{ui}-\mu-b_u-b_i\end{split}</script><p>参数更新：</p><script type="math/tex; mode=display">\begin{split}b_u&:=b_u + \alpha*((r_{ui}-\mu-b_u-b_i) -\lambda*b_u)  \\&:=b_u + \alpha*(error - \lambda*b_u) \\\\b_i&:=b_i + \alpha*((r_{ui}-\mu-b_u-b_i) -\lambda*b_i)\\&:=b_i + \alpha*(error -\lambda*b_i)\end{split}</script><h6 id="step-3：算法实现"><a href="#step-3：算法实现" class="headerlink" title="step 3：算法实现"></a>step 3：算法实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        print(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure><h6 id="Step-4-准确性指标评估——数据的拆分-训练集-和-测试集"><a href="#Step-4-准确性指标评估——数据的拆分-训练集-和-测试集" class="headerlink" title="Step 4: 准确性指标评估——数据的拆分 训练集 和 测试集"></a>Step 4: 准确性指标评估——数据的拆分 训练集 和 测试集</h6><ul><li>添加test方法，然后使用之前实现accuary方法计算准确性指标</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    print(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=<span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合（如1用户有40条数据，训练集有32条，测试集有8条）</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).<span class="built_in">any</span>().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random: <span class="comment"># 是否打乱</span></span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表——pandas的index是不可以修改的。</span></span><br><span class="line">            index = <span class="built_in">list</span>(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x) <span class="comment"># 此处x为测试集所占的百分比 round()取整数</span></span><br><span class="line">            testset_index += <span class="built_in">list</span>(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    print(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>), <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFBySGD</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, alpha, reg, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># 学习率</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="comment"># 正则参数</span></span><br><span class="line">        self.reg = reg</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.sgd()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sgd</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> self.dataset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">                error = real_rating - (self.global_mean + bu[uid] + bi[iid])</span><br><span class="line"></span><br><span class="line">                bu[uid] += self.alpha * (error - self.reg * bu[uid])</span><br><span class="line">                bi[iid] += self.alpha * (error - self.reg * bi[iid])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.<span class="built_in">format</span>(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFBySGD(<span class="number">20</span>, <span class="number">0.1</span>, <span class="number">0.1</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="方法二：交替最小二乘法优化（ALS）"><a href="#方法二：交替最小二乘法优化（ALS）" class="headerlink" title="方法二：交替最小二乘法优化（ALS）"></a>方法二：交替最小二乘法优化（ALS）</h4><p>使用交替最小二乘法优化算法预测Baseline偏置值</p><h6 id="step-1-交替最小二乘法推导"><a href="#step-1-交替最小二乘法推导" class="headerlink" title="step 1: 交替最小二乘法推导"></a>step 1: 交替最小二乘法推导</h6><p>最小二乘法和梯度下降法一样，可以用于求极值。</p><p><strong>最小二乘法思想：对损失函数求偏导，然后再使偏导为0</strong></p><p>同样，损失函数：</p><script type="math/tex; mode=display">J(\theta)=\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i)^2 + \lambda*(\sum_u {b_u}^2 + \sum_i {b_i}^2)</script><p>对损失函数求偏导：</p><script type="math/tex; mode=display">\cfrac{\partial}{\partial b_u} f(b_u, b_i) =-2 \sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) + 2\lambda * b_u</script><p>令偏导为0，则可得：</p><script type="math/tex; mode=display">\sum_{u,i\in R}(r_{ui}-\mu-b_u-b_i) = \lambda* b_u\\\sum_{u,i\in R}(r_{ui}-\mu-b_i) = \sum_{u,i\in R} b_u+\lambda * b_u</script><p>为了简化公式，这里令$\sum_{u,i\in R} b_u \approx |R(u)|*b_u$，即直接假设每一项的偏置都相等，可得：</p><script type="math/tex; mode=display">b_u := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_i)}{\lambda_1 + |R(u)|}</script><p>其中$|R(u)|$表示用户$u$的有过评分数量</p><p>同理可得：</p><script type="math/tex; mode=display">b_i := \cfrac {\sum_{u,i\in R}(r_{ui}-\mu-b_u)}{\lambda_2 + |R(i)|}</script><p>其中$|R(i)|$表示物品$i$收到的评分数量</p><p>$b_u$和$b_i$分别属于用户和物品的偏置，因此他们的正则参数可以分别设置两个独立的参数</p><h6 id="step-2-交替最小二乘法应用"><a href="#step-2-交替最小二乘法应用" class="headerlink" title="step 2: 交替最小二乘法应用"></a>step 2: 交替最小二乘法应用</h6><p>通过最小二乘推导，我们最终分别得到了$b_u$和$b_i$的表达式，但他们的表达式中却又各自包含对方，因此这里我们将利用一种叫交替最小二乘的方法来计算他们的值：    </p><ul><li>计算其中一项，先固定其他未知参数，即看作其他未知参数为已知</li><li>如求$b_u$时，将$b_i$看作是已知；求$b_i$时，将$b_u$看作是已知；如此反复交替，不断更新二者的值，求得最终的结果。这就是<strong>交替最小二乘法（ALS）</strong></li></ul><h6 id="step-3-算法实现"><a href="#step-3-算法实现" class="headerlink" title="step 3: 算法实现"></a>step 3: 算法实现</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(uids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _sum / (self.reg_bi + <span class="built_in">len</span>(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(iids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _sum / (self.reg_bu + <span class="built_in">len</span>(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dtype = [(<span class="string">&quot;userId&quot;</span>, np.int32), (<span class="string">&quot;movieId&quot;</span>, np.int32), (<span class="string">&quot;rating&quot;</span>, np.float32)]</span><br><span class="line">    dataset = pd.read_csv(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, usecols=<span class="built_in">range</span>(<span class="number">3</span>), dtype=<span class="built_in">dict</span>(dtype))</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(dataset)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        uid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;uid: &quot;</span>))</span><br><span class="line">        iid = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;iid: &quot;</span>))</span><br><span class="line">        print(bcf.predict(uid, iid))</span><br></pre></td></tr></table></figure><h6 id="Step-4-准确性指标评估"><a href="#Step-4-准确性指标评估" class="headerlink" title="Step 4: 准确性指标评估"></a>Step 4: 准确性指标评估</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span>(<span class="params">data_path, x=<span class="number">0.8</span>, random=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    切分数据集， 这里为了保证用户数量保持不变，将每个用户的评分数据按比例进行拆分</span></span><br><span class="line"><span class="string">    :param data_path: 数据集路径</span></span><br><span class="line"><span class="string">    :param x: 训练集的比例，如x=0.8，则0.2是测试集</span></span><br><span class="line"><span class="string">    :param random: 是否随机切分，默认False</span></span><br><span class="line"><span class="string">    :return: 用户-物品评分矩阵</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    print(<span class="string">&quot;开始切分数据集...&quot;</span>)</span><br><span class="line">    <span class="comment"># 设置要加载的数据字段的类型</span></span><br><span class="line">    dtype = &#123;<span class="string">&quot;userId&quot;</span>: np.int32, <span class="string">&quot;movieId&quot;</span>: np.int32, <span class="string">&quot;rating&quot;</span>: np.float32&#125;</span><br><span class="line">    <span class="comment"># 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分</span></span><br><span class="line">    ratings = pd.read_csv(data_path, dtype=dtype, usecols=<span class="built_in">range</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    testset_index = []</span><br><span class="line">    <span class="comment"># 为了保证每个用户在测试集和训练集都有数据，因此按userId聚合</span></span><br><span class="line">    <span class="keyword">for</span> uid <span class="keyword">in</span> ratings.groupby(<span class="string">&quot;userId&quot;</span>).<span class="built_in">any</span>().index:</span><br><span class="line">        user_rating_data = ratings.where(ratings[<span class="string">&quot;userId&quot;</span>]==uid).dropna()</span><br><span class="line">        <span class="keyword">if</span> random:</span><br><span class="line">            <span class="comment"># 因为不可变类型不能被 shuffle方法作用，所以需要强行转换为列表</span></span><br><span class="line">            index = <span class="built_in">list</span>(user_rating_data.index)</span><br><span class="line">            np.random.shuffle(index)    <span class="comment"># 打乱列表</span></span><br><span class="line">            _index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(index[_index:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将每个用户的x比例的数据作为训练集，剩余的作为测试集</span></span><br><span class="line">            index = <span class="built_in">round</span>(<span class="built_in">len</span>(user_rating_data) * x)</span><br><span class="line">            testset_index += <span class="built_in">list</span>(user_rating_data.index.values[index:])</span><br><span class="line"></span><br><span class="line">    testset = ratings.loc[testset_index]</span><br><span class="line">    trainset = ratings.drop(testset_index)</span><br><span class="line">    print(<span class="string">&quot;完成数据集切分...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> trainset, testset</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuray</span>(<span class="params">predict_results, method=<span class="string">&quot;all&quot;</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    准确性指标计算方法</span></span><br><span class="line"><span class="string">    :param predict_results: 预测结果，类型为容器，每个元素是一个包含uid,iid,real_rating,pred_rating的序列</span></span><br><span class="line"><span class="string">    :param method: 指标方法，类型为字符串，rmse或mae，否则返回两者rmse和mae</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rmse_mae</span>(<span class="params">predict_results</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        rmse和mae评估指标</span></span><br><span class="line"><span class="string">        :param predict_results:</span></span><br><span class="line"><span class="string">        :return: rmse, mae</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        _rmse_sum = <span class="number">0</span></span><br><span class="line">        _mae_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating, pred_rating <span class="keyword">in</span> predict_results:</span><br><span class="line">            length += <span class="number">1</span></span><br><span class="line">            _rmse_sum += (pred_rating - real_rating) ** <span class="number">2</span></span><br><span class="line">            _mae_sum += <span class="built_in">abs</span>(pred_rating - real_rating)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">round</span>(np.sqrt(_rmse_sum / length), <span class="number">4</span>), <span class="built_in">round</span>(_mae_sum / length, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> method.lower() == <span class="string">&quot;rmse&quot;</span>:</span><br><span class="line">        rmse(predict_results)</span><br><span class="line">    <span class="keyword">elif</span> method.lower() == <span class="string">&quot;mae&quot;</span>:</span><br><span class="line">        mae(predict_results)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> rmse_mae(predict_results)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaselineCFByALS</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, number_epochs, reg_bu, reg_bi, columns=[<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;iid&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span>):</span></span><br><span class="line">        <span class="comment"># 梯度下降最高迭代次数</span></span><br><span class="line">        self.number_epochs = number_epochs</span><br><span class="line">        <span class="comment"># bu的正则参数</span></span><br><span class="line">        self.reg_bu = reg_bu</span><br><span class="line">        <span class="comment"># bi的正则参数</span></span><br><span class="line">        self.reg_bi = reg_bi</span><br><span class="line">        <span class="comment"># 数据集中user-item-rating字段的名称</span></span><br><span class="line">        self.columns = columns</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, dataset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param dataset: uid, iid, rating</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        <span class="comment"># 用户评分数据</span></span><br><span class="line">        self.users_ratings = dataset.groupby(self.columns[<span class="number">0</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">1</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 物品评分数据</span></span><br><span class="line">        self.items_ratings = dataset.groupby(self.columns[<span class="number">1</span>]).agg([<span class="built_in">list</span>])[[self.columns[<span class="number">0</span>], self.columns[<span class="number">2</span>]]]</span><br><span class="line">        <span class="comment"># 计算全局平均分</span></span><br><span class="line">        self.global_mean = self.dataset[self.columns[<span class="number">2</span>]].mean()</span><br><span class="line">        <span class="comment"># 调用sgd方法训练模型参数</span></span><br><span class="line">        self.bu, self.bi = self.als()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">als</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        利用随机梯度下降，优化bu，bi的值</span></span><br><span class="line"><span class="string">        :return: bu, bi</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># 初始化bu、bi的值，全部设为0</span></span><br><span class="line">        bu = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.users_ratings.index, np.zeros(<span class="built_in">len</span>(self.users_ratings))))</span><br><span class="line">        bi = <span class="built_in">dict</span>(<span class="built_in">zip</span>(self.items_ratings.index, np.zeros(<span class="built_in">len</span>(self.items_ratings))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.number_epochs):</span><br><span class="line">            print(<span class="string">&quot;iter%d&quot;</span> % i)</span><br><span class="line">            <span class="keyword">for</span> iid, uids, ratings <span class="keyword">in</span> self.items_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> uid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(uids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bu[uid]</span><br><span class="line">                bi[iid] = _sum / (self.reg_bi + <span class="built_in">len</span>(uids))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> uid, iids, ratings <span class="keyword">in</span> self.users_ratings.itertuples(index=<span class="literal">True</span>):</span><br><span class="line">                _sum = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> iid, rating <span class="keyword">in</span> <span class="built_in">zip</span>(iids, ratings):</span><br><span class="line">                    _sum += rating - self.global_mean - bi[iid]</span><br><span class="line">                bu[uid] = _sum / (self.reg_bu + <span class="built_in">len</span>(iids))</span><br><span class="line">        <span class="keyword">return</span> bu, bi</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, uid, iid</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;评分预测&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> iid <span class="keyword">not</span> <span class="keyword">in</span> self.items_ratings.index:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;无法预测用户&lt;&#123;uid&#125;&gt;对电影&lt;&#123;iid&#125;&gt;的评分，因为训练集中缺失&lt;&#123;iid&#125;&gt;的数据&quot;</span>.<span class="built_in">format</span>(uid=uid, iid=iid))</span><br><span class="line"></span><br><span class="line">        predict_rating = self.global_mean + self.bu[uid] + self.bi[iid]</span><br><span class="line">        <span class="keyword">return</span> predict_rating</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testset</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;预测测试集数据&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> uid, iid, real_rating <span class="keyword">in</span> testset.itertuples(index=<span class="literal">False</span>):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                pred_rating = self.predict(uid, iid)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">yield</span> uid, iid, real_rating, pred_rating</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    trainset, testset = data_split(<span class="string">&quot;datasets/ml-latest-small/ratings.csv&quot;</span>, random=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    bcf = BaselineCFByALS(<span class="number">20</span>, <span class="number">25</span>, <span class="number">15</span>, [<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;movieId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line">    bcf.fit(trainset)</span><br><span class="line"></span><br><span class="line">    pred_results = bcf.test(testset)</span><br><span class="line"></span><br><span class="line">    rmse, mae = accuray(pred_results)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;rmse: &quot;</span>, rmse, <span class="string">&quot;mae: &quot;</span>, mae)</span><br></pre></td></tr></table></figure><p>函数求导：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004114.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210617004135.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于回归模型的协同过滤推荐&quot;&gt;&lt;a href=&quot;#基于回归模型的协同过滤推荐&quot; class=&quot;headerlink&quot; title=&quot;基于回归模型的协同过滤推荐&quot;&gt;&lt;/a&gt;基于回归模型的协同过滤推荐&lt;/h2&gt;&lt;p&gt;如果我们将评分看作是一个连续的值而不是离散的值，那么</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>10-基于K最近邻的协同过滤推荐</title>
    <link href="https://xxren8218.github.io/20210617/10-%E5%9F%BA%E4%BA%8EK%E6%9C%80%E8%BF%91%E9%82%BB%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90.html"/>
    <id>https://xxren8218.github.io/20210617/10-%E5%9F%BA%E4%BA%8EK%E6%9C%80%E8%BF%91%E9%82%BB%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%90.html</id>
    <published>2021-06-16T16:36:51.000Z</published>
    <updated>2021-06-16T16:37:20.354Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于K最近邻的协同过滤推荐"><a href="#基于K最近邻的协同过滤推荐" class="headerlink" title="基于K最近邻的协同过滤推荐"></a>基于K最近邻的协同过滤推荐</h2><p>基于K最近邻的协同过滤推荐其实本质上就是MemoryBased CF，只不过在选取近邻的时候，加上K最近邻的限制。</p><p>这里我们直接根据MemoryBased CF的代码实现</p><p>修改以下地方</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CollaborativeFiltering</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    based = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, k=<span class="number">40</span>, rules=<span class="literal">None</span>, use_cache=<span class="literal">False</span>, standard=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        :param k: 取K个最近邻来进行预测</span></span><br><span class="line"><span class="string">        :param rules: 过滤规则，四选一，否则将抛异常：&quot;unhot&quot;, &quot;rated&quot;, [&quot;unhot&quot;,&quot;rated&quot;], None</span></span><br><span class="line"><span class="string">        :param use_cache: 相似度计算结果是否开启缓存</span></span><br><span class="line"><span class="string">        :param standard: 评分标准化方法，None表示不使用、mean表示均值中心化、zscore表示Z-Score标准化</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.k = <span class="number">40</span></span><br><span class="line">        self.rules = rules</span><br><span class="line">        self.use_cache = use_cache</span><br><span class="line">        self.standard = standard</span><br></pre></td></tr></table></figure><p>修改所有的选取近邻的地方的代码，根据相似度来选取K个最近邻</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">similar_users = self.similar[uid].drop([uid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br><span class="line"></span><br><span class="line">similar_items = self.similar[iid].drop([iid]).dropna().sort_values(ascending=<span class="literal">False</span>)[:self.k]</span><br></pre></td></tr></table></figure><p>但由于我们的原始数据较少，这里我们的KNN方法的效果会比纯粹的MemoryBasedCF要差</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基于K最近邻的协同过滤推荐&quot;&gt;&lt;a href=&quot;#基于K最近邻的协同过滤推荐&quot; class=&quot;headerlink&quot; title=&quot;基于K最近邻的协同过滤推荐&quot;&gt;&lt;/a&gt;基于K最近邻的协同过滤推荐&lt;/h2&gt;&lt;p&gt;基于K最近邻的协同过滤推荐其实本质上就是Memory</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
