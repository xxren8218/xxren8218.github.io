<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>X.X.Ren</title>
  
  <subtitle>个人博客</subtitle>
  <link href="https://xxren8218.github.io/atom.xml" rel="self"/>
  
  <link href="https://xxren8218.github.io/"/>
  <updated>2021-07-09T14:01:05.938Z</updated>
  <id>https://xxren8218.github.io/</id>
  
  <author>
    <name>任晓雄</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>12-二叉树的路径问题汇总</title>
    <link href="https://xxren8218.github.io/20210709/12-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html"/>
    <id>https://xxren8218.github.io/20210709/12-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html</id>
    <published>2021-07-09T13:51:32.000Z</published>
    <updated>2021-07-09T14:01:05.938Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的路径问题"><a href="#二叉树的路径问题" class="headerlink" title="二叉树的路径问题"></a>二叉树的路径问题</h2><p>对于刚刚接触树的问题的新手而言，路径问题是一个比较棘手的问题。题解中关于二叉树路径问题的总结还偏少，今天我用一篇文章总结一下二叉树的路径问题。学透这篇文章，二叉树路径题可以秒杀</p><h3 id="1-问题分类"><a href="#1-问题分类" class="headerlink" title="1.问题分类"></a>1.问题分类</h3><p>二叉树路径的问题大致可以分为两类：</p><ul><li><p>自顶向下：<br>顾名思义，就是从某一个节点(不一定是根节点)，从上向下寻找路径，到某一个节点(不一定是叶节点)结束<br>具体题目如下：</p><p>257.二叉树的所有路径</p><p>面试题 04.12. 求和路径</p><p>112.路径总和</p><p>113.路径总和 II</p><p>437.路径总和 III</p><p>988.从叶结点开始的最小字符串</p></li></ul><p>而继续细分的话还可以分成一般路径与给定和的路径</p><ul><li>非自顶向下：<br>就是从任意节点到任意节点的路径，不需要自顶向下<br>124.二叉树中的最大路径和<br>125.最长同值路径<br>126.二叉树的直径</li></ul><h3 id="2-解题模板"><a href="#2-解题模板" class="headerlink" title="2.解题模板"></a>2.解题模板</h3><p>这类题通常用深度优先搜索(DFS)和广度优先搜索(BFS)解决，BFS较DFS繁琐，这里为了简洁只展现DFS代码<br>下面是我对两类题目的分析与模板</p><h4 id="一、自顶而下："><a href="#一、自顶而下：" class="headerlink" title="一、自顶而下："></a>一、自顶而下：</h4><p>DFS</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##########</span></span><br><span class="line"><span class="comment">#一般路径：#</span></span><br><span class="line"><span class="comment">##########</span></span><br><span class="line">res = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, path</span>)：</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span>  <span class="comment"># 根节点为空直接返回</span></span><br><span class="line">    path.append(root.val)  <span class="comment"># 作出选择</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right: <span class="comment"># 如果到叶节点  </span></span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    dfs(root.left,path)   <span class="comment"># 继续递归</span></span><br><span class="line">    dfs(root.right,path) </span><br><span class="line"></span><br><span class="line"><span class="comment">##############</span></span><br><span class="line"><span class="comment"># 给定和的路径：#</span></span><br><span class="line"><span class="comment">##############</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, Sum, path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    Sum -= root.val</span><br><span class="line">    path.append(root.val)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> Sum == <span class="number">0</span>:</span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"> </span><br><span class="line">    dfs(root.left, Sum, path)</span><br><span class="line">    dfs(root.right, Sum, path)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>这类题型DFS注意点：</strong></p><ol><li><p>如果是找路径和等于给定target的路径的，那么可以不用新增一个临时变量cursum来判断当前路径和，<br>只需要用给定和target减去节点值，最终结束条件判断 target==0 即可</p></li><li><p>是否要回溯：二叉树的问题大部分是不需要回溯的，原因如下：<br>二叉树的递归部分：dfs(root.left),dfs(root.right)已经把可能的路径穷尽了,<br>因此到任意叶节点的路径只可能有一条，绝对不可能出现另外的路径也到这个满足条件的叶节点的;</p><p>而对比二维数组(例如迷宫问题)的DFS,for循环向四个方向查找每次只能朝向一个方向，并没有穷尽路径，<br>因此某一个满足条件的点可能是有多条路径到该点的</p><p>并且visited数组标记已经走过的路径是会受到另外路径是否访问的影响，这时候必须回溯</p></li><li><p>找到路径后是否要return:<br>取决于题目是否要求找到叶节点满足条件的路径,如果必须到叶节点,那么就要return;<br>但如果是到任意节点都可以，那么必不能return,因为这条路径下面还可能有更深的路径满足条件，还要在此基础上继续递归</p></li><li><p>是否要双重递归(即调用根节点的dfs函数后，继续调用根左右节点的pathsum函数)：看题目要不要求从根节点开始的，还是从任意节点开始</p></li></ol><h4 id="二、非自顶而下："><a href="#二、非自顶而下：" class="headerlink" title="二、非自顶而下："></a>二、非自顶而下：</h4><p>这类题目一般解题思路如下：<br>设计一个辅助函数<code>maxpath</code>，调用自身求出以一个节点为根节点的左侧最长路径left和右侧最长路径right，那么经过该节点的最长路径就是left+right<br>接着只需要从根节点开始dfs,不断比较更新全局变量即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">root</span>) # 以<span class="title">root</span>为路径起始点的最长路径</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = maxPath(root.left)</span><br><span class="line">    right = maxPath(root.right)</span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right + root.val) <span class="comment"># 更新全局变量  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left, right)   <span class="comment"># 返回左右路径较长者</span></span><br></pre></td></tr></table></figure><p>这类题型DFS注意点：</p><ol><li><p>left,right代表的含义要根据题目所求设置，比如最长路径、最大路径和等等</p></li><li><p>全局变量res的初值设置是0还是INT_MIN要看题目节点是否存在负值,如果存在就用INT_MIN，否则就是0</p></li><li><p>注意两点之间路径为1，因此一个点是不能构成路径的</p></li></ol><h4 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a>题目分析</h4><p>下面是对具体题目的分析和代码呈现</p><h4 id="一、自顶向下"><a href="#一、自顶向下" class="headerlink" title="一、自顶向下"></a>一、自顶向下</h4><p>257.二叉树的所有路径</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215304.PNG" alt=""></p><p>直接套用模板1即可，注意把”-&gt;”放在递归调用中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">root</span>):</span></span><br><span class="line">    dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    path += <span class="built_in">str</span>(root.val)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    dfs(root.left, path+<span class="string">&quot;-&gt;&quot;</span>)</span><br><span class="line">    dfs(root.right, path+<span class="string">&quot;-&gt;&quot;</span>)</span><br></pre></td></tr></table></figure><p>答题代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        path = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        self.dfs(root, path)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, root, path</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        path += <span class="built_in">str</span>(root.val)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">            self.res.append(path)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.dfs(root.left, path + <span class="string">&#x27;-&gt;&#x27;</span>)</span><br><span class="line">        self.dfs(root.right, path + <span class="string">&#x27;-&gt;&#x27;</span>)</span><br></pre></td></tr></table></figure><p>113.路径总和 II</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215332.PNG" alt=""></p><p>直接套用模板2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">res = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">root, targetSum</span>):</span></span><br><span class="line">    path = []</span><br><span class="line">    dfs(root, path, targetSum)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, path, Sum</span>)</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    Sum -= root.val</span><br><span class="line">    <span class="comment"># path.append(root.val)</span></span><br><span class="line">    <span class="comment"># 注意此处传递的是引用，用append方法path的地址不会变，所以，出栈以后的函数的path值并不会减小，这里使用一个赋值语句来存储新增加的值。</span></span><br><span class="line">    <span class="comment"># ＋相当于extend方法。</span></span><br><span class="line">    path = path + [root.val]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> Sum == <span class="number">0</span>:</span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">   </span><br><span class="line">    dfs(root.left, path, Sum)</span><br><span class="line">    dfs(root.right, path, Sum)</span><br></pre></td></tr></table></figure><p>完成代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">self, root, targetSum</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :type targetSum: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        path = []</span><br><span class="line">        self.dfs(root, path, targetSum)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, root, path, Sum</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        Sum -= root.val</span><br><span class="line">        path = path + [root.val]</span><br><span class="line">        <span class="comment"># path.append(root.val)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> Sum == <span class="number">0</span>:</span><br><span class="line">            self.res.append(path)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.dfs(root.left, path, Sum)</span><br><span class="line">        self.dfs(root.right, path, Sum)</span><br></pre></td></tr></table></figure><p>437.路径总和 III</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215348.PNG" alt=""></p><p>双重递归：先调用dfs函数从root开始查找路径，再调用pathsum函数到root左右子树开始查找<br>套用模板2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">root, targetSum</span>)</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dfs1(root, targetSum)            <span class="comment"># 以root为起始点查找路径</span></span><br><span class="line">    pathSum(root.left, targetSum)    <span class="comment"># 左子树递归</span></span><br><span class="line">    pathSum(root.right, targetSum)   <span class="comment"># 右子树递归</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, Sum</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    Sum -= root.val</span><br><span class="line">    <span class="keyword">if</span> Sum == <span class="number">0</span>:    <span class="comment"># 注意不要return,因为不要求到叶节点结束,所以一条路径下面还可能有另一条</span></span><br><span class="line">        count += <span class="number">1</span>  <span class="comment"># 如果找到了一个路径全局变量就+1</span></span><br><span class="line">    dfs1(root.left, Sum)</span><br><span class="line">    dfs1(root.right, Sum)</span><br></pre></td></tr></table></figure><p>完成代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.count = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">self, root, targetSum</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :type targetSum: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        self.dfs1(root, targetSum)</span><br><span class="line">        self.pathSum(root.left, targetSum)</span><br><span class="line">        self.pathSum(root.right, targetSum)</span><br><span class="line">        <span class="keyword">return</span> self.count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs1</span>(<span class="params">self, root, <span class="built_in">sum</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        <span class="built_in">sum</span> -= root.val</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span> == <span class="number">0</span>:</span><br><span class="line">            self.count += <span class="number">1</span></span><br><span class="line">        self.dfs1(root.left, <span class="built_in">sum</span>)</span><br><span class="line">        self.dfs1(root.right, <span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure><p>988.从叶结点开始的最小字符串</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215401.PNG" alt=""></p><p>换汤不换药，套用模板1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">path = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smallestFromLeaf</span>(<span class="params">root</span>):</span></span><br><span class="line"></span><br><span class="line">    dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    path = path.sort() <span class="comment"># 升序排序</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> path[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, s</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    s += <span class="built_in">chr</span>(<span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>) + root.val)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">        </span><br><span class="line">        s = s[::-<span class="number">1</span>]  <span class="comment"># 题目要求从叶子节点到根节点，因此反转</span></span><br><span class="line">        path.append(s)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    dfs(root.left, s)</span><br><span class="line">    dfs(root.right, s)</span><br></pre></td></tr></table></figure><p>整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.path = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">smallestFromLeaf</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        self.dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line">        self.path.sort() <span class="comment"># 升序排序</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.path[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, root, s</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        s += <span class="built_in">chr</span>(<span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>) + root.val)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">            </span><br><span class="line">            s = s[::-<span class="number">1</span>]  <span class="comment"># 题目要求从叶子节点到根节点，因此反转</span></span><br><span class="line">            self.path.append(s)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        self.dfs(root.left, s)</span><br><span class="line">        self.dfs(root.right, s)</span><br></pre></td></tr></table></figure><h4 id="二、非自顶向下"><a href="#二、非自顶向下" class="headerlink" title="二、非自顶向下"></a>二、非自顶向下</h4><p>124.二叉树中的最大路径和right分别为根节点左右子树最大路径和,</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215415.PNG" alt=""></p><p>注意：如果最大路径和&lt;0,意味着该路径和对总路径和做负贡献，因此不要计入到总路径中，将它设置为0</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">res = -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="comment"># 注意节点值可能为负数，因此要设置为最小值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPathSum</span>(<span class="params">root</span>):</span></span><br><span class="line">    maxPath(root)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">root</span>):</span> <span class="comment"># 以root为路径起始点的最长路径</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = <span class="built_in">max</span>(maxPath(root.left), <span class="number">0</span>)</span><br><span class="line">    right = <span class="built_in">max</span>(maxPath(root.right), <span class="number">0</span>)</span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right + root.val)  <span class="comment"># 比较当前最大路径和与左右子树最长路径加上根节点值的较大值，更新全局变量</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left + root.val, right + root.val) <span class="comment"># 返回左右子树较大的路径和加上根节点值</span></span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxPathSum</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        self.maxPath(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left = <span class="built_in">max</span>(self.maxPath(root.left), <span class="number">0</span>)</span><br><span class="line">        right = <span class="built_in">max</span>(self.maxPath(root.right), <span class="number">0</span>)</span><br><span class="line">        self.res = <span class="built_in">max</span>(self.res, left + right + root.val)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(left + root.val, right + root.val)</span><br></pre></td></tr></table></figure><p>687.最长同值路径</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215433.PNG" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">longestUnivaluePath</span>(<span class="params">root</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    longestPath(root)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">longestPath</span>(<span class="params">root</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = longestPath(root.left) </span><br><span class="line">    right = longestPath(root.right)</span><br><span class="line">    <span class="comment"># 如果存在左子节点和根节点同值，更新左最长路径;否则左最长路径为0</span></span><br><span class="line">    <span class="keyword">if</span> root.left <span class="keyword">and</span> root.val == root.left.val:</span><br><span class="line">        left += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> root.right <span class="keyword">and</span> root.val == root.right.val:</span><br><span class="line">        right += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left, right)</span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestUnivaluePath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        self.longestPath(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestPath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left = self.longestPath(root.left)</span><br><span class="line">        right = self.longestPath(root.right)</span><br><span class="line">        <span class="keyword">if</span> root.left <span class="keyword">and</span> root.left.val == root.val:</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            left = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> root.right <span class="keyword">and</span> root.right.val == root.val:</span><br><span class="line">            right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right = <span class="number">0</span></span><br><span class="line">        self.res = <span class="built_in">max</span>(self.res, left + right)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(left, right)</span><br></pre></td></tr></table></figure><p>543.二叉树的直径</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215446.PNG" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">diameterOfBinaryTree</span>(<span class="params">root</span>):</span></span><br><span class="line">    maxPath(root)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">root</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里递归结束条件要特别注意：不能是not root(而且不需要判断root为空,因为只有非空才会进入递归)，因为单个节点路径长也是0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right: </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 判断左子节点是否为空，从而更新左边最长路径</span></span><br><span class="line">    <span class="keyword">if</span> root.left:</span><br><span class="line">        left = maxPath(root.left) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> root.right:</span><br><span class="line">        right = maxPath(root.right) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right) <span class="comment"># 更新全局变量</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left, right)      <span class="comment"># 返回左右路径较大者</span></span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">diameterOfBinaryTree</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.maxPath(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right: </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 判断左子节点是否为空，从而更新左边最长路径</span></span><br><span class="line">        <span class="keyword">if</span> root.left:</span><br><span class="line">            left = self.maxPath(root.left) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            left = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> root.right:</span><br><span class="line">            right = self.maxPath(root.right) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        self.res = <span class="built_in">max</span>(self.res, left + right) <span class="comment"># 更新全局变量</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(left, right)                <span class="comment"># 返回左右路径较大者</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的路径问题&quot;&gt;&lt;a href=&quot;#二叉树的路径问题&quot; class=&quot;headerlink&quot; title=&quot;二叉树的路径问题&quot;&gt;&lt;/a&gt;二叉树的路径问题&lt;/h2&gt;&lt;p&gt;对于刚刚接触树的问题的新手而言，路径问题是一个比较棘手的问题。题解中关于二叉树路径问题的总结</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>02-推荐系统实战之根据用户行为数据创建ALS模型并召回商品</title>
    <link href="https://xxren8218.github.io/20210709/02-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E6%A0%B9%E6%8D%AE%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E5%88%9B%E5%BB%BAALS%E6%A8%A1%E5%9E%8B%E5%B9%B6%E5%8F%AC%E5%9B%9E%E5%95%86%E5%93%81.html"/>
    <id>https://xxren8218.github.io/20210709/02-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E6%A0%B9%E6%8D%AE%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E5%88%9B%E5%BB%BAALS%E6%A8%A1%E5%9E%8B%E5%B9%B6%E5%8F%AC%E5%9B%9E%E5%95%86%E5%93%81.html</id>
    <published>2021-07-08T17:00:30.000Z</published>
    <updated>2021-07-08T17:03:25.325Z</updated>
    
    <content type="html"><![CDATA[<h2 id="根据用户行为数据创建ALS模型并召回商品"><a href="#根据用户行为数据创建ALS模型并召回商品" class="headerlink" title="根据用户行为数据创建ALS模型并召回商品"></a>根据用户行为数据创建ALS模型并召回商品</h2><ul><li>打开HDFS，Hadoop下的sbin目录下的./start-dfs.sh</li><li>打开Spark, <ul><li>Spark下的sbin目录下的./start-master.sh -h 192.168.19.2</li><li>Spark下的sbin目录下的./start-slave.sh spark://192.168.19.2:7077</li><li>可以使用192.168.19.2:8080进行可视化查看</li></ul></li><li>进入虚拟环境 workon 虚拟环境名字（有所需的工具包：如jupyter notebook）<ul><li>jupyter notebook —ip 0.0.0.0</li></ul></li></ul><h3 id="0-用户行为数据拆分"><a href="#0-用户行为数据拆分" class="headerlink" title="0. 用户行为数据拆分"></a>0. 用户行为数据拆分</h3><ul><li><p>海量数据处理应该怎么办？2T数据的处理，不至于在Excel中处理吧。</p><ul><li>这里说一个面试题：给你2T的邮箱数据，如何去重排序？</li><li>外排序：分成多块，去重排序，然后再合并。</li></ul></li><li><p>方便练习可以对数据做拆分处理</p><ul><li>pandas的数据分批读取  chunk 厚厚的一块 相当大的数量或部分</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">reader = pd.read_csv(<span class="string">&#x27;behavior_log.csv&#x27;</span>,chunksize=<span class="number">100</span>,iterator=<span class="literal">True</span>) </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">chunksize  一次数据读多少条。</span></span><br><span class="line"><span class="string">iterator   是否返回可迭代对象。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> reader:</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">1</span>:</span><br><span class="line">        chunk.to_csv(<span class="string">&#x27;test4.csv&#x27;</span>,index = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># index = False 去掉自动添加行索引。保留列索引</span></span><br><span class="line">    <span class="keyword">elif</span> count &gt; <span class="number">1</span> <span class="keyword">and</span> count &lt; <span class="number">1000</span>:</span><br><span class="line">        chunk.to_csv(<span class="string">&#x27;test4.csv&#x27;</span>,index = <span class="literal">False</span>, mode = <span class="string">&#x27;a&#x27;</span>, header = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># mode = ‘a’ 表示追加模式，去掉自动添加行索引，去掉列索引。</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">pd.read_csv(<span class="string">&#x27;test4.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></li></ul><h3 id="1-预处理behavior-log数据集"><a href="#1-预处理behavior-log数据集" class="headerlink" title="1. 预处理behavior_log数据集"></a>1. 预处理behavior_log数据集</h3><p>创建Spark的连接，通过SparkSQL将数据加载进来，进行简单分析。</p><ul><li>创建spark session</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line"><span class="comment"># spark配置信息</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">SPARK_APP_NAME = <span class="string">&quot;preprocessingBehaviorLog&quot;</span></span><br><span class="line">SPARK_URL = <span class="string">&quot;spark://192.168.19.2:7077&quot;</span></span><br><span class="line"></span><br><span class="line">conf = SparkConf()    <span class="comment"># 创建spark config对象</span></span><br><span class="line">config = (</span><br><span class="line">(<span class="string">&quot;spark.app.name&quot;</span>, SPARK_APP_NAME),    <span class="comment"># 设置启动的spark的app名称，没有提供，将随机产生一个名称</span></span><br><span class="line">(<span class="string">&quot;spark.executor.memory&quot;</span>, <span class="string">&quot;6g&quot;</span>),    <span class="comment"># 设置该app启动时占用的内存用量，默认1g</span></span><br><span class="line">(<span class="string">&quot;spark.master&quot;</span>, SPARK_URL),    <span class="comment"># spark master的地址</span></span><br><span class="line">    (<span class="string">&quot;spark.executor.cores&quot;</span>, <span class="string">&quot;4&quot;</span>),    <span class="comment"># 设置spark executor使用的CPU核心数</span></span><br><span class="line">    <span class="comment"># 以下三项配置，可以控制执行器数量</span></span><br><span class="line"><span class="comment">#     (&quot;spark.dynamicAllocation.enabled&quot;, True),</span></span><br><span class="line"><span class="comment">#     (&quot;spark.dynamicAllocation.initialExecutors&quot;, 1),    # 1个执行器</span></span><br><span class="line"><span class="comment">#     (&quot;spark.shuffle.service.enabled&quot;, True)</span></span><br><span class="line"><span class="comment"># (&#x27;spark.sql.pivotMaxValues&#x27;, &#x27;99999&#x27;),  # 当需要pivot DF，且值很多时，需要修改，默认是10000</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 查看更详细配置及说明：https://spark.apache.org/docs/latest/configuration.html</span></span><br><span class="line"></span><br><span class="line">conf.setAll(config)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用config对象，创建spark session</span></span><br><span class="line">spark = SparkSession.builder.config(conf=conf).getOrCreate()</span><br></pre></td></tr></table></figure><ul><li>从hdfs中加载csv文件为DataFrame</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从hdfs加载CSV文件为DataFrame</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/behavior_log.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">df.show()    <span class="comment"># 查看dataframe，默认显示前20条</span></span><br><span class="line"><span class="comment"># 大致查看一下数据类型</span></span><br><span class="line">df.printSchema()    <span class="comment"># 打印当前dataframe的结构</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----+-----+------+</span><br><span class="line">|  user|time_stamp|btag| cate| brand|</span><br><span class="line">+------+----------+----+-----+------+</span><br><span class="line">|558157|1493741625|  pv| 6250| 91286|</span><br><span class="line">|558157|1493741626|  pv| 6250| 91286|</span><br><span class="line">|558157|1493741627|  pv| 6250| 91286|</span><br><span class="line">|728690|1493776998|  pv|11800| 62353|</span><br><span class="line">|332634|1493809895|  pv| 1101|365477|</span><br><span class="line">|857237|1493816945|  pv| 1043|110616|</span><br><span class="line">|619381|1493774638|  pv|  385|428950|</span><br><span class="line">|467042|1493772641|  pv| 8237|301299|</span><br><span class="line">|467042|1493772644|  pv| 8237|301299|</span><br><span class="line">|991528|1493780710|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780714|  pv| 7270|274795|</span><br><span class="line">|991528|1493780765|  pv| 7270|274795|</span><br><span class="line">|991528|1493780714|  pv| 7270|274795|</span><br><span class="line">|991528|1493780765|  pv| 7270|274795|</span><br><span class="line">|991528|1493780764|  pv| 7270|274795|</span><br><span class="line">|991528|1493780633|  pv| 7270|274795|</span><br><span class="line">|991528|1493780764|  pv| 7270|274795|</span><br><span class="line">+------+----------+----+-----+------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- user: string (nullable = true)</span><br><span class="line"> |-- time_stamp: string (nullable = true)</span><br><span class="line"> |-- btag: string (nullable = true)</span><br><span class="line"> |-- cate: string (nullable = true)</span><br><span class="line"> |-- brand: string (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>从hdfs加载数据为dataframe，并设置结构—schema </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType</span><br><span class="line"><span class="comment"># 构建结构对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;timestamp&quot;</span>, LongType()),</span><br><span class="line">    StructField(<span class="string">&quot;btag&quot;</span>, StringType()),</span><br><span class="line">    StructField(<span class="string">&quot;cateId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;brandId&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 从hdfs加载数据为dataframe，并设置结构</span></span><br><span class="line">behavior_log_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/datasets/behavior_log.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">behavior_log_df.show()</span><br><span class="line">behavior_log_df.count() </span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----+------+-------+</span><br><span class="line">|userId| timestamp|btag|cateId|brandId|</span><br><span class="line">+------+----------+----+------+-------+</span><br><span class="line">|558157|1493741625|  pv|  6250|  91286|</span><br><span class="line">|558157|1493741626|  pv|  6250|  91286|</span><br><span class="line">|558157|1493741627|  pv|  6250|  91286|</span><br><span class="line">|728690|1493776998|  pv| 11800|  62353|</span><br><span class="line">|332634|1493809895|  pv|  1101| 365477|</span><br><span class="line">|857237|1493816945|  pv|  1043| 110616|</span><br><span class="line">|619381|1493774638|  pv|   385| 428950|</span><br><span class="line">|467042|1493772641|  pv|  8237| 301299|</span><br><span class="line">|467042|1493772644|  pv|  8237| 301299|</span><br><span class="line">|991528|1493780710|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780714|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780765|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780714|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780765|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780764|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780633|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780764|  pv|  7270| 274795|</span><br><span class="line">+------+----------+----+------+-------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- btag: string (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>分析数据集字段的类型和格式<ul><li>查看是否有空值</li><li>查看每列数据的类型</li><li>查看每列数据的类别情况</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看userId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;userId&quot;</span>).count().count()) <span class="comment"># 第一个count是将相同的用户放在同一组内。，再count数数。</span></span><br><span class="line"><span class="comment"># 约113w用户</span></span><br><span class="line"><span class="comment">#注意：behavior_log_df.groupBy(&quot;userId&quot;).count()  返回的是一个dataframe，这里的count计算的是每一个分组的个数，但当前还没有进行计算</span></span><br><span class="line"><span class="comment"># 当调用df.count()时才开始进行计算，这里的count计算的是dataframe的条目数，也就是共有多少个分组</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看user的数据情况： 1136340</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看btag的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;btag&quot;</span>).count().collect())    <span class="comment"># collect会把计算结果全部加载到内存，谨慎使用</span></span><br><span class="line"><span class="comment"># 只有四种类型数据：pv、fav、cart、buy</span></span><br><span class="line"><span class="comment"># 这里由于类型只有四个，所以直接使用collect，把数据全部加载出来</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看btag的数据情况： [Row(btag=&#x27;buy&#x27;, count=9115919), Row(btag=&#x27;fav&#x27;, count=9301837), Row(btag=&#x27;cart&#x27;, count=15946033), Row(btag=&#x27;pv&#x27;, count=688904345)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看cateId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;cateId&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约12968类别id</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看cateId的数据情况： 12968</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看brandId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;brandId&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约460561品牌id</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看brandId的数据情况： 460561</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;判断数据是否有空值：&quot;</span>, behavior_log_df.count(), behavior_log_df.dropna().count())</span><br><span class="line"><span class="comment"># 约7亿条目723268134 723268134</span></span><br><span class="line"><span class="comment"># 本数据集无空值条目，可放心处理</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">判断数据是否有空值： 723268134 723268134</span><br></pre></td></tr></table></figure><ul><li>pivot透视操作，把某列里的字段值转换成行并进行聚合运算(pyspark.sql.GroupedData.pivot)<ul><li>如果透视的字段中的不同属性值超过10000个，则需要设置spark.sql.pivotMaxValues，否则计算过程中会出现错误。<a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=pivot#pyspark.sql.GroupedData.pivot">文档介绍</a>。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户对各类商品的pv、fav、cart、buy数量</span></span><br><span class="line">cate_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.cateId).pivot(<span class="string">&quot;btag&quot;</span>,[<span class="string">&quot;pv&quot;</span>,<span class="string">&quot;fav&quot;</span>,<span class="string">&quot;cart&quot;</span>,<span class="string">&quot;buy&quot;</span>]).count() <span class="comment"># 默认按照字典排序的，想要按重要程度排序，在里面穿值。此处已经传了。[&quot;pv&quot;,&quot;fav&quot;,&quot;cart&quot;,&quot;buy&quot;]</span></span><br><span class="line">cate_count_df.printSchema()    <span class="comment"># 此时还没有开始计算</span></span><br></pre></td></tr></table></figure><p>显示效果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- pv: long (nullable = true)</span><br><span class="line"> |-- fav: long (nullable = true)</span><br><span class="line"> |-- cart: long (nullable = true)</span><br><span class="line"> |-- buy: long (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>统计每个用户对各个品牌的pv、fav、cart、buy数量并保存结果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户对各个品牌的pv、fav、cart、buy数量</span></span><br><span class="line">brand_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.brandId).pivot(<span class="string">&quot;btag&quot;</span>,[<span class="string">&quot;pv&quot;</span>,<span class="string">&quot;fav&quot;</span>,<span class="string">&quot;cart&quot;</span>,<span class="string">&quot;buy&quot;</span>]).count()</span><br><span class="line"><span class="comment"># brand_count_df.show()    # 同上</span></span><br><span class="line"><span class="comment"># 113w * 46w</span></span><br><span class="line"><span class="comment"># 由于运算时间比较长，所以这里先将结果存储起来，供后续其他操作使用</span></span><br><span class="line"><span class="comment"># 写入数据时才开始计算</span></span><br><span class="line">cate_count_df.write.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">brand_count_df.write.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="2-根据用户对类目偏好打分训练ALS模型"><a href="#2-根据用户对类目偏好打分训练ALS模型" class="headerlink" title="2. 根据用户对类目偏好打分训练ALS模型"></a>2. 根据用户对类目偏好打分训练ALS模型</h3><ul><li>根据您统计的次数 + 打分规则 ==&gt; 偏好打分数据集 ==&gt; ALS模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark ml的模型训练是基于内存的，如果数据过大，内存空间小，迭代次数过多的化，可能会造成内存溢出，报错</span></span><br><span class="line"><span class="comment"># 设置Checkpoint的话，会把所有数据落盘，这样如果异常退出，下次重启后，可以接着上次的训练节点继续运行</span></span><br><span class="line"><span class="comment"># 但该方法其实指标不治本，因为无法防止内存溢出，所以还是会报错</span></span><br><span class="line"><span class="comment"># 如果数据量大，应考虑的是增加内存、或限制迭代次数和训练数据量级等</span></span><br><span class="line">spark.sparkContext.setCheckpointDir(<span class="string">&quot;/checkPoint/&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建结构对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cateId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pv&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;fav&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cart&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;buy&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从hdfs加载CSV文件</span></span><br><span class="line">cate_count_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">cate_count_df.printSchema()</span><br><span class="line">cate_count_df.first()    <span class="comment"># 第一行数据</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- pv: integer (nullable = true)</span><br><span class="line"> |-- fav: integer (nullable = true)</span><br><span class="line"> |-- cart: integer (nullable = true)</span><br><span class="line"> |-- buy: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">Row(userId=1061650, cateId=4520, pv=2326, fav=None, cart=53, buy=None)</span><br></pre></td></tr></table></figure><ul><li>处理每一行数据：r表示row对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="comment"># 处理每一行数据：r表示row对象</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 偏好评分规则：</span></span><br><span class="line"><span class="comment">#     m: 用户对应的行为次数</span></span><br><span class="line">    <span class="comment">#     该偏好权重比例，次数上限仅供参考，具体数值应根据产品业务场景权衡</span></span><br><span class="line"><span class="comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span></span><br><span class="line"><span class="comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span></span><br><span class="line"><span class="comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span></span><br><span class="line"><span class="comment">#     buy: if m&lt;=20: score=1*m; else score=20</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 注意这里要全部设为浮点数，spark运算时对类型比较敏感，要保持数据类型都一致</span></span><br><span class="line">pv_count = r.pv <span class="keyword">if</span> r.pv <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">fav_count = r.fav <span class="keyword">if</span> r.fav <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">cart_count = r.cart <span class="keyword">if</span> r.cart <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">buy_count = r.buy <span class="keyword">if</span> r.buy <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">pv_score = <span class="number">0.2</span>*pv_count <span class="keyword">if</span> pv_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">4.0</span></span><br><span class="line">fav_score = <span class="number">0.4</span>*fav_count <span class="keyword">if</span> fav_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">8.0</span></span><br><span class="line">cart_score = <span class="number">0.6</span>*cart_count <span class="keyword">if</span> cart_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">12.0</span></span><br><span class="line">buy_score = <span class="number">1.0</span>*buy_count <span class="keyword">if</span> buy_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">20.0</span></span><br><span class="line"></span><br><span class="line">rating = pv_score + fav_score + cart_score + buy_score</span><br><span class="line"><span class="comment"># 返回用户ID、分类ID、用户对分类的偏好打分</span></span><br><span class="line"><span class="keyword">return</span> r.userId, r.cateId, rating</span><br></pre></td></tr></table></figure><ul><li>返回一个PythonRDD类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个PythonRDD类型，此时还没开始计算</span></span><br><span class="line"><span class="comment"># 先转化为RDD再进行map，一条数据一条数据算。虽然DF也可以用UDF，但是麻烦！处理好好再转为DF</span></span><br><span class="line"><span class="comment"># 并不是所有的RDD都能转为DF，必须有结构的才行。Schema才可以。此处可以是因为，他就是DF转过去的。</span></span><br><span class="line">cate_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;cateId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: bigint, cateId: bigint, rating: double]</span><br></pre></td></tr></table></figure><ul><li>用户对商品类别的打分数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户对商品类别的打分数据</span></span><br><span class="line"><span class="comment"># map返回的结果是rdd类型，需要调用toDF方法转换为Dataframe</span></span><br><span class="line">cate_rating_df = cate_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;cateId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line"><span class="comment"># 注意：toDF不是每个rdd都有的方法，仅局限于此处的rdd</span></span><br><span class="line"><span class="comment"># 可通过该方法获得 user-cate-matrix</span></span><br><span class="line"><span class="comment"># 但由于cateId字段过多，这里运算量比很大，机器内存要求很高才能执行，否则无法完成任务</span></span><br><span class="line"><span class="comment"># 请谨慎使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但好在我们训练ALS模型时，不需要转换为user-cate-matrix，所以这里可以不用运行</span></span><br><span class="line"><span class="comment"># cate_rating_df.groupBy(&quot;userId&quot;).povit(&quot;cateId&quot;).min(&quot;rating&quot;)</span></span><br><span class="line"><span class="comment"># 用户对类别的偏好打分数据</span></span><br><span class="line">cate_rating_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: bigint, cateId: bigint, rating: double]</span><br></pre></td></tr></table></figure><ul><li>通常如果USER-ITEM打分数据应该是通过一下方式进行处理转换为USER-ITEM-MATRIX</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709010230.png" alt=""></p><p><strong>但这里我们将使用的Spark的ALS模型进行CF推荐，因此注意这里数据输入不需要提前转换为矩阵，直接是 USER-ITEM-RATE的数据</strong></p><ul><li><p>基于Spark的ALS隐因子模型进行CF评分预测</p><ul><li><p>ALS的意思是交替最小二乘法（Alternating Least Squares），是Spark2.*中加入的进行基于模型的协同过滤（model-based CF）的推荐系统算法。</p><p>同SVD，它也是一种矩阵分解技术，对数据进行降维处理。</p></li><li><p>详细使用方法：<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation">pyspark.ml.recommendation.ALS</a></p></li><li><p><strong>注意：由于数据量巨大，因此这里也不考虑基于内存的CF算法</strong></p><p>参考：<a href="https://www.cnblogs.com/mooba/p/6539142.html">为什么Spark中只有ALS</a></p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pyspark中的ALS矩阵分解方法实现CF评分预测</span></span><br><span class="line"><span class="comment"># 文档地址：https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS   <span class="comment"># ml：dataframe， mllib：rdd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用打分数据，训练ALS模型</span></span><br><span class="line">als = ALS(userCol=<span class="string">&#x27;userId&#x27;</span>, itemCol=<span class="string">&#x27;cateId&#x27;</span>, ratingCol=<span class="string">&#x27;rating&#x27;</span>, checkpointInterval=<span class="number">5</span>)   <span class="comment"># 训练五步缓存一次。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处训练时间较长</span></span><br><span class="line">model = als.fit(cate_rating_df)</span><br></pre></td></tr></table></figure><ul><li>模型训练好后，调用方法进行使用，<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=alsmodel#pyspark.ml.recommendation.ALSModel">具体API查看</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给所有用户推荐TOP-N个物品</span></span><br><span class="line">ret = model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 由于是给所有用户进行推荐，此处运算时间也较长</span></span><br><span class="line">ret.show()</span><br><span class="line"><span class="comment"># 推荐结果存放在recommendations列中，</span></span><br><span class="line">ret.select(<span class="string">&quot;recommendations&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|   148|[[3347, 12.547271...|</span><br><span class="line">|   463|[[1610, 9.250818]...|</span><br><span class="line">|   471|[[1610, 10.246621...|</span><br><span class="line">|   496|[[1610, 5.162216]...|</span><br><span class="line">|   833|[[5607, 9.065482]...|</span><br><span class="line">|  1088|[[104, 6.886987],...|</span><br><span class="line">|  1238|[[5631, 14.51981]...|</span><br><span class="line">|  1342|[[5720, 10.89842]...|</span><br><span class="line">|  1580|[[5731, 8.466453]...|</span><br><span class="line">|  1591|[[1610, 12.835257...|</span><br><span class="line">|  1645|[[1610, 11.968531...|</span><br><span class="line">|  1829|[[1610, 17.576496...|</span><br><span class="line">|  1959|[[1610, 8.353473]...|</span><br><span class="line">|  2122|[[1610, 12.652732...|</span><br><span class="line">|  2142|[[1610, 12.48068]...|</span><br><span class="line">|  2366|[[1610, 11.904813...|</span><br><span class="line">|  2659|[[5607, 11.699315...|</span><br><span class="line">|  2866|[[1610, 7.752719]...|</span><br><span class="line">|  3175|[[3347, 2.3429515...|</span><br><span class="line">|  3749|[[1610, 3.641833]...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br><span class="line">|     recommendations|</span><br><span class="line">+--------------------+</span><br><span class="line">|[[3347, 12.547271...|</span><br><span class="line">|[[1610, 9.250818]...|</span><br><span class="line">|[[1610, 10.246621...|</span><br><span class="line">|[[1610, 5.162216]...|</span><br><span class="line">|[[5607, 9.065482]...|</span><br><span class="line">|[[104, 6.886987],...|</span><br><span class="line">|[[5631, 14.51981]...|</span><br><span class="line">|[[5720, 10.89842]...|</span><br><span class="line">|[[5731, 8.466453]...|</span><br><span class="line">|[[1610, 12.835257...|</span><br><span class="line">|[[1610, 11.968531...|</span><br><span class="line">|[[1610, 17.576496...|</span><br><span class="line">|[[1610, 8.353473]...|</span><br><span class="line">|[[1610, 12.652732...|</span><br><span class="line">|[[1610, 12.48068]...|</span><br><span class="line">|[[1610, 11.904813...|</span><br><span class="line">|[[5607, 11.699315...|</span><br><span class="line">|[[1610, 7.752719]...|</span><br><span class="line">|[[3347, 2.3429515...|</span><br><span class="line">|[[1610, 3.641833]...|</span><br><span class="line">+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>model.recommendForUserSubset 给部分用户推荐TOP-N个物品</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：recommendForUserSubset API，2.2.2版本中无法使用</span></span><br><span class="line">dataset = spark.createDataFrame([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line"><span class="comment"># 若不指定行索引，会有个默认的&#x27;_1&#x27;,将其改为&#x27;userId&#x27;</span></span><br><span class="line">dataset = dataset.withColumnRenamed(<span class="string">&quot;_1&quot;</span>, <span class="string">&quot;userId&quot;</span>) </span><br><span class="line"><span class="comment"># 指定用户 推荐物品 参数1 要给哪些用户推荐（用户id的dataframe） 参数2 给这些用户推荐几个物品</span></span><br><span class="line">ret = model.recommendForUserSubset(dataset, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只给部分用推荐，运算时间短</span></span><br><span class="line">ret.show()</span><br><span class="line">ret.collect()    <span class="comment"># 注意： collect会将所有数据加载到内存，慎用</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|     1|[[1610, 25.4989],...|</span><br><span class="line">|     3|[[5607, 13.665942...|</span><br><span class="line">|     2|[[5579, 5.9051886...|</span><br><span class="line">+------+--------------------+</span><br><span class="line"></span><br><span class="line">[Row(userId=1, recommendations=[Row(cateId=1610, rating=25.498899459838867), Row(cateId=5737, rating=24.901548385620117), Row(cateId=3347, rating=20.736785888671875)]),</span><br><span class="line"> Row(userId=3, recommendations=[Row(cateId=5607, rating=13.665942192077637), Row(cateId=1610, rating=11.770171165466309), Row(cateId=3347, rating=10.35690689086914)]),</span><br><span class="line"> Row(userId=2, recommendations=[Row(cateId=5579, rating=5.90518856048584), Row(cateId=2447, rating=5.624575138092041), Row(cateId=5690, rating=5.2555742263793945)])]</span><br></pre></td></tr></table></figure><ul><li>transform中提供userId和cateId可以对打分进行预测，利用打分结果排序后</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transform中提供userId和cateId可以对打分进行预测，利用打分结果排序后，同样可以实现TOP-N的推荐</span></span><br><span class="line">model.transform</span><br><span class="line"><span class="comment"># 将模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 测试存储的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载之前存储的模型</span></span><br><span class="line">als_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">result = als_model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line">result.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|   148|[[3347, 12.547271...|</span><br><span class="line">|   463|[[1610, 9.250818]...|</span><br><span class="line">|   471|[[1610, 10.246621...|</span><br><span class="line">|   496|[[1610, 5.162216]...|</span><br><span class="line">|   833|[[5607, 9.065482]...|</span><br><span class="line">|  1088|[[104, 6.886987],...|</span><br><span class="line">|  1238|[[5631, 14.51981]...|</span><br><span class="line">|  1342|[[5720, 10.89842]...|</span><br><span class="line">|  1580|[[5731, 8.466453]...|</span><br><span class="line">|  1591|[[1610, 12.835257...|</span><br><span class="line">|  1645|[[1610, 11.968531...|</span><br><span class="line">|  1829|[[1610, 17.576496...|</span><br><span class="line">|  1959|[[1610, 8.353473]...|</span><br><span class="line">|  2122|[[1610, 12.652732...|</span><br><span class="line">|  2142|[[1610, 12.48068]...|</span><br><span class="line">|  2366|[[1610, 11.904813...|</span><br><span class="line">|  2659|[[5607, 11.699315...|</span><br><span class="line">|  2866|[[1610, 7.752719]...|</span><br><span class="line">|  3175|[[3347, 2.3429515...|</span><br><span class="line">|  3749|[[1610, 3.641833]...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>召回到redis</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line">host = <span class="string">&quot;192.168.19.8&quot;</span></span><br><span class="line">port = <span class="number">6379</span>    </span><br><span class="line"><span class="comment"># 召回到redis</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall_cate_by_cf</span>(<span class="params">partition</span>):</span></span><br><span class="line">    <span class="comment"># 建立redis 连接池</span></span><br><span class="line">    pool = redis.ConnectionPool(host=host, port=port)</span><br><span class="line">    <span class="comment"># 建立redis客户端</span></span><br><span class="line">    client = redis.Redis(connection_pool=pool)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> partition:</span><br><span class="line">        client.hset(<span class="string">&quot;recall_cate&quot;</span>, row.userId, [i.cateId <span class="keyword">for</span> i <span class="keyword">in</span> row.recommendations])</span><br><span class="line"><span class="comment"># 对每个分片的数据进行处理 #mapPartition Transformation   map（一条一条走，和数据库建立链接耗时间）  而此处的partation是多块走，transformer的操作（）</span></span><br><span class="line"><span class="comment"># foreachPartition Action操作             foreachRDD       一块一块的走。是action的操作（一块召回一次）</span></span><br><span class="line">result.foreachPartition(recall_cate_by_cf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：这里这是召回的是用户最感兴趣的n个类别</span></span><br><span class="line"><span class="comment"># 总的条目数，查看redis中总的条目数是否一致</span></span><br><span class="line">result.count()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1136340</span><br></pre></td></tr></table></figure><h3 id="3-根据用户对品牌偏好打分训练ALS模型-与上面的套路一样"><a href="#3-根据用户对品牌偏好打分训练ALS模型-与上面的套路一样" class="headerlink" title="3. 根据用户对品牌偏好打分训练ALS模型(与上面的套路一样)"></a>3. 根据用户对品牌偏好打分训练ALS模型(与上面的套路一样)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType</span><br><span class="line"></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;brandId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pv&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;fav&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cart&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;buy&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 从hdfs加载预处理好的品牌的统计数据</span></span><br><span class="line">brand_count_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line"><span class="comment"># brand_count_df.show()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="comment"># 处理每一行数据：r表示row对象</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 偏好评分规则：</span></span><br><span class="line"><span class="comment">#     m: 用户对应的行为次数</span></span><br><span class="line">    <span class="comment">#     该偏好权重比例，次数上限仅供参考，具体数值应根据产品业务场景权衡</span></span><br><span class="line"><span class="comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span></span><br><span class="line"><span class="comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span></span><br><span class="line"><span class="comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span></span><br><span class="line"><span class="comment">#     buy: if m&lt;=20: score=1*m; else score=20</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 注意这里要全部设为浮点数，spark运算时对类型比较敏感，要保持数据类型都一致</span></span><br><span class="line">pv_count = r.pv <span class="keyword">if</span> r.pv <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">fav_count = r.fav <span class="keyword">if</span> r.fav <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">cart_count = r.cart <span class="keyword">if</span> r.cart <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">buy_count = r.buy <span class="keyword">if</span> r.buy <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">pv_score = <span class="number">0.2</span>*pv_count <span class="keyword">if</span> pv_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">4.0</span></span><br><span class="line">fav_score = <span class="number">0.4</span>*fav_count <span class="keyword">if</span> fav_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">8.0</span></span><br><span class="line">cart_score = <span class="number">0.6</span>*cart_count <span class="keyword">if</span> cart_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">12.0</span></span><br><span class="line">buy_score = <span class="number">1.0</span>*buy_count <span class="keyword">if</span> buy_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">20.0</span></span><br><span class="line"></span><br><span class="line">rating = pv_score + fav_score + cart_score + buy_score</span><br><span class="line"><span class="comment"># 返回用户ID、品牌ID、用户对品牌的偏好打分</span></span><br><span class="line"><span class="keyword">return</span> r.userId, r.brandId, rating</span><br><span class="line"><span class="comment"># 用户对品牌的打分数据</span></span><br><span class="line">brand_rating_df = brand_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;brandId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line"><span class="comment"># brand_rating_df.show()</span></span><br></pre></td></tr></table></figure><ul><li><p>基于Spark的ALS隐因子模型进行CF评分预测</p><ul><li><p>ALS的意思是交替最小二乘法（Alternating Least Squares），是Spark中进行基于模型的协同过滤（model-based CF）的推荐系统算法，也是目前Spark内唯一一个推荐算法。</p><p>同SVD，它也是一种矩阵分解技术，但理论上，ALS在海量数据的处理上要优于SVD。</p><p>更多了解：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation">pyspark.ml.recommendation.ALS</a></p><p>注意：由于数据量巨大，因此这里不考虑基于内存的CF算法</p><p>参考：<a href="https://www.cnblogs.com/mooba/p/6539142.html">为什么Spark中只有ALS</a></p></li></ul></li><li><p>使用pyspark中的ALS矩阵分解方法实现CF评分预测</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pyspark中的ALS矩阵分解方法实现CF评分预测</span></span><br><span class="line"><span class="comment"># 文档地址：https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"></span><br><span class="line">als = ALS(userCol=<span class="string">&#x27;userId&#x27;</span>, itemCol=<span class="string">&#x27;brandId&#x27;</span>, ratingCol=<span class="string">&#x27;rating&#x27;</span>, checkpointInterval=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 利用打分数据，训练ALS模型</span></span><br><span class="line"><span class="comment"># 此处训练时间较长</span></span><br><span class="line">model = als.fit(brand_rating_df)</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">model.recommendForAllUsers(<span class="number">3</span>).show()</span><br><span class="line"><span class="comment"># 将模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 测试存储的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载模型</span></span><br><span class="line">my_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)</span><br><span class="line">my_model</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">my_model.recommendForAllUsers(<span class="number">3</span>).first()</span><br></pre></td></tr></table></figure><h3 id="4-小结"><a href="#4-小结" class="headerlink" title="4.小结"></a>4.小结</h3><h3 id="spark-训练-ALS-模型"><a href="#spark-训练-ALS-模型" class="headerlink" title="spark 训练 ALS 模型"></a>spark 训练 ALS 模型</h3><ul><li><p>spark 机器学习相关的库</p><ul><li>spark MLlib<ul><li>最早开发的</li><li><strong>基于RDD 的api</strong></li><li>目前已经停止维护了 （从2.3开始停止维护）</li><li>还可以使用</li></ul></li><li>spark ML<ul><li>目前在更新的是这个库</li><li><strong>基于dataframe</strong></li></ul></li></ul></li><li><p>ALS 模型训练</p><ul><li><p>spark ML的库中封装了 协同过滤的 ALS模型</p></li><li><p>from pyspark.ml.recommendation import ALS</p></li><li><p>需要准备一个dataframe 包含 用户id 物品id 用户-物品评分 这三列，利用这三列数据就可以使用spark ALS模块训练ALS模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line">als = ALS(userCol = <span class="string">&#x27;userId&#x27;</span>,itemCol=<span class="string">&#x27;cateId&#x27;</span>,ratingCol = <span class="string">&#x27;rating&#x27;</span>,checkpointInterval = <span class="number">5</span>)</span><br><span class="line">model = als.fit(dataframe)</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>训练出模型之后就可以为用户召回物品</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#为指定用户推荐物品</span></span><br><span class="line">dataset = spark.createDataFrame([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line">dataset = dataset.withColumnRenamed(<span class="string">&quot;_1&quot;</span>, <span class="string">&quot;userId&quot;</span>)</span><br><span class="line">ret = model.recommendForUserSubset(dataset, <span class="number">3</span>)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;根据用户行为数据创建ALS模型并召回商品&quot;&gt;&lt;a href=&quot;#根据用户行为数据创建ALS模型并召回商品&quot; class=&quot;headerlink&quot; title=&quot;根据用户行为数据创建ALS模型并召回商品&quot;&gt;&lt;/a&gt;根据用户行为数据创建ALS模型并召回商品&lt;/h2&gt;&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>01-推荐系统实战之个性化电商广告推荐系统介绍</title>
    <link href="https://xxren8218.github.io/20210708/01%E2%80%94%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E4%B8%AA%E6%80%A7%E5%8C%96%E7%94%B5%E5%95%86%E5%B9%BF%E5%91%8A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D.html"/>
    <id>https://xxren8218.github.io/20210708/01%E2%80%94%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E4%B8%AA%E6%80%A7%E5%8C%96%E7%94%B5%E5%95%86%E5%B9%BF%E5%91%8A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D.html</id>
    <published>2021-07-07T17:10:24.000Z</published>
    <updated>2021-07-08T17:03:13.109Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一-个性化电商广告推荐系统介绍"><a href="#一-个性化电商广告推荐系统介绍" class="headerlink" title="一 个性化电商广告推荐系统介绍"></a>一 个性化电商广告推荐系统介绍</h2><h3 id="1-数据集介绍"><a href="#1-数据集介绍" class="headerlink" title="1 数据集介绍"></a>1 数据集介绍</h3><ul><li><p>Ali_Display_Ad_Click是阿里巴巴提供的一个淘宝展示广告点击率预估数据集</p><p>数据集来源：天池竞赛 <a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=56">数据集-阿里云天池 (aliyun.com)</a></p></li><li><p>原始样本骨架raw_sample</p><p>淘宝网站中随机抽样了114万用户8天内的广告展示/点击日志（2600万条记录），构成原始的样本骨架。 字段说明如下：</p><ol><li>user_id：脱敏过的用户ID；</li><li>adgroup_id：脱敏过的广告单元ID；</li><li>time_stamp：时间戳；</li><li>pid：资源位；</li><li>noclk：为1代表没有点击；为0代表点击；</li><li>clk：为0代表没有点击；为1代表点击；<ul><li>此处的点与没点通过埋点来实现（JS代码）。</li><li>有两个点和没点数据，是记录展示了什么数据，他没点。（看了没点与压根没看到区别）</li><li>得通过两个埋点对比得到结果，一个记录曝光，一个记录点击的。</li></ul></li></ol><p>用前面7天的做训练样本（20170506-20170512），用第8天的做测试样本（20170513）</p></li><li><p>广告基本信息表ad_feature</p><p>本数据集涵盖了raw_sample中全部广告的基本信息(约80万条目)。字段说明如下：</p><ol><li>adgroup_id：脱敏过的广告ID；</li><li>cate_id：脱敏过的商品类目ID；</li><li>campaign_id：脱敏过的广告计划ID；</li><li>customer_id: 脱敏过的广告主ID；</li><li>brand_id：脱敏过的品牌ID；</li><li>price: 宝贝的价格</li></ol><p>其中一个广告ID对应一个商品（宝贝），一个宝贝属于一个类目，一个宝贝属于一个品牌。</p></li><li><p>用户基本信息表user_profile</p><p>本数据集涵盖了raw_sample中全部用户的基本信息(约100多万用户)。字段说明如下：</p><ol><li>userid：脱敏过的用户ID；</li><li>cms_segid：微群ID；</li><li>cms_group_id：cms_group_id；</li><li>final_gender_code：性别 1:男,2:女；</li><li>age_level：年龄层次； 1234</li><li>pvalue_level：消费档次，1:低档，2:中档，3:高档；</li><li>shopping_level：购物深度，1:浅层用户,2:中度用户,3:深度用户</li><li>occupation：是否大学生 ，1:是,0:否</li><li>new_user_class_level：城市层级</li></ol></li><li><p>用户的行为日志behavior_log</p><p>本数据集涵盖了raw_sample中全部用户22天内的购物行为(共七亿条记录)。字段说明如下：</p><p>user：脱敏过的用户ID；<br>time_stamp：时间戳；<br>btag：行为类型, 包括以下四种：<br>​    类型 | 说明<br>​    pv | 浏览<br>​    cart | 加入购物车<br>​    fav | 收藏<br>​    buy | 购买<br>cate_id：脱敏过的商品类目id；<br>brand_id: 脱敏过的品牌id；<br>这里以user + time_stamp为key，会有很多重复的记录；这是因为我们的不同的类型的行为数据是不同部门记录的，在打包到一起的时候，实际上会有小的偏差（即两个一样的time_stamp实际上是差异比较小的两个时间）</p></li></ul><h3 id="2-项目效果展示"><a href="#2-项目效果展示" class="headerlink" title="2. 项目效果展示"></a>2. 项目效果展示</h3><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210708011249.png" alt=""></p><h3 id="3-项目实现分析"><a href="#3-项目实现分析" class="headerlink" title="3. 项目实现分析"></a>3. 项目实现分析</h3><ul><li><p>主要包括</p><ul><li>一份广告点击的样本数据raw_sample.csv：体现的是用户对不同位置广告点击、没点击的情况</li><li>一份广告基本信息数据ad_feature.csv：体现的是每个广告的类目(id)、品牌(id)、价格特征</li><li>一份用户基本信息数据user_profile.csv：体现的是用户群组、性别、年龄、消费购物档次、所在城市级别等特征</li><li>一份用户行为日志数据behavior_log.csv：体现用户对商品类目(id)、品牌(id)的浏览、加购物车、收藏、购买等信息</li></ul><p>我们是在对非搜索类型的广告进行点击率预测和推荐(没有搜索词、没有广告的内容特征信息)</p><ol><li>推荐业务处理主要流程： 召回 ===&gt; 排序 ===&gt; 过滤<ul><li>离线处理业务流（<strong>①训练逻辑回归模型，②为每个用户召回感兴趣的广告</strong>）<ul><li>raw_sample.csv ==&gt; 历史样本数据</li><li>ad_feature.csv ==&gt; 广告特征数据</li><li>user_profile.csv ==&gt; 用户特征数据</li><li>raw_sample.csv + ad_feature.csv + user_profile.csv ==&gt; CTR点击率预测模型</li><li>behavior_log.csv ==&gt; 评分数据 ==&gt; user-cate/brand评分数据 ==&gt; 协同过滤 ==&gt; top-N cate/brand ==&gt; 关联广告（找到感兴趣的广告）</li><li>协同过滤召回 ==&gt; top-N cate/brand ==&gt; 关联对应的广告完成召回</li></ul></li><li>在线处理业务流<ul><li>数据处理部分：<ul><li>实时行为日志 ==&gt; 实时特征 ==&gt; 缓存</li><li>实时行为日志 ==&gt; 实时商品类别/品牌 ==&gt; 实时广告召回集 ==&gt; 缓存</li></ul></li><li>推荐任务部分：<ul><li>CTR点击率预测模型 + 广告/用户特征(缓存) + 对应的召回集(缓存) ==&gt; 点击率排序 ==&gt; top-N 广告推荐结果</li></ul></li></ul></li></ul></li><li>涉及技术：Flume、Kafka、Spark-streming\HDFS、Spark SQL、Spark ML、Redis<ul><li>Flume：日志数据收集</li><li>Kafka：实时日志数据处理队列</li><li>HDFS：存储数据</li><li>Spark SQL：离线处理</li><li>Spark ML：模型训练</li><li>Redis：缓存</li></ul></li></ol></li></ul><h3 id="4-点击率预测-CTR—Click-Through-Rate-概念"><a href="#4-点击率预测-CTR—Click-Through-Rate-概念" class="headerlink" title="4. 点击率预测(CTR—Click-Through-Rate)概念"></a>4. 点击率预测(CTR—Click-Through-Rate)概念</h3><ul><li><p>电商广告推荐通常使用广告点击率(CTR—Click-Through-Rate)预测来实现</p><p><strong>点击率预测 VS 推荐算法</strong></p><p>点击率预测需要给出精准的点击概率，比如广告A点击率0.5%、广告B的点击率0.12%等；而推荐算法很多时候只需要得出一个最优的次序A&gt;B&gt;C即可。</p><p>点击率预测使用的算法通常是如逻辑回归(Logic Regression)这样的机器学习算法，而推荐算法则是一些基于协同过滤推荐、基于内容的推荐等思想实现的算法</p><p><strong>点击率 VS 转化率</strong></p><p>点击率预测是对每次广告的点击情况做出预测，可以判定这次为点击或不点击，也可以给出点击或不点击的概率</p><p>转化率指的是从状态A进入到状态B的概率，电商的转化率通常是指到达网站后，进而有成交记录的用户比率，如用户成交量/用户访问量</p><p><strong>搜索和非搜索广告点击率预测的区别</strong></p><p>搜索中有很强的搜索信号-“查询词(Query)”，查询词和广告内容的匹配程度很大程度影响了点击概率，<strong>搜索广告的点击率普遍较高</strong></p><p>非搜索广告（例如展示广告，信息流广告）的点击率的计算很多就来源于用户的兴趣和广告自身的特征，以及上下文环境。通常好<strong>位置能达到百分之几的点击率</strong>（5%左右就很不错了）。对于很多底部的广告，点击率非常低，常常是千分之几，甚至更低。</p></li></ul><h2 id="5-小结："><a href="#5-小结：" class="headerlink" title="5.小结："></a>5.小结：</h2><h3 id="数据集分析"><a href="#数据集分析" class="headerlink" title="数据集分析"></a>数据集分析</h3><ul><li><p>召回</p><ul><li>采用用户的行为日志 behavior_log 创建召回模型</li><li>协同过滤   <strong>ALS</strong>——Spark有封装<ul><li>协同过滤需需要用户对物品的评分。</li><li>用户-物品 评分<ul><li>这里没有。只有对品类、品牌的数据。</li><li>用户-品类 评分</li><li>用户-品牌 评分</li></ul></li><li>pv  cart fav buy通过四种行为转化成 -&gt; 评分<ul><li>评分的设定是根据具体的业务来的。如买给的评分最高，看最低。以及不同行为的上限，看了100次，那最多评分50.</li></ul></li></ul></li></ul></li><li><p>排序</p><ul><li>LR 逻辑回归</li><li>以  <strong>raw_sample</strong>  为骨架 把ad_feature 广告信息和user_profile用户信息拼接过来 训练逻辑回归模型</li><li>训练逻辑回归模型时 ：<ul><li>用到user_profile中会影响到用户是否会点击广告的用户特征 </li></ul></li><li>用到ad_feature会影响到用户是否会点击广告的特征 <ul><li>点/不点作为目标值</li></ul></li></ul></li><li>预测的是点击的概率<ul><li>若预测是0,1的话全部都是0.（实际广告100个人，有5个人点，正负样本极度不均衡，那我模型直接预测成全部不点也很好。所以需要调整阈值，概率不能以0.5划分了。得到结果处理：如果几个物品不点的概率分别为，0.87 0.88 0.91），那我先推荐的是点的概率大的0.13那个物品。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一-个性化电商广告推荐系统介绍&quot;&gt;&lt;a href=&quot;#一-个性化电商广告推荐系统介绍&quot; class=&quot;headerlink&quot; title=&quot;一 个性化电商广告推荐系统介绍&quot;&gt;&lt;/a&gt;一 个性化电商广告推荐系统介绍&lt;/h2&gt;&lt;h3 id=&quot;1-数据集介绍&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>33-Spark Streaming的状态操作</title>
    <link href="https://xxren8218.github.io/20210707/33-Spark-Streaming%E7%9A%84%E7%8A%B6%E6%80%81%E6%93%8D%E4%BD%9C.html"/>
    <id>https://xxren8218.github.io/20210707/33-Spark-Streaming%E7%9A%84%E7%8A%B6%E6%80%81%E6%93%8D%E4%BD%9C.html</id>
    <published>2021-07-06T16:39:56.000Z</published>
    <updated>2021-07-06T16:42:23.690Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、Spark-Streaming的状态操作"><a href="#1、Spark-Streaming的状态操作" class="headerlink" title="1、Spark Streaming的状态操作"></a>1、Spark Streaming的状态操作</h2><p>在Spark Streaming中存在两种状态操作</p><ul><li>UpdateStateByKey</li><li>Windows操作</li></ul><p>使用有状态的transformation，需要开启Checkpoint</p><ul><li>spark streaming 的容错机制</li><li>它将足够多的信息checkpoint到某些具备容错性的存储系统如hdfs上，以便出错时能够迅速恢复</li></ul><h3 id="1-1-updateStateByKey"><a href="#1-1-updateStateByKey" class="headerlink" title="1.1 updateStateByKey"></a>1.1 updateStateByKey</h3><p>Spark Streaming实现的是一个实时批处理操作，每隔一段时间将数据进行打包，封装成RDD，是无状态的。</p><p>无状态：指的是每个时间片段的数据之间是没有关联的。</p><p>需求：想要将一个大时间段（1天），即多个小时间段的数据内的数据持续进行累积操作</p><p>一般超过一天都是用RDD或Spark SQL来进行离线批处理</p><p>如果没有UpdateStateByKey，我们需要将每一秒的数据计算好放入mysql中取，再用mysql来进行统计计算</p><p>Spark Streaming中提供这种状态保护机制，即updateStateByKey</p><p>步骤：</p><ul><li>首先，要定义一个state，可以是任意的数据类型</li><li>其次，要定义state更新函数—指定一个函数如何使用之前的state和新值来更新state</li><li>对于每个batch，Spark都会为每个之前已经存在的key去应用一次state更新函数，无论这个key在batch中是否有新的数据。如果state更新函数返回none，那么key对应的state就会被删除</li><li>对于每个新出现的key，也会执行state更新函数</li></ul><p>举例：词统计。</p><h3 id="案例：updateStateByKey"><a href="#案例：updateStateByKey" class="headerlink" title="案例：updateStateByKey"></a>案例：updateStateByKey</h3><p>需求：监听网络端口的数据，获取到每个批次的出现的单词数量，并且需要把每个批次的信息保留下来</p><p><strong>代码</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SparkContext</span></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">&quot;local[2]&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">ssc = StreamingContext(sc, <span class="number">3</span>)</span><br><span class="line"><span class="comment">##### 开启检查点 #####</span></span><br><span class="line">ssc.checkpoint(<span class="string">&quot;checkpoint&quot;</span>) <span class="comment"># 默认会在Hadoop的/user/root下有个Chekpoint</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义state更新函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateFunc</span>(<span class="params">new_values, last_sum</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(new_values) + (last_sum <span class="keyword">or</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">lines = ssc.socketTextStream(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>)</span><br><span class="line"><span class="comment"># 对数据以空格进行拆分，分为多个单词</span></span><br><span class="line">counts = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>)) \</span><br><span class="line">    .<span class="built_in">map</span>(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>)) \</span><br><span class="line">    .updateStateByKey(updateFunc=updateFunc) <span class="comment"># 应用updateStateByKey函数</span></span><br><span class="line">    </span><br><span class="line">counts.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure><h3 id="1-2-Windows"><a href="#1-2-Windows" class="headerlink" title="1.2 Windows"></a>1.2 Windows</h3><ul><li><p>实时热搜</p></li><li><p>窗口长度L：运算的数据量</p></li><li>滑动间隔G：控制每隔多长时间做一次运算</li><li>两个函数：<ul><li>删除的数据怎么处理</li><li>新加入的数据怎么处理</li></ul></li></ul><p>每隔G秒，统计最近L秒的数据</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004109.png" alt=""></p><p><strong>操作细节</strong></p><ul><li>Window操作是基于窗口长度和滑动间隔来工作的</li><li>窗口的长度控制考虑前几批次数据量</li><li>默认为批处理的滑动间隔来确定计算结果的频率</li></ul><p><strong>相关函数</strong></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004126.png" alt=""></p><ul><li>Smart computation</li><li>invAddFunc</li></ul><p>reduceByKeyAndWindow(func,invFunc,windowLength,slideInterval,[num,Tasks])</p><ul><li>func:正向操作，类似于updateStateByKey</li><li>invFunc：反向操作，移除的数据如何处理</li><li>windowLength 窗口长度，统计一小时的热搜关键词，窗口长度就是1h。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004144.png" alt=""></p><p>例如在热词时，在上一个窗口中可能是热词，这个一个窗口中可能不是热词，就需要在这个窗口中把该次剔除掉</p><p>典型案例：热点搜索词滑动统计，每隔10秒，统计最近60秒钟的搜索词的搜索频次，并打印出最靠前的3个搜索词出现次数。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004200.png" alt=""></p><p><strong>案例</strong></p><p>监听网络端口的数据，每隔3秒统计前6秒出现的单词数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_countryname</span>(<span class="params">line</span>):</span></span><br><span class="line">    country_name = line.strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> country_name == <span class="string">&#x27;usa&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;USA&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> country_name == <span class="string">&#x27;ind&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;India&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> country_name == <span class="string">&#x27;aus&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;Australia&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = <span class="string">&#x27;Unknown&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="comment"># 定义处理的时间间隔</span></span><br><span class="line">    batch_interval = <span class="number">1</span> <span class="comment"># base time unit (in seconds)</span></span><br><span class="line">    <span class="comment"># 定义窗口长度</span></span><br><span class="line">    window_length = <span class="number">6</span> * batch_interval</span><br><span class="line">    <span class="comment"># 定义滑动时间间隔</span></span><br><span class="line">    frequency = <span class="number">3</span> * batch_interval</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取StreamingContext</span></span><br><span class="line">    spark = SparkSession.builder.master(<span class="string">&quot;local[2]&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">ssc = StreamingContext(sc, batch_interval)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 需要设置检查点</span></span><br><span class="line">    ssc.checkpoint(<span class="string">&quot;checkpoint&quot;</span>)</span><br><span class="line"></span><br><span class="line">    lines = ssc.socketTextStream(<span class="string">&#x27;localhost&#x27;</span>, <span class="number">9999</span>)</span><br><span class="line">    addFunc = <span class="keyword">lambda</span> x, y: x + y</span><br><span class="line">    invAddFunc = <span class="keyword">lambda</span> x, y: x - y</span><br><span class="line">    <span class="comment"># 调用reduceByKeyAndWindow，来进行窗口函数的调用</span></span><br><span class="line">    window_counts = lines.<span class="built_in">map</span>(get_countryname) \</span><br><span class="line">        .reduceByKeyAndWindow(addFunc, invAddFunc, window_length, frequency)</span><br><span class="line"><span class="comment"># 输出处理结果信息</span></span><br><span class="line">    window_counts.pprint()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1、Spark-Streaming的状态操作&quot;&gt;&lt;a href=&quot;#1、Spark-Streaming的状态操作&quot; class=&quot;headerlink&quot; title=&quot;1、Spark Streaming的状态操作&quot;&gt;&lt;/a&gt;1、Spark Streaming的状态</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>11-二叉树的左下角的值</title>
    <link href="https://xxren8218.github.io/20210706/11-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E4%B8%8B%E8%A7%92%E7%9A%84%E5%80%BC.html"/>
    <id>https://xxren8218.github.io/20210706/11-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E4%B8%8B%E8%A7%92%E7%9A%84%E5%80%BC.html</id>
    <published>2021-07-06T14:01:31.000Z</published>
    <updated>2021-07-06T14:02:16.681Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的左下角的值"><a href="#二叉树的左下角的值" class="headerlink" title="二叉树的左下角的值"></a>二叉树的左下角的值</h2><ul><li>513.找树左下角的值</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706220206.PNG" alt=""></p><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>所要求的的是</p><h4 id="1-递归法"><a href="#1-递归法" class="headerlink" title="1.递归法"></a>1.递归法</h4><p>可以用一个字典来保护每行第一个节点，使用前序遍历。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.dic = &#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findBottomLeftValue</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.leftValue(root, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">leftValue</span>(<span class="params">self, node, index</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> index <span class="keyword">not</span> <span class="keyword">in</span> self.dic:</span><br><span class="line">            self.dic[index] = node.val</span><br><span class="line">        <span class="comment">##########################################</span></span><br><span class="line">        <span class="comment"># 只需要把下面的两行代码互换，就可以找右边的元素了#</span></span><br><span class="line">        <span class="comment">##########################################</span></span><br><span class="line">        self.leftValue(node.left, index + <span class="number">1</span>)</span><br><span class="line">        self.leftValue(node.right, index + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 由于是数字hash，所以其实是有序的，直接values.pop()即可。</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(self.dic.values()).pop()</span><br></pre></td></tr></table></figure><h4 id="2-迭代法"><a href="#2-迭代法" class="headerlink" title="2.迭代法"></a>2.迭代法</h4><p>可以套用框架。在每层判断时，只讲第一个值赋值给结果即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findBottomLeftValue</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        result = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 保存这行第一个元素即可</span></span><br><span class="line">                <span class="comment">#####################################################</span></span><br><span class="line">                <span class="comment">#只需要把i == 0，换成 i == len(queue),就可以找右边的元素了#</span></span><br><span class="line">                <span class="comment">#####################################################</span></span><br><span class="line">                <span class="keyword">if</span> i == <span class="number">0</span>: result = cur_node.val</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本题同样采用了递归和迭代的方式进行求解。</p><ul><li>迭代法直接套框架。用一个临时变量存值。</li><li>递归法可以用字典对每一层的第一个值进行保护。而字典的键可以用数字（每层的层数），使得无序的字典有序，直接取最后一个值即可。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的左下角的值&quot;&gt;&lt;a href=&quot;#二叉树的左下角的值&quot; class=&quot;headerlink&quot; title=&quot;二叉树的左下角的值&quot;&gt;&lt;/a&gt;二叉树的左下角的值&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;513.找树左下角的值&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>10-二叉树的左叶子之和</title>
    <link href="https://xxren8218.github.io/20210706/10-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E5%8F%B6%E5%AD%90%E4%B9%8B%E5%92%8C.html"/>
    <id>https://xxren8218.github.io/20210706/10-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E5%8F%B6%E5%AD%90%E4%B9%8B%E5%92%8C.html</id>
    <published>2021-07-06T14:00:10.000Z</published>
    <updated>2021-07-06T14:01:14.305Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的左叶子之和"><a href="#二叉树的左叶子之和" class="headerlink" title="二叉树的左叶子之和"></a>二叉树的左叶子之和</h2><ul><li>404 左叶子之和</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706220041.PNG" alt=""></p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1.思路"></a>1.思路</h3><p><strong>「首先要注意是判断左叶子，不是二叉树左侧节点，所以不要上来想着层序遍历。」</strong></p><p>其实题目说的也很清晰了，左和叶子我们都知道表示什么，那么左叶子也应该知道了，但为了大家不会疑惑，我还是来给出左叶子的明确定义：<strong>「如果左节点不为空，且左节点没有左右孩子，那么这个节点就是左叶子」</strong></p><p><strong>「判断当前节点是不是左叶子是无法判断的，必须要通过节点的父节点来判断其左孩子是不是左叶子。」</strong></p><p>思考一下如下图中二叉树，左叶子之和究竟是多少？</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706220101.jpg" alt=""></p><p><strong>「其实是0，因为这棵树根本没有左叶子！」</strong></p><p>那么<strong>「判断当前节点是不是左叶子是无法判断的，必须要通过节点的父节点来判断其左孩子是不是左叶子。」</strong></p><p>如果该节点的左节点不为空，该节点的左节点的左节点为空，该节点的左节点的右节点为空，则找到了一个左叶子，判断代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.left.left <span class="keyword">and</span> <span class="keyword">not</span> node.left.right:</span><br><span class="line">    左叶子节点处理逻辑</span><br></pre></td></tr></table></figure><h4 id="1-1递归法"><a href="#1-1递归法" class="headerlink" title="1.1递归法"></a>1.1递归法</h4><p>递归的遍历顺序为后序遍历（左右中），是因为要通过递归函数的返回值来累加求取左叶子数值之和。</p><p>递归三部曲：</p><ol><li>确定递归函数的参数和返回值</li></ol><p>判断一个树的左叶子节点之和，那么一定要传入树的根节点，递归函数的返回值为数值之和。</p><ol><li>确定终止条件</li></ol><p>依然是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑</li></ol><p>当遇到左叶子节点的时候，记录数值，然后通过递归求取左子树左叶子之和，和 右子树左叶子之和，相加便是整个树的左叶子之和。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sumOfLeftLeaves</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        leftValue = self.sumOfLeftLeaves(root.left)                  <span class="comment"># 左</span></span><br><span class="line">        rightValue = self.sumOfLeftLeaves(root.right)                <span class="comment"># 右</span></span><br><span class="line"></span><br><span class="line">        midValue = <span class="number">0</span>                                                    </span><br><span class="line">        <span class="keyword">if</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.left.left <span class="keyword">and</span> <span class="keyword">not</span> root.left.right: <span class="comment"># 中</span></span><br><span class="line">            midValue = root.left.val</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> leftValue + rightValue + midValue</span><br></pre></td></tr></table></figure><h4 id="1-2-迭代法"><a href="#1-2-迭代法" class="headerlink" title="1.2 迭代法"></a>1.2 迭代法</h4><p>我们可以使用一个辅助函数来判断此节点是否是叶子节点。然后按照层序遍历的框架进行判断即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sumOfLeftLeaves</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 来判断此节点是否是叶子结点</span></span><br><span class="line">        isLeafNode = <span class="keyword">lambda</span> node: <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right</span><br><span class="line"></span><br><span class="line">        queue = [root]</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                <span class="comment"># 若此节点为叶子结点，加入结果</span></span><br><span class="line">                <span class="keyword">if</span> isLeafNode(cur_node.left):</span><br><span class="line">                    result += cur_node.left.val</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                <span class="comment"># 若此节点为叶子结点，不用管它，若不是，则加入队列中。</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> isLeafNode(cur_node.right):</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>我觉得这道题还是有一定难度的，不知道为什么给划分为简单，</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的左叶子之和&quot;&gt;&lt;a href=&quot;#二叉树的左叶子之和&quot; class=&quot;headerlink&quot; title=&quot;二叉树的左叶子之和&quot;&gt;&lt;/a&gt;二叉树的左叶子之和&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;404 左叶子之和&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;ht</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>09-二叉树的所有路径</title>
    <link href="https://xxren8218.github.io/20210706/09-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84.html"/>
    <id>https://xxren8218.github.io/20210706/09-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84.html</id>
    <published>2021-07-06T13:58:48.000Z</published>
    <updated>2021-07-06T13:59:43.736Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的所有路径"><a href="#二叉树的所有路径" class="headerlink" title="二叉树的所有路径"></a>二叉树的所有路径</h2><ul><li>257.二叉树的所有路径</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706215924.PNG" alt=""></p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1. 思路"></a>1. 思路</h3><h4 id="1-1递归法"><a href="#1-1递归法" class="headerlink" title="1.1递归法"></a>1.1递归法</h4><p>最直观的方法是使用深度优先搜索。在深度优先搜索遍历二叉树时，我们需要考虑当前的节点以及它的孩子节点。</p><ul><li><p>如果当前节点不是叶子节点，则在当前的路径末尾添加该节点，并继续递归遍历该节点的每一个孩子节点。</p></li><li><p>如果当前节点是叶子节点，则在当前路径末尾添加该节点后我们就得到了一条从根节点到叶子节点的路径，将</p><p>该路径加入到答案即可。</p></li></ul><p>如此，当遍历完整棵二叉树以后我们就得到了所有从根节点到叶子节点的路径。当然，深度优先搜索也可以使用非递归的方式实现，这里不再赘述。</p><ul><li>注意字符串的拼接是  += （公共方法）</li><li>列表的extend和append的区别。+= 与 extend类似。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">return</span> self.traversal(root, <span class="string">&#x27;&#x27;</span>, result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">traversal</span>(<span class="params">self, node, path, result</span>):</span></span><br><span class="line">        <span class="comment"># 如果当前节点不存在</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># 否则当前节点存在</span></span><br><span class="line">        path += <span class="built_in">str</span>(node.val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 判断是否到达叶子节点</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 到达叶子节点</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">            <span class="comment"># 将路径增加到答案中</span></span><br><span class="line">            result.append(path)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 未到达叶子节点</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            path += <span class="string">&quot;-&gt;&quot;</span></span><br><span class="line">            self.traversal(node.left, path, result)</span><br><span class="line">            self.traversal(node.right, path, result)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>时间复杂度：O(N^2)</p><p>空间复杂度：O(N^2)</p><h4 id="1-2-迭代法"><a href="#1-2-迭代法" class="headerlink" title="1.2 迭代法"></a>1.2 迭代法</h4><p>这里的迭代法采用广度优先搜索来实现。我们维护一个队列，存储节点以及根到该节点的路径。一开始这个队列里只有根节点。在每一步迭代中，我们取出队列中的首节点，如果它是叶子节点，则将它对应的路径加入到答案中。如果它不是叶子节点，则将它的所有孩子节点加入到队列的末尾。当队列为空时广度优先搜索结束，我们即能得到答案。</p><p>这种方式不能保证从左到右的输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        result = []</span><br><span class="line">        node_queue = [root]</span><br><span class="line">        path_queue = [<span class="built_in">str</span>(root.val)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> node_queue:</span><br><span class="line">            node = node_queue.pop(<span class="number">0</span>)</span><br><span class="line">            path = path_queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">                result.append(path)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                node_queue.append(node.left)</span><br><span class="line">                path_queue.append(path + <span class="string">&quot;-&gt;&quot;</span> + <span class="built_in">str</span>(node.left.val))</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                node_queue.append(node.right)</span><br><span class="line">                path_queue.append(path + <span class="string">&quot;-&gt;&quot;</span> + <span class="built_in">str</span>(node.right.val))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="2-总结"><a href="#2-总结" class="headerlink" title="2. 总结"></a>2. 总结</h3><p>可以看出来，不管是递归的前序遍历还是广度的迭代遍历，都有我们模板的影子。实际上还是在模板上的一些小改进而已。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的所有路径&quot;&gt;&lt;a href=&quot;#二叉树的所有路径&quot; class=&quot;headerlink&quot; title=&quot;二叉树的所有路径&quot;&gt;&lt;/a&gt;二叉树的所有路径&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;257.二叉树的所有路径&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;htt</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>32-Spark Streaming概述及编码实战</title>
    <link href="https://xxren8218.github.io/20210706/32-Spark-Streaming%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%BC%96%E7%A0%81%E5%AE%9E%E6%88%98.html"/>
    <id>https://xxren8218.github.io/20210706/32-Spark-Streaming%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%BC%96%E7%A0%81%E5%AE%9E%E6%88%98.html</id>
    <published>2021-07-05T17:04:53.000Z</published>
    <updated>2021-07-05T17:06:32.231Z</updated>
    
    <content type="html"><![CDATA[<h1 id="掌握目标"><a href="#掌握目标" class="headerlink" title="掌握目标"></a>掌握目标</h1><ul><li>说出Spark Streaming的特点</li><li>说出DStreaming的常见操作api</li><li>能够应用Spark Streaming实现实时数据处理</li><li>能够应用Spark Streaming的状态操作解决实际问题</li><li>独立实现foreachRDD向mysql数据库的数据写入</li><li>独立实现Spark Streaming对接kafka实现实时数据处理</li></ul><h2 id="1、sparkStreaming概述"><a href="#1、sparkStreaming概述" class="headerlink" title="1、sparkStreaming概述"></a>1、sparkStreaming概述</h2><h3 id="1-1-SparkStreaming是什么"><a href="#1-1-SparkStreaming是什么" class="headerlink" title="1.1 SparkStreaming是什么"></a>1.1 SparkStreaming是什么</h3><ul><li><p>它是一个<strong>可扩展</strong>，<strong>高吞吐</strong>具有<strong>容错性</strong>的<strong>流式计算框架</strong></p><p>吞吐量：单位时间内成功传输数据的数量</p></li></ul><p>之前我们接触的spark-core和spark-sql都是处理属于<strong>离线批处理</strong>任务，数据一般都是在固定位置上，通常我们写好一个脚本，每天定时去处理数据，计算，保存数据结果。这类任务通常是T+1(一天一个任务)，对实时性要求不高。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706010555.png" alt=""></p><p>但在企业中存在很多实时性处理的需求，例如：双十一的京东阿里，通常会做一个实时的数据大屏，显示实时订单。这种情况下，对数据实时性要求较高，仅仅能够容忍到延迟1分钟或几秒钟。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706010619.PNG" alt=""></p><p><strong>实时计算框架对比</strong></p><p>Storm</p><ul><li>流式计算框架</li><li>以record为单位处理数据</li><li>也支持micro-batch方式（Trident）</li><li>没有处理机器学习的生态</li><li>没有离线计算的框架</li><li>对python不友好</li></ul><p>Spark</p><ul><li>批处理计算框架</li><li>以RDD为单位处理数据</li><li>支持micro-batch流式处理数据（Spark Streaming）</li><li>有机器学习相关的库</li></ul><p>对比：</p><ul><li>吞吐量：Spark Streaming优于Storm</li><li>延迟：Spark Streaming差于Storm</li></ul><h3 id="1-2-Spark-Streaming的组件"><a href="#1-2-Spark-Streaming的组件" class="headerlink" title="1.2 Spark Streaming的组件"></a>1.2 Spark Streaming的组件</h3><ul><li>Streaming Context<ul><li>一旦一个Context已经启动(调用了Streaming Context的start()),就不能有新的流算子(Dstream)建立或者是添加到context中</li><li>一旦一个context已经停止,不能重新启动(Streaming Context调用了stop方法之后 就不能再次调 start())</li><li>在JVM(java虚拟机)中, 同一时间只能有一个Streaming Context处于活跃状态, 一个SparkContext创建一个Streaming Context</li><li>在Streaming Context上调用Stop方法, 也会关闭SparkContext对象, 如果只想仅关闭Streaming Context对象,设置stop()的可选参数为false</li><li>一个SparkContext对象可以重复利用去创建多个Streaming Context对象(不关闭SparkContext前提下), 但是需要关一个再开下一个</li></ul></li><li>DStream (离散流)<ul><li>代表一个连续的数据流</li><li>在内部, DStream由一系列连续的RDD组成</li><li>DStreams中的每个RDD都包含确定时间间隔内的数据</li><li>任何对DStreams的操作都转换成了对DStreams隐含的RDD的操作</li><li>数据源<ul><li>基本源<ul><li>TCP/IP Socket</li><li>FileSystem</li></ul></li><li>高级源<ul><li>Kafka</li><li>Flume</li></ul></li></ul></li></ul></li></ul><h2 id="2、Spark-Streaming编码实践"><a href="#2、Spark-Streaming编码实践" class="headerlink" title="2、Spark Streaming编码实践"></a>2、Spark Streaming编码实践</h2><p><strong>Spark Streaming编码步骤：</strong></p><ul><li>1，创建一个StreamingContext</li><li>2，从StreamingContext中创建一个数据对象</li><li>3，对数据对象进行Transformations操作</li><li>4，输出结果</li><li>5，开始和停止</li></ul><p><strong>利用Spark Streaming实现WordCount</strong></p><p>需求：监听某个端口上的网络数据，实时统计出现的不同单词个数。</p><p>1，需要安装一个nc工具：sudo yum install -y nc</p><p>2，执行指令：nc -lk 9999 -v</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    </span><br><span class="line">    sc = SparkContext(<span class="string">&quot;local[2]&quot;</span>,appName=<span class="string">&quot;NetworkWordCount&quot;</span>)</span><br><span class="line">    <span class="comment"># 参数2：指定执行计算的时间间隔</span></span><br><span class="line">    ssc = StreamingContext(sc, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 监听ip，端口上的上的数据 （需要打开端口）【nc -lk 9999 -v】</span></span><br><span class="line">    lines = ssc.socketTextStream(<span class="string">&#x27;localhost&#x27;</span>,<span class="number">9999</span>) </span><br><span class="line">    <span class="comment"># 将数据按空格进行拆分为多个单词</span></span><br><span class="line">    words = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    <span class="comment"># 将单词转换为(单词，1)的形式</span></span><br><span class="line">    pairs = words.<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 统计单词个数</span></span><br><span class="line">    wordCounts = pairs.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)</span><br><span class="line">    <span class="comment"># 打印结果信息，会使得前面的transformation操作执行</span></span><br><span class="line">    wordCounts.pprint() <span class="comment"># pprint() 对RDD的操作</span></span><br><span class="line">    <span class="comment"># 启动StreamingContext</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    <span class="comment"># 等待计算结束(不是交互式环境的话需要加这个参数，不然很快就停了)</span></span><br><span class="line">    ssc.awaitTermination()</span><br></pre></td></tr></table></figure><p>可视化查看效果：<a href="http://192.168.199.188:4040">http://192.168.199.188:4040</a></p><p>点击streaming，查看效果</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;掌握目标&quot;&gt;&lt;a href=&quot;#掌握目标&quot; class=&quot;headerlink&quot; title=&quot;掌握目标&quot;&gt;&lt;/a&gt;掌握目标&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;说出Spark Streaming的特点&lt;/li&gt;
&lt;li&gt;说出DStreaming的常见操作api&lt;/li&gt;
</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>31-Spark JSON数据处理 &amp; 数据清洗</title>
    <link href="https://xxren8218.github.io/20210706/31-Spark-JSON%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97.html"/>
    <id>https://xxren8218.github.io/20210706/31-Spark-JSON%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97.html</id>
    <published>2021-07-05T17:03:02.000Z</published>
    <updated>2021-07-05T17:04:23.493Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、JSON数据的处理"><a href="#1、JSON数据的处理" class="headerlink" title="1、JSON数据的处理"></a>1、JSON数据的处理</h1><h2 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h2><p><strong>JSON数据</strong></p><ul><li>网页和后端数据交互所用我的格式。</li><li><p>在Spark中能自动化的把结构加载进来，并且能推断数据类型。（CSV将所有都处理成 String）</p></li><li><p><code>Spark SQL can automatically infer the schema of a JSON dataset and load it as a DataFrame</code></p><p>Spark SQL能够自动将JSON数据集以结构化的形式加载为一个DataFrame</p></li><li><p>This conversion can be done using SparkSession.read.json on a JSON file</p><p>读取一个JSON文件可以用SparkSession.read.json方法</p></li></ul><p><strong>从JSON到DataFrame</strong></p><ul><li><p>指定DataFrame的schema</p><p>1，通过反射自动推断，适合静态数据</p><p>2，程序指定，适合程序运行中动态生成的数据</p></li></ul><p><strong>加载json数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用内部的schema</span></span><br><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line">jsonDF = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;json&#x27;</span>).load(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定schema</span></span><br><span class="line">jsonDF = spark.read.schema(jsonSchema).json(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>嵌套结构的JSON</strong></p><ul><li><p>重要的方法</p><p>1，get_json_object</p><p>2，get_json</p><p>3，explode</p></li></ul><h2 id="1-2-实践"><a href="#1-2-实践" class="headerlink" title="1.2 实践"></a>1.2 实践</h2><h3 id="1-2-1-静态json数据的读取和操作"><a href="#1-2-1-静态json数据的读取和操作" class="headerlink" title="1.2.1 静态json数据的读取和操作"></a>1.2.1 静态json数据的读取和操作</h3><p><strong>无嵌套结构的json数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark =  SparkSession.builder.appName(<span class="string">&#x27;json_demo&#x27;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==========================================</span></span><br><span class="line"><span class="comment">#                无嵌套结构的json</span></span><br><span class="line"><span class="comment"># ==========================================</span></span><br><span class="line">jsonString = [</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01001&quot;, &quot;city&quot; : &quot;AGAWAM&quot;,  &quot;pop&quot; : 15338, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span>,</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01002&quot;, &quot;city&quot; : &quot;CUSHMAN&quot;, &quot;pop&quot; : 36963, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><strong>从json字符串数组得到DataFrame</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从json字符串数组得到rdd有两种方法</span></span><br><span class="line"><span class="comment"># 1. 转换为rdd，再从rdd到DataFrame</span></span><br><span class="line"><span class="comment"># 2. 直接利用spark.createDataFrame()，见后面例子</span></span><br><span class="line"></span><br><span class="line">jsonRDD = sc.parallelize(jsonString)   <span class="comment"># stringJSONRDD</span></span><br><span class="line">jsonDF =  spark.read.json(jsonRDD)  <span class="comment"># convert RDD into DataFrame</span></span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show()</span><br></pre></td></tr></table></figure><p><strong>直接从文件生成DataFrame</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -- 直接从文件生成DataFrame</span></span><br><span class="line"><span class="comment"># 只有被压缩后的json文件内容，才能被spark-sql正确读取，否则格式化后的数据读取会出现问题</span></span><br><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="comment"># jsonDF = spark.read.format(&#x27;json&#x27;).load(&#x27;xxx.json&#x27;)</span></span><br><span class="line"></span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show(truncate=<span class="literal">False</span>) <span class="comment"># truncate=False 数据较长的时候不会...进行省略。默认会以...替换行内过长的数据</span></span><br><span class="line"></span><br><span class="line">jsonDF.<span class="built_in">filter</span>(jsonDF.pop&gt;<span class="number">4000</span>).show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 依照已有的DataFrame，创建一个临时的表(相当于mysql数据库中的一个表)，这样就可以用纯sql语句进行数据操作</span></span><br><span class="line">jsonDF.createOrReplaceTempView(<span class="string">&quot;tmp_table&quot;</span>)</span><br><span class="line"></span><br><span class="line">resultDF = spark.sql(<span class="string">&quot;select * from tmp_table where pop&gt;4000&quot;</span>)</span><br><span class="line">resultDF.show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="1-2-1-动态json数据的读取和操作"><a href="#1-2-1-动态json数据的读取和操作" class="headerlink" title="1.2.1 动态json数据的读取和操作"></a>1.2.1 动态json数据的读取和操作</h3><p><strong>指定DataFrame的Schema</strong></p><p>上面的例子为通过反射自动推断schema，适合静态数据</p><p>下面我们来讲解如何进行程序指定schema</p><p><strong>没有嵌套结构的json</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">jsonString = [</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01001&quot;, &quot;city&quot; : &quot;AGAWAM&quot;,  &quot;pop&quot; : 15338, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span>,</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01002&quot;, &quot;city&quot; : &quot;CUSHMAN&quot;, &quot;pop&quot; : 36963, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">jsonRDD = sc.parallelize(jsonString)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义结构类型</span></span><br><span class="line"><span class="comment"># StructType：schema的整体结构，表示JSON的对象结构</span></span><br><span class="line"><span class="comment"># XXXStype:指的是某一列的数据类型</span></span><br><span class="line">jsonSchema = StructType() \</span><br><span class="line">  .add(<span class="string">&quot;id&quot;</span>, StringType(),<span class="literal">True</span>) \</span><br><span class="line">  .add(<span class="string">&quot;city&quot;</span>, StringType()) \</span><br><span class="line">  .add(<span class="string">&quot;pop&quot;</span> , LongType()) \</span><br><span class="line">  .add(<span class="string">&quot;state&quot;</span>,StringType())</span><br><span class="line"></span><br><span class="line">jsonSchema = StructType() \</span><br><span class="line">  .add(<span class="string">&quot;id&quot;</span>, LongType(),<span class="literal">True</span>) \</span><br><span class="line">  .add(<span class="string">&quot;city&quot;</span>, StringType()) \</span><br><span class="line">  .add(<span class="string">&quot;pop&quot;</span> , DoubleType()) \</span><br><span class="line">  .add(<span class="string">&quot;state&quot;</span>,StringType())</span><br><span class="line"></span><br><span class="line">reader = spark.read.schema(jsonSchema)</span><br><span class="line"></span><br><span class="line">jsonDF = reader.json(jsonRDD)</span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show()</span><br></pre></td></tr></table></figure><p><strong>带有嵌套结构的json</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line">jsonSchema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;id&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;city&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;loc&quot;</span> , ArrayType(DoubleType())),</span><br><span class="line">    StructField(<span class="string">&quot;pop&quot;</span>, LongType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;state&quot;</span>, StringType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">reader = spark.read.schema(jsonSchema)</span><br><span class="line">jsonDF = reader.json(<span class="string">&#x27;data/nest.json&#x27;</span>)</span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show(<span class="number">2</span>)</span><br><span class="line">jsonDF.<span class="built_in">filter</span>(jsonDF.pop&gt;<span class="number">4000</span>).show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h1 id="2、数据清洗"><a href="#2、数据清洗" class="headerlink" title="2、数据清洗"></a>2、数据清洗</h1><ul><li>处理重复数据</li><li>处理缺失情况</li><li>处理异常值</li></ul><p>前面我们处理的数据实际上都是已经被处理好的规整数据，但是在大数据整个生产过程中，需要先对数据进行数据清洗，将杂乱无章的数据整理为符合后面处理要求的规整数据。</p><h2 id="2-1-数据去重"><a href="#2-1-数据去重" class="headerlink" title="2.1 数据去重"></a>2.1 数据去重</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1.删除重复数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">groupby().count()：可以看到数据的重复情况</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">  (<span class="number">1</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">2</span>, <span class="number">167.2</span>, <span class="number">5.4</span>, <span class="number">45</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="number">23</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.7</span>, <span class="number">54</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="number">23</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">], [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看重复记录</span></span><br><span class="line"><span class="comment"># 无意义重复数据去重：数据中行与行完全重复</span></span><br><span class="line"><span class="comment"># 1.首先删除完全一样的记录</span></span><br><span class="line">df2 = df.dropDuplicates()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 有意义去重：删除除去无意义字段之外的完全重复的行数据</span></span><br><span class="line"><span class="comment"># 2.其次，关键字段值完全一模一样的记录（在这个例子中，是指除了id之外的列一模一样）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除某些字段值完全一样的重复记录，subset参数定义这些字段</span></span><br><span class="line">df3 = df2.dropDuplicates(subset = [c <span class="keyword">for</span> c <span class="keyword">in</span> df2.columns <span class="keyword">if</span> c!=<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.有意义的重复记录去重之后，再看某个无意义字段的值是否有重复（在这个例子中，是看id是否重复）</span></span><br><span class="line"><span class="comment"># 查看某一列是否有重复值</span></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> fn</span><br><span class="line">df3.agg(fn.count(<span class="string">&#x27;id&#x27;</span>).alias(<span class="string">&#x27;id_count&#x27;</span>),fn.countDistinct(<span class="string">&#x27;id&#x27;</span>).alias(<span class="string">&#x27;distinct_id_count&#x27;</span>)).collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.对于id这种无意义的列重复，添加另外一列自增id——不连续。</span></span><br><span class="line">df3.withColumn(<span class="string">&#x27;new_id&#x27;</span>,fn.monotonically_increasing_id()).show()</span><br></pre></td></tr></table></figure><h3 id="2-2-缺失值处理"><a href="#2-2-缺失值处理" class="headerlink" title="2.2 缺失值处理"></a>2.2 缺失值处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">2.处理缺失值</span></span><br><span class="line"><span class="string">2.1 对缺失值进行删除操作(行，列)</span></span><br><span class="line"><span class="string">2.2 对缺失值进行填充操作(列的均值)</span></span><br><span class="line"><span class="string">2.3 对缺失值对应的行或列进行标记</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df_miss = spark.createDataFrame([</span><br><span class="line">(<span class="number">1</span>, <span class="number">143.5</span>, <span class="number">5.6</span>, <span class="number">28</span>,<span class="string">&#x27;M&#x27;</span>, <span class="number">100000</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="number">167.2</span>, <span class="number">5.4</span>, <span class="number">45</span>,<span class="string">&#x27;M&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="literal">None</span> , <span class="number">5.2</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.7</span>, <span class="number">54</span>, <span class="string">&#x27;F&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="literal">None</span>, <span class="string">&#x27;F&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">76000</span>),],</span><br><span class="line"> [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.计算每条记录的缺失值情况</span></span><br><span class="line"><span class="comment"># 将DataFrame转换成RDD，这样写自定义函数方便些。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从行的角度统计缺失情况.</span></span><br><span class="line">df_miss.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> row:(row[<span class="string">&#x27;id&#x27;</span>], <span class="built_in">sum</span>([c==<span class="literal">None</span> <span class="keyword">for</span> c <span class="keyword">in</span> row]))).collect()</span><br><span class="line">[(<span class="number">1</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">3</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">1</span>), (<span class="number">5</span>, <span class="number">1</span>), (<span class="number">6</span>, <span class="number">2</span>), (<span class="number">7</span>, <span class="number">0</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.计算各列的缺失情况百分比</span></span><br><span class="line">df_miss.agg(*[(<span class="number">1</span> - (fn.count(c) / fn.count(<span class="string">&#x27;*&#x27;</span>))).alias(c + <span class="string">&#x27;_missing&#x27;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> df_miss.columns]).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、删除缺失值过于严重的列</span></span><br><span class="line"><span class="comment"># 其实是先建一个DF，不要缺失值的列</span></span><br><span class="line">df_miss_no_income = df_miss.select([</span><br><span class="line">c <span class="keyword">for</span> c <span class="keyword">in</span> df_miss.columns <span class="keyword">if</span> c != <span class="string">&#x27;income&#x27;</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、按照缺失值删除行（threshold是根据一行记录中，缺失字段的百分比的定义）</span></span><br><span class="line">df_miss_no_income.dropna(thresh=<span class="number">3</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、填充缺失值，可以用fillna来填充缺失值，</span></span><br><span class="line"><span class="comment"># 对于bool类型、或者分类类型，可以为缺失值单独设置一个类型，missing</span></span><br><span class="line"><span class="comment"># 对于数值类型，可以用均值或者中位数等填充</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fillna可以接收两种类型的参数：</span></span><br><span class="line"><span class="comment"># 一个数字、字符串，这时整个DataSet中所有的缺失值都会被填充为相同的值。</span></span><br><span class="line"><span class="comment"># 也可以接收一个字典｛列名：值｝这样</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先计算均值，并组织成一个字典(除去性别这一列。)</span></span><br><span class="line">means = df_miss_no_income.agg( *[fn.mean(c).alias(c) <span class="keyword">for</span> c <span class="keyword">in</span> df_miss_no_income.columns <span class="keyword">if</span> c != <span class="string">&#x27;gender&#x27;</span>]).toPandas().to_dict(<span class="string">&#x27;records&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后添加其它的列——非数值型</span></span><br><span class="line">means[<span class="string">&#x27;gender&#x27;</span>] = <span class="string">&#x27;missing&#x27;</span></span><br><span class="line"></span><br><span class="line">df_miss_no_income.fillna(means).show()</span><br></pre></td></tr></table></figure><h3 id="2-3-异常值处理——年龄等。"><a href="#2-3-异常值处理——年龄等。" class="headerlink" title="2.3 异常值处理——年龄等。"></a>2.3 异常值处理——年龄等。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">3、异常值处理</span></span><br><span class="line"><span class="string">异常值：不属于正常的值 包含：缺失值，超过正常范围内的较大值或较小值</span></span><br><span class="line"><span class="string">分位数去极值</span></span><br><span class="line"><span class="string">中位数绝对偏差去极值</span></span><br><span class="line"><span class="string">正态分布去极值</span></span><br><span class="line"><span class="string">上述三种操作的核心都是：通过原始数据设定一个正常的范围，超过此范围的就是一个异常值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df_outliers = spark.createDataFrame([</span><br><span class="line">(<span class="number">1</span>, <span class="number">143.5</span>, <span class="number">5.3</span>, <span class="number">28</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="number">154.2</span>, <span class="number">5.5</span>, <span class="number">45</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="number">342.3</span>, <span class="number">5.1</span>, <span class="number">99</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.5</span>, <span class="number">33</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.4</span>, <span class="number">54</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="number">124.1</span>, <span class="number">5.1</span>, <span class="number">21</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>),</span><br><span class="line">], [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>])</span><br><span class="line"><span class="comment"># 设定范围 超出这个范围的 用边界值替换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># approxQuantile方法接收三个参数：参数1，列名；参数2：想要计算的分位点，可以是一个点，也可以是一个列表（0和1之间的小数），第三个参数是能容忍的误差，如果是0，代表百分百精确计算。</span></span><br><span class="line"></span><br><span class="line">cols = [<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line"></span><br><span class="line">bounds = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">    quantiles = df_outliers.approxQuantile(col, [<span class="number">0.25</span>, <span class="number">0.75</span>], <span class="number">0.05</span>)</span><br><span class="line">    IQR = quantiles[<span class="number">1</span>] - quantiles[<span class="number">0</span>]</span><br><span class="line">    bounds[col] = [</span><br><span class="line">        quantiles[<span class="number">0</span>] - <span class="number">1.5</span> * IQR,</span><br><span class="line">        quantiles[<span class="number">1</span>] + <span class="number">1.5</span> * IQR</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bounds</span><br><span class="line">&#123;<span class="string">&#x27;age&#x27;</span>: [-<span class="number">11.0</span>, <span class="number">93.0</span>], <span class="string">&#x27;height&#x27;</span>: [<span class="number">4.499999999999999</span>, <span class="number">6.1000000000000005</span>], <span class="string">&#x27;weight&#x27;</span>: [<span class="number">91.69999999999999</span>, <span class="number">191.7</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为异常值字段打标志</span></span><br><span class="line">outliers = df_outliers.select(*[<span class="string">&#x27;id&#x27;</span>] + [( (df_outliers[c] &lt; bounds[c][<span class="number">0</span>]) | (df_outliers[c] &gt; bounds[c][<span class="number">1</span>]) ).alias(c + <span class="string">&#x27;_o&#x27;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> cols ])</span><br><span class="line">outliers.show()</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"><span class="comment"># | id|weight_o|height_o|age_o|</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"><span class="comment"># |  1|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  2|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  3|    true|   false| true|</span></span><br><span class="line"><span class="comment"># |  4|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  5|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  6|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  7|   false|   false|false|</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再回头看看这些异常值的值，重新和原始数据关联</span></span><br><span class="line"></span><br><span class="line">df_outliers = df_outliers.join(outliers, on=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">df_outliers.<span class="built_in">filter</span>(<span class="string">&#x27;weight_o&#x27;</span>).select(<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>).show()</span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"><span class="comment"># | id|weight|</span></span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"><span class="comment"># |  3| 342.3|</span></span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"></span><br><span class="line">df_outliers.<span class="built_in">filter</span>(<span class="string">&#x27;age_o&#x27;</span>).select(<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;age&#x27;</span>).show()</span><br><span class="line"><span class="comment"># +---+---+</span></span><br><span class="line"><span class="comment"># | id|age|</span></span><br><span class="line"><span class="comment"># +---+---+</span></span><br><span class="line"><span class="comment"># |  3| 99|</span></span><br><span class="line"><span class="comment"># +---+---+</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、JSON数据的处理&quot;&gt;&lt;a href=&quot;#1、JSON数据的处理&quot; class=&quot;headerlink&quot; title=&quot;1、JSON数据的处理&quot;&gt;&lt;/a&gt;1、JSON数据的处理&lt;/h1&gt;&lt;h2 id=&quot;1-1-介绍&quot;&gt;&lt;a href=&quot;#1-1-介绍&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>08-平衡二叉树</title>
    <link href="https://xxren8218.github.io/20210705/08-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91.html"/>
    <id>https://xxren8218.github.io/20210705/08-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91.html</id>
    <published>2021-07-05T10:36:20.000Z</published>
    <updated>2021-07-05T10:37:28.881Z</updated>
    
    <content type="html"><![CDATA[<h2 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h2><ul><li>110.平衡二叉树</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183701.PNG" alt=""></p><p>咋眼一看这道题目和[二叉树的最大深度]很像，其实有很大区别。</p><p>这里强调一波概念：</p><ul><li>二叉树节点的深度：指从根节点到该节点的最长简单路径边的条数。</li><li>二叉树节点的高度：指从该节点到叶子节点的最长简单路径边的条数。</li></ul><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>这道题中的平衡二叉树的定义是：二叉树的每个节点的左右子树的高度差的绝对值不超过 1，则二叉树是平衡二叉树。根据定义，一棵二叉树是平衡二叉树，当且仅当其所有子树也都是平衡二叉树，因此可以使用递归的方式判断二叉树是不是平衡二叉树，递归的顺序可以是自顶向下或者自底向上。</p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1.思路"></a>1.思路</h3><h4 id="1-1递归法——自上而下（前序遍历）"><a href="#1-1递归法——自上而下（前序遍历）" class="headerlink" title="1.1递归法——自上而下（前序遍历）"></a>1.1递归法——自上而下（前序遍历）</h4><p>定义函数 height，用于计算二叉树中的任意一个节点 p 的高度：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183719.PNG" alt=""></p><p>有了计算节点高度的函数，即可判断二叉树是否平衡。具体做法类似于二叉树的前序遍历，即对于当前遍历到的节点，首先计算左右子树的高度，如果左右子树的高度差是否不超过 1，再分别递归地遍历左右子节点，并判断左子树和右子树是否平衡。这是一个自顶向下的递归的过程。也就是前序遍历。</p><ul><li><strong>实际上就是写找最大深度即可(后序遍历写出)</strong>。再前序递归进行计算。</li></ul><p>递归三步曲分析：</p><ol><li>明确递归函数的参数和返回值</li></ol><p>参数的话为传入的节点指针，就没有其他参数需要传递了，返回值要返回传入节点为根节点树的高度。</p><p>那么如何标记左右子树是否差值大于1呢。</p><p>只需要单独判断</p><ul><li>左右子树是否为平衡树，</li><li>左子树是否为平衡树</li><li>右子树是否为平衡树即可</li></ul><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义函数找深度当前节点为根节点的树的深度。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Height</span>(<span class="params">node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>明确终止条件</li></ol><p>递归的过程中依然是遇到空节点了为终止，返回0，表示当前节点为根节点的高度为0</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>明确单层递归的逻辑</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只要一个不满足就不是平衡树了。</span></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">abs</span>(leftHeight - rightHeight) &lt;= <span class="number">1</span> <span class="keyword">and</span> isBalanced(root.left) <span class="keyword">and</span> </span><br><span class="line">isBalanced(root.right)</span><br></pre></td></tr></table></figure><p>整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isBalanced</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="comment">##   前序在这里体现   ##</span></span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">abs</span>(self.Height(root.left) - self.Height(root.right)) &lt;= <span class="number">1</span> <span class="keyword">and</span> \</span><br><span class="line">                self.isBalanced(root.left) <span class="keyword">and</span> \</span><br><span class="line">                self.isBalanced(root.right)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Height</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftHeight = self.Height(node.left)</span><br><span class="line">        rightHeight = self.Height(node.right)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + <span class="built_in">max</span>(leftHeight, rightHeight)</span><br></pre></td></tr></table></figure><p>时间复杂度：O(n^2)，其中 n 是二叉树中的节点个数。</p><p>空间复杂度：O(n)。</p><h4 id="1-2-递归法——自下而上（后序遍历）"><a href="#1-2-递归法——自下而上（后序遍历）" class="headerlink" title="1.2 递归法——自下而上（后序遍历）"></a>1.2 递归法——自下而上（后序遍历）</h4><p>方法一由于是自顶向下递归，因此对于同一个节点，函数 height 会被重复调用，导致时间复杂度较高。如果使用自底向上的做法，则对于每个节点，函数 height 只会被调用一次。</p><p>自底向上递归的做法类似于后序遍历，对于当前遍历到的节点，先递归地判断其左右子树是否平衡，再判断以当前节点为根的子树是否平衡。如果一棵子树是平衡的，则返回其高度（高度一定是非负整数），否则返回 -1−1。如果存在一棵子树不平衡，则整个二叉树一定不平衡。</p><p>只需修改后序遍历的代码，相当于在子函数（Height()）递归时进行判断了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isBalanced</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> self.Height(root) &gt;= <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Height</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        此处的单层递归的逻辑是：</span></span><br><span class="line"><span class="string">        若是平衡二叉树，直接返回深度</span></span><br><span class="line"><span class="string">        若不是平衡二叉树，返回 -1。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftHeight = self.Height(node.left)</span><br><span class="line">        rightHeight = self.Height(node.right)</span><br><span class="line">        <span class="comment">####################</span></span><br><span class="line">        <span class="comment">##  后序在这里体现  ## </span></span><br><span class="line">        <span class="comment">####################</span></span><br><span class="line">        <span class="keyword">if</span> leftHeight == -<span class="number">1</span> <span class="keyword">or</span> rightHeight == -<span class="number">1</span> <span class="keyword">or</span> <span class="built_in">abs</span>(leftHeight - rightHeight) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(leftHeight, rightHeight) + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>时间复杂度：O(n)，其中 nn 是二叉树中的节点个数。使用自底向上的递归，每个节点的计算高度和判断是否平衡都只需要处理一次，最坏情况下需要遍历二叉树中的所有节点，因此时间复杂度是 O(n)。</p><p>空间复杂度：O(n)，其中 nn 是二叉树中的节点个数。空间复杂度主要取决于递归调用的层数，递归调用的层数不会超过 n。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本题没有给迭代的解法，说实话我觉得有点难，懒得想了！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;平衡二叉树&quot;&gt;&lt;a href=&quot;#平衡二叉树&quot; class=&quot;headerlink&quot; title=&quot;平衡二叉树&quot;&gt;&lt;/a&gt;平衡二叉树&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;110.平衡二叉树&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdeli</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>07-完全二叉树的节点个数</title>
    <link href="https://xxren8218.github.io/20210705/07-%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%AA%E6%95%B0.html"/>
    <id>https://xxren8218.github.io/20210705/07-%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%AA%E6%95%B0.html</id>
    <published>2021-07-05T10:34:49.000Z</published>
    <updated>2021-07-05T10:35:49.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="完全二叉树的节点个数"><a href="#完全二叉树的节点个数" class="headerlink" title="完全二叉树的节点个数"></a>完全二叉树的节点个数</h2><ul><li>222.完全二叉树的节点个数</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183522.PNG" alt=""></p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1.思路"></a>1.思路</h3><p>这道题目其实没有必要强调是完全二叉树，就是求二叉树节点的个数。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183536.png" alt=""></p><p>依然可以使用递归法和迭代法来解决。</p><p>这道题目的递归法和求二叉树的深度写法类似， 而迭代法：二叉树层序遍历模板稍稍修改一下，记录遍历的节点数量就可以了。</p><p>递归遍历的顺序依然是后序（左右中）。</p><h3 id="2-递归法"><a href="#2-递归法" class="headerlink" title="2.递归法"></a>2.递归法</h3><ol><li>确定递归函数的参数和返回值：参数就是传入树的根节点，返回就返回以该节点为根节点二叉树的节点数量。</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTreeNumber</span>(<span class="params">node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>确定终止条件：如果为空节点的话，就返回0，表示节点数为0</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑：先求它的左子树的节点数量，再求的右子树的节点数量，最后取总和再加一 （加1是因为算上当前中间节点）就是目前节点为根节点的节点数量。</li></ol><p>整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countNodes</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getTreeNumber(root)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTreeNumber</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftnum = self.getTreeNumber(node.left)</span><br><span class="line">        rightnum = self.getTreeNumber(node.right)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + leftnum + rightnum</span><br></pre></td></tr></table></figure><h3 id="3-迭代法"><a href="#3-迭代法" class="headerlink" title="3.迭代法"></a>3.迭代法</h3><p>层序迭代法也很简单。只要模板少做改动，加一个变量result，统计节点数量就可以了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countNodes</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                queue.append(cur_node.left)</span><br><span class="line">            <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>一样的分析套路，代码也差不多，估计此时大家最这一类求二叉树节点数量以及求深度应该非常熟练了。</p><p>没有做过这道题目的同学可以愉快的刷了它。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;完全二叉树的节点个数&quot;&gt;&lt;a href=&quot;#完全二叉树的节点个数&quot; class=&quot;headerlink&quot; title=&quot;完全二叉树的节点个数&quot;&gt;&lt;/a&gt;完全二叉树的节点个数&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;222.完全二叉树的节点个数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;im</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>30-Spark SQL概述 &amp; Spark DataFrame</title>
    <link href="https://xxren8218.github.io/20210705/30-Spark-SQL%E6%A6%82%E8%BF%B0-Spark-DataFrame.html"/>
    <id>https://xxren8218.github.io/20210705/30-Spark-SQL%E6%A6%82%E8%BF%B0-Spark-DataFrame.html</id>
    <published>2021-07-04T17:00:41.000Z</published>
    <updated>2021-07-04T17:04:20.780Z</updated>
    
    <content type="html"><![CDATA[<h1 id="掌握目标"><a href="#掌握目标" class="headerlink" title="掌握目标"></a>掌握目标</h1><ul><li>说出Spark Sql的相关概念</li><li>说出DataFrame与RDD的联系</li><li>独立实现Spark Sql对JSON数据的处理</li><li>独立实现Spark Sql进行数据清洗</li></ul><h2 id="1、Spark-SQL-概述"><a href="#1、Spark-SQL-概述" class="headerlink" title="1、Spark SQL 概述"></a>1、Spark SQL 概述</h2><p><strong>Spark SQL概念</strong></p><ul><li>Spark SQL is Apache Spark’s module for working with structured data.<ul><li>它是spark中用于处理结构化数据的一个模块</li></ul></li></ul><p><strong>Spark SQL历史</strong></p><ul><li>Hive是目前大数据领域，事实上的数据仓库标准。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010211.PNG" alt=""></p><ul><li>Shark：shark底层使用spark的基于内存的计算模型，从而让性能比Hive提升了数倍到上百倍。</li><li>底层很多东西还是依赖于Hive，修改了内存管理、物理计划、执行三个模块</li><li>2014年6月1日的时候，Spark宣布了不再开发Shark，全面转向Spark SQL的开发</li></ul><p><strong>Spark SQL优势</strong></p><ul><li>Write Less Code</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010243.PNG" alt=""></p><ul><li>Performance</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010304.PNG" alt=""></p><p>python操作RDD，转换为可执行代码，运行在java虚拟机，涉及两个不同语言引擎之间的切换，进行进程间        通信很耗费性能。</p><p>DataFrame</p><ul><li>是RDD为基础的分布式数据集，类似于传统关系型数据库的二维表，dataframe记录了对应列的名称和类型</li><li>dataFrame引入schema和off-heap(使用操作系统层面上的内存)<ul><li>1、解决了RDD的缺点</li><li>序列化和反序列化开销大</li><li>频繁的创建和销毁对象造成大量的GC</li><li>2、丢失了RDD的优点</li><li>RDD编译时进行类型检查</li><li>RDD具有面向对象编程的特性</li></ul></li></ul><p>用scala/python编写的RDD比Spark SQL编写转换的RDD慢，涉及到执行计划</p><ul><li>CatalystOptimizer：Catalyst优化器</li><li>ProjectTungsten：钨丝计划，为了提高RDD的效率而制定的计划</li><li>Code gen：代码生成器</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010321.PNG" alt=""></p><p>直接编写RDD也可以自实现优化代码，但是远不及SparkSQL前面的优化操作后转换的RDD效率高，快1倍左右</p><p>优化引擎：类似mysql等关系型数据库基于成本的优化器</p><p>首先执行逻辑执行计划，然后转换为物理执行计划(选择成本最小的)，通过Code Generation最终生成为RDD</p><ul><li><p>Language-independent API</p><p>用任何语言编写生成的RDD都一样，而使用spark-core编写的RDD，不同的语言生成不同的RDD</p></li></ul><ul><li><p>Schema</p><p>结构化数据，可以直接看出数据的详情</p><p>在RDD中无法看出，解释性不强，无法告诉引擎信息，没法详细优化。</p></li></ul><p><strong>为什么要学习sparksql </strong></p><p>sparksql特性</p><ul><li>1、易整合</li><li>2、统一的数据源访问</li><li>3、兼容hive</li><li>4、提供了标准的数据库连接（jdbc/odbc）</li></ul><h1 id="2、DataFrame"><a href="#2、DataFrame" class="headerlink" title="2、DataFrame"></a>2、DataFrame</h1><h2 id="2-1-介绍"><a href="#2-1-介绍" class="headerlink" title="2.1 介绍"></a>2.1 介绍</h2><p>在Spark语义中，DataFrame是一个分布式的<strong>行集合</strong>，可以想象为一个关系型数据库的表，或者一个带有列名的Excel表格。它和RDD一样，有这样一些特点：</p><ul><li>Immuatable：一旦RDD、DataFrame被创建，就不能更改，只能通过transformation生成新的RDD、DataFrame</li><li>Lazy Evaluations：只有action才会触发Transformation的执行</li><li>Distributed：DataFrame和RDD一样都是分布式的</li><li>dataframe和dataset（没有python版本,没法做类型校验。python是若类型语言）统一，dataframe只是dataset[ROW]的类型别名。由于Python是弱类型语言，只能使用DataFrame</li></ul><p><strong>DataFrame vs RDD</strong></p><ul><li>RDD：分布式的对象的集合，Spark并不知道对象的详细模式信息</li><li>DataFrame：分布式的Row对象的集合，其提供了由列组成的详细模式信息，使得Spark SQL可以进行某些形式的执行优化。</li><li>DataFrame和普通的RDD的逻辑框架区别如下所示：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010339.PNG" alt=""></p><ul><li><p>左侧的RDD Spark框架本身不了解 Person类的内部结构。</p></li><li><p>右侧的DataFrame提供了详细的结构信息（schema——每列的名称，类型）</p></li><li>DataFrame还配套了新的操作数据的方法，DataFrame API（如df.select())和SQL(select id, name from xx_table where …)。</li><li><p>DataFrame还引入了off-heap,意味着JVM堆以外的内存, 这些内存直接受操作系统管理（而不是JVM）。</p></li><li><p>RDD是分布式的Java对象的集合。DataFrame是分布式的Row对象的集合。DataFrame除了提供了比RDD更丰富的算子以外，更重要的特点是提升执行效率、减少数据读取以及执行计划的优化。</p></li><li>DataFrame的抽象后，我们处理数据更加简单了，甚至可以用SQL来处理数据了</li><li>通过DataFrame API或SQL处理数据，会自动经过Spark 优化器（Catalyst）的优化，即使你写的程序或SQL不仅高效，也可以运行的很快。</li><li><strong>DataFrame相当于是一个带着schema的RDD</strong></li></ul><p><strong>Pandas DataFrame vs Spark DataFrame</strong></p><ul><li>Cluster Parallel：集群并行执行</li><li>Lazy Evaluations: 只有action才会触发Transformation的执行</li><li>Immutable：不可更改</li><li>Pandas rich API：比Spark SQL api丰富</li></ul><h2 id="2-2-创建DataFrame"><a href="#2-2-创建DataFrame" class="headerlink" title="2.2 创建DataFrame"></a>2.2 创建DataFrame</h2><p>0.创建之前必须有一个SparkSession.</p><p>1，创建dataFrame的步骤</p><p>​    调用方法例如：spark.read.xxx方法</p><p>2，其他方式创建dataframe</p><ul><li><p>createDataFrame：pandas dataframe、list、RDD</p></li><li><p>数据源：RDD、csv、json、parquet、orc、jdbc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">jsonDF = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;json&#x27;</span>).load(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br><span class="line"></span><br><span class="line">parquetDF = spark.read.parquet(<span class="string">&quot;xxx.parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">jdbcDF = spark.read.<span class="built_in">format</span>(<span class="string">&quot;jdbc&quot;</span>).option(<span class="string">&quot;url&quot;</span>,<span class="string">&quot;jdbc:mysql://localhost:3306/db_name&quot;</span>).option(<span class="string">&quot;dbtable&quot;</span>,<span class="string">&quot;table_name&quot;</span>).option(<span class="string">&quot;user&quot;</span>,<span class="string">&quot;xxx&quot;</span>).option(<span class="string">&quot;password&quot;</span>,<span class="string">&quot;xxx&quot;</span>).load()</span><br></pre></td></tr></table></figure></li><li><p>Transformation:延迟性操作</p></li><li><p>action：立即操作</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010358.PNG" alt=""></p></li></ul><h2 id="2-3-DataFrame-API实现"><a href="#2-3-DataFrame-API实现" class="headerlink" title="2.3 DataFrame API实现"></a>2.3 DataFrame API实现</h2><p><strong>基于RDD创建</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DatFrame需要有 Spark Session</span></span><br><span class="line"><span class="comment"># 创建RDD需要有SparkContext</span></span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&#x27;test&#x27;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"><span class="comment"># spark.conf.set(&quot;spark.sql.shuffle.partitions&quot;, 6)</span></span><br><span class="line"><span class="comment"># ================直接创建==========================</span></span><br><span class="line">l = [(<span class="string">&#x27;Ankit&#x27;</span>,<span class="number">25</span>),(<span class="string">&#x27;Jalfaizy&#x27;</span>,<span class="number">22</span>),(<span class="string">&#x27;saurabh&#x27;</span>,<span class="number">20</span>),(<span class="string">&#x27;Bala&#x27;</span>,<span class="number">26</span>)]</span><br><span class="line">rdd = sc.parallelize(l)</span><br><span class="line"><span class="comment"># 为数据添加列名</span></span><br><span class="line">people = rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: Row(name=x[<span class="number">0</span>], age=<span class="built_in">int</span>(x[<span class="number">1</span>])))</span><br><span class="line"><span class="comment"># 通过SparkSession来创建DataFrame</span></span><br><span class="line">schemaPeople = spark.createDataFrame(people)</span><br></pre></td></tr></table></figure><p><strong>从csv中读取数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==================从csv读取======================</span></span><br><span class="line"><span class="comment"># 加载csv类型的数据并转换为DataFrame,默认是从hadoop的/user/root//下查找，目前我们用户是root</span></span><br><span class="line">df = spark.read.<span class="built_in">format</span>(<span class="string">&quot;csv&quot;</span>). \</span><br><span class="line">    option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>) \   <span class="comment"># header True,把最前面的展示出来。</span></span><br><span class="line">    .load(<span class="string">&quot;iris.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 显示数据结构</span></span><br><span class="line">df.printSchema()</span><br><span class="line"><span class="comment"># 显示前10条数据</span></span><br><span class="line">df.show(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 统计总量</span></span><br><span class="line">df.count()</span><br><span class="line"><span class="comment"># 列名</span></span><br><span class="line">df.columns</span><br></pre></td></tr></table></figure><p><strong>增加一列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ===============增加一列(或者替换) withColumn===========</span></span><br><span class="line"><span class="comment"># 定义一个新的列，数据为其他某列数据的两倍</span></span><br><span class="line"><span class="comment"># 如果操作的是原有列，可以替换原有列的数据</span></span><br><span class="line">df.withColumn(<span class="string">&#x27;newWidth&#x27;</span>,df.SepalWidth * <span class="number">2</span>).show()</span><br></pre></td></tr></table></figure><p><strong>删除一列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==========删除一列  drop=========================</span></span><br><span class="line"><span class="comment"># 删除一列</span></span><br><span class="line">df.drop(<span class="string">&#x27;newWidth&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>统计信息</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================ 统计信息 describe================</span></span><br><span class="line">df.describe().show()</span><br><span class="line"><span class="comment"># 计算某一列的描述信息</span></span><br><span class="line">df.describe(<span class="string">&#x27;newWidth&#x27;</span>).show()   </span><br></pre></td></tr></table></figure><p><strong>提取部分列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ===============提取部分列 select==============</span></span><br><span class="line">df.select(<span class="string">&#x27;SepalLength&#x27;</span>,<span class="string">&#x27;SepalWidth&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>基本统计功能</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==================基本统计功能 distinct count=====</span></span><br><span class="line">df.select(<span class="string">&#x27;cls&#x27;</span>).distinct().count()</span><br></pre></td></tr></table></figure><p><strong>分组统计</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分组统计 groupby(colname).agg(&#123;&#x27;col&#x27;:&#x27;fun&#x27;,&#x27;col2&#x27;:&#x27;fun2&#x27;&#125;)</span></span><br><span class="line">df.groupby(<span class="string">&#x27;cls&#x27;</span>).agg(&#123;<span class="string">&#x27;SepalWidth&#x27;</span>:<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;SepalLength&#x27;</span>:<span class="string">&#x27;max&#x27;</span>&#125;).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># avg(), count(), countDistinct(), first(), kurtosis(),</span></span><br><span class="line"><span class="comment"># max(), mean(), min(), skewness(), stddev(), stddev_pop(),</span></span><br><span class="line"><span class="comment"># stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance()</span></span><br></pre></td></tr></table></figure><p><strong>自定义的汇总方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义的汇总方法</span></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> fn</span><br><span class="line"><span class="comment"># 调用函数并起一个别名</span></span><br><span class="line">df.agg(fn.count(<span class="string">&#x27;SepalWidth&#x27;</span>).alias(<span class="string">&#x27;width_count&#x27;</span>),fn.countDistinct(<span class="string">&#x27;cls&#x27;</span>).alias(<span class="string">&#x27;distinct_cls_count&#x27;</span>)).show()</span><br></pre></td></tr></table></figure><p><strong>拆分数据集</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ====================数据集拆成两部分 randomSplit ===========</span></span><br><span class="line"><span class="comment"># 设置数据比例将数据划分为两部分</span></span><br><span class="line">trainDF, testDF = df.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>])</span><br></pre></td></tr></table></figure><p><strong>采样数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================采样数据 sample===========</span></span><br><span class="line"><span class="comment"># withReplacement：是否有放回的采样</span></span><br><span class="line"><span class="comment"># fraction：采样比例</span></span><br><span class="line"><span class="comment"># seed：随机种子</span></span><br><span class="line">sdf = df.sample(<span class="literal">False</span>,<span class="number">0.2</span>,<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p><strong>查看两个数据集在类别上的差异</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看两个数据集在类别上的差异 subtract，确保训练数据集覆盖了所有分类</span></span><br><span class="line">diff_in_train_test = testDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(trainDF.select(<span class="string">&#x27;cls&#x27;</span>))</span><br><span class="line">diff_in_train_test.distinct().count()</span><br></pre></td></tr></table></figure><p><strong>交叉表</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================交叉表 crosstab=============</span></span><br><span class="line">df.crosstab(<span class="string">&#x27;cls&#x27;</span>,<span class="string">&#x27;SepalLength&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>udf</strong></p><p>udf：自定义函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================== 综合案例 + udf================</span></span><br><span class="line"><span class="comment"># 测试数据集中有些类别在训练集中是不存在的，找到这些数据集做后续处理</span></span><br><span class="line">trainDF,testDF = df.randomSplit([<span class="number">0.99</span>,<span class="number">0.01</span>])</span><br><span class="line"></span><br><span class="line">diff_in_train_test = trainDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(testDF.select(<span class="string">&#x27;cls&#x27;</span>)).distinct().show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先找到这些类，整理到一个列表</span></span><br><span class="line">not_exist_cls = trainDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(testDF.select(<span class="string">&#x27;cls&#x27;</span>)).distinct().rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x :x[<span class="number">0</span>]).collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个方法，用于检测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">should_remove</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">in</span> not_exist_cls:</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建udf，udf函数需要两个参数：</span></span><br><span class="line"><span class="comment"># Function</span></span><br><span class="line"><span class="comment"># Return type (in my case StringType())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在RDD中可以直接定义函数，交给rdd的transformatioins方法进行执行</span></span><br><span class="line"><span class="comment"># 在DataFrame中 需要通过udf将自定义函数封装成udf函数，创建一个UDF对象，只有UDF对象 才可以DataFrame进行调用执行</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先封装成UDF函数。</span></span><br><span class="line">check = udf(should_remove,StringType())</span><br><span class="line"></span><br><span class="line">resultDF = trainDF.withColumn(<span class="string">&#x27;New_cls&#x27;</span>,check(trainDF[<span class="string">&#x27;cls&#x27;</span>])).<span class="built_in">filter</span>(<span class="string">&#x27;New_cls &lt;&gt; -1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">resultDF.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;掌握目标&quot;&gt;&lt;a href=&quot;#掌握目标&quot; class=&quot;headerlink&quot; title=&quot;掌握目标&quot;&gt;&lt;/a&gt;掌握目标&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;说出Spark Sql的相关概念&lt;/li&gt;
&lt;li&gt;说出DataFrame与RDD的联系&lt;/li&gt;
&lt;li&gt;独立</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>06-二叉树的最小深度</title>
    <link href="https://xxren8218.github.io/20210704/06-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%B0%8F%E6%B7%B1%E5%BA%A6.html"/>
    <id>https://xxren8218.github.io/20210704/06-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%B0%8F%E6%B7%B1%E5%BA%A6.html</id>
    <published>2021-07-04T13:36:56.000Z</published>
    <updated>2021-07-04T13:38:02.041Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的最小深度"><a href="#二叉树的最小深度" class="headerlink" title="二叉树的最小深度"></a>二叉树的最小深度</h2><ul><li>111.二叉树的最小深度</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213732.PNG" alt=""></p><p>直觉上好像和求最大深度差不多，其实还是差不少的。</p><p>遍历顺序上依然是后序遍历（因为要比较递归返回之后的结果），但在处理中间节点的逻辑上，最大深度很容易理解，最小深度可有一个误区，如图：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213744.png" alt=""></p><p>这就重新审题了，题目中说的是：<strong>「最小深度是从根节点到最近叶子节点的最短路径上的节点数量。」</strong>，注意是<strong>「叶子节点」</strong>。</p><p>什么是叶子节点，左右孩子都为空的节点才是叶子节点！</p><h4 id="1-递归法"><a href="#1-递归法" class="headerlink" title="1.递归法"></a>1.递归法</h4><p>来来来，一起递归三部曲：</p><ol><li>确定递归函数的参数和返回值</li></ol><p>参数为要传入的二叉树根节点。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>确定终止条件</li></ol><p>终止条件也是遇到空节点返回0，表示当前节点的高度为0。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑</li></ol><p>这块和求最大深度可就不一样了，一些同学可能会写如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftDepth = getDepth(node.left)</span><br><span class="line">rightDepth = getDepth(node.right)</span><br><span class="line">result = <span class="number">1</span> + <span class="built_in">min</span>(leftDepth, rightDepth)</span><br><span class="line"><span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>这个代码就犯了此图中的误区：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213744.png" alt=""></p><p>如果这么求的话，没有左孩子的分支会算为最短深度。</p><p>所以，如果左子树为空，右子树不为空，说明最小深度是 1 + 右子树的深度。</p><p>反之，右子树为空，左子树不为空，最小深度是 1 + 左子树的深度。最后如果左右子树都不为空，返回左右子树深度最小值 + 1 。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">leftDepth = getDepth(node.left)    <span class="comment"># 左</span></span><br><span class="line">rightDepth = getDepth(node.right)  <span class="comment"># 右</span></span><br><span class="line">                                   <span class="comment"># 中</span></span><br><span class="line"><span class="comment"># 当一个左子树为空，右不为空，这时并不是最低点</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> node.right: </span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + rightDepth</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当一个右子树为空，左不为空，这时并不是最低点</span></span><br><span class="line"><span class="keyword">if</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right: </span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + leftDepth</span><br><span class="line">result = <span class="number">1</span> + <span class="built_in">min</span>(leftDepth, rightDepth)  </span><br><span class="line"><span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>遍历的顺序为后序（左右中），可以看出：<strong>「求二叉树的最小深度和求二叉树的最大深度的差别主要在于处理左右孩子不为空的逻辑。」</strong></p><p>整体递归代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getDepth(root)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftDpeth = self.getDepth(node.left)</span><br><span class="line">        rightDepth = self.getDepth(node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> node.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> + rightDepth</span><br><span class="line">        <span class="keyword">if</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> + leftDpeth</span><br><span class="line">        result = <span class="number">1</span> + <span class="built_in">min</span>(leftDpeth, rightDepth)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h4 id="2-迭代法"><a href="#2-迭代法" class="headerlink" title="2. 迭代法"></a>2. 迭代法</h4><p>按照层序遍历的方法很好解决：直接套模板。用res来记录结果，每进入一层res加1，当左右孩子都为空的时候，说明为最小深度，直接返回结果即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> cur_node.left <span class="keyword">and</span> <span class="keyword">not</span> cur_node.right:</span><br><span class="line">                    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3></blockquote><p>最大深度与最小深度也不过如此嘛！可以用【递归法】和【迭代法分别实现】！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的最小深度&quot;&gt;&lt;a href=&quot;#二叉树的最小深度&quot; class=&quot;headerlink&quot; title=&quot;二叉树的最小深度&quot;&gt;&lt;/a&gt;二叉树的最小深度&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;111.二叉树的最小深度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;htt</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>05-二（N）叉树的最大深度</title>
    <link href="https://xxren8218.github.io/20210704/05-%E4%BA%8C%EF%BC%88N%EF%BC%89%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%A4%A7%E6%B7%B1%E5%BA%A6.html"/>
    <id>https://xxren8218.github.io/20210704/05-%E4%BA%8C%EF%BC%88N%EF%BC%89%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%A4%A7%E6%B7%B1%E5%BA%A6.html</id>
    <published>2021-07-04T13:35:05.000Z</published>
    <updated>2021-07-04T17:04:51.355Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二（N）叉树的最大深度"><a href="#二（N）叉树的最大深度" class="headerlink" title="二（N）叉树的最大深度"></a>二（N）叉树的最大深度</h2><blockquote><h3 id="1-二叉树的最大深度"><a href="#1-二叉树的最大深度" class="headerlink" title="1. 二叉树的最大深度"></a>1. 二叉树的最大深度</h3></blockquote><ul><li>104.二叉树的最大深度</li><li>559.N叉树的最大深度</li></ul><p>给定一个二叉树，找出其最大深度。</p><p>二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。</p><p>说明: 叶子节点是指没有子节点的节点。</p><p>示例：<br>给定二叉树 [3,9,20,null,null,15,7]，</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213548.png" alt=""></p><p>返回它的最大深度 3 。</p><h4 id="1-思路"><a href="#1-思路" class="headerlink" title="1. 思路"></a>1. 思路</h4><h4 id="1-1-递归法"><a href="#1-1-递归法" class="headerlink" title="1.1 递归法"></a>1.1 递归法</h4><p>本题其实也要后序遍历（左右中），依然是因为要通过递归函数的返回值做计算树的高度。</p><p>按照递归三部曲，来看看如何来写。</p><ol><li>确定递归函数的参数和返回值：参数就是传入树的根节点，返回就返回这棵树的深度。</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>确定终止条件：如果为空节点的话，就返回0，表示高度为0。</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node == <span class="literal">None</span>: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑：先求它的左子树的深度，再求的右子树的深度，最后取左右深度最大的数值 再+1 （加1是因为算上当前中间节点）就是目前节点为根节点的树的深度。</li></ol><p>代码如下：后序遍历，按照左右中的顺序）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftDepth = getDepth(node.left);       <span class="comment"># 左</span></span><br><span class="line">rightDepth = getDepth(node.right);     <span class="comment"># 右</span></span><br><span class="line">depth = <span class="number">1</span> + <span class="built_in">max</span>(leftDepth, rightDepth); <span class="comment"># 中</span></span><br><span class="line"><span class="keyword">return</span> depth</span><br></pre></td></tr></table></figure><p>所以整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getDepth(root)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftDepth = self.getDepth(node.left)</span><br><span class="line">        rightDepth = self.getDepth(node.right)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + <span class="built_in">max</span>(leftDepth, rightDepth) </span><br></pre></td></tr></table></figure><h4 id="1-2-迭代法"><a href="#1-2-迭代法" class="headerlink" title="1.2 迭代法"></a>1.2 迭代法</h4><p>使用迭代法的话，使用层序遍历是比较合适的，也是比较容易理解的。因为最大的深度就是二叉树的层数，和层序遍历的方式极其吻合。</p><p>在二叉树中，一层一层的来遍历二叉树，记录一下遍历的层数就是二叉树的深度，如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213601.png" alt=""></p><p>所以这道题的迭代法就是一道【模板题】，可以使用二叉树层序遍历的模板来解决的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 框架上改一行</span></span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            n = <span class="built_in">len</span>(queue)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="2-N叉树的最大深度"><a href="#2-N叉树的最大深度" class="headerlink" title="2. N叉树的最大深度"></a>2. N叉树的最大深度</h3></blockquote><p>给定一个 N 叉树，找到其最大深度。</p><p>最大深度是指从根节点到最远叶子节点的最长路径上的节点总数。</p><p>例如，给定一个 3叉树 :</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213613.png" alt=""></p><p>我们应返回其最大深度，3。</p><h4 id="1-思路："><a href="#1-思路：" class="headerlink" title="1. 思路："></a>1. 思路：</h4><p>依然可以提供递归法和迭代法，来解决这个问题，思路是和二叉树思路一样的，直接给出代码如下：</p><h4 id="2-1-递归法"><a href="#2-1-递归法" class="headerlink" title="2.1 递归法"></a>2.1 递归法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val=None, children=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.children = children</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getDepth(root)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        depth = <span class="number">0</span></span><br><span class="line">        <span class="comment"># leftDepth = self.getDepth(node.left)</span></span><br><span class="line">        <span class="comment"># rightDepth = self.getDepth(node.right)</span></span><br><span class="line">        <span class="comment"># return 1 + max(leftDepth, rightDepth)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(node.children)):</span><br><span class="line">            depth = <span class="built_in">max</span>(depth, self.getDepth(node.children[i]))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + depth</span><br></pre></td></tr></table></figure><h4 id="2-2-迭代法"><a href="#2-2-迭代法" class="headerlink" title="2.2 迭代法"></a>2.2 迭代法</h4><p>同样的也是套用模板。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val=None, children=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.children = children</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            n = <span class="built_in">len</span>(queue)</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 只需要改变这里就可以了。</span></span><br><span class="line">                <span class="keyword">while</span> cur_node.children:</span><br><span class="line">                    queue.append(cur_node.children.pop(<span class="number">0</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3></blockquote><p>至此，二（N）叉树的最大深度就完成了，分别采用了递归法和迭代法进行求解，递归法可以看到递归三部曲的身影，迭代法套用模板即可！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二（N）叉树的最大深度&quot;&gt;&lt;a href=&quot;#二（N）叉树的最大深度&quot; class=&quot;headerlink&quot; title=&quot;二（N）叉树的最大深度&quot;&gt;&lt;/a&gt;二（N）叉树的最大深度&lt;/h2&gt;&lt;blockquote&gt;
&lt;h3 id=&quot;1-二叉树的最大深度&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>04-对称二叉树</title>
    <link href="https://xxren8218.github.io/20210704/04-%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91.html"/>
    <id>https://xxren8218.github.io/20210704/04-%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91.html</id>
    <published>2021-07-04T13:32:41.000Z</published>
    <updated>2021-07-04T13:34:15.917Z</updated>
    
    <content type="html"><![CDATA[<h2 id="对称二叉树"><a href="#对称二叉树" class="headerlink" title="对称二叉树"></a>对称二叉树</h2><ul><li>101.对称二叉树</li></ul><p>给定一个二叉树，检查它是否是镜像对称的。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213329.PNG" alt=""></p><h3 id="一、思路"><a href="#一、思路" class="headerlink" title="一、思路"></a>一、思路</h3><p><strong>「首先想清楚，判断对称二叉树要比较的是哪两个节点，要比较的可不是左右节点！」</strong></p><p>对于二叉树是否对称，要比较的是根节点的左子树与右子树是不是相互翻转的，理解这一点就知道了<strong>「其实我们要比较的是两个树（这两个树是根节点的左右子树）」</strong>，所以在递归遍历的过程中，也是要同时遍历两棵树。</p><p>那么如果比较呢？</p><p>比较的是两个子树的里侧和外侧的元素是否相等。如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213343.jpg" alt=""></p><p>那么遍历的顺序应该是什么样的呢？</p><p>本题遍历只能是“后序遍历”，因为我们要通过递归函数的返回值来判断两个子树的内侧节点和外侧节点是否相等。</p><p><strong>「正是因为要遍历两棵树而且要比较内侧和外侧节点，所以准确的来说是一个树的遍历顺序是左右中，一个树的遍历顺序是右左中。」</strong></p><p>但都可以理解算是后序遍历，尽管已经不是严格上在一个树上进行遍历的后序遍历了。</p><p>说到这大家可能感觉我有点啰嗦，哪有这么多道理，上来就干就完事了。别急，我说的这些在下面的代码讲解中都有身影。</p><p>那么我们先来看看递归法的代码应该怎么写。</p><h3 id="二、递归法"><a href="#二、递归法" class="headerlink" title="二、递归法"></a>二、递归法</h3><p><strong>递归三部曲</strong></p><ul><li><p>确定递归函数的参数和返回值</p><p>因为我们要比较的是根节点的两个子树是否是相互翻转的，进而判断这个树是不是对称树，所以要比较的是两个树，参数自然也是左子树节点和右子树节点。</p><p>返回值自然是bool类型。</p></li></ul><p>代码如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def compare(left, right): -&gt; bool</span><br></pre></td></tr></table></figure><ul><li><p>确定终止条件</p><p>要比较两个节点数值相不相同，首先要把两个节点为空的情况弄清楚！否则后面比较数值的时候就会操作空指针了。</p><p>节点为空的情况有：（<strong>「注意我们比较的其实不是左孩子和右孩子，所以如下我称之为左节点右节点」</strong>）</p><ul><li><p>左节点为空，右节点不为空，不对称，return false</p></li><li><p>左不为空，右为空，不对称 return  false</p></li><li><p>左右都为空，对称，返回true</p></li></ul><p>此时已经排除掉了节点为空的情况，那么剩下的就是左右节点不为空：</p><ul><li>左右都不为空，比较节点数值，不相同就return false</li></ul><p>此时左右节点不为空，且数值也不相同的情况我们也处理了。</p></li></ul><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> left != <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right != <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> left.val != right.val: <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><ul><li><p>确定单层递归的逻辑</p><p>此时才进入单层递归的逻辑，单层递归的逻辑就是处理 右节点都不为空，且数值相同的情况。</p><ul><li>比较二叉树外侧是否对称：传入的是左节点的左孩子，右节点的右孩子。</li><li>比较内测是否对称，传入左节点的右孩子，右节点的左孩子。</li><li>如果左右都对称就返回true ，有一侧不对称就返回false 。</li></ul></li></ul><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">outside = compare(left.left, right.right)</span><br><span class="line">inside = compare(left.right, right.left)</span><br><span class="line">isSame = outside <span class="keyword">and</span> inside</span><br></pre></td></tr></table></figure><p>如上代码中，我们可以看出使用的遍历方式，左子树左右中，右子树右左中，所以我把这个遍历顺序也称之为“后序遍历”（尽管不是严格的后序遍历）.</p><p>最后看一下完整的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.compare(root.left, root.right)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compare</span>(<span class="params">self, left, right</span>):</span></span><br><span class="line">        <span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> left != <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right != <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> left.val != right.val: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        outside = self.compare(left.left, right.right)</span><br><span class="line">        inside = self.compare(left.right, right.left)</span><br><span class="line">        isSame = outside <span class="keyword">and</span> inside</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> isSame</span><br></pre></td></tr></table></figure><p><strong>「建议大家做题的时候，一定要想清楚逻辑，每一步做什么。把道题目所有情况想到位，相应的代码写出来之后，再去追求简洁代码的效果。」</strong></p><h3 id="三、迭代法"><a href="#三、迭代法" class="headerlink" title="三、迭代法"></a>三、迭代法</h3><p>这道题目我们也可以使用迭代法，但要注意，这里的迭代法可不是前中后序的迭代写法，因为本题的本质是判断两个树是否是相互翻转的，其实已经不是所谓二叉树遍历的前中后序的关系了。</p><p>这里我们可以使用队列来比较两个树（根节点的左右子树）是否相互翻转，（<strong>「注意这不是层序遍历」</strong>）</p><h4 id="1-使用队列"><a href="#1-使用队列" class="headerlink" title="1.使用队列"></a>1.使用队列</h4><p>通过队列来判断根节点的左子树和右子树的内侧和外侧是否相等，如动画所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213358.gif" alt=""></p><p>如下的条件判断和递归的逻辑是一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = []</span><br><span class="line">        queue.append(root.left)</span><br><span class="line">        queue.append(root.right)</span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            <span class="comment"># 将左右节点分别加入队列</span></span><br><span class="line">            left_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">            right_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 两个都为空，则对称，继续。</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node: </span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 一个为空，另一个不为空，返回False</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">not</span> left_node <span class="keyword">and</span> right_node) <span class="keyword">or</span> \</span><br><span class="line">               (left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node):</span><br><span class="line">               <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 两个都不为空，值不相等，返回False</span></span><br><span class="line">            <span class="keyword">if</span> left_node.val != right_node.val:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line">            queue.append(left_node.left)</span><br><span class="line">            queue.append(right_node.right)</span><br><span class="line">            queue.append(left_node.right)</span><br><span class="line">            queue.append(right_node.left)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure><h4 id="2-使用栈"><a href="#2-使用栈" class="headerlink" title="2.使用栈"></a>2.使用栈</h4><p>细心的话，其实可以发现，这个迭代法，其实是把左右两个子树要比较的元素顺序放进一个容器，然后成对成对的取出来进行比较，那么其实使用栈也是可以的。——先判断里侧和先判断外侧的顺序不影响。</p><p>只要把队列原封不动的改成栈就可以了，我下面也给出了代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        stack = []</span><br><span class="line">        stack.append(root.left)</span><br><span class="line">        stack.append(root.right)</span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            <span class="comment"># 将左右节点分别加入队列</span></span><br><span class="line">            left_node = stack.pop()</span><br><span class="line">            right_node = stack.pop()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 两个都为空，则对称，继续。</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node: </span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 一个为空，另一个不为空，返回False</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">not</span> left_node <span class="keyword">and</span> right_node) <span class="keyword">or</span> \</span><br><span class="line">               (left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node):</span><br><span class="line">               <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 两个都不为空，值不相等，返回False</span></span><br><span class="line">            <span class="keyword">if</span> left_node.val != right_node.val:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line">            stack.append(left_node.left)</span><br><span class="line">            stack.append(right_node.right)</span><br><span class="line">            stack.append(left_node.right)</span><br><span class="line">            stack.append(right_node.left)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure><blockquote><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3></blockquote><p>这次我们又深度剖析了一道二叉树的“简单题”，大家会发现，真正的把题目搞清楚其实并不简单，leetcode上accept了和真正掌握了还是有距离的。</p><p>我们介绍了递归法和迭代法，递归依然通过递归三部曲来解决了这道题目。</p><p>在迭代法中我们使用了队列，需要注意的是这不是层序遍历，而且仅仅通过一个容器来成对的存放我们要比较的元素，知道这一本质之后就发现：用队列，用栈，甚至用数组，都是可以的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;对称二叉树&quot;&gt;&lt;a href=&quot;#对称二叉树&quot; class=&quot;headerlink&quot; title=&quot;对称二叉树&quot;&gt;&lt;/a&gt;对称二叉树&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;101.对称二叉树&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;给定一个二叉树，检查它是否是镜像对称的。&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>29-spark_core补充</title>
    <link href="https://xxren8218.github.io/20210704/29-spark-core%E8%A1%A5%E5%85%85.html"/>
    <id>https://xxren8218.github.io/20210704/29-spark-core%E8%A1%A5%E5%85%85.html</id>
    <published>2021-07-03T17:58:13.000Z</published>
    <updated>2021-07-03T18:01:52.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="spark-相关概念补充"><a href="#spark-相关概念补充" class="headerlink" title="spark 相关概念补充"></a>spark 相关概念补充</h2><p>掌握目标</p><ul><li>了解spark的安装部署</li><li>知道spark作业提交集群的过程</li></ul><h3 id="1-spark的安装部署"><a href="#1-spark的安装部署" class="headerlink" title="1. spark的安装部署"></a>1. spark的安装部署</h3><ul><li><p>1、下载spark安装包</p><p><a href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a></p><p>高版本不存在cdh的编译版本，可以从官网下载源码版本，指定高版本hadoop进行编译</p><p>编译步骤：</p><ul><li><p>1，安装java(JDK 1.7及以上)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;xxx</span><br><span class="line">export JRE_HOME&#x3D;&#x2F;xxx</span><br><span class="line">export CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar:$JRE_HOME&#x2F;lib:$CLASSPATH</span><br><span class="line">export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>2，安装Maven， 版本为3.3.9或者以上</p><p>下载地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache//maven/maven-3/3.3.9/binaries">https://mirrors.tuna.tsinghua.edu.cn/apache//maven/maven-3/3.3.9/binaries</a></p><p>配置MAVEN_HOME</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export MAVEN_HOME&#x3D;&#x2F;xxx</span><br><span class="line">export PATH&#x3D;$MAVEN_HOME&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>3，下载spark源码</p></li><li><p>4，增加cdh的repository</p><p>解压spark的源码包，编辑pom.xml文件， 在repositories节点 加入如下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;repository&gt;</span><br><span class="line">          &lt;id&gt;cloudera&lt;&#x2F;id&gt;</span><br><span class="line">          &lt;url&gt;https:&#x2F;&#x2F;repository.cloudera.com&#x2F;artifactory&#x2F;cloudera-repos&#x2F;&lt;&#x2F;url&gt;&lt;&#x2F;repository&gt;</span><br></pre></td></tr></table></figure></li><li><p>5，编译</p><p>设置内存：</p><p>export MAVEN_OPTS=”-Xmx2g -XX:ReservedCodeCacheSize=512m”</p><p>开始编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;dev&#x2F;make-distribution.sh --name 2.6.0-cdh5.7.0 --tgz  -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version&#x3D;2.6.0-cdh5.7.0 -DskipTests clean package</span><br></pre></td></tr></table></figure><p>源码编译后，bin目录下的文件可能不存在可执行权限，需要通过chmod指令添加可执行权限</p><p>chmod +x xxx</p></li></ul></li><li><p>2、规划spark安装目录</p></li><li><p>3、解压安装包</p></li><li><p>4、重命名安装目录</p></li><li><p>5、修改配置文件</p><ul><li>spark-env.sh(需要将spark-env.sh.template重命名)<ul><li>配置java环境变量<ul><li>export JAVA_HOME=java_home_path</li></ul></li><li>配置PYTHON环境<ul><li>export PYSPARK_PYTHON=/xx/pythonx_home/bin/pythonx</li></ul></li><li>配置master的地址<ul><li>export SPARK_MASTER_HOST=node-teach</li></ul></li><li>配置master的端口<ul><li>export SPARK_MASTER_PORT=7077</li></ul></li></ul></li></ul></li><li><p>6、配置spark环境变量</p><ul><li>export SPARK_HOME=/xxx/spark2.x</li><li>export PATH=\$PATH:\$SPARK_HOME/bin</li></ul></li></ul><h3 id="2-启动Spark集群"><a href="#2-启动Spark集群" class="headerlink" title="2. 启动Spark集群"></a>2. 启动Spark集群</h3><ul><li>进入到$SPARK_HOME/sbin目录</li><li>启动Master    </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-master.sh -h 192.168.19.137</span><br></pre></td></tr></table></figure><ul><li>启动Slave</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-slave.sh spark://192.168.19.137:7077</span><br></pre></td></tr></table></figure><ul><li>jps查看进程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">27073 Master</span><br><span class="line">27151 Worker</span><br></pre></td></tr></table></figure><ul><li>关闭防火墙</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><ul><li>通过SPARK WEB UI查看Spark集群及Spark<ul><li><a href="http://192.168.199.188:8080/">http://192.168.199.188:8080/</a>  监控Spark集群</li><li><a href="http://192.168.199.188:4040/">http://192.168.199.188:4040/</a>  监控Spark Job</li></ul></li></ul><h3 id="3-spark-集群相关概念"><a href="#3-spark-集群相关概念" class="headerlink" title="3. spark 集群相关概念"></a>3. spark 集群相关概念</h3><ul><li><p>spark集群架构(Standalone模式)</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704015921.png" alt=""></p><ul><li><p>Application</p><p>用户自己写的Spark应用程序，批处理作业的集合。Application的main方法为应用程序的入口，用户通过Spark的API，定义了RDD和对RDD的操作。</p></li><li><p>Master和Worker</p><p>整个集群分为 Master 节点和 Worker 节点，相当于 Hadoop 的 Master 和 Slave 节点。</p><ul><li>Master：Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动Driver和Executor。</li><li>Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。</li></ul></li><li><p>Client：客户端进程，负责提交作业到Master。</p></li><li><p>Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGSchedule（负责作业的拆解），TaskScheduler（负责把对应的Task发到对应的Worker上，交给Executor求执行）。</p></li><li><p>Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。</p></li></ul></li><li><p>Spark作业相关概念</p><ul><li><p>Stage：一个Spark作业一般包含一到多个Stage。</p></li><li><p>Task：一个Stage包含一到多个Task，通过多个Task实现并行运行的功能（可能算的结果不一样，前面有讲）。</p></li><li><p>DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。</p></li><li><p>TaskScheduler：实现Task分配到Executor上执行。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704015938.png" alt=""></p></li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704020004.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;spark-相关概念补充&quot;&gt;&lt;a href=&quot;#spark-相关概念补充&quot; class=&quot;headerlink&quot; title=&quot;spark 相关概念补充&quot;&gt;&lt;/a&gt;spark 相关概念补充&lt;/h2&gt;&lt;p&gt;掌握目标&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解spark的安装部署</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>28-spark_core 实战案例</title>
    <link href="https://xxren8218.github.io/20210703/28-spark-core-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B.html"/>
    <id>https://xxren8218.github.io/20210703/28-spark-core-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B.html</id>
    <published>2021-07-02T17:03:57.000Z</published>
    <updated>2021-07-02T17:07:57.328Z</updated>
    
    <content type="html"><![CDATA[<h2 id="spark-core-实战案例"><a href="#spark-core-实战案例" class="headerlink" title="spark-core 实战案例"></a>spark-core 实战案例</h2><p>掌握目标：</p><ul><li>独立实现Spark RDD的word count案例</li><li>独立实现spark RDD的PV UV统计案例</li><li>说出广播变量的概念</li></ul><p>对于数据在shell里面写，没有交互，对于数据分析而言不好，将其用PyCharm编写可进行交互，便于分析。</p><ul><li>即在PyCharm上编写，然后数据同步到Centos上面运行，运行结束后，还在PyCharm上面显示。</li></ul><h3 id="1-0-Pycharm编写spark代码环境配置"><a href="#1-0-Pycharm编写spark代码环境配置" class="headerlink" title="1.0 Pycharm编写spark代码环境配置"></a>1.0 Pycharm编写spark代码环境配置</h3><p>准备pycharm环境</p><ul><li><p>1.PyCharm的配置</p><ul><li>file-&gt;new-project-&gt;pure Python-&gt;exiting interpreter-&gt;add remote-&gt;SSH Crederitals-&gt;填写Host(192.168.19.137)-&gt;Username(root)-&gt;密码-&gt;选择python的解释器路径为(/miniconda2/envs/py365/bin/python)-&gt;Remote project location(/root/bigdata/code)</li></ul></li><li><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个是链接用的哪种环境，若几个集群的话，传递的应该是master节点的RL地址</span></span><br><span class="line">sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>)</span><br><span class="line"></span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/code/test.txt&quot;</span>).\</span><br><span class="line">    flatMap(<span class="keyword">lambda</span> x: x.split()).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> a,b: a+b)</span><br><span class="line"></span><br><span class="line">print(rdd1.collect())</span><br></pre></td></tr></table></figure><p>运行出现了错误：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210703010459.PNG" alt=""></p></li></ul><p>解决方法：</p><ul><li>在centos上面查找JAVA_HOME所在位置(vi ~/.bash_profile)，添加到环境变量中：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####################################</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">JAVA_HOME = <span class="string">&#x27;/root/bigdata/jdk&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>] = JAVA_HOME</span><br><span class="line"><span class="comment">####################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个master的位置，第二个是spark作业的名字。</span></span><br><span class="line">sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>) <span class="comment"># 第一个是链接用的哪种环境，若几个集群的话，传递的应该是master节点的RL地址</span></span><br><span class="line"></span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/code/test.txt&quot;</span>).\</span><br><span class="line">    flatMap(<span class="keyword">lambda</span> x: x.split()).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> a,b: a+b)</span><br><span class="line"></span><br><span class="line">print(rdd1.collect())</span><br></pre></td></tr></table></figure><p>  还会出现python的版本不一致的问题，再添加python的环境。以及pyspark的版本问题。</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####################################</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">JAVA_HOME = <span class="string">&#x27;/root/bigdata/jdk&#x27;</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/miniconda2/envs/py365/bin/python&quot;</span></span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>] = JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&#x27;PYSPARK_PYTHON&#x27;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;PYSPARK_DRIVER_PYTHON&#x27;</span>] = PYSPARK_PYTHON</span><br><span class="line"><span class="comment">####################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line">sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>)</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/code/test.txt&quot;</span>).\</span><br><span class="line">    flatMap(<span class="keyword">lambda</span> x: x.split()).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x,<span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> a,b: a+b)</span><br><span class="line"></span><br><span class="line">print(rdd1.collect())</span><br></pre></td></tr></table></figure><h3 id="1-1利用PyCharm编写spark-wordcount程序"><a href="#1-1利用PyCharm编写spark-wordcount程序" class="headerlink" title="1.1利用PyCharm编写spark wordcount程序"></a>1.1利用PyCharm编写spark wordcount程序</h3><ul><li>代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">JAVA_HOME = <span class="string">&#x27;/root/bigdata/jdk&#x27;</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/miniconda2/envs/py365/bin/python&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;JAVA_HOME&quot;</span>] = JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 创建spark context</span></span><br><span class="line">    sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>)</span><br><span class="line">    <span class="comment"># 通过spark context 获取rdd</span></span><br><span class="line">    rdd1 = sc.textFile(<span class="string">&#x27;file:///root/tmp/test.txt&#x27;</span>)</span><br><span class="line">    rdd2 = rdd1.flatMap(<span class="keyword">lambda</span> line:line.split())</span><br><span class="line">    rdd3 = rdd2.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x,<span class="number">1</span>))</span><br><span class="line">    rdd4 = rdd3.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)</span><br><span class="line">    print(rdd4.collect())</span><br></pre></td></tr></table></figure><h3 id="1-2-通过spark实现点击流日志分析"><a href="#1-2-通过spark实现点击流日志分析" class="headerlink" title="1.2 通过spark实现点击流日志分析"></a>1.2 通过spark实现点击流日志分析</h3><p>在新闻类网站中，经常要衡量一条网络新闻的页面访问量，最常见的就是uv和pv，如果在所有新闻中找到访问最多的前几条新闻，topN是最常见的指标。</p><ul><li>数据示例</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 每条数据代表一次访问记录 包含了ip 访问时间 访问的请求方式 访问的地址...信息</span></span><br><span class="line">194.237.142.21 - - [18/Sep/2013:06:49:18 +0000] &quot;GET /wp-content/uploads/2013/07/rstudio-git3.png HTTP/1.1&quot; 304 0 &quot;-&quot; &quot;Mozilla/4.0 (compatible;)&quot;</span><br><span class="line">183.49.46.228 - - [18/Sep/2013:06:49:23 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</span><br><span class="line">163.177.71.12 - - [18/Sep/2013:06:49:33 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">163.177.71.12 - - [18/Sep/2013:06:49:36 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">101.226.68.137 - - [18/Sep/2013:06:49:42 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">101.226.68.137 - - [18/Sep/2013:06:49:45 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span><br><span class="line">222.68.172.190 - - [18/Sep/2013:06:49:57 +0000] &quot;GET /images/my.jpg HTTP/1.1&quot; 200 19939 &quot;http://www.angularjs.cn/A00n&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span><br><span class="line">222.68.172.190 - - [18/Sep/2013:06:50:08 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</span><br></pre></td></tr></table></figure><ul><li><p>访问的pv</p><p>pv：网站的总访问量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;pv&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment"># 把每一行数据记为(&quot;pv&quot;,1)</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(<span class="string">&quot;pv&quot;</span>,<span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> a,b:a+b)</span><br><span class="line">rdd2.collect()</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>访问的uv</p><p>uv：网站的独立用户访问量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;pv&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment"># 对每一行按照空格拆分，将ip地址取出</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot; &quot;</span>)).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 把每个ur记为1</span></span><br><span class="line">rdd3 = rdd2.distinct().<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(<span class="string">&quot;uv&quot;</span>,<span class="number">1</span>))</span><br><span class="line">rdd4 = rdd3.reduceByKey(<span class="keyword">lambda</span> a,b:a+b)</span><br><span class="line">rdd4.saveAsTextFile(<span class="string">&quot;hdfs:///uv/result&quot;</span>)</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>访问的topN</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;topN&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment"># 对每一行按照空格拆分，将url数据取出，把每个url记为1</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot; &quot;</span>)).<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x)&gt;<span class="number">10</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x[<span class="number">10</span>],<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 对数据进行累加，按照url出现次数的降序排列</span></span><br><span class="line">rdd3 = rdd2.reduceByKey(<span class="keyword">lambda</span> a,b:a+b).sortBy(<span class="keyword">lambda</span> x:x[<span class="number">1</span>],ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 取出序列数据中的前n个</span></span><br><span class="line">rdd4 = rdd3.take(<span class="number">5</span>)</span><br><span class="line">rdd4.collect()</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li></ul><h3 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h3><p>这里不懂的可以去上篇看数据的具体格式！</p><h3 id="2-通过spark实现ip地址查询"><a href="#2-通过spark实现ip地址查询" class="headerlink" title="2. 通过spark实现ip地址查询"></a>2. 通过spark实现ip地址查询</h3><p><strong>需求</strong></p><p>在互联网中，我们经常会见到城市热点图这样的报表数据，例如在百度统计中，会统计今年的热门旅游城市、热门报考学校等，会将这样的信息显示在热点图中。</p><p>因此，我们需要通过日志信息（运行商或者网站自己生成）和城市ip段信息来判断用户的ip段，统计热点经纬度。</p><p><strong>ip日志信息</strong></p><p>在ip日志信息中，我们只需要关心ip这一个维度就可以了，其他的不做介绍</p><p><strong>思路</strong></p><p>1、 加载城市ip段信息，获取ip起始数字和结束数字，经度，纬度</p><p>2、 加载日志数据，获取ip信息，然后转换为数字，和ip段比较</p><p>3、 比较的时候采用二分法查找，找到对应的经度和纬度</p><p>4，对相同的经度和纬度做累计求和</p><p>5， 取出最终的topN的经纬度</p><p><strong>启动Spark集群</strong></p><ul><li><p>进入到$SPARK_HOME/sbin目录</p><ul><li>启动Master    </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-master.sh -h 192.168.199.188</span><br></pre></td></tr></table></figure><ul><li>启动Slave</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-slave.sh spark://192.168.199.188:7077</span><br></pre></td></tr></table></figure><ul><li>jps查看进程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">27073 Master</span><br><span class="line">27151 Worker</span><br></pre></td></tr></table></figure><ul><li>关闭防火墙</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><ul><li>通过SPARK WEB UI查看Spark集群及Spark<ul><li><a href="http://192.168.199.188:8080/">http://192.168.199.188:8080/</a>  监控Spark集群</li><li><a href="http://192.168.199.188:4040/">http://192.168.199.188:4040/</a>  监控Spark Job</li></ul></li></ul></li><li><p>代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="comment"># 255.255.255.255 0~255 256个数  2^8 是8位2进制数  ——&gt;转化成32位的二进制数</span></span><br><span class="line"><span class="comment">#将ip转换为特殊的数字形式  223.243.0.0|223.243.191.255|  255 2^8</span></span><br><span class="line"><span class="comment">#‭11011111‬</span></span><br><span class="line"><span class="comment">#00000000</span></span><br><span class="line"><span class="comment">#1101111100000000</span></span><br><span class="line"><span class="comment">#‭        11110011‬</span></span><br><span class="line"><span class="comment">#11011111111100110000000000000000</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ip_transform</span>(<span class="params">ip</span>):</span>     </span><br><span class="line">    ips = ip.split(<span class="string">&quot;.&quot;</span>) <span class="comment"># [223,243,0,0] 32位二进制数</span></span><br><span class="line">    ip_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ips:</span><br><span class="line">        ip_num = <span class="built_in">int</span>(i) | ip_num &lt;&lt; <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> ip_num</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二分法查找ip对应的行的索引</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">ip_num, broadcast_value</span>):</span></span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    end = <span class="built_in">len</span>(broadcast_value) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> (start &lt;= end):</span><br><span class="line">        mid = <span class="built_in">int</span>((start + end) / <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> ip_num &gt;= <span class="built_in">int</span>(broadcast_value[mid][<span class="number">0</span>]) <span class="keyword">and</span> ip_num &lt;= <span class="built_in">int</span>(broadcast_value[mid][<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        <span class="keyword">if</span> ip_num &lt; <span class="built_in">int</span>(broadcast_value[mid][<span class="number">0</span>]):</span><br><span class="line">            end = mid</span><br><span class="line">        <span class="keyword">if</span> ip_num &gt; <span class="built_in">int</span>(broadcast_value[mid][<span class="number">1</span>]):</span><br><span class="line">            start = mid</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">&quot;test&quot;</span>).getOrCreate()</span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line">    city_id_rdd = sc.textFile(<span class="string">&quot;file:///home/hadoop/app/tmp/data/ip.txt&quot;</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot;|&quot;</span>)).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">2</span>], x[<span class="number">3</span>], x[<span class="number">13</span>], x[<span class="number">14</span>]))</span><br><span class="line">    <span class="comment"># 创建一个广播变量</span></span><br><span class="line">    city_broadcast = sc.broadcast(city_id_rdd.collect())</span><br><span class="line">    dest_data = sc.textFile(<span class="string">&quot;file:///home/hadoop/app/tmp/data/20090121000132.394251.http.format&quot;</span>).<span class="built_in">map</span>(</span><br><span class="line">        <span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>)[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 根据取出对应的位置信息</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pos</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="comment"># 从广播变量中获取ip地址库</span></span><br><span class="line">        city_broadcast_value = city_broadcast.value</span><br><span class="line">        <span class="comment"># 根据单个ip获取对应经纬度信息</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_result</span>(<span class="params">ip</span>):</span></span><br><span class="line">            ip_num = ip_transform(ip)</span><br><span class="line">            index = binary_search(ip_num, city_broadcast_value)</span><br><span class="line">            <span class="comment"># ((纬度,精度),1)</span></span><br><span class="line">            <span class="keyword">return</span> ((city_broadcast_value[index][<span class="number">2</span>], city_broadcast_value[index][<span class="number">3</span>]), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = <span class="built_in">map</span>(<span class="built_in">tuple</span>,[get_result(ip) <span class="keyword">for</span> ip <span class="keyword">in</span> x])</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    dest_rdd = dest_data.mapPartitions(<span class="keyword">lambda</span> x: get_pos(x)) <span class="comment"># ((纬度,精度),1)</span></span><br><span class="line">    result_rdd = dest_rdd.reduceByKey(<span class="keyword">lambda</span> a, b: a + b).sortBy(<span class="keyword">lambda</span> x:x[<span class="number">1</span>],ascending=<span class="literal">False</span>)</span><br><span class="line">    print(result_rdd.collect())</span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></li><li><p><strong>广播变量的使用</strong></p><ul><li>要统计Ip所对应的经纬度, 每一条数据都会去查询ip表</li><li>每一个task 都需要这一个ip表, 默认情况下, 所有task都会去复制ip表</li><li>实际上 每一个Worker上会有多个task, 数据也是只需要进行查询操作的, 所以这份数据可以共享,没必要每个task复制一份</li><li>可以通过广播变量, 通知当前worker上所有的task, 来共享这个数据,避免数据的多次复制,可以大大降低内存的开销</li><li>sparkContext.broadcast(要共享的数据)</li></ul></li><li><p><strong>mapPartitions</strong> </p><ul><li>transformation操作 </li><li>类似map 但是map是一条一条传给里面函数的 mapPartitions 数据是一部分一部分传给函数的</li><li>应用场景 数据处理的时候 需要连接其它资源 如果一条一条处理 会处理一条连一次， 一份一份处理可以很多条数据连一次其它资源 可以提高效率</li></ul></li><li><p><strong>二分法查找</strong></p></li><li><p>ip_transform 把223.243.0.0 转换成10进制的数字——位运算。 </p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;spark-core-实战案例&quot;&gt;&lt;a href=&quot;#spark-core-实战案例&quot; class=&quot;headerlink&quot; title=&quot;spark-core 实战案例&quot;&gt;&lt;/a&gt;spark-core 实战案例&lt;/h2&gt;&lt;p&gt;掌握目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>03-翻转二叉树--递归和迭代的应用</title>
    <link href="https://xxren8218.github.io/20210702/03-%E7%BF%BB%E8%BD%AC%E4%BA%8C%E5%8F%89%E6%A0%91-%E9%80%92%E5%BD%92%E5%92%8C%E8%BF%AD%E4%BB%A3%E7%9A%84%E5%BA%94%E7%94%A8.html"/>
    <id>https://xxren8218.github.io/20210702/03-%E7%BF%BB%E8%BD%AC%E4%BA%8C%E5%8F%89%E6%A0%91-%E9%80%92%E5%BD%92%E5%92%8C%E8%BF%AD%E4%BB%A3%E7%9A%84%E5%BA%94%E7%94%A8.html</id>
    <published>2021-07-02T10:16:14.000Z</published>
    <updated>2021-07-04T13:29:55.300Z</updated>
    
    <content type="html"><![CDATA[<h2 id="03-翻转二叉树—递归和迭代的应用"><a href="#03-翻转二叉树—递归和迭代的应用" class="headerlink" title="03_翻转二叉树—递归和迭代的应用"></a>03_翻转二叉树—递归和迭代的应用</h2><ul><li>226.翻转二叉树</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181715.PNG" alt=""></p><p>这道题目是非常经典的题目，也是比较简单的题目（至少一看就会）。</p><p>但正是因为这道题太简单，一看就会，一些同学都没有抓住其本质，稀里糊涂的就把这道题目过了。</p><p>如果做过这道题的同学也建议认真看完，相信一定有所收获！</p><h3 id="一、思路"><a href="#一、思路" class="headerlink" title="一、思路"></a>一、思路</h3><p>我们之前介绍的都是各种方式遍历二叉树，这次要翻转了，感觉还是有点懵逼。</p><p>这得怎么翻转呢？</p><p>如果要从整个树来看，翻转还真的挺复杂，整个树以中间线进行翻转，如图：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181727.png" alt=""></p><p>可以发现想要翻转它，其实就把每一个节点的左右孩子交换一下（注意孩子下面的节点是一起交换的）就可以了。</p><p>关键在于遍历顺序，前中后序应该选哪一种遍历顺序？（一些同学这道题都过了，但是不知道自己用的是什么顺序）</p><p>遍历的过程中去翻转每一个节点的左右孩子就可以达到整体翻转的效果。</p><p><strong>「注意只要把每一个节点的左右孩子翻转一下，就可以达到整体翻转的效果」</strong></p><p><strong>「这道题目使用前序遍历和后序遍历都可以，唯独中序遍历不行，因为中序遍历会把某些节点的左右孩子翻转了两次！建议拿纸画一画，就理解了」</strong></p><p>那么层序遍历可以不可以呢？<strong>「依然可以的！只要把每一个节点的左右孩子翻转一下的遍历方式都是可以的！」</strong></p><h3 id="二、递归法"><a href="#二、递归法" class="headerlink" title="二、递归法"></a>二、递归法</h3><p>我们下文以前序遍历为例，通过动画来看一下翻转的过程:</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181742.gif" alt=""></p><p>我们来看一下递归三部曲：</p><p>1.确定递归函数的参数和返回值</p><p>参数就是要传入节点的指针，不需要其他参数了，通常此时定下来主要参数，如果在写递归的逻辑中发现还需要其他参数的时候，随时补充。</p><p>返回值的话其实也不需要，但是题目中给出的要返回root节点的指针，可以直接使用题目定义好的函数，所以就函数的返回类型为<code>TreeNode</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">invertTree</span>(<span class="params">self, root: TreeNode</span>) -&gt; TreeNode:</span></span><br></pre></td></tr></table></figure><p>2.确定终止条件:</p><p>当前节点为空的时候，就返回</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>3.确定单层递归的逻辑</p><p>因为是先前序遍历，所以先进行交换左右孩子节点，然后反转左子树，反转右子树。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root.left, root.right = root.right, root.left</span><br><span class="line"></span><br><span class="line"><span class="comment"># tmp = root.left</span></span><br><span class="line"><span class="comment"># root.left = root.right</span></span><br><span class="line"><span class="comment"># root.right = tmp</span></span><br><span class="line"></span><br><span class="line">invertTree(root.left)</span><br><span class="line">invertTree(root.right)</span><br></pre></td></tr></table></figure><p>基于这递归三步法，代码基本写完，代码如下（前序）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">invertTree</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: TreeNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前序遍历</span></span><br><span class="line">        root.left, root.right = root.right, root.left</span><br><span class="line"></span><br><span class="line">        self.invertTree(root.left)</span><br><span class="line">        self.invertTree(root.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><h3 id="三、迭代法"><a href="#三、迭代法" class="headerlink" title="三、迭代法"></a>三、迭代法</h3><h4 id="1-深度优先遍历"><a href="#1-深度优先遍历" class="headerlink" title="1.深度优先遍历"></a>1.深度优先遍历</h4><p>可以很轻松的切出如下迭代法（前序）的代码：只需稍作修改即可。将添加值的操作改为变化左右</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">invertTree</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: TreeNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        stack = [root]</span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            node = stack.pop()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> node:</span><br><span class="line">            <span class="comment">### 若不为空，将node的左右孩子调换。</span></span><br><span class="line">                node.left, node.right = node.right, node.left</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 若为空，结束本次循环（他没有左右孩子）</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 将右左孩子分别添加进stack中，因为是栈,所以先处理的是左</span></span><br><span class="line">            stack.append(node.right)</span><br><span class="line">            stack.append(node.left)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><h4 id="2-广度优先遍历"><a href="#2-广度优先遍历" class="headerlink" title="2.广度优先遍历"></a>2.广度优先遍历</h4><p>广度优先遍历也是比较容易的：只需要添加一行——处理队列的节点的代码改变即可。直接上代码！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">invertTree</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: TreeNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        queue = [root]</span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line"><span class="comment">## 只需要添加这一行就行了！</span></span><br><span class="line">            cur_node.left, cur_node.right = cur_node.right, cur_node.left</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                queue.append(cur_node.left)</span><br><span class="line">            <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3></blockquote><p>针对二叉树的问题，解题之前一定要想清楚究竟是前中后序遍历，还是层序遍历。</p><p><strong>「二叉树解题的大忌就是自己稀里糊涂的过了（因为这道题相对简单），但是也不知道自己是怎么遍历的。」</strong></p><p>这也是造成了二叉树的题目“一看就会，一写就废”的原因。</p><p><strong>针对翻转二叉树，我给出了一种递归，三种迭代（一种深度优先遍历，一种层序遍历）的写法，都是之前我们讲过的写法，融汇贯通一下而已。</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;03-翻转二叉树—递归和迭代的应用&quot;&gt;&lt;a href=&quot;#03-翻转二叉树—递归和迭代的应用&quot; class=&quot;headerlink&quot; title=&quot;03_翻转二叉树—递归和迭代的应用&quot;&gt;&lt;/a&gt;03_翻转二叉树—递归和迭代的应用&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;226.</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>00-二叉树的层序遍历2</title>
    <link href="https://xxren8218.github.io/20210702/00-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%862.html"/>
    <id>https://xxren8218.github.io/20210702/00-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%862.html</id>
    <published>2021-07-02T10:13:20.000Z</published>
    <updated>2021-07-04T13:30:05.787Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二-N-叉树的层序遍历2"><a href="#二-N-叉树的层序遍历2" class="headerlink" title="二(N)叉树的层序遍历2"></a>二(N)叉树的层序遍历2</h2><p>上文学习了二叉树的层序遍历，还有四道题没有做完，今天就给做了吧！</p><ul><li>637.⼆叉树的层平均值</li><li>515.在每个树行中找最⼤值</li><li>116.填充每个节点的下⼀个右侧节点指针</li><li>117.填充每个节点的下⼀个右侧节点指针II  </li></ul><blockquote><h3 id="一、二叉树的层平均值"><a href="#一、二叉树的层平均值" class="headerlink" title="一、二叉树的层平均值"></a>一、二叉树的层平均值</h3></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181409.PNG" alt=""></p><p>思路也是比较简单的，只需要在原来的基础上修改一行即可。对tmp列表的元素求和，然后除以列表的长度。——<strong>注意</strong>，python的两个整数相除仍是整数，需要把一个转化为浮点型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">averageOfLevels</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[float]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        queue = [root]</span><br><span class="line">        res = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            tmp = []</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                tmp.append(cur_node.val)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line">     <span class="comment"># 仅仅修改这一行即可。</span></span><br><span class="line">            res.append(<span class="built_in">sum</span>(tmp)/<span class="built_in">float</span>(<span class="built_in">len</span>(tmp)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="二、在每个树行中找最⼤值"><a href="#二、在每个树行中找最⼤值" class="headerlink" title="二、在每个树行中找最⼤值"></a>二、在每个树行中找最⼤值</h3></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181431.PNG" alt=""></p><p>这个思路不需多说吧，也是改变那一行的事情！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">largestValues</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        queue = [root]</span><br><span class="line">        res = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            tmp = []</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                tmp.append(cur_node.val)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"><span class="comment"># 仅需修改这一行</span></span><br><span class="line">            res.append(<span class="built_in">max</span>(tmp))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="三、填充每个节点的下⼀个右侧节点指针"><a href="#三、填充每个节点的下⼀个右侧节点指针" class="headerlink" title="三、填充每个节点的下⼀个右侧节点指针"></a>三、填充每个节点的下⼀个右侧节点指针</h3></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181443.PNG" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181454.PNG" alt=""></p><p>看着这道题像层序遍历，那么我们就先写下我们的框架，然后看怎么处理！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val=0, left=None, right=None, next=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.left = left</span></span><br><span class="line"><span class="string">        self.right = right</span></span><br><span class="line"><span class="string">        self.next = next</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: Node</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = [root]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line"></span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><p>这道题目的关键是返回Node，并不是list，所以，我写了上面的框架。</p><p>在框架上每层处理节点之间的“<code>连线</code>”即可。题目的难点在于:</p><ul><li>如何知道下一个节点是啥？很容易那就是队列的第一个元素。</li><li>如何找到这层的最后一个节点。可以在进入for遍历之后取一下本层的长度n。这样“<code>连线</code>”时，n-1这个节点就是本层的最后了，不需要“连线”了。这样就解决了。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val=0, left=None, right=None, next=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.left = left</span></span><br><span class="line"><span class="string">        self.right = right</span></span><br><span class="line"><span class="string">        self.next = next</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: Node</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = [root]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 记录本层的长度</span></span><br><span class="line">            n = <span class="built_in">len</span>(queue)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):       </span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 判断是否是本层的最后一个节点</span></span><br><span class="line">                <span class="keyword">if</span> i &lt; n - <span class="number">1</span>:</span><br><span class="line">                    cur_node.<span class="built_in">next</span> = queue[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><blockquote><h3 id="四、填充每个节点的下⼀个右侧节点指针II"><a href="#四、填充每个节点的下⼀个右侧节点指针II" class="headerlink" title="四、填充每个节点的下⼀个右侧节点指针II"></a>四、填充每个节点的下⼀个右侧节点指针II</h3></blockquote><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702181512.PNG" alt=""></p><p>代码思路完全一样，不过一个是完全二叉树、一个不是而已。上题写的代码具有鲁棒性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val=0, left=None, right=None, next=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.left = left</span></span><br><span class="line"><span class="string">        self.right = right</span></span><br><span class="line"><span class="string">        self.next = next</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: Node</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = [root]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            n = <span class="built_in">len</span>(queue)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> i &lt; n - <span class="number">1</span>:</span><br><span class="line">                    cur_node.<span class="built_in">next</span> = queue[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure><blockquote><h3 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h3></blockquote><p>至此层序遍历的题目做完了。归根结底就两个框架。</p><ul><li><p>返回Node</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: Node</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = [root]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line"></span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></li><li><p>返回列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connect</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: Node</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = [root]</span><br><span class="line">res = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            tmp = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line"></span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">tmp.append(cur_node.val)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line">            </span><br><span class="line">            res.append(tmp)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二-N-叉树的层序遍历2&quot;&gt;&lt;a href=&quot;#二-N-叉树的层序遍历2&quot; class=&quot;headerlink&quot; title=&quot;二(N)叉树的层序遍历2&quot;&gt;&lt;/a&gt;二(N)叉树的层序遍历2&lt;/h2&gt;&lt;p&gt;上文学习了二叉树的层序遍历，还有四道题没有做完，今天就给做了</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>27-Spark_core概述</title>
    <link href="https://xxren8218.github.io/20210702/27-Spark-core%E6%A6%82%E8%BF%B0.html"/>
    <id>https://xxren8218.github.io/20210702/27-Spark-core%E6%A6%82%E8%BF%B0.html</id>
    <published>2021-07-01T17:32:25.000Z</published>
    <updated>2021-07-01T17:36:09.544Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-spark-core概述"><a href="#1-spark-core概述" class="headerlink" title="1. spark-core概述"></a>1. spark-core概述</h2><p>掌握目标：</p><ul><li>知道RDD的概念</li><li>独立实现RDD的创建</li></ul><h3 id="1-1-什么是RDD"><a href="#1-1-什么是RDD" class="headerlink" title="1.1 什么是RDD"></a>1.1 什么是RDD</h3><ul><li>RDD（Resilient Distributed Dataset）叫做<strong>弹性分布式数据集</strong>，是Spark中最基本的数据抽象，它代表一个<strong>不可变、可分区</strong>、里面的元素<strong>可并行</strong>计算的集合.<ul><li>Dataset:一个数据集，简单的理解为集合，用于存放数据的</li><li>Distributed：它的数据是分布式存储，并且可以做分布式的计算</li><li>Resilient：弹性的<ul><li>它表示的是数据可以保存在磁盘，也可以保存在内存中——弹性的一种表现</li><li>数据分布式也是弹性的</li><li>弹性:并不是指他可以动态扩展，而是容错机制。<ul><li>RDD会在多个节点上存储，就和hdfs的分布式道理是一样的。<strong>hdfs</strong>文件被<strong>切分为多个block存储在各个节点上</strong>，而<strong>RDD</strong>是被切分为多个<strong>partition</strong>。<strong>不同的partition</strong>可能在<strong>不同的节点</strong>上</li><li>spark读取hdfs的场景下，spark把hdfs的block读到内存就会抽象为spark的partition。</li><li>spark计算结束，一般会把数据做持久化到hive，hbase，hdfs等等。我们就拿hdfs举例，将RDD持久化到hdfs上，RDD的每个partition就会存成一个文件，如果文件小于128M，就可以理解为一个partition对应hdfs的一个block。反之，如果大于128M，就会被且分为多个block，这样，一个partition就会对应多个block。</li></ul></li></ul></li><li>不可变</li><li>可分区</li><li>并行计算</li></ul></li></ul><h3 id="1-2-RDD的创建"><a href="#1-2-RDD的创建" class="headerlink" title="1.2 RDD的创建"></a>1.2 RDD的创建</h3><ul><li><p>第一步 创建sparkContext</p><ul><li>SparkContext, Spark程序的入口. SparkContext代表了和Spark集群的链接, 在Spark集群中通过SparkContext来创建RDD</li><li>SparkConf  创建SparkContext的时候需要一个SparkConf， 用来传递Spark应用的基本信息</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf = SparkConf().setAppName(appName).setMaster(master)</span><br><span class="line">sc = SparkContext(conf=conf)</span><br></pre></td></tr></table></figure></li><li><p>创建RDD</p><ul><li>进入pyspark环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop000 ~]$ pyspark</span><br><span class="line">Python 3.5.0 (default, Nov 13 2018, 15:43:53)</span><br><span class="line">[GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">19/03/08 12:19:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Setting default log level to &quot;WARN&quot;.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span><br><span class="line">   /__ / .__/\_,_/_/ /_/\_\   version 2.3.0</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Python version 3.5.0 (default, Nov 13 2018 15:43:53)</span><br><span class="line">SparkSession available as &#x27;spark&#x27;.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc</span></span><br><span class="line">&lt;SparkContext master=local[*] appName=PySparkShell&gt;</span><br></pre></td></tr></table></figure><ul><li>在spark shell中 已经为我们创建好了 SparkContext 通过sc直接使用</li><li>可以在spark UI中看到当前的Spark作业 在浏览器访问当前centos的4040端口</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702013325.png" alt=""></p><ul><li><p>Parallelized Collections方式创建RDD</p><ul><li>调用<code>SparkContext</code>的 <code>parallelize</code> 方法并且传入已有的可迭代对象或者集合</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">distData = sc.parallelize(data)</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; data = [1, 2, 3, 4, 5]</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData = sc.parallelize(data)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; data</span></span><br><span class="line">[1, 2, 3, 4, 5]</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData</span></span><br><span class="line">ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:175</span><br></pre></td></tr></table></figure><ul><li>在spark ui中观察执行情况</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702013346.png" alt=""></p><ul><li>在通过<code>parallelize</code>方法创建RDD 的时候可以指定分区数量</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData = sc.parallelize(data,5) <span class="comment"># 5表示数据分区的数量，最终一个分区对应一个task</span></span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; distData.reduce(lambda a, b: a + b)</span></span><br><span class="line">15</span><br></pre></td></tr></table></figure><ul><li>在spark ui中观察执行情况</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702013411.png" alt=""></p><ul><li>Spark将为群集的每个分区（partition）运行一个任务（task）。 通常，可以根据CPU核心数量指定分区数量（每个CPU有2-4个分区）如未指定分区数量，Spark会自动设置分区数。</li></ul></li><li><p>通过外部数据创建RDD</p><ul><li>PySpark可以<strong>从Hadoop支持的任何存储源创建RDD</strong>，包括本地文件系统，HDFS，Cassandra，HBase，Amazon S3等</li><li>支持整个目录、多文件、通配符</li><li>支持压缩文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.textFile(<span class="string">&#x27;file:///home/hadoop/tmp/word.txt&#x27;</span>)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1.collect()</span></span><br><span class="line">[&#x27;foo foo quux labs foo bar quux abc bar see you by test welcome test&#x27;, &#x27;abc labs foo me python hadoop ab ac bc bec python&#x27;]</span><br></pre></td></tr></table></figure></li></ul></li><li><p>加载了数据以后接下来就是计算了。</p></li></ul><h2 id="2-spark-core-RDD常用算子练习"><a href="#2-spark-core-RDD常用算子练习" class="headerlink" title="2. spark-core RDD常用算子练习"></a>2. spark-core RDD常用算子练习</h2><p>掌握目标</p><ul><li>说出RDD的三类算子</li><li>掌握transformation和action算子的基本使用</li></ul><h3 id="2-1-RDD-常用操作"><a href="#2-1-RDD-常用操作" class="headerlink" title="2.1 RDD 常用操作"></a>2.1 RDD 常用操作</h3><ul><li><p>RDD 支持两种类型的操作：</p><ul><li>transformation<ul><li>从一个已经存在的数据集创建一个新的数据集<ul><li>rdd a ——-&gt;transformation ——&gt; rdd b</li></ul></li><li>比如， map就是一个transformation 操作，把数据集中的每一个元素传给一个函数并<strong>返回一个新的RDD</strong>，代表transformation操作的结果 </li></ul></li><li>action<ul><li>获取对数据进行运算操作之后的结果</li><li>比如， reduce 就是一个action操作，使用某个函数聚合RDD所有元素的操作，并<strong>返回最终计算结果</strong></li></ul></li></ul></li><li><p>所有的transformation操作都是惰性的（lazy）</p><ul><li>不会立即计算结果</li><li>只记下应用于数据集的transformation操作</li><li>只有调用action一类的操作之后才会计算所有transformation</li><li>这种设计使Spark运行效率更高</li><li>例如map reduce 操作，map创建的数据集将用于reduce，map阶段的结果不会返回，仅会返回reduce结果。</li></ul></li><li><em>persist</em> 操作<ul><li><em>persist</em>操作用于将数据缓存 可以缓存在内存中 也可以缓存到磁盘上， 也可以复制到磁盘的其它节点上</li></ul></li></ul><h3 id="2-2-RDD-Transformation算子"><a href="#2-2-RDD-Transformation算子" class="headerlink" title="2.2 RDD Transformation算子"></a>2.2 RDD Transformation算子</h3><ul><li><p>map: map(func)——<strong>进来几个元素，出去几个元素。</strong></p><ul><li>将func函数作用到数据集的每一个元素上，生成一个新的RDD返回</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5,6,7,8,9],3)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(lambda x: x+1)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect() <span class="comment"># collect就属于 action。若不调用拿不到结果。</span></span></span><br><span class="line">[2, 3, 4, 5, 6, 7, 8, 9, 10]</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5,6,7,8,9],3)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; def add(x):</span></span><br><span class="line">...     return x+1</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(add)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect()</span></span><br><span class="line">[2, 3, 4, 5, 6, 7, 8, 9, 10]</span><br></pre></td></tr></table></figure></li></ul><p>  <img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702013432.png" alt=""></p><ul><li><p>filter</p><ul><li>filter(func) 选出所有func返回值为true的元素，生成一个新的RDD返回</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5,6,7,8,9],3)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(lambda x:x*2)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3 = rdd2.filter(lambda x:x&gt;4)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3.collect()</span></span><br><span class="line">[6, 8, 10, 12, 14, 16, 18]</span><br></pre></td></tr></table></figure></li><li><p>flatmap</p><ul><li>flatMap会先执行map的操作，再将所有对象合并为一个对象</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([<span class="string">&quot;a b c&quot;</span>,<span class="string">&quot;d e f&quot;</span>,<span class="string">&quot;h i j&quot;</span>])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.flatMap(lambda x:x.split(<span class="string">&quot; &quot;</span>))</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect()</span></span><br><span class="line">[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;h&#x27;, &#x27;i&#x27;, &#x27;j&#x27;]</span><br></pre></td></tr></table></figure><ul><li>flatMap和map的区别：flatMap在map的基础上将结果合并到一个list中</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([<span class="string">&quot;a b c&quot;</span>,<span class="string">&quot;d e f&quot;</span>,<span class="string">&quot;h i j&quot;</span>])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = rdd1.map(lambda x:x.split(<span class="string">&quot; &quot;</span>))</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2.collect()</span></span><br><span class="line">[[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;], [&#x27;h&#x27;, &#x27;i&#x27;, &#x27;j&#x27;]]</span><br></pre></td></tr></table></figure></li><li><p>union</p><ul><li>对两个RDD求并集</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,2)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = sc.parallelize([(<span class="string">&quot;c&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,3)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3 = rdd1.union(rdd2)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3.collect()</span></span><br><span class="line">[(&#x27;a&#x27;, 1), (&#x27;b&#x27;, 2), (&#x27;c&#x27;, 1), (&#x27;b&#x27;, 3)]</span><br></pre></td></tr></table></figure></li><li><p>intersection</p><ul><li>对两个RDD求交集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd2 = sc.parallelize([(<span class="string">&quot;c&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;b&quot;</span>,<span class="number">3</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd3 = rdd1.union(rdd2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd4 = rdd3.intersection(rdd2)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd4.collect()</span><br><span class="line">[(<span class="string">&#x27;c&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">3</span>)]</span><br></pre></td></tr></table></figure></li><li><p>groupByKey</p><ul><li>以元组中的第0个元素作为key，进行分组，返回一个新的RDD</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([(<span class="string">&quot;a&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,2)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd2 = sc.parallelize([(<span class="string">&quot;c&quot;</span>,1),(<span class="string">&quot;b&quot;</span>,3)])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd3 = rdd1.union(rdd2)</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd4 = rdd3.groupByKey()</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd4.collect()</span></span><br><span class="line">[(&#x27;a&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fba6a5e5898&gt;), (&#x27;c&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fba6a5e5518&gt;), (&#x27;b&#x27;, &lt;pyspark.resultiterable.ResultIterable object at 0x7fba6a5e5f28&gt;)]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>groupByKey之后的结果中 value是一个Iterable</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>result[<span class="number">2</span>]</span><br><span class="line">(<span class="string">&#x27;b&#x27;</span>, &lt;pyspark.resultiterable.ResultIterable <span class="built_in">object</span> at <span class="number">0x7fba6c18e518</span>&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>result[<span class="number">2</span>][<span class="number">1</span>]</span><br><span class="line">&lt;pyspark.resultiterable.ResultIterable <span class="built_in">object</span> at <span class="number">0x7fba6c18e518</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(result[<span class="number">2</span>][<span class="number">1</span>])</span><br><span class="line">[<span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure><ul><li><p>reduceByKey</p><ul><li>将key相同的键值对，按照Function进行计算</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd = sc.parallelize([(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">1</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd.reduceByKey(<span class="keyword">lambda</span> x,y:x+y).collect()</span><br><span class="line">[(<span class="string">&#x27;b&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">2</span>)]</span><br></pre></td></tr></table></figure></li><li><p>sortByKey</p><ul><li><p><code>sortByKey</code>(<em>ascending=True</em>, <em>numPartitions=None</em>, <em>keyfunc=<function RDD.<lambda>&gt;</em>)</p><p>Sorts this RDD, which is assumed to consist of (key, value) pairs.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp = [(<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="number">5</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp).sortByKey().first()</span><br><span class="line">(<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp).sortByKey(<span class="literal">True</span>, <span class="number">1</span>).collect()</span><br><span class="line">[(<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">4</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp).sortByKey(<span class="literal">True</span>, <span class="number">2</span>).collect()</span><br><span class="line">[(<span class="string">&#x27;1&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;2&#x27;</span>, <span class="number">5</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;d&#x27;</span>, <span class="number">4</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp2 = [(<span class="string">&#x27;Mary&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;had&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;a&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;little&#x27;</span>, <span class="number">4</span>), (<span class="string">&#x27;lamb&#x27;</span>, <span class="number">5</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tmp2.extend([(<span class="string">&#x27;whose&#x27;</span>, <span class="number">6</span>), (<span class="string">&#x27;fleece&#x27;</span>, <span class="number">7</span>), (<span class="string">&#x27;was&#x27;</span>, <span class="number">8</span>), (<span class="string">&#x27;white&#x27;</span>, <span class="number">9</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize(tmp2).sortByKey(<span class="literal">True</span>, <span class="number">3</span>, keyfunc=<span class="keyword">lambda</span> k: k.lower()).collect()</span><br><span class="line">[(<span class="string">&#x27;a&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;fleece&#x27;</span>, <span class="number">7</span>), (<span class="string">&#x27;had&#x27;</span>, <span class="number">2</span>), (<span class="string">&#x27;lamb&#x27;</span>, <span class="number">5</span>),...(<span class="string">&#x27;white&#x27;</span>, <span class="number">9</span>), (<span class="string">&#x27;whose&#x27;</span>, <span class="number">6</span>)]</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="2-3-RDD-Action算子"><a href="#2-3-RDD-Action算子" class="headerlink" title="2.3 RDD Action算子"></a>2.3 RDD Action算子</h3><ul><li><p>collect——大数据慎用！</p><ul><li>返回一个list，list中包含 RDD中的所有元素</li><li>只有当数据量较小的时候使用Collect 因为所有的结果都会加载到内存中</li></ul></li><li><p>reduce</p><ul><li><strong>reduce</strong>将<strong>RDD</strong>中元素两两传递给输入函数，同时产生一个新的值，新产生的值与RDD中下一个元素再被传递给输入函数直到最后只有一个值为止。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1 = sc.parallelize([1,2,3,4,5])</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; rdd1.reduce(lambda x,y : x+y)</span></span><br><span class="line">15</span><br></pre></td></tr></table></figure></li><li><p>first</p><ul><li>返回RDD的第一个元素</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sc.parallelize([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]).first()</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure></li><li><p>take</p><ul><li>返回RDD的前N个元素</li><li><code>take</code>(<em>num</em>)</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc.parallelize([2, 3, 4, 5, 6]).take(2)</span></span><br><span class="line">[2, 3]</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc.parallelize([2, 3, 4, 5, 6]).take(10)</span></span><br><span class="line">[2, 3, 4, 5, 6]</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; sc.parallelize(range(100), 100).filter(lambda x: x &gt; 90).take(3)</span></span><br><span class="line">[91, 92, 93]</span><br></pre></td></tr></table></figure></li><li><p>count</p><p>返回RDD中元素的个数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; sc.parallelize([2, 3, 4]).count()</span><br><span class="line">3</span><br></pre></td></tr></table></figure></li></ul><h3 id="2-4-Spark-RDD两类算子执行示意"><a href="#2-4-Spark-RDD两类算子执行示意" class="headerlink" title="2.4 Spark RDD两类算子执行示意"></a>2.4 Spark RDD两类算子执行示意</h3><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702013508.PNG" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210702013522.PNG" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-spark-core概述&quot;&gt;&lt;a href=&quot;#1-spark-core概述&quot; class=&quot;headerlink&quot; title=&quot;1. spark-core概述&quot;&gt;&lt;/a&gt;1. spark-core概述&lt;/h2&gt;&lt;p&gt;掌握目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;知</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
