<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>X.X.Ren</title>
  
  <subtitle>个人博客</subtitle>
  <link href="https://xxren8218.github.io/atom.xml" rel="self"/>
  
  <link href="https://xxren8218.github.io/"/>
  <updated>2021-07-10T14:51:29.256Z</updated>
  <id>https://xxren8218.github.io/</id>
  
  <author>
    <name>任晓雄</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>36-离线推荐处理&amp;实时推荐</title>
    <link href="https://xxren8218.github.io/20210710/36-%E7%A6%BB%E7%BA%BF%E6%8E%A8%E8%8D%90%E5%A4%84%E7%90%86-%E5%AE%9E%E6%97%B6%E6%8E%A8%E8%8D%90.html"/>
    <id>https://xxren8218.github.io/20210710/36-%E7%A6%BB%E7%BA%BF%E6%8E%A8%E8%8D%90%E5%A4%84%E7%90%86-%E5%AE%9E%E6%97%B6%E6%8E%A8%E8%8D%90.html</id>
    <published>2021-07-10T14:50:29.000Z</published>
    <updated>2021-07-10T14:51:29.256Z</updated>
    
    <content type="html"><![CDATA[<h2 id="离线推荐数据缓存-amp-实时推荐"><a href="#离线推荐数据缓存-amp-实时推荐" class="headerlink" title="离线推荐数据缓存 &amp; 实时推荐"></a>离线推荐数据缓存 &amp; 实时推荐</h2><h3 id="1-1-离线数据缓存之离线召回集"><a href="#1-1-离线数据缓存之离线召回集" class="headerlink" title="1.1 离线数据缓存之离线召回集"></a>1.1 离线数据缓存之离线召回集</h3><ul><li><p>这里主要是利用我们前面训练的ALS模型进行协同过滤召回，但是注意，我们ALS模型召回的是用户最感兴趣的类别，而我们需要的是用户可能感兴趣的广告的集合，因此我们还需要根据召回的类别匹配出对应的广告。</p><p>所以这里我们除了需要我们训练的ALS模型以外，还需要有一个广告和类别的对应关系。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS中加载广告基本信息数据，返回spark dafaframe对象</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：由于本数据集中存在NULL字样的数据，无法直接设置schema，只能先将NULL类型的数据处理掉，然后进行类型转换</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串，替换掉</span></span><br><span class="line">df = df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, df.price.cast(FloatType()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们只需要adgroupId、和cateId</span></span><br><span class="line">_ = ad_feature_df.select(<span class="string">&quot;adgroupId&quot;</span>, <span class="string">&quot;cateId&quot;</span>)</span><br><span class="line"><span class="comment"># 由于这里数据集其实很少，所以我们再直接转成Pandas dataframe来处理，把数据载入内存</span></span><br><span class="line">pdf = _.toPandas()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动释放一些内存</span></span><br><span class="line"><span class="keyword">del</span> df</span><br><span class="line"><span class="keyword">del</span> ad_feature_df</span><br><span class="line"><span class="keyword">del</span> _</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure><ul><li>根据指定的类别找到对应的广告</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">pdf.where(pdf.cateId==<span class="number">11156</span>).dropna().adgroupId <span class="comment"># 举个例子，随便找个cateId看看他的adgroupId都有哪些。</span></span><br><span class="line"></span><br><span class="line">np.random.choice(pdf.where(pdf.cateId==<span class="number">11156</span>).dropna().adgroupId.astype(np.int64), <span class="number">200</span>) <span class="comment"># 在召回的用户感兴趣的类别上随机挑选200个物品。</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">313       138953.0</span><br><span class="line">314       467512.0</span><br><span class="line">1661      140008.0</span><br><span class="line">1666      238772.0</span><br><span class="line">1669      237471.0</span><br><span class="line">1670      238761.0</span><br><span class="line">...   </span><br><span class="line">843456    352273.0</span><br><span class="line">846728    818681.0</span><br><span class="line">846729    838953.0</span><br><span class="line">846810    845337.0</span><br><span class="line">Name: adgroupId, Length: 731, dtype: float64</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>利用ALS模型进行类别的召回</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载als模型，注意必须先有spark上下文管理器，即sparkContext，但这里sparkSession创建后，自动创建了sparkContext</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载之前存储的模型</span></span><br><span class="line">als_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 返回模型中关于用户的所有属性   df:   id   features</span></span><br><span class="line">als_model.userFactors</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[id: int, features: array&lt;float&gt;]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">cateId_df = pd.DataFrame(pdf.cateId.unique(),columns=[<span class="string">&quot;cateId&quot;</span>])</span><br><span class="line">cateId_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cateId</span><br><span class="line">01</span><br><span class="line">12</span><br><span class="line">23</span><br><span class="line">34</span><br><span class="line">45</span><br><span class="line">56</span><br><span class="line">67</span><br><span class="line">......</span><br><span class="line">676612948</span><br><span class="line">676712955</span><br><span class="line">676812960</span><br><span class="line">6769 rows × 1 columns</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cateId_df.insert(<span class="number">0</span>, <span class="string">&quot;userId&quot;</span>, np.array([<span class="number">8</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6769</span>)]))</span><br><span class="line">cateId_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> userId cateId</span><br><span class="line">081</span><br><span class="line">182</span><br><span class="line">283</span><br><span class="line">384</span><br><span class="line">485</span><br><span class="line">.........</span><br><span class="line">6766812948</span><br><span class="line">6767812955</span><br><span class="line">6768812960</span><br><span class="line">6769 rows × 2 columns</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>传入 userid、cataId的df，对应预测值进行排序（也可以用之前的recommandForAllusers，这样是为了另外一种ALS的用法）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">als_model.transform(spark.createDataFrame(cateId_df)).sort(<span class="string">&quot;prediction&quot;</span>, ascending=<span class="literal">False</span>).na.drop().show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">+------+------+----------+</span><br><span class="line">|userId|cateId|prediction|</span><br><span class="line">+------+------+----------+</span><br><span class="line">|     8|  7214|  9.917084|</span><br><span class="line">|     8|   877|  7.479664|</span><br><span class="line">|     8|  7266| 7.4762917|</span><br><span class="line">|     8| 10856| 7.3395424|</span><br><span class="line">|     8|  4766|  7.149538|</span><br><span class="line">|     8|  7282| 6.6835284|</span><br><span class="line">|     8|  7270| 6.2145095|</span><br><span class="line">|     8|   201| 6.0623236|</span><br><span class="line">|     8|  4267| 5.9155636|</span><br><span class="line">|     8|  7267|  5.838009|</span><br><span class="line">|     8|  5392| 5.6882005|</span><br><span class="line">|     8|  6261| 5.6804466|</span><br><span class="line">|     8|  6306| 5.2992325|</span><br><span class="line">|     8| 11050|  5.245261|</span><br><span class="line">|     8|  8655| 5.1701374|</span><br><span class="line">|     8|  4610|  5.139578|</span><br><span class="line">|     8|   932|   5.12694|</span><br><span class="line">|     8| 12276| 5.0776596|</span><br><span class="line">|     8|  8071|  4.979195|</span><br><span class="line">|     8|  6580| 4.8523283|</span><br><span class="line">+------+------+----------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储用户召回，使用redis第9号数据库，类型：sets类型</span></span><br><span class="line">client = redis.StrictRedis(host=<span class="string">&quot;192.168.199.188&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> als_model.userFactors.select(<span class="string">&quot;id&quot;</span>).collect():</span><br><span class="line">    </span><br><span class="line">    userId = r.<span class="built_in">id</span></span><br><span class="line">    </span><br><span class="line">    cateId_df = pd.DataFrame(pdf.cateId.unique(),columns=[<span class="string">&quot;cateId&quot;</span>])</span><br><span class="line">    cateId_df.insert(<span class="number">0</span>, <span class="string">&quot;userId&quot;</span>, np.array([userId <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6769</span>)]))</span><br><span class="line">    ret = <span class="built_in">set</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 利用模型，传入datasets(userId, cateId)，这里控制了userId一样，所以相当于是在求某用户对所有分类的兴趣程度（评分）</span></span><br><span class="line">    cateId_list = als_model.transform(spark.createDataFrame(cateId_df)).sort(<span class="string">&quot;prediction&quot;</span>, ascending=<span class="literal">False</span>).na.drop()</span><br><span class="line">    <span class="comment"># 从前20个分类中选出500个进行召回</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> cateId_list.head(<span class="number">20</span>):</span><br><span class="line">        need = <span class="number">500</span> - <span class="built_in">len</span>(ret)    <span class="comment"># 如果不足500个，那么随机选出need个广告</span></span><br><span class="line">        ret = ret.union(np.random.choice(pdf.where(pdf.cateId==i.cateId).adgroupId.dropna().astype(np.int64), need))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(ret) &gt;= <span class="number">500</span>:    <span class="comment"># 如果达到500个则退出</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    client.sadd(userId, *ret)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 如果redis所在机器，内存不足，会抛出异常</span></span><br></pre></td></tr></table></figure><h3 id="2-1-离线数据缓存之离线特征"><a href="#2-1-离线数据缓存之离线特征" class="headerlink" title="2.1 离线数据缓存之离线特征"></a>2.1 离线数据缓存之离线特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &quot;pid&quot;, 广告资源位，属于场景特征，也就是说，每一种广告通常是可以防止在多种资源外下的</span></span><br><span class="line"><span class="comment"># 因此这里对于pid，应该是由广告系统发起推荐请求时，向推荐系统明确要推荐的用户是谁，以及对应的资源位，或者说有哪些</span></span><br><span class="line"><span class="comment"># 这样如果有多个资源位，那么每个资源位都会对应相应的一个推荐列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要进行缓存的特征值</span></span><br><span class="line"></span><br><span class="line">feature_cols_from_ad = [</span><br><span class="line">    <span class="string">&quot;price&quot;</span>    <span class="comment"># 来自广告基本信息中</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户特征</span></span><br><span class="line">feature_cols_from_user = [</span><br><span class="line">    <span class="string">&quot;cms_group_id&quot;</span>,</span><br><span class="line">    <span class="string">&quot;final_gender_code&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pvalue_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;new_user_class_level&quot;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li>从HDFS中加载广告基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">_ad_feature_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串</span></span><br><span class="line">_ad_feature_df = _ad_feature_df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = _ad_feature_df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, _ad_feature_df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, _ad_feature_df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, _ad_feature_df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, _ad_feature_df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, _ad_feature_df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, _ad_feature_df.price.cast(FloatType()))</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreachPartition</span>(<span class="params">partition</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">import</span> redis</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line">    client = redis.StrictRedis(host=<span class="string">&quot;192.168.199.188&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> partition:</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&quot;price&quot;</span>: r.price</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 转成json字符串再保存，能保证数据再次倒出来时，能有效的转换成python类型</span></span><br><span class="line">        client.hset(<span class="string">&quot;ad_features&quot;</span>, r.adgroupId, json.dumps(data))</span><br><span class="line">        </span><br><span class="line">ad_feature_df.foreachPartition(foreachPartition)</span><br></pre></td></tr></table></figure><ul><li>从HDFS加载用户基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建表结构schema对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_segid&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_group_id&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;final_gender_code&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;age_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pvalue_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;shopping_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;occupation&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;new_user_class_level&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 利用schema从hdfs加载</span></span><br><span class="line">user_profile_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/user_profile.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">user_profile_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: int, cms_segid: int, cms_group_id: int, final_gender_code: int, age_level: int, pvalue_level: int, shopping_level: int, occupation: int, new_user_class_level: int]</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreachPartition2</span>(<span class="params">partition</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">import</span> redis</span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line">    client = redis.StrictRedis(host=<span class="string">&quot;192.168.199.188&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> partition:</span><br><span class="line">        data = &#123;</span><br><span class="line">            <span class="string">&quot;cms_group_id&quot;</span>: r.cms_group_id,</span><br><span class="line">            <span class="string">&quot;final_gender_code&quot;</span>: r.final_gender_code,</span><br><span class="line">            <span class="string">&quot;age_level&quot;</span>: r.age_level,</span><br><span class="line">            <span class="string">&quot;shopping_level&quot;</span>: r.shopping_level,</span><br><span class="line">            <span class="string">&quot;occupation&quot;</span>: r.occupation,</span><br><span class="line">            <span class="string">&quot;pvalue_level&quot;</span>: r.pvalue_level,</span><br><span class="line">            <span class="string">&quot;new_user_class_level&quot;</span>: r.new_user_class_level</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 转成json字符串再保存，能保证数据再次倒出来时，能有效的转换成python类型</span></span><br><span class="line">        client.hset(<span class="string">&quot;user_features1&quot;</span>, r.userId, json.dumps(data))</span><br><span class="line">        </span><br><span class="line">user_profile_df.foreachPartition(foreachPartition2)</span><br></pre></td></tr></table></figure><h2 id="二-实时产生推荐结果"><a href="#二-实时产生推荐结果" class="headerlink" title="二. 实时产生推荐结果"></a>二. 实时产生推荐结果</h2><h3 id="2-1-推荐任务处理"><a href="#2-1-推荐任务处理" class="headerlink" title="2.1 推荐任务处理"></a>2.1 推荐任务处理</h3><ul><li>CTR预测模型 + 特征 ==&gt; 预测结果 ==&gt; TOP-N列表</li><li>数据缓存取出之后 还原成对应的onehot编码</li><li>热编码中：”pvalue_level”特征对应关系:</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+------------+----------------------+</span><br><span class="line">|pvalue_level|pl_onehot_feature     |</span><br><span class="line">+------------+----------------------+</span><br><span class="line">|          -1|                   0.0|</span><br><span class="line">|           3|                   3.0|</span><br><span class="line">|           1|                   2.0|</span><br><span class="line">|           2|                   1.0|</span><br><span class="line">+------------+----------------------+</span><br></pre></td></tr></table></figure><ul><li>“new_user_class_level”的特征对应关系：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------------------------+</span><br><span class="line">|new_user_class_level|nucl_onehot_feature     |</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|                  -1|                     0.0|</span><br><span class="line">|                   3|                     2.0|</span><br><span class="line">|                   1|                     4.0|</span><br><span class="line">|                   4|                     3.0|</span><br><span class="line">|                   2|                     1.0|</span><br><span class="line">+--------------------+------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pvalue_level_rela = &#123;-<span class="number">1</span>: <span class="number">0</span>, <span class="number">3</span>:<span class="number">3</span>, <span class="number">1</span>:<span class="number">2</span>, <span class="number">2</span>:<span class="number">1</span>&#125;</span><br><span class="line">new_user_class_level_rela = &#123;-<span class="number">1</span>:<span class="number">0</span>, <span class="number">3</span>:<span class="number">2</span>, <span class="number">1</span>:<span class="number">4</span>, <span class="number">4</span>:<span class="number">3</span>, <span class="number">2</span>:<span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure><ul><li>“cms_group_id”特征对应关系：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+------------+-------------------------+</span><br><span class="line">|cms_group_id|min(cms_group_id_feature)|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line">|           7|                      9.0|</span><br><span class="line">|          11|                      6.0|</span><br><span class="line">|           3|                      0.0|</span><br><span class="line">|           8|                      8.0|</span><br><span class="line">|           0|                     12.0|</span><br><span class="line">|           5|                      3.0|</span><br><span class="line">|           6|                     10.0|</span><br><span class="line">|           9|                      5.0|</span><br><span class="line">|           1|                      7.0|</span><br><span class="line">|          10|                      4.0|</span><br><span class="line">|           4|                      1.0|</span><br><span class="line">|          12|                     11.0|</span><br><span class="line">|           2|                      2.0|</span><br><span class="line">+------------+-------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cms_group_id_rela &#x3D; &#123;</span><br><span class="line">    7: 9,</span><br><span class="line">    11: 6,</span><br><span class="line">    3: 0,</span><br><span class="line">    8: 8,</span><br><span class="line">    0: 12,</span><br><span class="line">    5: 3,</span><br><span class="line">    6: 10,</span><br><span class="line">    9: 5,</span><br><span class="line">    1: 7,</span><br><span class="line">    10: 4,</span><br><span class="line">    4: 1,</span><br><span class="line">    12: 11,</span><br><span class="line">    2: 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>“final_gender_code”特征对应关系：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+------------------------------+</span><br><span class="line">|final_gender_code|min(final_gender_code_feature)|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|                1|                           1.0|</span><br><span class="line">|                2|                           0.0|</span><br><span class="line">+-----------------+------------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final_gender_code_rela &#x3D; &#123;1:1, 2:0&#125;</span><br></pre></td></tr></table></figure><ul><li>“age_level”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+---------+----------------------+</span><br><span class="line">|age_level|min(age_level_feature)|</span><br><span class="line">+---------+----------------------+</span><br><span class="line">|        3|                   0.0|</span><br><span class="line">|        0|                   6.0|</span><br><span class="line">|        5|                   2.0|</span><br><span class="line">|        6|                   5.0|</span><br><span class="line">|        1|                   4.0|</span><br><span class="line">|        4|                   1.0|</span><br><span class="line">|        2|                   3.0|</span><br><span class="line">+---------+----------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">age_level_rela &#x3D; &#123;3:0, 0:6, 5:2, 6:5, 1:4, 4:1, 2:3&#125;</span><br></pre></td></tr></table></figure><ul><li>“shopping_level”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">|shopping_level|min(shopping_level_feature)|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|             3|                        0.0|</span><br><span class="line">|             1|                        2.0|</span><br><span class="line">|             2|                        1.0|</span><br><span class="line">+--------------+---------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shopping_level_rela &#x3D; &#123;3:0, 1:2, 2:1&#125;</span><br></pre></td></tr></table></figure><ul><li>“occupation”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----------------------+</span><br><span class="line">|occupation|min(occupation_feature)|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|         0|                    0.0|</span><br><span class="line">|         1|                    1.0|</span><br><span class="line">+----------+-----------------------+</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">occupation_rela &#x3D; &#123;0:0, 1:1&#125;</span><br><span class="line"></span><br><span class="line">pid_rela &#x3D; &#123;</span><br><span class="line">    &quot;430548_1007&quot;: 0, </span><br><span class="line">    &quot;430549_1007&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>特征获取</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> DenseVector</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_datasets</span>(<span class="params">userId, pid</span>):</span></span><br><span class="line">    client_of_recall = redis.StrictRedis(host=<span class="string">&quot;192.168.199.88&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">9</span>)</span><br><span class="line">    client_of_features = redis.StrictRedis(host=<span class="string">&quot;192.168.199.88&quot;</span>, port=<span class="number">6379</span>, db=<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 获取用户特征</span></span><br><span class="line">    user_feature = json.loads(client_of_features.hget(<span class="string">&quot;user_features&quot;</span>, userId))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取用户召回集</span></span><br><span class="line">    recall_sets = client_of_recall.smembers(userId)</span><br><span class="line">    </span><br><span class="line">    result = []</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 遍历召回集</span></span><br><span class="line">    <span class="keyword">for</span> adgroupId <span class="keyword">in</span> recall_sets:</span><br><span class="line">        adgroupId = <span class="built_in">int</span>(adgroupId)</span><br><span class="line">        <span class="comment"># 获取该广告的特征值</span></span><br><span class="line">        ad_feature = json.loads(client_of_features.hget(<span class="string">&quot;ad_features&quot;</span>, adgroupId))</span><br><span class="line">        </span><br><span class="line">        features = &#123;&#125;</span><br><span class="line">        features.update(user_feature)</span><br><span class="line">        features.update(ad_feature)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> features.items():</span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                features[k] = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        features_col = [</span><br><span class="line">            <span class="comment"># 特征值</span></span><br><span class="line">            <span class="string">&quot;price&quot;</span>,</span><br><span class="line">            <span class="string">&quot;cms_group_id&quot;</span>,</span><br><span class="line">            <span class="string">&quot;final_gender_code&quot;</span>,</span><br><span class="line">            <span class="string">&quot;age_level&quot;</span>,</span><br><span class="line">            <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">            <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">            <span class="string">&quot;pid&quot;</span>, </span><br><span class="line">            <span class="string">&quot;pvalue_level&quot;</span>,</span><br><span class="line">            <span class="string">&quot;new_user_class_level&quot;</span></span><br><span class="line">        ]</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        &quot;cms_group_id&quot;, 类别型特征，约13个分类 ==&gt; 13维</span></span><br><span class="line"><span class="string">        &quot;final_gender_code&quot;, 类别型特征，2个分类 ==&gt; 2维</span></span><br><span class="line"><span class="string">        &quot;age_level&quot;, 类别型特征，7个分类 ==&gt;7维</span></span><br><span class="line"><span class="string">        &quot;shopping_level&quot;, 类别型特征，3个分类 ==&gt; 3维</span></span><br><span class="line"><span class="string">        &quot;occupation&quot;, 类别型特征，2个分类 ==&gt; 2维</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        price = <span class="built_in">float</span>(features[<span class="string">&quot;price&quot;</span>])</span><br><span class="line"></span><br><span class="line">        pid_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]<span class="comment">#[0,0]</span></span><br><span class="line">        cms_group_id_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">13</span>)]</span><br><span class="line">        final_gender_code_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">        age_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>)]</span><br><span class="line">        shopping_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)]</span><br><span class="line">        occupation_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>)]</span><br><span class="line">        pvalue_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>)]</span><br><span class="line">        new_user_class_level_value = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br><span class="line"></span><br><span class="line">        pid_value[pid_rela[pid]] = <span class="number">1</span></span><br><span class="line">        cms_group_id_value[cms_group_id_rela[<span class="built_in">int</span>(features[<span class="string">&quot;cms_group_id&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        final_gender_code_value[final_gender_code_rela[<span class="built_in">int</span>(features[<span class="string">&quot;final_gender_code&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        age_level_value[age_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;age_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        shopping_level_value[shopping_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;shopping_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        occupation_value[occupation_rela[<span class="built_in">int</span>(features[<span class="string">&quot;occupation&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        pvalue_level_value[pvalue_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;pvalue_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line">        new_user_class_level_value[new_user_class_level_rela[<span class="built_in">int</span>(features[<span class="string">&quot;new_user_class_level&quot;</span>])]] = <span class="number">1</span></span><br><span class="line"><span class="comment">#         print(pid_value)</span></span><br><span class="line"><span class="comment">#         print(cms_group_id_value)</span></span><br><span class="line"><span class="comment">#         print(final_gender_code_value)</span></span><br><span class="line"><span class="comment">#         print(age_level_value)</span></span><br><span class="line"><span class="comment">#         print(shopping_level_value)</span></span><br><span class="line"><span class="comment">#         print(occupation_value)</span></span><br><span class="line"><span class="comment">#         print(pvalue_level_value)</span></span><br><span class="line"><span class="comment">#         print(new_user_class_level_value)</span></span><br><span class="line">        </span><br><span class="line">        vector = DenseVector([price] + pid_value + cms_group_id_value + final_gender_code_value\</span><br><span class="line">        + age_level_value + shopping_level_value + occupation_value + pvalue_level_value + new_user_class_level_value)</span><br><span class="line">        </span><br><span class="line">        result.append((userId, adgroupId, vector))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># create_datasets(88, &quot;430548_1007&quot;)</span></span><br></pre></td></tr></table></figure><ul><li>载入训练好的模型</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.ml.classification import LogisticRegressionModel</span><br><span class="line">CTR_model &#x3D; LogisticRegressionModel.load(&quot;hdfs:&#x2F;&#x2F;localhost:9000&#x2F;models&#x2F;CTRModel_AllOneHot.obj&quot;)</span><br><span class="line">pdf &#x3D; pd.DataFrame(create_datasets(8, &quot;430548_1007&quot;), columns&#x3D;[&quot;userId&quot;, &quot;adgroupId&quot;, &quot;features&quot;])</span><br><span class="line">datasets &#x3D; spark.createDataFrame(pdf)</span><br><span class="line">datasets.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+--------------------+</span><br><span class="line">|userId|adgroupId|            features|</span><br><span class="line">+------+---------+--------------------+</span><br><span class="line">|     8|   445914|[9.89999961853027...|</span><br><span class="line">|     8|   258252|[7.59999990463256...|</span><br><span class="line">|     8|   129682|[8.5,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   763027|[68.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   292027|[16.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   430023|[34.2000007629394...|</span><br><span class="line">|     8|   133457|[169.0,1.0,0.0,1....|</span><br><span class="line">|     8|   816999|[5.0,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   221714|[4.80000019073486...|</span><br><span class="line">|     8|   186334|[106.0,1.0,0.0,1....|</span><br><span class="line">|     8|   169717|[2.20000004768371...|</span><br><span class="line">|     8|    31314|[15.8000001907348...|</span><br><span class="line">|     8|   815312|[2.29999995231628...|</span><br><span class="line">|     8|   199445|[5.0,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   746178|[16.7999992370605...|</span><br><span class="line">|     8|   290950|[6.5,1.0,0.0,1.0,...|</span><br><span class="line">|     8|   221585|[18.5,1.0,0.0,1.0...|</span><br><span class="line">|     8|   692672|[47.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   797982|[33.0,1.0,0.0,1.0...|</span><br><span class="line">|     8|   815219|[2.40000009536743...|</span><br><span class="line">+------+---------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">prediction &#x3D; CTR_model.transform(datasets).sort(&quot;probability&quot;)</span><br><span class="line">prediction.show()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|userId|adgroupId|            features|       rawPrediction|         probability|prediction|</span><br><span class="line">+------+---------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|     8|   631204|[19888.0,1.0,0.0,...|[2.69001234046578...|[0.93643471623189...|       0.0|</span><br><span class="line">|     8|   583215|[3750.0,1.0,0.0,1...|[2.69016170680037...|[0.93644360664433...|       0.0|</span><br><span class="line">|     8|   275819|[3280.0,1.0,0.0,1...|[2.69016605691669...|[0.93644386554961...|       0.0|</span><br><span class="line">|     8|   401433|[1200.0,1.0,0.0,1...|[2.69018530849532...|[0.93644501133142...|       0.0|</span><br><span class="line">|     8|    29466|[640.0,1.0,0.0,1....|[2.69019049161265...|[0.93644531980785...|       0.0|</span><br><span class="line">|     8|   173327|[356.0,1.0,0.0,1....|[2.69019312019358...|[0.93644547624893...|       0.0|</span><br><span class="line">|     8|   241402|[269.0,1.0,0.0,1....|[2.69019392542787...|[0.93644552417271...|       0.0|</span><br><span class="line">|     8|   351366|[246.0,1.0,0.0,1....|[2.69019413830591...|[0.93644553684221...|       0.0|</span><br><span class="line">|     8|   229827|[238.0,1.0,0.0,1....|[2.69019421235044...|[0.93644554124900...|       0.0|</span><br><span class="line">|     8|   164807|[228.0,1.0,0.0,1....|[2.69019430490611...|[0.93644554675747...|       0.0|</span><br><span class="line">|     8|   227731|[199.0,1.0,0.0,1....|[2.69019457331754...|[0.93644556273205...|       0.0|</span><br><span class="line">|     8|   265403|[198.0,1.0,0.0,1....|[2.69019458257311...|[0.93644556328290...|       0.0|</span><br><span class="line">|     8|   569939|[188.0,1.0,0.0,1....|[2.69019467512877...|[0.93644556879138...|       0.0|</span><br><span class="line">|     8|   277335|[181.5,1.0,0.0,1....|[2.69019473528996...|[0.93644557237189...|       0.0|</span><br><span class="line">|     8|   575633|[180.0,1.0,0.0,1....|[2.69019474917331...|[0.93644557319816...|       0.0|</span><br><span class="line">|     8|   201867|[179.0,1.0,0.0,1....|[2.69019475842887...|[0.93644557374900...|       0.0|</span><br><span class="line">|     8|    25542|[176.0,1.0,0.0,1....|[2.69019478619557...|[0.93644557540155...|       0.0|</span><br><span class="line">|     8|   133457|[169.0,1.0,0.0,1....|[2.69019485098454...|[0.93644557925748...|       0.0|</span><br><span class="line">|     8|   494224|[169.0,1.0,0.0,1....|[2.69019485098454...|[0.93644557925748...|       0.0|</span><br><span class="line">|     8|   339382|[163.0,1.0,0.0,1....|[2.69019490651794...|[0.93644558256256...|       0.0|</span><br><span class="line">+------+---------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>TOP-20</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TOP-20</span></span><br><span class="line">prediction.select(<span class="string">&quot;adgroupId&quot;</span>).head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[Row(adgroupId=631204),</span><br><span class="line"> Row(adgroupId=583215),</span><br><span class="line"> Row(adgroupId=275819),</span><br><span class="line"> Row(adgroupId=401433),</span><br><span class="line"> Row(adgroupId=29466),</span><br><span class="line"> Row(adgroupId=173327),</span><br><span class="line"> Row(adgroupId=241402),</span><br><span class="line"> Row(adgroupId=351366),</span><br><span class="line"> Row(adgroupId=229827),</span><br><span class="line"> Row(adgroupId=164807),</span><br><span class="line"> Row(adgroupId=227731),</span><br><span class="line"> Row(adgroupId=265403),</span><br><span class="line"> Row(adgroupId=569939),</span><br><span class="line"> Row(adgroupId=277335),</span><br><span class="line"> Row(adgroupId=575633),</span><br><span class="line"> Row(adgroupId=201867),</span><br><span class="line"> Row(adgroupId=25542),</span><br><span class="line"> Row(adgroupId=133457),</span><br><span class="line"> Row(adgroupId=494224),</span><br><span class="line"> Row(adgroupId=339382)]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[i.adgroupId for i in prediction.select(&quot;adgroupId&quot;).head(20)]</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[631204,</span><br><span class="line"> 583215,</span><br><span class="line"> 275819,</span><br><span class="line"> 401433,</span><br><span class="line"> 29466,</span><br><span class="line"> 173327,</span><br><span class="line"> 241402,</span><br><span class="line"> 351366,</span><br><span class="line"> 229827,</span><br><span class="line"> 164807,</span><br><span class="line"> 227731,</span><br><span class="line"> 265403,</span><br><span class="line"> 569939,</span><br><span class="line"> 277335,</span><br><span class="line"> 575633,</span><br><span class="line"> 201867,</span><br><span class="line"> 25542,</span><br><span class="line"> 133457,</span><br><span class="line"> 494224,</span><br><span class="line"> 339382]</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="推荐服务"><a href="#推荐服务" class="headerlink" title="推荐服务"></a>推荐服务</h3><ul><li>离线推荐<ul><li>先召回对召回结果排序</li><li>为每一个用户都进行召回并排序的过程并且把拍好顺序的结果放到数据库中</li><li>如果需要推荐结果的时候 直接到数据库中按照user_id查询，返回推荐结果</li><li>优点 结构比较简单 推荐服务只需要不断计算，把结果保存到数据库中即可</li><li>缺点 实时性差 如果数据1天不更新 1天之内推荐结果一样的，不能反映用户的实时兴趣 </li></ul></li><li>实时推荐<ul><li>排序的模型加载好</li><li>召回阶段的结果缓存</li><li>所有用户的特征缓存</li><li>所有物品的特征缓存</li><li>把推荐的服务暴露出去（django flask) 需要推荐结果的服务把 用户id 传递过来<ul><li>根据id 找到召回结果</li><li>根据id 找到缓存的用户特征</li><li>根据召回结果的物品id 找到物品的特征</li><li>用户特征+物品特征-》逻辑回归模型 就可以预测点击率</li><li>所有召回的物品的点记率都预测并排序 推荐topN</li><li>实时通过LR模型进行排序的好处<ul><li>随时修改召回集</li><li>随时调整用户的特征</li><li>当用户需要推荐服务的时候，获取到最新的召回集和用户特征 得到最新的排序结果 更能体现出用户的实时兴趣</li></ul></li></ul></li></ul></li></ul><p>召回（群策群力）</p><ul><li>协同过滤</li><li>基于内容召回</li><li>基于流行度召回</li></ul><p>排序（根据自身特征和物品特征预估）</p><ul><li>LR CTR预估</li></ul><h3 id="SparkML-和SparkMLlib-区别"><a href="#SparkML-和SparkMLlib-区别" class="headerlink" title="SparkML 和SparkMLlib 区别"></a>SparkML 和SparkMLlib 区别</h3><ul><li>spark mllib 基于RDD<ul><li>数据准备 需要创建一个 基于LabeledPoint的RDD</li><li>LabeledPoint（目标，[特征]）</li><li>已经停止更新了 处于维护状态</li></ul></li><li>spark ML 基于dataframe<ul><li>数据准备 需要把所有的特征放到一列中 dataframe还需要有一列是 目标值</li><li>model = lr.setLabelCol(‘affairs’).setFeaturesCol(‘feautures’).fit(trainDF)</li><li>spark ML 与 sklearn更类似</li><li>最新的API放到 spark ML中的</li></ul></li></ul><h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><ul><li>分类特征<ul><li>把缺失作为单独的特征处理</li><li>算法预测</li></ul></li><li>连续的特征<ul><li>算法预测</li><li>平均值 默认值 中位数填充</li></ul></li></ul><h3 id="利用spark-处理-onehot"><a href="#利用spark-处理-onehot" class="headerlink" title="利用spark 处理 onehot"></a>利用spark 处理 onehot</h3><ul><li>稀疏向量 大部分维度上的值都是0 sparseVector (向量的维度,[非零元素的索引],[非零元素的值])</li><li>对应的API：stringindexer onehotEncoder pipline </li></ul><p>239146001</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;离线推荐数据缓存-amp-实时推荐&quot;&gt;&lt;a href=&quot;#离线推荐数据缓存-amp-实时推荐&quot; class=&quot;headerlink&quot; title=&quot;离线推荐数据缓存 &amp;amp; 实时推荐&quot;&gt;&lt;/a&gt;离线推荐数据缓存 &amp;amp; 实时推荐&lt;/h2&gt;&lt;h3 id=&quot;1</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>35-逻辑回归(LR)实现CTR预估</title>
    <link href="https://xxren8218.github.io/20210710/35-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-LR-%E5%AE%9E%E7%8E%B0CTR%E9%A2%84%E4%BC%B0.html"/>
    <id>https://xxren8218.github.io/20210710/35-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-LR-%E5%AE%9E%E7%8E%B0CTR%E9%A2%84%E4%BC%B0.html</id>
    <published>2021-07-10T14:49:27.000Z</published>
    <updated>2021-07-10T14:50:05.750Z</updated>
    
    <content type="html"><![CDATA[<h2 id="LR实现CTR预估"><a href="#LR实现CTR预估" class="headerlink" title="LR实现CTR预估"></a>LR实现CTR预估</h2><h3 id="1-Spark逻辑回归-LR-模型使用介绍"><a href="#1-Spark逻辑回归-LR-模型使用介绍" class="headerlink" title="1. Spark逻辑回归(LR)模型使用介绍"></a>1. Spark逻辑回归(LR)模型使用介绍</h3><ul><li>先通过小案例来看看逻辑回归的模型怎么处理。</li><li><code>pyspark.ml</code>需要准备<code>DataFrame</code>的数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本数据集</span></span><br><span class="line">sample_dataset = [</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">37</span>, <span class="number">10</span>, <span class="string">&quot;no&quot;</span>, <span class="number">3</span>, <span class="number">18</span>, <span class="number">7</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">4</span>, <span class="string">&quot;no&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">6</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">1</span>, <span class="number">12</span>, <span class="number">1</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">57</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">5</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">22</span>, <span class="number">0.75</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">6</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">0.75</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">12</span>, <span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">57</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">14</span>, <span class="number">4</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">16</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">22</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">37</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">20</span>, <span class="number">7</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">27</span>, <span class="number">4</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">47</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">5</span>, <span class="number">17</span>, <span class="number">6</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">4</span>, <span class="string">&quot;no&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">37</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">1</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">37</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">18</span>, <span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">0.75</span>, <span class="string">&quot;no&quot;</span>, <span class="number">3</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">22</span>, <span class="number">1.5</span>, <span class="string">&quot;no&quot;</span>, <span class="number">2</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">10</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">14</span>, <span class="number">1</span>, <span class="number">5</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;female&quot;</span>, <span class="number">32</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">3</span>, <span class="number">14</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;female&quot;</span>, <span class="number">27</span>, <span class="number">7</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">16</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">42</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">3</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;female&quot;</span>, <span class="number">42</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">14</span>, <span class="number">3</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">27</span>, <span class="number">7</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">17</span>, <span class="number">5</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">32</span>, <span class="number">10</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">4</span>, <span class="number">14</span>, <span class="number">4</span>, <span class="number">3</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">&quot;male&quot;</span>, <span class="number">47</span>, <span class="number">15</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">3</span>, <span class="number">16</span>, <span class="number">4</span>, <span class="number">2</span>),</span><br><span class="line">    (<span class="number">0</span>, <span class="string">&quot;male&quot;</span>, <span class="number">37</span>, <span class="number">4</span>, <span class="string">&quot;yes&quot;</span>, <span class="number">2</span>, <span class="number">20</span>, <span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">columns = [<span class="string">&quot;affairs&quot;</span>, <span class="string">&quot;gender&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;label&quot;</span>, <span class="string">&quot;children&quot;</span>, <span class="string">&quot;religiousness&quot;</span>, <span class="string">&quot;education&quot;</span>, <span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas构建dataframe，方便（若不用pd预先创建的话，写Spark的DataFrame的话，还得写Schema，是比较麻烦的。）</span></span><br><span class="line">pdf = pd.DataFrame(sample_dataset, columns=columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换成spark的dataframe</span></span><br><span class="line">df = spark.createDataFrame(pdf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征选取：affairs为目标值，其余为特征值</span></span><br><span class="line">df2 = df.select(<span class="string">&quot;affairs&quot;</span>,<span class="string">&quot;age&quot;</span>, <span class="string">&quot;religiousness&quot;</span>, <span class="string">&quot;education&quot;</span>, <span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;rating&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于计算特征向量的字段</span></span><br><span class="line">colArray2 = [<span class="string">&quot;age&quot;</span>, <span class="string">&quot;religiousness&quot;</span>, <span class="string">&quot;education&quot;</span>, <span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;rating&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算出特征向量(将特征向量放在一列里。)</span></span><br><span class="line">df3 = VectorAssembler().setInputCols(colArray2).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(df2)</span><br><span class="line">print(<span class="string">&quot;数据集：&quot;</span>)</span><br><span class="line">df3.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#  随机切分为训练集和测试集</span></span><br><span class="line">trainDF, testDF = df3.randomSplit([<span class="number">0.8</span>,<span class="number">0.2</span>])</span><br><span class="line">print(<span class="string">&quot;训练集：&quot;</span>)</span><br><span class="line">trainDF.show(<span class="number">10</span>)</span><br><span class="line">print(<span class="string">&quot;测试集：&quot;</span>)</span><br><span class="line">testDF.show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">数据集：</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|      0| 37|            3|       18|         7|     4|[37.0,3.0,18.0,7....|</span><br><span class="line">|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|</span><br><span class="line">|      0| 32|            1|       12|         1|     4|[32.0,1.0,12.0,1....|</span><br><span class="line">|      0| 57|            5|       18|         6|     5|[57.0,5.0,18.0,6....|</span><br><span class="line">|      0| 22|            2|       17|         6|     3|[22.0,2.0,17.0,6....|</span><br><span class="line">|      0| 32|            2|       17|         5|     5|[32.0,2.0,17.0,5....|</span><br><span class="line">|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|</span><br><span class="line">|      0| 57|            2|       14|         4|     4|[57.0,2.0,14.0,4....|</span><br><span class="line">|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|</span><br><span class="line">|      0| 22|            4|       14|         4|     5|[22.0,4.0,14.0,4....|</span><br><span class="line">|      0| 37|            2|       20|         7|     2|[37.0,2.0,20.0,7....|</span><br><span class="line">|      0| 27|            4|       18|         6|     4|[27.0,4.0,18.0,6....|</span><br><span class="line">|      0| 47|            5|       17|         6|     4|[47.0,5.0,17.0,6....|</span><br><span class="line">|      0| 22|            2|       17|         5|     4|[22.0,2.0,17.0,5....|</span><br><span class="line">|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|</span><br><span class="line">|      0| 37|            1|       17|         5|     5|[37.0,1.0,17.0,5....|</span><br><span class="line">|      0| 37|            2|       18|         4|     3|[37.0,2.0,18.0,4....|</span><br><span class="line">|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|</span><br><span class="line">|      0| 22|            2|       16|         5|     5|[22.0,2.0,16.0,5....|</span><br><span class="line">|      0| 27|            2|       14|         1|     5|[27.0,2.0,14.0,1....|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">训练集：</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|      0| 32|            1|       12|         1|     4|[32.0,1.0,12.0,1....|</span><br><span class="line">|      0| 37|            3|       18|         7|     4|[37.0,3.0,18.0,7....|</span><br><span class="line">|      0| 22|            2|       17|         6|     3|[22.0,2.0,17.0,6....|</span><br><span class="line">|      0| 32|            2|       17|         5|     5|[32.0,2.0,17.0,5....|</span><br><span class="line">|      0| 57|            5|       18|         6|     5|[57.0,5.0,18.0,6....|</span><br><span class="line">|      0| 57|            2|       14|         4|     4|[57.0,2.0,14.0,4....|</span><br><span class="line">|      0| 22|            2|       17|         5|     4|[22.0,2.0,17.0,5....|</span><br><span class="line">|      0| 22|            4|       14|         4|     5|[22.0,4.0,14.0,4....|</span><br><span class="line">|      0| 27|            4|       18|         6|     4|[27.0,4.0,18.0,6....|</span><br><span class="line">|      0| 37|            2|       20|         7|     2|[37.0,2.0,20.0,7....|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">测试集：</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br><span class="line">|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|</span><br><span class="line">|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|</span><br><span class="line">|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|</span><br><span class="line">|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|</span><br><span class="line">|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|</span><br><span class="line">|      1| 27|            4|       16|         1|     2|[27.0,4.0,16.0,1....|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+</span><br></pre></td></tr></table></figure><ul><li>逻辑回归训练模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment"># 创建逻辑回归训练器</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model = lr.setLabelCol(<span class="string">&quot;affairs&quot;</span>).setFeaturesCol(<span class="string">&quot;features&quot;</span>).fit(trainDF)</span><br><span class="line"><span class="comment"># 预测数据</span></span><br><span class="line">model.transform(testDF).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|affairs|age|religiousness|education|occupation|rating|            features|       rawPrediction|         probability|prediction|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+</span><br><span class="line">|      0| 27|            4|       14|         6|     4|[27.0,4.0,14.0,6....|[0.39067871041193...|[0.59644607432863...|       0.0|</span><br><span class="line">|      0| 22|            2|       12|         1|     3|[22.0,2.0,12.0,1....|[-2.6754687573263...|[0.06443650129497...|       1.0|</span><br><span class="line">|      0| 32|            4|       16|         1|     2|[32.0,4.0,16.0,1....|[-4.5240336812732...|[0.01072883305878...|       1.0|</span><br><span class="line">|      0| 27|            4|       14|         5|     4|[27.0,4.0,14.0,5....|[0.16206512668426...|[0.54042783360658...|       0.0|</span><br><span class="line">|      0| 22|            3|       16|         5|     4|[22.0,3.0,16.0,5....|[1.69102697292197...|[0.84435916906682...|       0.0|</span><br><span class="line">|      1| 27|            4|       16|         1|     2|[27.0,4.0,16.0,1....|[-4.7969907272012...|[0.00818697014985...|       1.0|</span><br><span class="line">+-------+---+-------------+---------+----------+------+--------------------+--------------------+--------------------+----------+</span><br></pre></td></tr></table></figure><h3 id="2-基于LR的点击率预测模型训练"><a href="#2-基于LR的点击率预测模型训练" class="headerlink" title="2. 基于LR的点击率预测模型训练"></a>2. 基于LR的点击率预测模型训练</h3><ul><li><p>本小节主要根据广告点击样本数据集(raw_sample)、广告基本特征数据集(ad_feature)、用户基本信息数据集(user_profile)构建出了一个完整的样本数据集，并按日期划分为了训练集(前七天)和测试集(最后一天)，利用逻辑回归进行训练。</p><p>训练模型时，通过对类别特征数据进行处理，一定程度达到提高了模型的效果</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;从HDFS中加载样本数据信息&#x27;&#x27;&#x27;</span></span><br><span class="line">_raw_sample_df1 = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/raw_sample.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># _raw_sample_df1.show()    # 展示数据，默认前20条</span></span><br><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType, LongType, StringType</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">_raw_sample_df2 = _raw_sample_df1.\</span><br><span class="line">    withColumn(<span class="string">&quot;user&quot;</span>, _raw_sample_df1.user.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;userId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;time_stamp&quot;</span>, _raw_sample_df1.time_stamp.cast(LongType())).withColumnRenamed(<span class="string">&quot;time_stamp&quot;</span>, <span class="string">&quot;timestamp&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, _raw_sample_df1.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;pid&quot;</span>, _raw_sample_df1.pid.cast(StringType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;nonclk&quot;</span>, _raw_sample_df1.nonclk.cast(IntegerType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;clk&quot;</span>, _raw_sample_df1.clk.cast(IntegerType()))</span><br><span class="line">_raw_sample_df2.printSchema()</span><br><span class="line">_raw_sample_df2.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本数据pid特征处理</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pid&#x27;</span>, outputCol=<span class="string">&#x27;pid_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pid_feature&#x27;</span>, outputCol=<span class="string">&#x27;pid_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(_raw_sample_df2)</span><br><span class="line">raw_sample_df = pipeline_fit.transform(_raw_sample_df2)</span><br><span class="line">raw_sample_df.show()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;pid和特征的对应关系</span></span><br><span class="line"><span class="string">430548_1007：0</span></span><br><span class="line"><span class="string">430549_1007：1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: integer (nullable = true)</span><br><span class="line"> |-- clk: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|pid_feature|    pid_value|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">&#x27;pid和特征的对应关系\n430548_1007：0\n430549_1007：1\n&#x27;</span><br></pre></td></tr></table></figure><ul><li>从HDFS中加载广告基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">_ad_feature_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串</span></span><br><span class="line">_ad_feature_df = _ad_feature_df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = _ad_feature_df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, _ad_feature_df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, _ad_feature_df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, _ad_feature_df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, _ad_feature_df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, _ad_feature_df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, _ad_feature_df.price.cast(FloatType()))</span><br><span class="line">ad_feature_df.printSchema()</span><br><span class="line">ad_feature_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- campaignId: integer (nullable = true)</span><br><span class="line"> |-- customerId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br><span class="line"> |-- price: float (nullable = true)</span><br><span class="line"></span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|price|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|    63133|  6406|     83237|         1|  95471|170.0|</span><br><span class="line">|   313401|  6406|     83237|         1|  87331|199.0|</span><br><span class="line">|   248909|   392|     83237|         1|  32233| 38.0|</span><br><span class="line">|   208458|   392|     83237|         1| 174374|139.0|</span><br><span class="line">|   110847|  7211|    135256|         2| 145952|32.99|</span><br><span class="line">|   607788|  6261|    387991|         6| 207800|199.0|</span><br><span class="line">|   375706|  4520|    387991|         6|     -1| 99.0|</span><br><span class="line">|    11115|  7213|    139747|         9| 186847| 33.0|</span><br><span class="line">|    24484|  7207|    139744|         9| 186847| 19.0|</span><br><span class="line">|    28589|  5953|    395195|        13|     -1|428.0|</span><br><span class="line">|    23236|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   300556|  5953|    395195|        13|     -1|639.0|</span><br><span class="line">|    92560|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   590965|  4284|     28145|        14| 454237|249.0|</span><br><span class="line">|   529913|  4284|     70206|        14|     -1|249.0|</span><br><span class="line">|   546930|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   639794|  6261|     70206|        14|  37004| 89.9|</span><br><span class="line">|   335413|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   794890|  4284|     70206|        14| 454237|249.0|</span><br><span class="line">|   684020|  6261|     70206|        14|  37004| 99.0|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>从HDFS加载用户基本信息数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建表结构schema对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_segid&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_group_id&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;final_gender_code&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;age_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pvalue_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;shopping_level&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;occupation&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;new_user_class_level&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 利用schema从hdfs加载</span></span><br><span class="line">_user_profile_df1 = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/user_profile.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line"><span class="comment"># user_profile_df.printSchema()</span></span><br><span class="line"><span class="comment"># user_profile_df.show()</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;对缺失数据进行特征热编码&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用热编码转换pvalue_level的一维数据为多维，增加n-1个虚拟变量，n为pvalue_level的取值范围</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要先将缺失值全部替换为数值，便于处理，否则会抛出异常</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line">_user_profile_df2 = _user_profile_df1.na.fill(-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># _user_profile_df2.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 热编码时，必须先将待处理字段转为字符串类型才可处理</span></span><br><span class="line">_user_profile_df3 = _user_profile_df2.withColumn(<span class="string">&quot;pvalue_level&quot;</span>, _user_profile_df2.pvalue_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;new_user_class_level&quot;</span>, _user_profile_df2.new_user_class_level.cast(StringType()))</span><br><span class="line"><span class="comment"># _user_profile_df3.printSchema()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对pvalue_level进行热编码，求值</span></span><br><span class="line"><span class="comment"># 运行过程是先将pvalue_level转换为一列新的特征数据，然后对该特征数据求出的热编码值，存在了新的一列数据中，类型为一个稀疏矩阵</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pvalue_level&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(_user_profile_df3)</span><br><span class="line">_user_profile_df4 = pipeline_fit.transform(_user_profile_df3)</span><br><span class="line"><span class="comment"># pl_onehot_value列的值为稀疏矩阵，存储热编码的结果</span></span><br><span class="line"><span class="comment"># _user_profile_df4.printSchema()</span></span><br><span class="line"><span class="comment"># _user_profile_df4.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用热编码转换new_user_class_level的一维数据为多维</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;new_user_class_level&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(_user_profile_df4)</span><br><span class="line">user_profile_df = pipeline_fit.transform(_user_profile_df4)</span><br><span class="line">user_profile_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|nucl_onehot_feature|nucl_onehot_value|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|                4.0|    (5,[4],[1.0])|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>热编码中：”pvalue_level”特征对应关系:</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+------------+----------------------+</span><br><span class="line">|pvalue_level|pl_onehot_feature     |</span><br><span class="line">+------------+----------------------+</span><br><span class="line">|          -1|                   0.0|</span><br><span class="line">|           3|                   3.0|</span><br><span class="line">|           1|                   2.0|</span><br><span class="line">|           2|                   1.0|</span><br><span class="line">+------------+----------------------+</span><br></pre></td></tr></table></figure><ul><li>“new_user_class_level”的特征对应关系</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+------------------------+</span><br><span class="line">|new_user_class_level|nucl_onehot_feature     |</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|                  -1|                     0.0|</span><br><span class="line">|                   3|                     2.0|</span><br><span class="line">|                   1|                     4.0|</span><br><span class="line">|                   4|                     3.0|</span><br><span class="line">|                   2|                     1.0|</span><br><span class="line">+--------------------+------------------------+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">user_profile_df.groupBy(<span class="string">&quot;pvalue_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;pl_onehot_feature&quot;</span>).show()</span><br><span class="line">user_profile_df.groupBy(<span class="string">&quot;new_user_class_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;nucl_onehot_feature&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">+------------+----------------------+</span><br><span class="line">|pvalue_level|min(pl_onehot_feature)|</span><br><span class="line">+------------+----------------------+</span><br><span class="line">|          -1|                   0.0|</span><br><span class="line">|           3|                   3.0|</span><br><span class="line">|           1|                   2.0|</span><br><span class="line">|           2|                   1.0|</span><br><span class="line">+------------+----------------------+</span><br><span class="line"></span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|new_user_class_level|min(nucl_onehot_feature)|</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line">|                  -1|                     0.0|</span><br><span class="line">|                   3|                     2.0|</span><br><span class="line">|                   1|                     4.0|</span><br><span class="line">|                   4|                     3.0|</span><br><span class="line">|                   2|                     1.0|</span><br><span class="line">+--------------------+------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>Dataframe数据合并：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=join#pyspark.sql.DataFrame.join">pyspark.sql.DataFrame.join</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># raw_sample_df 和 ad_feature_df 合并条件</span></span><br><span class="line">condition = [raw_sample_df.adgroupId==ad_feature_df.adgroupId]</span><br><span class="line">_ = raw_sample_df.join(ad_feature_df, condition, <span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># _和user_profile_df合并条件</span></span><br><span class="line">condition2 = [_.userId==user_profile_df.userId]</span><br><span class="line">datasets = _.join(user_profile_df, condition2, <span class="string">&quot;outer&quot;</span>)</span><br><span class="line"><span class="comment"># 查看datasets的结构</span></span><br><span class="line">datasets.printSchema()</span><br><span class="line"><span class="comment"># 查看datasets条目数</span></span><br><span class="line">print(datasets.count())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: integer (nullable = true)</span><br><span class="line"> |-- clk: integer (nullable = true)</span><br><span class="line"> |-- pid_feature: double (nullable = true)</span><br><span class="line"> |-- pid_value: vector (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- campaignId: integer (nullable = true)</span><br><span class="line"> |-- customerId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br><span class="line"> |-- price: float (nullable = true)</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: string (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: string (nullable = true)</span><br><span class="line"> |-- pl_onehot_feature: double (nullable = true)</span><br><span class="line"> |-- pl_onehot_value: vector (nullable = true)</span><br><span class="line"> |-- nucl_onehot_feature: double (nullable = true)</span><br><span class="line"> |-- nucl_onehot_value: vector (nullable = true)</span><br><span class="line"></span><br><span class="line">26557961</span><br></pre></td></tr></table></figure><ul><li>训练CTRModel_Normal：直接将对应的特征的特征值组合成对应的特征向量进行训练</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 剔除冗余、不需要的字段</span></span><br><span class="line">useful_cols = [</span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    <span class="comment"># 时间字段，划分训练集和测试集</span></span><br><span class="line">    <span class="string">&quot;timestamp&quot;</span>,</span><br><span class="line">    <span class="comment"># label目标值字段</span></span><br><span class="line">    <span class="string">&quot;clk&quot;</span>,  </span><br><span class="line">    <span class="comment"># 特征值字段</span></span><br><span class="line">    <span class="string">&quot;pid_value&quot;</span>,       <span class="comment"># 资源位的特征向量</span></span><br><span class="line">    <span class="string">&quot;price&quot;</span>,    <span class="comment"># 广告价格</span></span><br><span class="line">    <span class="string">&quot;cms_segid&quot;</span>,    <span class="comment"># 用户微群ID</span></span><br><span class="line">    <span class="string">&quot;cms_group_id&quot;</span>,    <span class="comment"># 用户组ID</span></span><br><span class="line">    <span class="string">&quot;final_gender_code&quot;</span>,    <span class="comment"># 用户性别特征，[1,2]</span></span><br><span class="line">    <span class="string">&quot;age_level&quot;</span>,    <span class="comment"># 年龄等级，1-</span></span><br><span class="line">    <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pl_onehot_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nucl_onehot_value&quot;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 筛选指定字段数据，构建新的数据集</span></span><br><span class="line">datasets_1 = datasets.select(*useful_cols)</span><br><span class="line"><span class="comment"># 由于前面使用的是outer方式合并的数据，产生了部分空值数据，这里必须先剔除掉</span></span><br><span class="line">datasets_1 = datasets_1.dropna()</span><br><span class="line">print(<span class="string">&quot;剔除空值数据后，还剩：&quot;</span>, datasets_1.count())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">剔除空值数据后，还剩： 25029435</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>根据特征字段计算出特征向量，并划分出训练数据集和测试数据集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="comment"># 根据特征字段计算特征向量（[2::]，前两个不要，后面的作为特征，具体看上面的结构）</span></span><br><span class="line">datasets_1 = VectorAssembler().setInputCols(useful_cols[<span class="number">2</span>:]).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(datasets_1)</span><br><span class="line"><span class="comment"># 训练数据集: 约7天的数据</span></span><br><span class="line">train_datasets_1 = datasets_1.<span class="built_in">filter</span>(datasets_1.timestamp&lt;=(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line"><span class="comment"># 测试数据集：约1天的数据量</span></span><br><span class="line">test_datasets_1 = datasets_1.<span class="built_in">filter</span>(datasets_1.timestamp&gt;(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line"><span class="comment"># 所有的特征的特征向量已经汇总到在features字段中</span></span><br><span class="line">train_datasets_1.show(<span class="number">5</span>)</span><br><span class="line">test_datasets_1.show(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">+----------+---+-------------+------+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">| timestamp|clk|    pid_value| price|cms_segid|cms_group_id|final_gender_code|age_level|shopping_level|occupation|pl_onehot_value|nucl_onehot_value|            features|</span><br><span class="line">+----------+---+-------------+------+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">|1494261938|  0|(2,[1],[1.0])| 108.0|        0|          11|                1|        5|             3|         0|  (4,[0],[1.0])|    (5,[1],[1.0])|(18,[1,2,4,5,6,7,...|</span><br><span class="line">|1494261938|  0|(2,[1],[1.0])|1880.0|        0|          11|                1|        5|             3|         0|  (4,[0],[1.0])|    (5,[1],[1.0])|(18,[1,2,4,5,6,7,...|</span><br><span class="line">|1494553913|  0|(2,[1],[1.0])|2360.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494553913|  0|(2,[1],[1.0])|2200.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494436784|  0|(2,[1],[1.0])|5649.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">+----------+---+-------------+------+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br><span class="line">+----------+---+-------------+-----+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">| timestamp|clk|    pid_value|price|cms_segid|cms_group_id|final_gender_code|age_level|shopping_level|occupation|pl_onehot_value|nucl_onehot_value|            features|</span><br><span class="line">+----------+---+-------------+-----+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">|1494677292|  0|(2,[1],[1.0])|176.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494677292|  0|(2,[1],[1.0])|698.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494677292|  0|(2,[1],[1.0])|697.0|       19|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[1],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494684007|  0|(2,[1],[1.0])|247.0|       18|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[4],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">|1494684007|  0|(2,[1],[1.0])|109.0|       18|           3|                2|        3|             3|         0|  (4,[1],[1.0])|    (5,[4],[1.0])|(18,[1,2,3,4,5,6,...|</span><br><span class="line">+----------+---+-------------+-----+---------+------------+-----------------+---------+--------------+----------+---------------+-----------------+--------------------+</span><br><span class="line">only showing top 5 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>创建逻辑回归训练器，并训练模型：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=logisticregression#pyspark.ml.classification.LogisticRegression">LogisticRegression</a>、 <a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=logisticregression#pyspark.ml.classification.LogisticRegressionModel">LogisticRegressionModel</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line"><span class="comment"># 设置目标字段、特征值字段并训练</span></span><br><span class="line">model = lr.setLabelCol(<span class="string">&quot;clk&quot;</span>).setFeaturesCol(<span class="string">&quot;features&quot;</span>).fit(train_datasets_1)</span><br><span class="line"><span class="comment"># 对模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_Normal.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 载入训练好的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegressionModel</span><br><span class="line">model = LogisticRegressionModel.load(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_Normal.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 根据测试数据进行预测（默认按照预测概率的50%进行划分的。所以预测都是0）</span></span><br><span class="line">result_1 = model.transform(test_datasets_1)</span><br><span class="line"><span class="comment"># 按probability升序排列数据，probability表示预测结果的概率</span></span><br><span class="line"><span class="comment"># 如果预测值是0，其概率是0.9248，那么反之可推出1的可能性就是1-0.9248=0.0752，即点击概率约为7.52%</span></span><br><span class="line"><span class="comment"># 因为前面提到广告的点击率一般都比较低，所以预测值通常都是0，因此通常需要反减得出点击的概率</span></span><br><span class="line">result_1.select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  0|      1.0E8|[0.86822033939259...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.88410457194969...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.89175497837562...|       0.0|</span><br><span class="line">|  1|5.5555556E7|[0.92481456486873...|       0.0|</span><br><span class="line">|  0|      1.5E7|[0.93741450446939...|       0.0|</span><br><span class="line">|  0|      1.5E7|[0.93757135079959...|       0.0|</span><br><span class="line">|  0|      1.5E7|[0.93834723093801...|       0.0|</span><br><span class="line">|  0|     1099.0|[0.93972095713786...|       0.0|</span><br><span class="line">|  0|      338.0|[0.93972134993018...|       0.0|</span><br><span class="line">|  0|      311.0|[0.93972136386626...|       0.0|</span><br><span class="line">|  0|      300.0|[0.93972136954393...|       0.0|</span><br><span class="line">|  0|      278.0|[0.93972138089925...|       0.0|</span><br><span class="line">|  0|      188.0|[0.93972142735283...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93972143354663...|       0.0|</span><br><span class="line">|  0|      168.0|[0.93972143767584...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93972144283734...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93972145316035...|       0.0|</span><br><span class="line">|  0|      125.0|[0.93972145987031...|       0.0|</span><br><span class="line">|  0|      119.0|[0.93972146296721...|       0.0|</span><br><span class="line">|  0|       78.0|[0.93972148412937...|       0.0|</span><br><span class="line">|  0|      59.98|[0.93972149343040...|       0.0|</span><br><span class="line">|  0|       58.0|[0.93972149445238...|       0.0|</span><br><span class="line">|  0|       56.0|[0.93972149548468...|       0.0|</span><br><span class="line">|  0|       38.0|[0.93972150477538...|       0.0|</span><br><span class="line">|  1|       35.0|[0.93972150632383...|       0.0|</span><br><span class="line">|  0|       33.0|[0.93972150735613...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93972150890458...|       0.0|</span><br><span class="line">|  0|       27.6|[0.93972151014334...|       0.0|</span><br><span class="line">|  0|       18.0|[0.93972151509838...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93980311191464...|       0.0|</span><br><span class="line">|  0|       28.0|[0.93980311294563...|       0.0|</span><br><span class="line">|  0|       25.0|[0.93980311449212...|       0.0|</span><br><span class="line">|  0|      688.0|[0.93999362023323...|       0.0|</span><br><span class="line">|  0|      339.0|[0.93999379960808...|       0.0|</span><br><span class="line">|  0|      335.0|[0.93999380166395...|       0.0|</span><br><span class="line">|  0|      220.0|[0.93999386077017...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93999388338470...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93999389263610...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93999389263610...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93999389726180...|       0.0|</span><br><span class="line">|  0|      122.5|[0.93999391088191...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93999392296012...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93999392861375...|       0.0|</span><br><span class="line">|  0|       79.0|[0.93999393323945...|       0.0|</span><br><span class="line">|  0|       75.0|[0.93999393529532...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93999393889308...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93999393889308...|       0.0|</span><br><span class="line">|  0|       59.9|[0.93999394305620...|       0.0|</span><br><span class="line">|  0|      44.98|[0.93999395072458...|       0.0|</span><br><span class="line">|  0|       35.5|[0.93999395559698...|       0.0|</span><br><span class="line">|  0|       33.0|[0.93999395688189...|       0.0|</span><br><span class="line">|  0|       32.8|[0.93999395698469...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93999395842379...|       0.0|</span><br><span class="line">|  0|       28.0|[0.93999395945172...|       0.0|</span><br><span class="line">|  0|       19.9|[0.93999396361485...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93999396366625...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93999396366625...|       0.0|</span><br><span class="line">|  0|       12.0|[0.93999396767518...|       0.0|</span><br><span class="line">|  0|        6.7|[0.93999397039920...|       0.0|</span><br><span class="line">|  0|      568.0|[0.94000369247841...|       0.0|</span><br><span class="line">|  0|      398.0|[0.94000377983931...|       0.0|</span><br><span class="line">|  0|      158.0|[0.94000390317214...|       0.0|</span><br><span class="line">|  0|     5718.0|[0.94001886593718...|       0.0|</span><br><span class="line">|  0|     5718.0|[0.94001886593718...|       0.0|</span><br><span class="line">|  1|     5608.0|[0.94001892245145...|       0.0|</span><br><span class="line">|  0|     4120.0|[0.94001968693052...|       0.0|</span><br><span class="line">|  0|     1027.5|[0.94002127571285...|       0.0|</span><br><span class="line">|  0|     1027.5|[0.94002127571285...|       0.0|</span><br><span class="line">|  0|      989.0|[0.94002129549211...|       0.0|</span><br><span class="line">|  0|      672.0|[0.94002145834965...|       0.0|</span><br><span class="line">|  0|      660.0|[0.94002146451460...|       0.0|</span><br><span class="line">|  0|      598.0|[0.94002149636681...|       0.0|</span><br><span class="line">|  0|      598.0|[0.94002149636681...|       0.0|</span><br><span class="line">|  0|      563.0|[0.94002151434789...|       0.0|</span><br><span class="line">|  0|      509.0|[0.94002154209012...|       0.0|</span><br><span class="line">|  0|      509.0|[0.94002154209012...|       0.0|</span><br><span class="line">|  0|      500.0|[0.94002154671382...|       0.0|</span><br><span class="line">|  0|      498.0|[0.94002154774131...|       0.0|</span><br><span class="line">|  0|      440.0|[0.94002157753851...|       0.0|</span><br><span class="line">|  0|      430.0|[0.94002158267595...|       0.0|</span><br><span class="line">|  0|      388.0|[0.94002160425322...|       0.0|</span><br><span class="line">|  0|      369.0|[0.94002161401436...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      368.0|[0.94002161452811...|       0.0|</span><br><span class="line">|  0|      366.0|[0.94002161555560...|       0.0|</span><br><span class="line">|  0|      366.0|[0.94002161555560...|       0.0|</span><br><span class="line">|  0|      348.0|[0.94002162480299...|       0.0|</span><br><span class="line">|  0|      299.0|[0.94002164997645...|       0.0|</span><br><span class="line">|  0|      299.0|[0.94002164997645...|       0.0|</span><br><span class="line">|  0|      299.0|[0.94002164997645...|       0.0|</span><br><span class="line">|  0|      298.0|[0.94002165049020...|       0.0|</span><br><span class="line">|  0|      297.0|[0.94002165100394...|       0.0|</span><br><span class="line">|  0|      278.0|[0.94002166076508...|       0.0|</span><br><span class="line">|  1|      275.0|[0.94002166230631...|       0.0|</span><br><span class="line">|  0|      275.0|[0.94002166230631...|       0.0|</span><br><span class="line">|  0|      273.0|[0.94002166333380...|       0.0|</span><br><span class="line">|  0|      258.0|[0.94002167103995...|       0.0|</span><br><span class="line">|  0|      256.0|[0.94002167206744...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br></pre></td></tr></table></figure><ul><li>查看样本中点击的被实际点击的条目的预测情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result_1.<span class="built_in">filter</span>(result_1.clk==<span class="number">1</span>).select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  1|5.5555556E7|[0.92481456486873...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93972145316035...|       0.0|</span><br><span class="line">|  1|       35.0|[0.93972150632383...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93999389726180...|       0.0|</span><br><span class="line">|  1|     5608.0|[0.94001892245145...|       0.0|</span><br><span class="line">|  1|      275.0|[0.94002166230631...|       0.0|</span><br><span class="line">|  1|       35.0|[0.94002178560473...|       0.0|</span><br><span class="line">|  1|       49.0|[0.94004219516957...|       0.0|</span><br><span class="line">|  1|      915.0|[0.94021082858784...|       0.0|</span><br><span class="line">|  1|      598.0|[0.94021099096349...|       0.0|</span><br><span class="line">|  1|      568.0|[0.94021100633025...|       0.0|</span><br><span class="line">|  1|      398.0|[0.94021109340848...|       0.0|</span><br><span class="line">|  1|      368.0|[0.94021110877521...|       0.0|</span><br><span class="line">|  1|      299.0|[0.94021114411869...|       0.0|</span><br><span class="line">|  1|      278.0|[0.94021115487539...|       0.0|</span><br><span class="line">|  1|      259.0|[0.94021116460765...|       0.0|</span><br><span class="line">|  1|      258.0|[0.94021116511987...|       0.0|</span><br><span class="line">|  1|      258.0|[0.94021116511987...|       0.0|</span><br><span class="line">|  1|      258.0|[0.94021116511987...|       0.0|</span><br><span class="line">|  1|      195.0|[0.94021119738998...|       0.0|</span><br><span class="line">|  1|      188.0|[0.94021120097554...|       0.0|</span><br><span class="line">|  1|      178.0|[0.94021120609778...|       0.0|</span><br><span class="line">|  1|      159.0|[0.94021121583003...|       0.0|</span><br><span class="line">|  1|      149.0|[0.94021122095226...|       0.0|</span><br><span class="line">|  1|      138.0|[0.94021122658672...|       0.0|</span><br><span class="line">|  1|       58.0|[0.94021126756458...|       0.0|</span><br><span class="line">|  1|       49.0|[0.94021127217459...|       0.0|</span><br><span class="line">|  1|       35.0|[0.94021127934572...|       0.0|</span><br><span class="line">|  1|       25.0|[0.94021128446795...|       0.0|</span><br><span class="line">|  1|     2890.0|[0.94028789742257...|       0.0|</span><br><span class="line">|  1|      220.0|[0.94028926340218...|       0.0|</span><br><span class="line">|  1|      188.0|[0.94031410659516...|       0.0|</span><br><span class="line">|  1|       68.0|[0.94031416796289...|       0.0|</span><br><span class="line">|  1|       58.0|[0.94031417307687...|       0.0|</span><br><span class="line">|  1|      198.0|[0.94035413548387...|       0.0|</span><br><span class="line">|  1|      208.0|[0.94039204931181...|       0.0|</span><br><span class="line">|  1|     8888.0|[0.94045237642030...|       0.0|</span><br><span class="line">|  1|      519.0|[0.94045664687995...|       0.0|</span><br><span class="line">|  1|      478.0|[0.94045666780037...|       0.0|</span><br><span class="line">|  1|      349.0|[0.94045673362308...|       0.0|</span><br><span class="line">|  1|      348.0|[0.94045673413334...|       0.0|</span><br><span class="line">|  1|      316.0|[0.94045675046144...|       0.0|</span><br><span class="line">|  1|      298.0|[0.94045675964600...|       0.0|</span><br><span class="line">|  1|      298.0|[0.94045675964600...|       0.0|</span><br><span class="line">|  1|      199.0|[0.94045681016104...|       0.0|</span><br><span class="line">|  1|      199.0|[0.94045681016104...|       0.0|</span><br><span class="line">|  1|      198.0|[0.94045681067129...|       0.0|</span><br><span class="line">|  1|      187.1|[0.94045681623305...|       0.0|</span><br><span class="line">|  1|      176.0|[0.94045682189685...|       0.0|</span><br><span class="line">|  1|      168.0|[0.94045682597887...|       0.0|</span><br><span class="line">|  1|      160.0|[0.94045683006090...|       0.0|</span><br><span class="line">|  1|      158.0|[0.94045683108140...|       0.0|</span><br><span class="line">|  1|      158.0|[0.94045683108140...|       0.0|</span><br><span class="line">|  1|      135.0|[0.94045684281721...|       0.0|</span><br><span class="line">|  1|      129.0|[0.94045684587872...|       0.0|</span><br><span class="line">|  1|      127.0|[0.94045684689923...|       0.0|</span><br><span class="line">|  1|      125.0|[0.94045684791973...|       0.0|</span><br><span class="line">|  1|      124.0|[0.94045684842999...|       0.0|</span><br><span class="line">|  1|      118.0|[0.94045685149150...|       0.0|</span><br><span class="line">|  1|      109.0|[0.94045685608377...|       0.0|</span><br><span class="line">|  1|      108.0|[0.94045685659402...|       0.0|</span><br><span class="line">|  1|       99.0|[0.94045686118630...|       0.0|</span><br><span class="line">|  1|       98.0|[0.94045686169655...|       0.0|</span><br><span class="line">|  1|       79.8|[0.94045687098314...|       0.0|</span><br><span class="line">|  1|       79.0|[0.94045687139134...|       0.0|</span><br><span class="line">|  1|       77.0|[0.94045687241185...|       0.0|</span><br><span class="line">|  1|       72.5|[0.94045687470798...|       0.0|</span><br><span class="line">|  1|       69.0|[0.94045687649386...|       0.0|</span><br><span class="line">|  1|       68.0|[0.94045687700412...|       0.0|</span><br><span class="line">|  1|       60.0|[0.94045688108613...|       0.0|</span><br><span class="line">|  1|      43.98|[0.94045688926037...|       0.0|</span><br><span class="line">|  1|       40.0|[0.94045689129118...|       0.0|</span><br><span class="line">|  1|       39.9|[0.94045689134220...|       0.0|</span><br><span class="line">|  1|       39.6|[0.94045689149528...|       0.0|</span><br><span class="line">|  1|       32.0|[0.94045689537319...|       0.0|</span><br><span class="line">|  1|       31.0|[0.94045689588345...|       0.0|</span><br><span class="line">|  1|      25.98|[0.94045689844491...|       0.0|</span><br><span class="line">|  1|       23.0|[0.94045689996546...|       0.0|</span><br><span class="line">|  1|       19.0|[0.94045690200647...|       0.0|</span><br><span class="line">|  1|       16.9|[0.94045690307800...|       0.0|</span><br><span class="line">|  1|       10.0|[0.94045690659874...|       0.0|</span><br><span class="line">|  1|        3.5|[0.94045690991538...|       0.0|</span><br><span class="line">|  1|        3.5|[0.94045690991538...|       0.0|</span><br><span class="line">|  1|        0.4|[0.94045691149716...|       0.0|</span><br><span class="line">|  1|     3960.0|[0.94055740378069...|       0.0|</span><br><span class="line">|  1|     3088.0|[0.94055784801535...|       0.0|</span><br><span class="line">|  1|     1689.0|[0.94055856072019...|       0.0|</span><br><span class="line">|  1|      998.0|[0.94055891273943...|       0.0|</span><br><span class="line">|  1|      888.0|[0.94055896877705...|       0.0|</span><br><span class="line">|  1|      788.0|[0.94055901972029...|       0.0|</span><br><span class="line">|  1|      737.0|[0.94055904570133...|       0.0|</span><br><span class="line">|  1|      629.0|[0.94055910071996...|       0.0|</span><br><span class="line">|  1|      599.0|[0.94055911600291...|       0.0|</span><br><span class="line">|  1|      599.0|[0.94055911600291...|       0.0|</span><br><span class="line">|  1|      599.0|[0.94055911600291...|       0.0|</span><br><span class="line">|  1|      499.0|[0.94055916694603...|       0.0|</span><br><span class="line">|  1|      468.0|[0.94055918273839...|       0.0|</span><br><span class="line">|  1|      459.0|[0.94055918732327...|       0.0|</span><br><span class="line">|  1|      399.0|[0.94055921788912...|       0.0|</span><br><span class="line">|  1|      399.0|[0.94055921788912...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>训练CTRModel_AllOneHot</p><ul><li>“pid_value”, 类别型特征，已被转换为多维特征==&gt; 2维</li><li>“price”, 统计型特征 ===&gt; 1维</li><li>“cms_segid”, 类别型特征，约97个分类 ===&gt; 1维</li><li>“cms_group_id”, 类别型特征，约13个分类 ==&gt; 1维</li><li>“final_gender_code”, 类别型特征，2个分类 ==&gt; 1维</li><li>“age_level”, 类别型特征，7个分类 ==&gt; 1维</li><li>“shopping_level”, 类别型特征，3个分类 ==&gt; 1维</li><li>“occupation”, 类别型特征，2个分类 ==&gt; 1维</li><li>“pl_onehot_value”, 类别型特征，已被转换为多维特征 ==&gt; 4维</li><li>“nucl_onehot_value” 类别型特征，已被转换为多维特征 ==&gt; 5维</li></ul><p>类别性特征都可以考虑进行热独编码，将单一变量变为多变量，相当于增加了相关特征的数量</p><ul><li>“cms_segid”, 类别型特征，约97个分类 ===&gt; 97维 舍弃</li><li>“cms_group_id”, 类别型特征，约13个分类 ==&gt; 13维</li><li>“final_gender_code”, 类别型特征，2个分类 ==&gt; 2维</li><li>“age_level”, 类别型特征，7个分类 ==&gt;7维</li><li>“shopping_level”, 类别型特征，3个分类 ==&gt; 3维</li><li>“occupation”, 类别型特征，2个分类 ==&gt; 2维</li></ul><p>但由于cms_segid分类过多，这里考虑舍弃，避免数据过于稀疏</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets_1.first()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">datasets_1.first()</span><br><span class="line">datasets_1.first()</span><br><span class="line">Row(timestamp=1494261938, clk=0, pid_value=SparseVector(2, &#123;1: 1.0&#125;), price=1880.0, cms_segid=0, cms_group_id=11, final_gender_code=1, age_level=5, shopping_level=3, occupation=0, pl_onehot_value=SparseVector(4, &#123;0: 1.0&#125;), nucl_onehot_value=SparseVector(5, &#123;1: 1.0&#125;), features=SparseVector(18, &#123;1: 1.0, 2: 1880.0, 4: 11.0, 5: 1.0, 6: 5.0, 7: 3.0, 9: 1.0, 14: 1.0&#125;))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先将下列五列数据转为字符串类型，以便于进行热独编码</span></span><br><span class="line"><span class="comment"># - &quot;cms_group_id&quot;,   类别型特征，约13个分类 ==&gt; 13</span></span><br><span class="line"><span class="comment"># - &quot;final_gender_code&quot;, 类别型特征，2个分类 ==&gt; 2</span></span><br><span class="line"><span class="comment"># - &quot;age_level&quot;,    类别型特征，7个分类 ==&gt;7</span></span><br><span class="line"><span class="comment"># - &quot;shopping_level&quot;,    类别型特征，3个分类 ==&gt; 3</span></span><br><span class="line"><span class="comment"># - &quot;occupation&quot;,    类别型特征，2个分类 ==&gt; 2</span></span><br><span class="line"></span><br><span class="line">datasets_2 = datasets.withColumn(<span class="string">&quot;cms_group_id&quot;</span>, datasets.cms_group_id.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;final_gender_code&quot;</span>, datasets.final_gender_code.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;age_level&quot;</span>, datasets.age_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;shopping_level&quot;</span>, datasets.shopping_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;occupation&quot;</span>, datasets.occupation.cast(StringType()))</span><br><span class="line">useful_cols_2 = [</span><br><span class="line">    <span class="comment"># 时间值，划分训练集和测试集</span></span><br><span class="line">    <span class="string">&quot;timestamp&quot;</span>,</span><br><span class="line">    <span class="comment"># label目标值</span></span><br><span class="line">    <span class="string">&quot;clk&quot;</span>,  </span><br><span class="line">    <span class="comment"># 特征值</span></span><br><span class="line">    <span class="string">&quot;price&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cms_group_id&quot;</span>,</span><br><span class="line">    <span class="string">&quot;final_gender_code&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pid_value&quot;</span>, </span><br><span class="line">    <span class="string">&quot;pl_onehot_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nucl_onehot_value&quot;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 筛选指定字段数据</span></span><br><span class="line">datasets_2 = datasets_2.select(*useful_cols_2)</span><br><span class="line"><span class="comment"># 由于前面使用的是outer方式合并的数据，产生了部分空值数据，这里必须先剔除掉</span></span><br><span class="line">datasets_2 = datasets_2.dropna()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="comment"># 热编码处理函数封装</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">oneHotEncoder</span>(<span class="params">col1, col2, col3, data</span>):</span></span><br><span class="line">    stringindexer = StringIndexer(inputCol=col1, outputCol=col2)</span><br><span class="line">    encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=col2, outputCol=col3)</span><br><span class="line">    pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">    pipeline_fit = pipeline.fit(data)</span><br><span class="line">    <span class="keyword">return</span> pipeline_fit.transform(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对这五个字段进行热独编码</span></span><br><span class="line"><span class="comment">#     &quot;cms_group_id&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;final_gender_code&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;age_level&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;shopping_level&quot;,</span></span><br><span class="line"><span class="comment">#     &quot;occupation&quot;,</span></span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;cms_group_id&quot;</span>, <span class="string">&quot;cms_group_id_feature&quot;</span>, <span class="string">&quot;cms_group_id_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;final_gender_code&quot;</span>, <span class="string">&quot;final_gender_code_feature&quot;</span>, <span class="string">&quot;final_gender_code_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;age_level&quot;</span>, <span class="string">&quot;age_level_feature&quot;</span>, <span class="string">&quot;age_level_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;shopping_level&quot;</span>, <span class="string">&quot;shopping_level_feature&quot;</span>, <span class="string">&quot;shopping_level_value&quot;</span>, datasets_2)</span><br><span class="line">datasets_2 = oneHotEncoder(<span class="string">&quot;occupation&quot;</span>, <span class="string">&quot;occupation_feature&quot;</span>, <span class="string">&quot;occupation_value&quot;</span>, datasets_2)</span><br></pre></td></tr></table></figure><ul><li>“cms_group_id”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">+------------+-------------------------+</span><br><span class="line">|cms_group_id|min(cms_group_id_feature)|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line">|           7|                      9.0|</span><br><span class="line">|          11|                      6.0|</span><br><span class="line">|           3|                      0.0|</span><br><span class="line">|           8|                      8.0|</span><br><span class="line">|           0|                     12.0|</span><br><span class="line">|           5|                      3.0|</span><br><span class="line">|           6|                     10.0|</span><br><span class="line">|           9|                      5.0|</span><br><span class="line">|           1|                      7.0|</span><br><span class="line">|          10|                      4.0|</span><br><span class="line">|           4|                      1.0|</span><br><span class="line">|          12|                     11.0|</span><br><span class="line">|           2|                      2.0|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“final_gender_code”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+-----------------+------------------------------+</span><br><span class="line">|final_gender_code|min(final_gender_code_feature)|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|                1|                           1.0|</span><br><span class="line">|                2|                           0.0|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“age_level”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+---------+----------------------+</span><br><span class="line">|age_level|min(age_level_feature)|</span><br><span class="line">+---------+----------------------+</span><br><span class="line">|        3|                   0.0|</span><br><span class="line">|        0|                   6.0|</span><br><span class="line">|        5|                   2.0|</span><br><span class="line">|        6|                   5.0|</span><br><span class="line">|        1|                   4.0|</span><br><span class="line">|        4|                   1.0|</span><br><span class="line">|        2|                   3.0|</span><br><span class="line">+---------+----------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“shopping_level”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">|shopping_level|min(shopping_level_feature)|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|             3|                        0.0|</span><br><span class="line">|             1|                        2.0|</span><br><span class="line">|             2|                        1.0|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>“occupation”特征对应关系：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+----------+-----------------------+</span><br><span class="line">|occupation|min(occupation_feature)|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|         0|                    0.0|</span><br><span class="line">|         1|                    1.0|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">datasets_2.groupBy(<span class="string">&quot;cms_group_id&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;cms_group_id_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;final_gender_code&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;final_gender_code_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;age_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;age_level_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;shopping_level&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;shopping_level_feature&quot;</span>).show()</span><br><span class="line">datasets_2.groupBy(<span class="string">&quot;occupation&quot;</span>).<span class="built_in">min</span>(<span class="string">&quot;occupation_feature&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">+------------+-------------------------+</span><br><span class="line">|cms_group_id|min(cms_group_id_feature)|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line">|           7|                      9.0|</span><br><span class="line">|          11|                      6.0|</span><br><span class="line">|           3|                      0.0|</span><br><span class="line">|           8|                      8.0|</span><br><span class="line">|           0|                     12.0|</span><br><span class="line">|           5|                      3.0|</span><br><span class="line">|           6|                     10.0|</span><br><span class="line">|           9|                      5.0|</span><br><span class="line">|           1|                      7.0|</span><br><span class="line">|          10|                      4.0|</span><br><span class="line">|           4|                      1.0|</span><br><span class="line">|          12|                     11.0|</span><br><span class="line">|           2|                      2.0|</span><br><span class="line">+------------+-------------------------+</span><br><span class="line"></span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|final_gender_code|min(final_gender_code_feature)|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line">|                1|                           1.0|</span><br><span class="line">|                2|                           0.0|</span><br><span class="line">+-----------------+------------------------------+</span><br><span class="line"></span><br><span class="line">+---------+----------------------+</span><br><span class="line">|age_level|min(age_level_feature)|</span><br><span class="line">+---------+----------------------+</span><br><span class="line">|        3|                   0.0|</span><br><span class="line">|        0|                   6.0|</span><br><span class="line">|        5|                   2.0|</span><br><span class="line">|        6|                   5.0|</span><br><span class="line">|        1|                   4.0|</span><br><span class="line">|        4|                   1.0|</span><br><span class="line">|        2|                   3.0|</span><br><span class="line">+---------+----------------------+</span><br><span class="line"></span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|shopping_level|min(shopping_level_feature)|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line">|             3|                        0.0|</span><br><span class="line">|             1|                        2.0|</span><br><span class="line">|             2|                        1.0|</span><br><span class="line">+--------------+---------------------------+</span><br><span class="line"></span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|occupation|min(occupation_feature)|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line">|         0|                    0.0|</span><br><span class="line">|         1|                    1.0|</span><br><span class="line">+----------+-----------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于热独编码后，特征字段不再是之前的字段，重新定义特征值字段</span></span><br><span class="line">feature_cols = [</span><br><span class="line">    <span class="comment"># 特征值</span></span><br><span class="line">    <span class="string">&quot;price&quot;</span>,</span><br><span class="line">    <span class="string">&quot;cms_group_id_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;final_gender_code_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age_level_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;shopping_level_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pid_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pl_onehot_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nucl_onehot_value&quot;</span></span><br><span class="line">]</span><br><span class="line"><span class="comment"># 根据特征字段计算出特征向量，并划分出训练数据集和测试数据集</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line">datasets_2 = VectorAssembler().setInputCols(feature_cols).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(datasets_2)</span><br><span class="line">train_datasets_2 = datasets_2.<span class="built_in">filter</span>(datasets_2.timestamp&lt;=(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line">test_datasets_2 = datasets_2.<span class="built_in">filter</span>(datasets_2.timestamp&gt;(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line">train_datasets_2.printSchema()</span><br><span class="line">train_datasets_2.first()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- timestamp: long (nullable &#x3D; true)</span><br><span class="line"> |-- clk: integer (nullable &#x3D; true)</span><br><span class="line"> |-- price: float (nullable &#x3D; true)</span><br><span class="line"> |-- cms_group_id: string (nullable &#x3D; true)</span><br><span class="line"> |-- final_gender_code: string (nullable &#x3D; true)</span><br><span class="line"> |-- age_level: string (nullable &#x3D; true)</span><br><span class="line"> |-- shopping_level: string (nullable &#x3D; true)</span><br><span class="line"> |-- occupation: string (nullable &#x3D; true)</span><br><span class="line"> |-- pid_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- pl_onehot_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- nucl_onehot_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- cms_group_id_feature: double (nullable &#x3D; false)</span><br><span class="line"> |-- cms_group_id_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- final_gender_code_feature: double (nullable &#x3D; false)</span><br><span class="line"> |-- final_gender_code_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- age_level_feature: double (nullable &#x3D; false)</span><br><span class="line"> |-- age_level_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- shopping_level_feature: double (nullable &#x3D; false)</span><br><span class="line"> |-- shopping_level_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- occupation_feature: double (nullable &#x3D; false)</span><br><span class="line"> |-- occupation_value: vector (nullable &#x3D; true)</span><br><span class="line"> |-- features: vector (nullable &#x3D; true)</span><br><span class="line"></span><br><span class="line">Row(timestamp&#x3D;1494261938, clk&#x3D;0, price&#x3D;108.0, cms_group_id&#x3D;&#39;11&#39;, final_gender_code&#x3D;&#39;1&#39;, age_level&#x3D;&#39;5&#39;, shopping_level&#x3D;&#39;3&#39;, occupation&#x3D;&#39;0&#39;, pid_value&#x3D;SparseVector(2, &#123;1: 1.0&#125;), pl_onehot_value&#x3D;SparseVector(4, &#123;0: 1.0&#125;), nucl_onehot_value&#x3D;SparseVector(5, &#123;1: 1.0&#125;), cms_group_id_feature&#x3D;6.0, cms_group_id_value&#x3D;SparseVector(13, &#123;6: 1.0&#125;), final_gender_code_feature&#x3D;1.0, final_gender_code_value&#x3D;SparseVector(2, &#123;1: 1.0&#125;), age_level_feature&#x3D;2.0, age_level_value&#x3D;SparseVector(7, &#123;2: 1.0&#125;), shopping_level_feature&#x3D;0.0, shopping_level_value&#x3D;SparseVector(3, &#123;0: 1.0&#125;), occupation_feature&#x3D;0.0, occupation_value&#x3D;SparseVector(2, &#123;0: 1.0&#125;), features&#x3D;SparseVector(39, &#123;0: 108.0, 7: 1.0, 15: 1.0, 18: 1.0, 23: 1.0, 26: 1.0, 29: 1.0, 30: 1.0, 35: 1.0&#125;))</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>创建逻辑回归训练器，并训练模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr2 = LogisticRegression()</span><br><span class="line"><span class="comment">#设置目标值对应的列   setFeaturesCol 设置特征值对应的列名</span></span><br><span class="line">model2 = lr2.setLabelCol(<span class="string">&quot;clk&quot;</span>).setFeaturesCol(<span class="string">&quot;features&quot;</span>).fit(train_datasets_2)</span><br><span class="line"><span class="comment"># 存储模型</span></span><br><span class="line">model2.save(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_AllOneHot.obj&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegressionModel</span><br><span class="line"><span class="comment"># 载入训练好的模型</span></span><br><span class="line">model2 = LogisticRegressionModel.load(<span class="string">&quot;hdfs://localhost:9000/models/CTRModel_AllOneHot.obj&quot;</span>)</span><br><span class="line">result_2 = model2.transform(test_datasets_2)</span><br><span class="line"><span class="comment"># 按probability升序排列数据，probability表示预测结果的概率</span></span><br><span class="line">result_2.select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比前面的result_1的预测结果，能发现这里的预测率稍微准确了一点，这里top20里出现了3个点击的，但前面的只出现了1个</span></span><br><span class="line"><span class="comment"># 因此可见对特征的细化处理，已经帮助我们提高模型的效果的</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  0|      1.0E8|[0.85524418892857...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.88353143762124...|       0.0|</span><br><span class="line">|  0|      1.0E8|[0.89169808985616...|       0.0|</span><br><span class="line">|  1|5.5555556E7|[0.92511743960350...|       0.0|</span><br><span class="line">|  0|     179.01|[0.93239951738307...|       0.0|</span><br><span class="line">|  1|      159.0|[0.93239952905659...|       0.0|</span><br><span class="line">|  0|      118.0|[0.93239955297535...|       0.0|</span><br><span class="line">|  0|      688.0|[0.93451506165953...|       0.0|</span><br><span class="line">|  0|      339.0|[0.93451525933626...|       0.0|</span><br><span class="line">|  0|      335.0|[0.93451526160190...|       0.0|</span><br><span class="line">|  0|      220.0|[0.93451532673881...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93451535166074...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93451536185607...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93451536185607...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93451536695374...|       0.0|</span><br><span class="line">|  0|      122.5|[0.93451538196353...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93451539527410...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93451540150458...|       0.0|</span><br><span class="line">|  0|       79.0|[0.93451540660224...|       0.0|</span><br><span class="line">|  0|       75.0|[0.93451540886787...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93451541283272...|       0.0|</span><br><span class="line">|  0|       68.0|[0.93451541283272...|       0.0|</span><br><span class="line">|  0|       59.9|[0.93451541742061...|       0.0|</span><br><span class="line">|  0|      44.98|[0.93451542587140...|       0.0|</span><br><span class="line">|  0|       35.5|[0.93451543124094...|       0.0|</span><br><span class="line">|  0|       33.0|[0.93451543265696...|       0.0|</span><br><span class="line">|  0|       32.8|[0.93451543277024...|       0.0|</span><br><span class="line">|  0|       30.0|[0.93451543435618...|       0.0|</span><br><span class="line">|  0|       28.0|[0.93451543548899...|       0.0|</span><br><span class="line">|  0|       19.9|[0.93451544007688...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93451544013353...|       0.0|</span><br><span class="line">|  0|       19.8|[0.93451544013353...|       0.0|</span><br><span class="line">|  0|       12.0|[0.93451544455150...|       0.0|</span><br><span class="line">|  0|        6.7|[0.93451544755345...|       0.0|</span><br><span class="line">|  0|      568.0|[0.93458159339238...|       0.0|</span><br><span class="line">|  0|      398.0|[0.93458168959099...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93458182540058...|       0.0|</span><br><span class="line">|  0|      245.0|[0.93471518526899...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93471526772971...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93471527394249...|       0.0|</span><br><span class="line">|  0|     1288.0|[0.93474589600376...|       0.0|</span><br><span class="line">|  0|      688.0|[0.93474623473450...|       0.0|</span><br><span class="line">|  0|      656.0|[0.93474625280009...|       0.0|</span><br><span class="line">|  0|      568.0|[0.93474630248045...|       0.0|</span><br><span class="line">|  0|      498.0|[0.93474634199889...|       0.0|</span><br><span class="line">|  0|      399.0|[0.93474639788922...|       0.0|</span><br><span class="line">|  0|      396.0|[0.93474639958287...|       0.0|</span><br><span class="line">|  0|      298.0|[0.93474645490860...|       0.0|</span><br><span class="line">|  0|      293.0|[0.93474645773134...|       0.0|</span><br><span class="line">|  0|      209.0|[0.93474650515337...|       0.0|</span><br><span class="line">|  0|      198.0|[0.93474651136339...|       0.0|</span><br><span class="line">|  0|      198.0|[0.93474651136339...|       0.0|</span><br><span class="line">|  0|      169.0|[0.93474652773527...|       0.0|</span><br><span class="line">|  0|      168.0|[0.93474652829982...|       0.0|</span><br><span class="line">|  0|      159.0|[0.93474653338074...|       0.0|</span><br><span class="line">|  0|      155.0|[0.93474653563893...|       0.0|</span><br><span class="line">|  0|      139.0|[0.93474654467169...|       0.0|</span><br><span class="line">|  0|      138.0|[0.93474654523624...|       0.0|</span><br><span class="line">|  0|      119.0|[0.93474655596264...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93474656725358...|       0.0|</span><br><span class="line">|  0|       99.0|[0.93474656725358...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93474657346360...|       0.0|</span><br><span class="line">|  0|       88.0|[0.93474657346360...|       0.0|</span><br><span class="line">|  0|       79.0|[0.93474657854453...|       0.0|</span><br><span class="line">|  0|       59.0|[0.93474658983547...|       0.0|</span><br><span class="line">|  0|       59.0|[0.93474658983547...|       0.0|</span><br><span class="line">|  0|       59.0|[0.93474658983547...|       0.0|</span><br><span class="line">|  0|       58.0|[0.93474659040002...|       0.0|</span><br><span class="line">|  0|       57.0|[0.93474659096456...|       0.0|</span><br><span class="line">|  0|       49.8|[0.93474659502930...|       0.0|</span><br><span class="line">|  0|      39.98|[0.93474660057315...|       0.0|</span><br><span class="line">|  0|       36.8|[0.93474660236841...|       0.0|</span><br><span class="line">|  0|       34.0|[0.93474660394914...|       0.0|</span><br><span class="line">|  0|     6520.0|[0.93480919087761...|       0.0|</span><br><span class="line">|  0|     3699.0|[0.93481078202537...|       0.0|</span><br><span class="line">|  0|     1980.0|[0.93481175158689...|       0.0|</span><br><span class="line">|  0|      660.0|[0.93481249609274...|       0.0|</span><br><span class="line">|  0|      660.0|[0.93481249609274...|       0.0|</span><br><span class="line">|  0|      398.0|[0.93481264386492...|       0.0|</span><br><span class="line">|  0|      369.0|[0.93481266022137...|       0.0|</span><br><span class="line">|  0|      299.0|[0.93481269970243...|       0.0|</span><br><span class="line">|  0|      295.0|[0.93481270195849...|       0.0|</span><br><span class="line">|  0|      278.0|[0.93481271154674...|       0.0|</span><br><span class="line">|  0|      270.0|[0.93481271605886...|       0.0|</span><br><span class="line">|  0|      228.0|[0.93481273974748...|       0.0|</span><br><span class="line">|  0|      228.0|[0.93481273974748...|       0.0|</span><br><span class="line">|  0|    11368.0|[0.93494253131370...|       0.0|</span><br><span class="line">|  0|     9999.0|[0.93494330201510...|       0.0|</span><br><span class="line">|  0|     1099.0|[0.93494360670448...|       0.0|</span><br><span class="line">|  1|     8888.0|[0.93494392746484...|       0.0|</span><br><span class="line">|  0|      338.0|[0.93494403511659...|       0.0|</span><br><span class="line">|  0|      311.0|[0.93494405031645...|       0.0|</span><br><span class="line">|  0|      300.0|[0.93494405650898...|       0.0|</span><br><span class="line">|  0|      278.0|[0.93494406889404...|       0.0|</span><br><span class="line">|  0|      188.0|[0.93494411956019...|       0.0|</span><br><span class="line">|  0|      176.0|[0.93494412631568...|       0.0|</span><br><span class="line">|  0|      168.0|[0.93494413081933...|       0.0|</span><br><span class="line">|  0|      158.0|[0.93494413644890...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93494414770804...|       0.0|</span><br><span class="line">|  0|      125.0|[0.93494415502647...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result_2.<span class="built_in">filter</span>(result_2.clk==<span class="number">1</span>).select(<span class="string">&quot;clk&quot;</span>, <span class="string">&quot;price&quot;</span>, <span class="string">&quot;probability&quot;</span>, <span class="string">&quot;prediction&quot;</span>).sort(<span class="string">&quot;probability&quot;</span>).show(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 从该结果也可以看出，result_2的点击率预测率普遍要比result_1高出一点点</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|clk|      price|         probability|prediction|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">|  1|5.5555556E7|[0.92511743960350...|       0.0|</span><br><span class="line">|  1|      159.0|[0.93239952905659...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93451536695374...|       0.0|</span><br><span class="line">|  1|     8888.0|[0.93494392746484...|       0.0|</span><br><span class="line">|  1|      138.0|[0.93494414770804...|       0.0|</span><br><span class="line">|  1|       35.0|[0.93494420569256...|       0.0|</span><br><span class="line">|  1|      519.0|[0.93494863870621...|       0.0|</span><br><span class="line">|  1|      478.0|[0.93494866178596...|       0.0|</span><br><span class="line">|  1|      349.0|[0.93494873440265...|       0.0|</span><br><span class="line">|  1|      348.0|[0.93494873496557...|       0.0|</span><br><span class="line">|  1|      316.0|[0.93494875297901...|       0.0|</span><br><span class="line">|  1|      298.0|[0.93494876311156...|       0.0|</span><br><span class="line">|  1|      298.0|[0.93494876311156...|       0.0|</span><br><span class="line">|  1|      199.0|[0.93494881884058...|       0.0|</span><br><span class="line">|  1|      199.0|[0.93494881884058...|       0.0|</span><br><span class="line">|  1|      198.0|[0.93494881940350...|       0.0|</span><br><span class="line">|  1|      187.1|[0.93494882553931...|       0.0|</span><br><span class="line">|  1|      176.0|[0.93494883178772...|       0.0|</span><br><span class="line">|  1|      168.0|[0.93494883629107...|       0.0|</span><br><span class="line">|  1|      160.0|[0.93494884079442...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93494884192026...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93494884192026...|       0.0|</span><br><span class="line">|  1|      135.0|[0.93494885486740...|       0.0|</span><br><span class="line">|  1|      129.0|[0.93494885824491...|       0.0|</span><br><span class="line">|  1|      127.0|[0.93494885937075...|       0.0|</span><br><span class="line">|  1|      125.0|[0.93494886049659...|       0.0|</span><br><span class="line">|  1|      124.0|[0.93494886105951...|       0.0|</span><br><span class="line">|  1|      118.0|[0.93494886443702...|       0.0|</span><br><span class="line">|  1|      109.0|[0.93494886950329...|       0.0|</span><br><span class="line">|  1|      108.0|[0.93494887006621...|       0.0|</span><br><span class="line">|  1|       99.0|[0.93494887513247...|       0.0|</span><br><span class="line">|  1|       98.0|[0.93494887569539...|       0.0|</span><br><span class="line">|  1|       79.8|[0.93494888594051...|       0.0|</span><br><span class="line">|  1|       79.0|[0.93494888639085...|       0.0|</span><br><span class="line">|  1|       77.0|[0.93494888751668...|       0.0|</span><br><span class="line">|  1|       72.5|[0.93494889004982...|       0.0|</span><br><span class="line">|  1|       69.0|[0.93494889202003...|       0.0|</span><br><span class="line">|  1|       68.0|[0.93494889258295...|       0.0|</span><br><span class="line">|  1|       60.0|[0.93494889708630...|       0.0|</span><br><span class="line">|  1|      43.98|[0.93494890610426...|       0.0|</span><br><span class="line">|  1|       40.0|[0.93494890834467...|       0.0|</span><br><span class="line">|  1|       39.9|[0.93494890840096...|       0.0|</span><br><span class="line">|  1|       39.6|[0.93494890856984...|       0.0|</span><br><span class="line">|  1|       32.0|[0.93494891284802...|       0.0|</span><br><span class="line">|  1|       31.0|[0.93494891341094...|       0.0|</span><br><span class="line">|  1|      25.98|[0.93494891623679...|       0.0|</span><br><span class="line">|  1|       23.0|[0.93494891791428...|       0.0|</span><br><span class="line">|  1|       19.0|[0.93494892016596...|       0.0|</span><br><span class="line">|  1|       16.9|[0.93494892134809...|       0.0|</span><br><span class="line">|  1|       10.0|[0.93494892523222...|       0.0|</span><br><span class="line">|  1|        3.5|[0.93494892889119...|       0.0|</span><br><span class="line">|  1|        3.5|[0.93494892889119...|       0.0|</span><br><span class="line">|  1|        0.4|[0.93494893063624...|       0.0|</span><br><span class="line">|  1|     1288.0|[0.93501426059874...|       0.0|</span><br><span class="line">|  1|      980.0|[0.93501443381533...|       0.0|</span><br><span class="line">|  1|      788.0|[0.93501454179429...|       0.0|</span><br><span class="line">|  1|      698.0|[0.93501459240937...|       0.0|</span><br><span class="line">|  1|      695.0|[0.93501459409654...|       0.0|</span><br><span class="line">|  1|      688.0|[0.93501459803326...|       0.0|</span><br><span class="line">|  1|      599.0|[0.93501464808591...|       0.0|</span><br><span class="line">|  1|      588.0|[0.93501465427219...|       0.0|</span><br><span class="line">|  1|      516.0|[0.93501469476419...|       0.0|</span><br><span class="line">|  1|      495.0|[0.93501470657436...|       0.0|</span><br><span class="line">|  1|      398.0|[0.93501476112603...|       0.0|</span><br><span class="line">|  1|      368.0|[0.93501477799768...|       0.0|</span><br><span class="line">|  1|      339.0|[0.93501479430693...|       0.0|</span><br><span class="line">|  1|      335.0|[0.93501479655648...|       0.0|</span><br><span class="line">|  1|      324.0|[0.93501480274275...|       0.0|</span><br><span class="line">|  1|      316.0|[0.93501480724185...|       0.0|</span><br><span class="line">|  1|      299.0|[0.93501481680244...|       0.0|</span><br><span class="line">|  1|      295.0|[0.93501481905199...|       0.0|</span><br><span class="line">|  1|      279.0|[0.93501482805020...|       0.0|</span><br><span class="line">|  1|      268.0|[0.93501483423646...|       0.0|</span><br><span class="line">|  1|      259.0|[0.93501483929795...|       0.0|</span><br><span class="line">|  1|      259.0|[0.93501483929795...|       0.0|</span><br><span class="line">|  1|      249.0|[0.93501484492182...|       0.0|</span><br><span class="line">|  1|      238.0|[0.93501485110809...|       0.0|</span><br><span class="line">|  1|      199.0|[0.93501487304119...|       0.0|</span><br><span class="line">|  1|      198.0|[0.93501487360358...|       0.0|</span><br><span class="line">|  1|      179.0|[0.93501488428894...|       0.0|</span><br><span class="line">|  1|      175.0|[0.93501488653849...|       0.0|</span><br><span class="line">|  1|      129.0|[0.93501491240829...|       0.0|</span><br><span class="line">|  1|      128.0|[0.93501491297068...|       0.0|</span><br><span class="line">|  1|      118.0|[0.93501491859455...|       0.0|</span><br><span class="line">|  1|      109.0|[0.93501492365603...|       0.0|</span><br><span class="line">|  1|       98.0|[0.93501492984229...|       0.0|</span><br><span class="line">|  1|       89.0|[0.93501493490377...|       0.0|</span><br><span class="line">|  1|       79.0|[0.93501494052764...|       0.0|</span><br><span class="line">|  1|       75.0|[0.93501494277718...|       0.0|</span><br><span class="line">|  1|       69.8|[0.93501494570159...|       0.0|</span><br><span class="line">|  1|       30.0|[0.93501496808458...|       0.0|</span><br><span class="line">|  1|       15.0|[0.93501497652038...|       0.0|</span><br><span class="line">|  1|      368.0|[0.93665387743951...|       0.0|</span><br><span class="line">|  1|      198.0|[0.93665397079735...|       0.0|</span><br><span class="line">|  1|      178.0|[0.93665398178062...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93665399276388...|       0.0|</span><br><span class="line">|  1|      158.0|[0.93665399276388...|       0.0|</span><br><span class="line">|  1|      149.0|[0.93665399770635...|       0.0|</span><br><span class="line">|  1|       68.0|[0.93665404218855...|       0.0|</span><br><span class="line">|  1|       36.0|[0.93665405976176...|       0.0|</span><br><span class="line">+---+-----------+--------------------+----------+</span><br><span class="line">only showing top 100 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="CTR预估模型建立"><a href="#CTR预估模型建立" class="headerlink" title="CTR预估模型建立"></a>CTR预估模型建立</h3><ul><li><p>利用raw_sample ad_feature user_profile 数据合并 挑选出合适的特征</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">useful_cols = [</span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    <span class="comment"># 时间字段，划分训练集和测试集</span></span><br><span class="line">    <span class="string">&quot;timestamp&quot;</span>,</span><br><span class="line">    <span class="comment"># label目标值字段</span></span><br><span class="line">    <span class="string">&quot;clk&quot;</span>,  </span><br><span class="line">    <span class="comment"># 特征值字段</span></span><br><span class="line">    <span class="string">&quot;pid_value&quot;</span>,       <span class="comment"># 资源位的特征向量</span></span><br><span class="line">    <span class="string">&quot;price&quot;</span>,    <span class="comment"># 广告价格</span></span><br><span class="line">    <span class="string">&quot;cms_segid&quot;</span>,    <span class="comment"># 用户微群ID</span></span><br><span class="line">    <span class="string">&quot;cms_group_id&quot;</span>,    <span class="comment"># 用户组ID</span></span><br><span class="line">    <span class="string">&quot;final_gender_code&quot;</span>,    <span class="comment"># 用户性别特征，[1,2]</span></span><br><span class="line">    <span class="string">&quot;age_level&quot;</span>,    <span class="comment"># 年龄等级，1-</span></span><br><span class="line">    <span class="string">&quot;shopping_level&quot;</span>,</span><br><span class="line">    <span class="string">&quot;occupation&quot;</span>,</span><br><span class="line">    <span class="string">&quot;pl_onehot_value&quot;</span>,</span><br><span class="line">    <span class="string">&quot;nucl_onehot_value&quot;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure></li><li><p>又对数据进行处理，把可能进行one-hot编码的分类特征都进行one_hot处理</p><ul><li><pre><code class="lang-python">useful_cols_2 = [    # 时间值，划分训练集和测试集    &quot;timestamp&quot;,    # label目标值    &quot;clk&quot;,      # 特征值    &quot;price&quot;,    &quot;cms_group_id&quot;, #13维    &quot;final_gender_code&quot;, #2维    &quot;age_level&quot;, #7维    &quot;shopping_level&quot;, #3维度    &quot;occupation&quot;, #2    &quot;pid_value&quot;,  #2    &quot;pl_onehot_value&quot;,#4    &quot;nucl_onehot_value&quot;#5]</code></pre></li></ul></li><li><p>逻辑回归训练出的CTR预估模型 预测值的理解</p><ul><li>因为数据大部分都是不点击， 样本极度偏斜的，点击样本很少 （5%） 预测出的结果都是0 不点</li><li>根据不点击的概率来排序 不点击概率越低的排在前面</li><li>在测试数据中 按照不点击的概率排序 考察精准率（找前10个 看看10个中是否有点击的样本）能有10%的CTR预估的概率就已经相当不错了。正常5%。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;LR实现CTR预估&quot;&gt;&lt;a href=&quot;#LR实现CTR预估&quot; class=&quot;headerlink&quot; title=&quot;LR实现CTR预估&quot;&gt;&lt;/a&gt;LR实现CTR预估&lt;/h2&gt;&lt;h3 id=&quot;1-Spark逻辑回归-LR-模型使用介绍&quot;&gt;&lt;a href=&quot;#1-Sp</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>34-CTR预估数据准备</title>
    <link href="https://xxren8218.github.io/20210710/34-CTR%E9%A2%84%E4%BC%B0%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87.html"/>
    <id>https://xxren8218.github.io/20210710/34-CTR%E9%A2%84%E4%BC%B0%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87.html</id>
    <published>2021-07-10T14:47:02.000Z</published>
    <updated>2021-07-10T14:48:51.257Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CTR预估数据准备"><a href="#CTR预估数据准备" class="headerlink" title="CTR预估数据准备"></a>CTR预估数据准备</h2><h3 id="1-分析并预处理raw-sample数据集"><a href="#1-分析并预处理raw-sample数据集" class="headerlink" title="1. 分析并预处理raw_sample数据集"></a>1. 分析并预处理raw_sample数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS中加载样本数据信息</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/raw_sample.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">df.show()    <span class="comment"># 展示数据，默认前20条</span></span><br><span class="line">df.printSchema()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----------+-----------+------+---+</span><br><span class="line">|  user|time_stamp|adgroup_id|        pid|nonclk|clk|</span><br><span class="line">+------+----------+----------+-----------+------+---+</span><br><span class="line">|581738|1494137644|         1|430548_1007|     1|  0|</span><br><span class="line">|449818|1494638778|         3|430548_1007|     1|  0|</span><br><span class="line">|914836|1494650879|         4|430548_1007|     1|  0|</span><br><span class="line">|914836|1494651029|         5|430548_1007|     1|  0|</span><br><span class="line">|399907|1494302958|         8|430548_1007|     1|  0|</span><br><span class="line">|628137|1494524935|         9|430548_1007|     1|  0|</span><br><span class="line">|298139|1494462593|         9|430539_1007|     1|  0|</span><br><span class="line">|775475|1494561036|         9|430548_1007|     1|  0|</span><br><span class="line">|555266|1494307136|        11|430539_1007|     1|  0|</span><br><span class="line">|117840|1494036743|        11|430548_1007|     1|  0|</span><br><span class="line">|739815|1494115387|        11|430539_1007|     1|  0|</span><br><span class="line">|623911|1494625301|        11|430548_1007|     1|  0|</span><br><span class="line">|623911|1494451608|        11|430548_1007|     1|  0|</span><br><span class="line">|421590|1494034144|        11|430548_1007|     1|  0|</span><br><span class="line">|976358|1494156949|        13|430548_1007|     1|  0|</span><br><span class="line">|286630|1494218579|        13|430539_1007|     1|  0|</span><br><span class="line">|286630|1494289247|        13|430539_1007|     1|  0|</span><br><span class="line">|771431|1494153867|        13|430548_1007|     1|  0|</span><br><span class="line">|707120|1494220810|        13|430548_1007|     1|  0|</span><br><span class="line">|530454|1494293746|        13|430548_1007|     1|  0|</span><br><span class="line">+------+----------+----------+-----------+------+---+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- user: string (nullable = true)</span><br><span class="line"> |-- time_stamp: string (nullable = true)</span><br><span class="line"> |-- adgroup_id: string (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: string (nullable = true)</span><br><span class="line"> |-- clk: string (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>分析数据集字段的类型和格式<ul><li>查看是否有空值</li><li>查看每列数据的类型</li><li>查看每列数据的类别情况</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;样本数据集总条目数：&quot;</span>, df.count())</span><br><span class="line"><span class="comment"># 约2600w</span></span><br><span class="line">print(<span class="string">&quot;用户user总数：&quot;</span>, df.groupBy(<span class="string">&quot;user&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约 114w，略多余日志数据中用户数</span></span><br><span class="line">print(<span class="string">&quot;广告id adgroup_id总数：&quot;</span>, df.groupBy(<span class="string">&quot;adgroup_id&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约85w</span></span><br><span class="line">print(<span class="string">&quot;广告展示位pid情况：&quot;</span>, df.groupBy(<span class="string">&quot;pid&quot;</span>).count().collect())</span><br><span class="line"><span class="comment"># 只有两种广告展示位，占比约为六比四</span></span><br><span class="line">print(<span class="string">&quot;广告点击数据情况clk：&quot;</span>, df.groupBy(<span class="string">&quot;clk&quot;</span>).count().collect())</span><br><span class="line"><span class="comment"># 点和不点比率约： 1:20</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">样本数据集总条目数： 26557961</span><br><span class="line">用户user总数： 1141729</span><br><span class="line">广告id adgroup_id总数： 846811</span><br><span class="line">广告展示位pid情况： [Row(pid=&#x27;430548_1007&#x27;, count=16472898), Row(pid=&#x27;430539_1007&#x27;, count=10085063)]</span><br><span class="line">广告点击数据情况clk： [Row(clk=&#x27;0&#x27;, count=25191905), Row(clk=&#x27;1&#x27;, count=1366056)]</span><br></pre></td></tr></table></figure><p><strong>默认加载进来的schema都是String类型的。修改为我们所需要的格式，并且一些名字给改过来。</strong></p><ul><li>使用dataframe.withColumn更改df列数据结构；使用dataframe.withColumnRenamed更改列名称</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更改表结构，转换为对应的数据类型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType, LongType, StringType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印df结构信息</span></span><br><span class="line">df.printSchema()   </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">raw_sample_df = df.\</span><br><span class="line">    withColumn(<span class="string">&quot;user&quot;</span>, df.user.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;userId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;time_stamp&quot;</span>, df.time_stamp.cast(LongType())).withColumnRenamed(<span class="string">&quot;time_stamp&quot;</span>, <span class="string">&quot;timestamp&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;pid&quot;</span>, df.pid.cast(StringType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;nonclk&quot;</span>, df.nonclk.cast(IntegerType())).\</span><br><span class="line">    withColumn(<span class="string">&quot;clk&quot;</span>, df.clk.cast(IntegerType()))</span><br><span class="line">raw_sample_df.printSchema()</span><br><span class="line">raw_sample_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- user: string (nullable = true)</span><br><span class="line"> |-- time_stamp: string (nullable = true)</span><br><span class="line"> |-- adgroup_id: string (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: string (nullable = true)</span><br><span class="line"> |-- clk: string (nullable = true)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- pid: string (nullable = true)</span><br><span class="line"> |-- nonclk: integer (nullable = true)</span><br><span class="line"> |-- clk: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|</span><br><span class="line">+------+----------+---------+-----------+------+---+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><p><strong>数据有了，接下来进行特征相关的操作。</strong></p><ul><li><p>特征选取（Feature Selection）</p><ul><li><p>特征选择就是选择那些靠谱的Feature，去掉冗余的Feature，对于搜索广告，Query关键词和广告的匹配程度很重要；但对于展示广告，广告本身的历史表现，往往是最重要的Feature。</p><p>根据经验，该数据集中，只有广告展示位pid对比较重要，且数据不同数据之间的占比约为6:4，因此pid可以作为一个关键特征</p><p>nonclk和clk在这里是作为目标值，不做为特征</p></li></ul></li><li><p>热独编码 OneHotEncode</p><ul><li><p>热独编码是一种经典编码，是使用N位状态寄存器(如0和1)来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。</p><p>假设有三组特征，分别表示年龄，城市，设备；</p><p>[“男”, “女”][0,1]</p><p>[“北京”, “上海”, “广州”][0,1,2]</p><p>[“苹果”, “小米”, “华为”, “微软”][0,1,2,3]</p><p>传统变化： 对每一组特征，使用枚举类型，从0开始；</p><p>[“男“，”上海“，”小米“]=[ 0,1,1]</p><p>[“女“，”北京“，”苹果“] =[1,0,0]</p><p>传统变化后的数据不是连续的，而是随机分配的，不容易应用在分类器中</p><p>而经过热独编码，数据会变成稀疏的，方便分类器处理：</p><p>[“男“，”上海“，”小米“]=[ 1,0,0,1,0,0,1,0,0]</p><p>[“女“，”北京“，”苹果“] =[0,1,1,0,0,1,0,0,0]</p><p>这样做保留了特征的多样性，但是也要注意如果数据过于稀疏(样本较少、维度过高)，其效果反而会变差</p></li></ul></li><li><p>Spark中使用热独编码</p><ul><li><p><strong>注意：热编码只能对字符串类型的列数据进行处理</strong></p><p><a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=stringindexer#pyspark.ml.feature.StringIndexer">StringIndexer</a>：对指定字符串列数据进行特征处理，如将性别数据“男”、“女”转化为0和1</p><p><a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=onehotencoder#pyspark.ml.feature.OneHotEncoder">OneHotEncoder</a>：对特征列数据，进行热编码，通常需结合StringIndexer一起使用</p><p><a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=pipeline#pyspark.ml.Pipeline">Pipeline</a>：让数据按顺序依次被处理，将前一次的处理结果作为下一次的输入</p></li></ul></li><li><p>特征处理</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;特征处理&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">pid 资源位。该特征属于分类特征，只有两类取值，因此考虑进行热编码处理即可，分为是否在资源位1、是否在资源位2 两个特征</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer <span class="comment"># 对指定字符串列数据进行特征处理，如将性别数据“男”、“女”转化为0和1</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># StringIndexer对指定字符串列进行特征处理，利用StringIndexer 把字符串类别转换成 0 1 2 数值类别</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pid&#x27;</span>, outputCol=<span class="string">&#x27;pid_feature&#x27;</span>)</span><br><span class="line">string_model = stringIndexer.fit(raw_sample_df)</span><br><span class="line">stringIndex_result = string_model.transform(raw_sample_df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对处理出来的特征处理列进行，热独编码，利用OneHotEncoder 在stringIndexer的基础上 获取onehot编码</span></span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pid_feature&#x27;</span>, outputCol=<span class="string">&#x27;pid_value&#x27;</span>) <span class="comment"># dropLast=False会把最后一去掉，用其余表示最后一个。</span></span><br><span class="line">result = encoder.transform(stringIndex_result) <span class="comment">#不需要fit，直接transform</span></span><br><span class="line"><span class="comment"># (2,[0],[1.0]) 表示两个维度，第0个维度为 1.0，Spark表示稀疏向量的方式。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用管道对每一个数据进行热独编码处理 ——（若处理步骤比较多，可以用pipline减少代码量。）</span></span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_model = pipeline.fit(raw_sample_df)</span><br><span class="line">new_df = pipeline_model.transform(raw_sample_df)</span><br><span class="line">new_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|pid_feature|    pid_value|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|581738|1494137644|        1|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|449818|1494638778|        3|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494650879|        4|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|914836|1494651029|        5|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|399907|1494302958|        8|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|628137|1494524935|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|298139|1494462593|        9|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|775475|1494561036|        9|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|555266|1494307136|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|117840|1494036743|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|739815|1494115387|       11|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|623911|1494625301|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|623911|1494451608|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|421590|1494034144|       11|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|976358|1494156949|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|286630|1494218579|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|286630|1494289247|       13|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|771431|1494153867|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|707120|1494220810|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|530454|1494293746|       13|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>返回字段pid_value是一个稀疏向量类型数据 <a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=sparse#pyspark.ml.linalg.SparseVector">pyspark.ml.linalg.SparseVector</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> SparseVector</span><br><span class="line"><span class="comment"># 参数：维度、索引列表、值列表</span></span><br><span class="line">print(SparseVector(<span class="number">4</span>, [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]))</span><br><span class="line">print(SparseVector(<span class="number">4</span>, [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]).toArray())</span><br><span class="line">print(<span class="string">&quot;*********&quot;</span>)</span><br><span class="line">print(new_df.select(<span class="string">&quot;pid_value&quot;</span>).first())</span><br><span class="line">print(new_df.select(<span class="string">&quot;pid_value&quot;</span>).first().pid_value.toArray())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(4,[1,3],[3.0,4.0])</span><br><span class="line">[0. 3. 0. 4.]</span><br><span class="line">*********</span><br><span class="line">Row(pid_value&#x3D;SparseVector(2, &#123;0: 1.0&#125;))</span><br><span class="line">[1. 0.]</span><br></pre></td></tr></table></figure><h3 id="2-划分训练集和测试集"><a href="#2-划分训练集和测试集" class="headerlink" title="2. 划分训练集和测试集"></a>2. 划分训练集和测试集</h3><ul><li>查看最大时间</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_df.sort(<span class="string">&quot;timestamp&quot;</span>, ascending=<span class="literal">False</span>).show()</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|userId| timestamp|adgroupId|        pid|nonclk|clk|pid_feature|    pid_value|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">|177002|1494691186|   593001|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|243671|1494691186|   600195|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|488527|1494691184|   494312|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|488527|1494691184|   431082|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">| 17054|1494691184|   742741|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">| 17054|1494691184|   756665|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|488527|1494691184|   687854|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|839493|1494691183|   561681|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|704223|1494691183|   624504|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|839493|1494691183|   582235|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|704223|1494691183|   675674|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|628998|1494691180|   618965|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|674444|1494691179|   427579|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|627200|1494691179|   782038|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|627200|1494691179|   420769|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|674444|1494691179|   588664|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|738335|1494691179|   451004|430539_1007|     1|  0|        1.0|(2,[1],[1.0])|</span><br><span class="line">|627200|1494691179|   817569|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|322244|1494691179|   820018|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">|322244|1494691179|   735220|430548_1007|     1|  0|        0.0|(2,[0],[1.0])|</span><br><span class="line">+------+----------+---------+-----------+------+---+-----------+-------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 本样本数据集共计8天数据</span></span><br><span class="line"><span class="comment"># 前七天为训练数据、最后一天为测试数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">datetime.fromtimestamp(<span class="number">1494691186</span>)</span><br><span class="line">print(<span class="string">&quot;该时间之前的数据为训练样本，该时间以后的数据为测试样本：&quot;</span>, datetime.fromtimestamp(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datetime.datetime(<span class="number">2017</span>, <span class="number">5</span>, <span class="number">12</span>, <span class="number">23</span>, <span class="number">59</span>, <span class="number">46</span>)</span><br></pre></td></tr></table></figure><p>该时间之前的数据为训练样本，该时间以后的数据为测试样本： 2017-05-12 23:59:46</p><ul><li>训练样本</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练样本：</span></span><br><span class="line">train_sample = raw_sample_df.<span class="built_in">filter</span>(raw_sample_df.timestamp&lt;=(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line">print(<span class="string">&quot;训练样本个数：&quot;</span>)</span><br><span class="line">print(train_sample.count())</span><br><span class="line"><span class="comment"># 测试样本</span></span><br><span class="line">test_sample = raw_sample_df.<span class="built_in">filter</span>(raw_sample_df.timestamp&gt;(<span class="number">1494691186</span>-<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span>))</span><br><span class="line">print(<span class="string">&quot;测试样本个数：&quot;</span>)</span><br><span class="line">print(test_sample.count())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：还需要加入广告基本特征和用户基本特征才能做程一份完整的样本数据集</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">训练样本个数：</span><br><span class="line">23249291</span><br><span class="line">测试样本个数：</span><br><span class="line">3308670</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-分析并预处理ad-feature数据集"><a href="#3-分析并预处理ad-feature数据集" class="headerlink" title="3. 分析并预处理ad_feature数据集"></a>3. 分析并预处理ad_feature数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS中加载广告基本信息数据，返回spark dafaframe对象</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/ad_feature.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">df.show()    <span class="comment"># 展示数据，默认前20条</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+----------+-------+-----------+--------+------+-----+</span><br><span class="line">|adgroup_id|cate_id|campaign_id|customer| brand|price|</span><br><span class="line">+----------+-------+-----------+--------+------+-----+</span><br><span class="line">|     63133|   6406|      83237|       1| 95471|170.0|</span><br><span class="line">|    313401|   6406|      83237|       1| 87331|199.0|</span><br><span class="line">|    248909|    392|      83237|       1| 32233| 38.0|</span><br><span class="line">|    208458|    392|      83237|       1|174374|139.0|</span><br><span class="line">|    110847|   7211|     135256|       2|145952|32.99|</span><br><span class="line">|    607788|   6261|     387991|       6|207800|199.0|</span><br><span class="line">|    375706|   4520|     387991|       6|  NULL| 99.0|</span><br><span class="line">|     11115|   7213|     139747|       9|186847| 33.0|</span><br><span class="line">|     24484|   7207|     139744|       9|186847| 19.0|</span><br><span class="line">|     28589|   5953|     395195|      13|  NULL|428.0|</span><br><span class="line">|     23236|   5953|     395195|      13|  NULL|368.0|</span><br><span class="line">|    300556|   5953|     395195|      13|  NULL|639.0|</span><br><span class="line">|     92560|   5953|     395195|      13|  NULL|368.0|</span><br><span class="line">|    590965|   4284|      28145|      14|454237|249.0|</span><br><span class="line">|    529913|   4284|      70206|      14|  NULL|249.0|</span><br><span class="line">|    546930|   4284|      28145|      14|  NULL|249.0|</span><br><span class="line">|    639794|   6261|      70206|      14| 37004| 89.9|</span><br><span class="line">|    335413|   4284|      28145|      14|  NULL|249.0|</span><br><span class="line">|    794890|   4284|      70206|      14|454237|249.0|</span><br><span class="line">|    684020|   6261|      70206|      14| 37004| 99.0|</span><br><span class="line">+----------+-------+-----------+--------+------+-----+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：由于本数据集中存在NULL字样的数据，无法直接设置schema，只能先将NULL类型的数据处理掉，然后进行类型转换</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, IntegerType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换掉NULL字符串，替换掉</span></span><br><span class="line">df = df.replace(<span class="string">&quot;NULL&quot;</span>, <span class="string">&quot;-1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印df结构信息</span></span><br><span class="line">df.printSchema()   </span><br><span class="line"><span class="comment"># 更改df表结构：更改列类型和列名称</span></span><br><span class="line">ad_feature_df = df.\</span><br><span class="line">    withColumn(<span class="string">&quot;adgroup_id&quot;</span>, df.adgroup_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;adgroup_id&quot;</span>, <span class="string">&quot;adgroupId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;cate_id&quot;</span>, df.cate_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;cate_id&quot;</span>, <span class="string">&quot;cateId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;campaign_id&quot;</span>, df.campaign_id.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;campaign_id&quot;</span>, <span class="string">&quot;campaignId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;customer&quot;</span>, df.customer.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;customer&quot;</span>, <span class="string">&quot;customerId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;brand&quot;</span>, df.brand.cast(IntegerType())).withColumnRenamed(<span class="string">&quot;brand&quot;</span>, <span class="string">&quot;brandId&quot;</span>).\</span><br><span class="line">    withColumn(<span class="string">&quot;price&quot;</span>, df.price.cast(FloatType()))</span><br><span class="line">ad_feature_df.printSchema()</span><br><span class="line">ad_feature_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- adgroup_id: string (nullable = true)</span><br><span class="line"> |-- cate_id: string (nullable = true)</span><br><span class="line"> |-- campaign_id: string (nullable = true)</span><br><span class="line"> |-- customer: string (nullable = true)</span><br><span class="line"> |-- brand: string (nullable = true)</span><br><span class="line"> |-- price: string (nullable = true)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- adgroupId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- campaignId: integer (nullable = true)</span><br><span class="line"> |-- customerId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br><span class="line"> |-- price: float (nullable = true)</span><br><span class="line"></span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|price|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|    63133|  6406|     83237|         1|  95471|170.0|</span><br><span class="line">|   313401|  6406|     83237|         1|  87331|199.0|</span><br><span class="line">|   248909|   392|     83237|         1|  32233| 38.0|</span><br><span class="line">|   208458|   392|     83237|         1| 174374|139.0|</span><br><span class="line">|   110847|  7211|    135256|         2| 145952|32.99|</span><br><span class="line">|   607788|  6261|    387991|         6| 207800|199.0|</span><br><span class="line">|   375706|  4520|    387991|         6|     -1| 99.0|</span><br><span class="line">|    11115|  7213|    139747|         9| 186847| 33.0|</span><br><span class="line">|    24484|  7207|    139744|         9| 186847| 19.0|</span><br><span class="line">|    28589|  5953|    395195|        13|     -1|428.0|</span><br><span class="line">|    23236|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   300556|  5953|    395195|        13|     -1|639.0|</span><br><span class="line">|    92560|  5953|    395195|        13|     -1|368.0|</span><br><span class="line">|   590965|  4284|     28145|        14| 454237|249.0|</span><br><span class="line">|   529913|  4284|     70206|        14|     -1|249.0|</span><br><span class="line">|   546930|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   639794|  6261|     70206|        14|  37004| 89.9|</span><br><span class="line">|   335413|  4284|     28145|        14|     -1|249.0|</span><br><span class="line">|   794890|  4284|     70206|        14| 454237|249.0|</span><br><span class="line">|   684020|  6261|     70206|        14|  37004| 99.0|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>查看各项数据的特征</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;总广告条数：&quot;</span>,df.count())   <span class="comment"># 数据条数</span></span><br><span class="line">_1 = ad_feature_df.groupBy(<span class="string">&quot;cateId&quot;</span>).count().count()</span><br><span class="line">print(<span class="string">&quot;cateId数值个数：&quot;</span>, _1)</span><br><span class="line">_2 = ad_feature_df.groupBy(<span class="string">&quot;campaignId&quot;</span>).count().count()</span><br><span class="line">print(<span class="string">&quot;campaignId数值个数：&quot;</span>, _2)</span><br><span class="line">_3 = ad_feature_df.groupBy(<span class="string">&quot;customerId&quot;</span>).count().count()</span><br><span class="line">print(<span class="string">&quot;customerId数值个数：&quot;</span>, _3)</span><br><span class="line">_4 = ad_feature_df.groupBy(<span class="string">&quot;brandId&quot;</span>).count().count()</span><br><span class="line">print(<span class="string">&quot;brandId数值个数：&quot;</span>, _4)</span><br><span class="line">ad_feature_df.sort(<span class="string">&quot;price&quot;</span>).show()</span><br><span class="line">ad_feature_df.sort(<span class="string">&quot;price&quot;</span>, ascending=<span class="literal">False</span>).show()</span><br><span class="line">print(<span class="string">&quot;价格高于1w的条目个数：&quot;</span>, ad_feature_df.select(<span class="string">&quot;price&quot;</span>).<span class="built_in">filter</span>(<span class="string">&quot;price&gt;10000&quot;</span>).count())</span><br><span class="line">print(<span class="string">&quot;价格低于1的条目个数&quot;</span>, ad_feature_df.select(<span class="string">&quot;price&quot;</span>).<span class="built_in">filter</span>(<span class="string">&quot;price&lt;1&quot;</span>).count())</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">总广告条数： 846811</span><br><span class="line">cateId数值个数： 6769</span><br><span class="line">campaignId数值个数： 423436</span><br><span class="line">customerId数值个数： 255875</span><br><span class="line">brandId数值个数： 99815</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|price|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">|   485749|  9970|    352666|    140520|     -1| 0.01|</span><br><span class="line">|    88975|  9996|    198424|    182415|     -1| 0.01|</span><br><span class="line">|   109704| 10539|     59774|     90351| 202710| 0.01|</span><br><span class="line">|    49911|  7032|    129079|    172334|     -1| 0.01|</span><br><span class="line">|   339334|  9994|    310408|    211292| 383023| 0.01|</span><br><span class="line">|     6636|  6703|    392038|     46239| 406713| 0.01|</span><br><span class="line">|    92241|  6130|     72781|    149714|     -1| 0.01|</span><br><span class="line">|    20397| 10539|    410958|     65726|  79971| 0.01|</span><br><span class="line">|   345870|  9995|    179595|    191036|  79971| 0.01|</span><br><span class="line">|    77797|  9086|    218276|     31183|     -1| 0.01|</span><br><span class="line">|    14435|  1136|    135610|     17788|     -1| 0.01|</span><br><span class="line">|    42055|  9994|     43866|    113068| 123242| 0.01|</span><br><span class="line">|    41925|  7032|     85373|    114532|     -1| 0.01|</span><br><span class="line">|    67558|  9995|     90141|     83948|     -1| 0.01|</span><br><span class="line">|   149570|  7043|    126746|    176076|     -1| 0.01|</span><br><span class="line">|   518883|  7185|    403318|     58013|     -1| 0.01|</span><br><span class="line">|     2246|  9996|    413653|     60214| 182966| 0.01|</span><br><span class="line">|   290675|  4824|    315371|    240984|     -1| 0.01|</span><br><span class="line">|   552638| 10305|    403318|     58013|     -1| 0.01|</span><br><span class="line">|    89831| 10539|     90141|     83948| 211816| 0.01|</span><br><span class="line">+---------+------+----------+----------+-------+-----+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">+---------+------+----------+----------+-------+-----------+</span><br><span class="line">|adgroupId|cateId|campaignId|customerId|brandId|      price|</span><br><span class="line">+---------+------+----------+----------+-------+-----------+</span><br><span class="line">|   658722|  1093|    218101|    207754|     -1|      1.0E8|</span><br><span class="line">|   468220|  1093|    270719|    207754|     -1|      1.0E8|</span><br><span class="line">|   179746|  1093|    270027|    102509| 405447|      1.0E8|</span><br><span class="line">|   443295|  1093|     44251|    102509| 300681|      1.0E8|</span><br><span class="line">|    31899|   685|    218918|     31239| 278301|      1.0E8|</span><br><span class="line">|   243384|   685|    218918|     31239| 278301|      1.0E8|</span><br><span class="line">|   554311|  1093|    266086|    207754|     -1|      1.0E8|</span><br><span class="line">|   513942|   745|      8401|     86243|     -1|8.8888888E7|</span><br><span class="line">|   201060|   745|      8401|     86243|     -1|5.5555556E7|</span><br><span class="line">|   289563|   685|     37665|    120847| 278301|      1.5E7|</span><br><span class="line">|    35156|   527|    417722|     72273| 278301|      1.0E7|</span><br><span class="line">|    33756|   527|    416333|     70894|     -1|  9900000.0|</span><br><span class="line">|   335495|   739|    170121|    148946| 326126|  9600000.0|</span><br><span class="line">|   218306|   206|    162394|      4339| 221720|  8888888.0|</span><br><span class="line">|   213567|  7213|    239302|    205612| 406125|  5888888.0|</span><br><span class="line">|   375920|   527|    217512|    148946| 326126|  4760000.0|</span><br><span class="line">|   262215|   527|    132721|     11947| 417898|  3980000.0|</span><br><span class="line">|   154623|   739|    170121|    148946| 326126|  3900000.0|</span><br><span class="line">|   152414|   739|    170121|    148946| 326126|  3900000.0|</span><br><span class="line">|   448651|   527|    422260|     41289| 209959|  3800000.0|</span><br><span class="line">+---------+------+----------+----------+-------+-----------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">价格高于1w的条目个数： 6527</span><br><span class="line">价格低于1的条目个数 5762</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>特征选择</p><ul><li>品牌有些缺失，我们并没有建立用户和品牌的关系（召回时，我只算了类目）。不考虑</li><li>类别：在召回时已经考虑了，虽说会影响点击结果，但是我们仍不考虑。</li><li>淘客无法从数据体现区别，所以用 price来作为具体特征。</li><li>cateId：脱敏过的商品类目ID；</li></ul></li><li><p>campaignId：脱敏过的广告计划ID；</p><ul><li>customerId:脱敏过的广告主ID；</li></ul></li><li><p>brandId：脱敏过的品牌ID；</p><p>以上四个特征均属于分类特征，但由于分类值个数均过于庞大，如果去做热独编码处理，会导致数据过于稀疏 且当前我们缺少对这些特征更加具体的信息，（如商品类目具体信息、品牌具体信息等），从而无法对这些特征的数据做聚类、降维处理 因此这里不选取它们作为特征</p><p>而只选取price作为特征数据，因为价格本身是一个统计类型连续数值型数据，且能很好的体现广告的价值属性特征，通常也不需要做其他处理(离散化、归一化、标准化等)，所以这里直接将当做特征数据来使用</p></li></ul><h3 id="4-分析并预处理user-profile数据集"><a href="#4-分析并预处理user-profile数据集" class="headerlink" title="4. 分析并预处理user_profile数据集"></a>4. 分析并预处理user_profile数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从HDFS加载用户基本信息数据</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/user_profile.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 发现pvalue_level和new_user_class_level存在空值：（注意此处的null表示空值，而如果是NULL，则往往表示是一个字符串）</span></span><br><span class="line"><span class="comment"># 因此直接利用schema就可以加载进该数据，无需替换null值</span></span><br><span class="line">df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+---------------------+</span><br><span class="line">|userid|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level |</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+---------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|        null|             3|         0|                    3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                    2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                 null|</span><br><span class="line">|  1670|        0|           4|                2|        4|        null|             1|         0|                 null|</span><br><span class="line">|  2545|        0|          10|                1|        4|        null|             3|         0|                 null|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                    2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                    2|</span><br><span class="line">|  6211|        0|           9|                1|        3|        null|             3|         0|                    2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                    4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                    1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                    2|</span><br><span class="line">|  9293|        0|           5|                2|        5|        null|             3|         0|                    4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                    2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                    2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                 null|</span><br><span class="line">| 10812|        0|           4|                2|        4|        null|             2|         0|                 null|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                 null|</span><br><span class="line">| 10996|        0|           5|                2|        5|        null|             3|         0|                    4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                    3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                    4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+---------------------+</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：这里的null会直接被pyspark识别为None数据，也就是na数据，所以这里可以直接利用schema导入数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建表结构schema对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),  </span><br><span class="line">    StructField(<span class="string">&quot;cms_segid&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cms_group_id&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;final_gender_code&quot;</span>, IntegerType()),  <span class="comment"># 性别</span></span><br><span class="line">    StructField(<span class="string">&quot;age_level&quot;</span>, IntegerType()),          <span class="comment"># 年龄范围 </span></span><br><span class="line">    StructField(<span class="string">&quot;pvalue_level&quot;</span>, IntegerType()),       <span class="comment"># 消费档次</span></span><br><span class="line">    StructField(<span class="string">&quot;shopping_level&quot;</span>, IntegerType()),     <span class="comment"># 购物频繁程度</span></span><br><span class="line">    StructField(<span class="string">&quot;occupation&quot;</span>, IntegerType()),         <span class="comment"># 是否是大学生</span></span><br><span class="line">    StructField(<span class="string">&quot;new_user_class_level&quot;</span>, IntegerType()) <span class="comment"># 居住城市水平</span></span><br><span class="line">])</span><br><span class="line"><span class="comment"># 利用schema从hdfs加载</span></span><br><span class="line">user_profile_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/csv/user_profile.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">user_profile_df.printSchema()</span><br><span class="line">user_profile_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: integer (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|        null|             3|         0|                   3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                null|</span><br><span class="line">|  1670|        0|           4|                2|        4|        null|             1|         0|                null|</span><br><span class="line">|  2545|        0|          10|                1|        4|        null|             3|         0|                null|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6211|        0|           9|                1|        3|        null|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|        null|             3|         0|                   4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 10812|        0|           4|                2|        4|        null|             2|         0|                null|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 10996|        0|           5|                2|        5|        null|             3|         0|                   4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>显示特征情况</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;分类特征值个数情况: &quot;</span>)</span><br><span class="line">print(<span class="string">&quot;cms_segid: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;cms_segid&quot;</span>).count().count())</span><br><span class="line">print(<span class="string">&quot;cms_group_id: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;cms_group_id&quot;</span>).count().count())</span><br><span class="line">print(<span class="string">&quot;final_gender_code: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;final_gender_code&quot;</span>).count().count())</span><br><span class="line">print(<span class="string">&quot;age_level: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;age_level&quot;</span>).count().count())</span><br><span class="line">print(<span class="string">&quot;shopping_level: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;shopping_level&quot;</span>).count().count())</span><br><span class="line">print(<span class="string">&quot;occupation: &quot;</span>, user_profile_df.groupBy(<span class="string">&quot;occupation&quot;</span>).count().count())</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;含缺失值的特征情况: &quot;</span>)</span><br><span class="line">user_profile_df.groupBy(<span class="string">&quot;pvalue_level&quot;</span>).count().show()</span><br><span class="line">user_profile_df.groupBy(<span class="string">&quot;new_user_class_level&quot;</span>).count().show()</span><br><span class="line"></span><br><span class="line">t_count = user_profile_df.count()</span><br><span class="line">pl_na_count = t_count - user_profile_df.dropna(subset=[<span class="string">&quot;pvalue_level&quot;</span>]).count()</span><br><span class="line">print(<span class="string">&quot;pvalue_level的空值情况：&quot;</span>, pl_na_count, <span class="string">&quot;空值占比：%0.2f%%&quot;</span>%(pl_na_count/t_count*<span class="number">100</span>))</span><br><span class="line">nul_na_count = t_count - user_profile_df.dropna(subset=[<span class="string">&quot;new_user_class_level&quot;</span>]).count()</span><br><span class="line">print(<span class="string">&quot;new_user_class_level的空值情况：&quot;</span>, nul_na_count, <span class="string">&quot;空值占比：%0.2f%%&quot;</span>%(nul_na_count/t_count*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><p>显示内容:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">分类特征值个数情况: </span><br><span class="line">cms_segid:  97</span><br><span class="line">cms_group_id:  13</span><br><span class="line">final_gender_code:  2</span><br><span class="line">age_level:  7</span><br><span class="line">shopping_level:  3</span><br><span class="line">occupation:  2</span><br><span class="line">含缺失值的特征情况: </span><br><span class="line">+------------+------+</span><br><span class="line">|pvalue_level| count|</span><br><span class="line">+------------+------+</span><br><span class="line">|        null|575917|</span><br><span class="line">|           1|154436|</span><br><span class="line">|           3| 37759|</span><br><span class="line">|           2|293656|</span><br><span class="line">+------------+------+</span><br><span class="line"></span><br><span class="line">+--------------------+------+</span><br><span class="line">|new_user_class_level| count|</span><br><span class="line">+--------------------+------+</span><br><span class="line">|                null|344920|</span><br><span class="line">|                   1| 80548|</span><br><span class="line">|                   3|173047|</span><br><span class="line">|                   4|138833|</span><br><span class="line">|                   2|324420|</span><br><span class="line">+--------------------+------+</span><br><span class="line"></span><br><span class="line">pvalue_level的空值情况： 575917 空值占比：54.24%</span><br><span class="line">new_user_class_level的空值情况： 344920 空值占比：32.49%</span><br></pre></td></tr></table></figure><ul><li><p>缺失值处理</p><ul><li><p>注意，一般情况下：</p><ul><li>缺失率低于10%：可直接进行相应的填充，如默认值、均值、算法拟合等等；</li><li>高于10%：往往会考虑舍弃该特征</li><li>特征处理，如1维转多维</li></ul><p>但根据我们的经验，我们的广告推荐其实和用户的消费水平、用户所在城市等级都有比较大的关联，因此在这里pvalue_level、new_user_class_level都是比较重要的特征，我们不考虑舍弃</p></li></ul></li><li><p>缺失值处理方案：</p><ul><li>填充方案：结合用户的其他特征值，利用随机森林算法进行预测；但产生了大量人为构建的数据，一定程度上增加了数据的噪音</li><li>把变量映射到高维空间：如pvalue_level的1维数据，转换成是否1、是否2、是否3、是否缺失的4维数据；这样保证了所有原始数据不变，同时能提高精确度，但这样会导致数据变得比较稀疏，如果样本量很小，反而会导致样本效果较差，因此也不能滥用</li></ul></li><li><p>填充方案</p><ul><li>利用随机森林对pvalue_level的缺失值进行预测</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># pyspark.mllib是基于RDD的，需要将数据先转化为RDD,转化时需要有特定的格式.</span></span><br><span class="line"><span class="comment"># 剔除掉缺失值数据，将余下的数据作为训练数据</span></span><br><span class="line"><span class="comment"># user_profile_df.dropna(subset=[&quot;pvalue_level&quot;])： 将pvalue_level中的空值所在行数据剔除后的数据，作为训练样本</span></span><br><span class="line">train_data = user_profile_df.dropna(subset=[<span class="string">&quot;pvalue_level&quot;</span>]).rdd.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> r:LabeledPoint(r.pvalue_level-<span class="number">1</span>, [r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation]) <span class="comment"># 目标值是从1开始。要求是从零开始，所以减一。</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意随机森林输入数据时，由于label的分类数是从0开始的，但pvalue_level的目前只分别是1，2，3，所以需要对应分别-1来作为目标值</span></span><br><span class="line"><span class="comment"># 自然那么最终得出预测值后，需要对应+1才能还原回来</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 我们使用cms_segid, cms_group_id, final_gender_code, age_level, shopping_level, occupation作为特征值，pvalue_level作为目标值</span></span><br></pre></td></tr></table></figure><ul><li>Labeled point</li></ul><p>A labeled point is a local vector, either dense or sparse, associated with a label/response. In MLlib, labeled points are used in supervised learning algorithms. We use a double to store a label, so we can use labeled points in both regression and classification. For binary classification, a label should be either 0 (negative) or 1 (positive). For multiclass classification, labels should be class indices starting from zero: 0, 1, 2, ….<br>标记点是与标签/响应相关联的密集或稀疏的局部矢量。在MLlib中，标记点用于监督学习算法。我们使用double来存储标签，因此我们可以在回归和分类中使用标记点。对于二分类，标签应为0（负）或1（正）。对于多类分类，标签应该是从零开始的类索引：0, 1, 2, …。</p><p><strong>Python</strong><br>A labeled point is represented by LabeledPoint.<br>标记点表示为 LabeledPoint。<br>Refer to the LabeledPoint Python docs for more details on the API.<br>有关API的更多详细信息，请参阅LabeledPointPython文档。</p><p><strong>如何创建LabeledPoint的数据格式呢？这里给个例子！</strong></p><p>每个样本都可以准备一个LabeledPoint，把一堆LabeledPoint交给模型进行处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.linalg <span class="keyword">import</span> SparseVector</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a labeled point with a positive label and a dense feature vector.</span></span><br><span class="line">pos = LabeledPoint(<span class="number">1.0</span>, [<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>]) <span class="comment"># 前一个1.0为目标值，后边的列表为特征——此处为稠密表示</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a labeled point with a negative label and a sparse feature vector.</span></span><br><span class="line">neg = LabeledPoint(<span class="number">0.0</span>, SparseVector(<span class="number">3</span>, [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">1.0</span>, <span class="number">3.0</span>]))  <span class="comment"># 此处为稀疏的表示</span></span><br></pre></td></tr></table></figure><ul><li>随机森林：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=randomforest#pyspark.mllib.tree.RandomForest">pyspark.mllib.tree.RandomForest</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> RandomForest</span><br><span class="line"><span class="comment"># 训练分类模型</span></span><br><span class="line"><span class="comment"># 参数1 训练的数据</span></span><br><span class="line"><span class="comment"># 参数2 目标值的分类个数 0,1,2</span></span><br><span class="line"><span class="comment"># 参数3 特征中是否包含分类的特征 &#123;2:2,3:7&#125; &#123;2:2&#125; 表示 在特征中 第三个特征是分类的: 有两个分类</span></span><br><span class="line"><span class="comment"># 参数4 随机森林中 树的棵数</span></span><br><span class="line">model = RandomForest.trainClassifier(train_data, <span class="number">3</span>, &#123;&#125;, <span class="number">5</span>)</span><br></pre></td></tr></table></figure><ul><li>随机森林模型：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=randomforest#pyspark.mllib.tree.RandomForestModel">pyspark.mllib.tree.RandomForestModel</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测单个数据</span></span><br><span class="line"><span class="comment"># 注意用法：https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=tree%20random#pyspark.mllib.tree.RandomForestModel.predict</span></span><br><span class="line">model.predict([<span class="number">0.0</span>, <span class="number">4.0</span> ,<span class="number">2.0</span> , <span class="number">4.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>])</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.0</span><br></pre></td></tr></table></figure><p>接下来进行有缺失值的预测。</p><ul><li>筛选出缺失值条目</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">pl_na_df = user_profile_df.na.fill(-<span class="number">1</span>).where(<span class="string">&quot;pvalue_level=-1&quot;</span>)</span><br><span class="line">pl_na_df.show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="keyword">return</span> r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为普通的rdd类型 MLlib都是基于 RDD 的、</span></span><br><span class="line">rdd = pl_na_df.rdd.<span class="built_in">map</span>(row)</span><br><span class="line"><span class="comment"># 预测全部的pvalue_level值:</span></span><br><span class="line">predicts = model.predict(rdd)</span><br><span class="line"><span class="comment"># 查看前20条</span></span><br><span class="line">print(predicts.take(<span class="number">20</span>))</span><br><span class="line">print(<span class="string">&quot;预测值总数&quot;</span>, predicts.count())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里注意predict参数，如果是预测多个，那么参数必须是直接由列表构成的rdd参数，而不能是dataframe.rdd类型</span></span><br><span class="line"><span class="comment"># 因此这里经过map函数处理，将每一行数据转换为普通的列表数据</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 11602|        0|           5|                2|        5|          -1|             3|         0|                   2|</span><br><span class="line">| 11727|        0|           3|                2|        3|          -1|             3|         0|                   1|</span><br><span class="line">| 12195|        0|          10|                1|        4|          -1|             3|         0|                   2|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]</span><br><span class="line">预测值总数 575917</span><br></pre></td></tr></table></figure><ul><li>转换为pandas dataframe</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里数据量比较小，直接转换为pandas dataframe来处理，因为方便，但注意如果数据量较大不推荐，因为这样会把全部数据加载到内存中</span></span><br><span class="line">temp = predicts.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:<span class="built_in">int</span>(x)).collect()</span><br><span class="line">pdf = pl_na_df.toPandas()</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> <span class="comment"># 在pandas df的基础上直接替换掉列数据</span></span><br><span class="line">pdf[<span class="string">&quot;pvalue_level&quot;</span>] = np.array(temp) + <span class="number">1</span>  <span class="comment"># 注意+1 还原预测值（前面减1了。）</span></span><br><span class="line">pdf</span><br></pre></td></tr></table></figure><ul><li>与非缺失数据进行拼接，完成pvalue_level的缺失值预测</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">new_user_profile_df = user_profile_df.dropna(subset=[<span class="string">&quot;pvalue_level&quot;</span>]).unionAll(spark.createDataFrame(pdf, schema=schema))</span><br><span class="line">new_user_profile_df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：unionAll的使用，两个df的表结构必须完全一样</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                null|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">| 11739|       20|           3|                2|        3|           2|             3|         0|                   4|</span><br><span class="line">| 12549|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 15155|       36|           5|                2|        5|           2|             1|         0|                null|</span><br><span class="line">| 15347|       20|           3|                2|        3|           2|             3|         0|                   3|</span><br><span class="line">| 15455|        8|           2|                2|        2|           2|             3|         0|                   3|</span><br><span class="line">| 15783|        0|           4|                2|        4|           2|             3|         0|                null|</span><br><span class="line">| 16749|        5|           2|                2|        2|           1|             3|         1|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>利用随机森林对new_user_class_level的缺失值进行预测</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.mllib.regression <span class="keyword">import</span> LabeledPoint</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选出new_user_class_level全部的</span></span><br><span class="line">train_data2 = user_profile_df.dropna(subset=[<span class="string">&quot;new_user_class_level&quot;</span>]).rdd.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> r:LabeledPoint(r.new_user_class_level - <span class="number">1</span>, [r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation])</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> pyspark.mllib.tree <span class="keyword">import</span> RandomForest</span><br><span class="line">model2 = RandomForest.trainClassifier(train_data2, <span class="number">4</span>, &#123;&#125;, <span class="number">5</span>)</span><br><span class="line">model2.predict([<span class="number">0.0</span>, <span class="number">4.0</span> ,<span class="number">2.0</span> , <span class="number">4.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>])</span><br><span class="line"><span class="comment"># 预测值实际应该为2</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1.0</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">nul_na_df = user_profile_df.na.fill(-<span class="number">1</span>).where(<span class="string">&quot;new_user_class_level=-1&quot;</span>)</span><br><span class="line">nul_na_df.show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="keyword">return</span> r.cms_segid, r.cms_group_id, r.final_gender_code, r.age_level, r.shopping_level, r.occupation</span><br><span class="line"></span><br><span class="line">rdd2 = nul_na_df.rdd.<span class="built_in">map</span>(row)</span><br><span class="line">predicts2 = model.predict(rdd2)</span><br><span class="line">predicts2.take(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><ul><li>显示结果:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 12620|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 14437|        0|           5|                2|        5|          -1|             3|         0|                  -1|</span><br><span class="line">| 14574|        0|           1|                2|        1|          -1|             2|         0|                  -1|</span><br><span class="line">| 14985|        0|          11|                1|        5|          -1|             2|         0|                  -1|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 10 rows</span><br><span class="line"></span><br><span class="line">[1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 1.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 0.0,</span><br><span class="line"> 1.0]</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>总结：可以发现由于这两个字段的缺失过多，所以预测出来的值已经大大失真，但如果缺失率在10%以下，这种方法是比较有效的一种</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">user_profile_df = user_profile_df.na.fill(-<span class="number">1</span>)</span><br><span class="line">user_profile_df.show()</span><br><span class="line"><span class="comment"># new_df = new_df.withColumn(&quot;pvalue_level&quot;, new_df.pvalue_level.cast(StringType()))\</span></span><br><span class="line"><span class="comment">#     .withColumn(&quot;new_user_class_level&quot;, new_df.new_user_class_level.cast(StringType()))</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>低维转高维方式<ul><li>我们接下来采用将变量映射到高维空间的方法来处理数据，即将缺失项也当做一个单独的特征来对待，保证数据的原始性<br>由于该思想正好和热独编码实现方法一样，因此这里直接使用热独编码方式处理数据</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用热独编码转换pvalue_level的一维数据为多维，其中缺失值单独作为一个特征值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要先将缺失值全部替换为数值，与原有特征一起处理</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line">user_profile_df = user_profile_df.na.fill(-<span class="number">1</span>)</span><br><span class="line">user_profile_df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 热独编码时，必须先将待处理字段转为字符串类型才可处理</span></span><br><span class="line">user_profile_df = user_profile_df.withColumn(<span class="string">&quot;pvalue_level&quot;</span>, user_profile_df.pvalue_level.cast(StringType()))\</span><br><span class="line">    .withColumn(<span class="string">&quot;new_user_class_level&quot;</span>, user_profile_df.new_user_class_level.cast(StringType()))</span><br><span class="line">user_profile_df.printSchema()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对pvalue_level进行热独编码，求值</span></span><br><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;pvalue_level&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;pl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;pl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(user_profile_df)</span><br><span class="line">user_profile_df2 = pipeline_fit.transform(user_profile_df)</span><br><span class="line"><span class="comment"># pl_onehot_value列的值为稀疏向量，存储热独编码的结果</span></span><br><span class="line">user_profile_df2.printSchema()</span><br><span class="line">user_profile_df2.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: string (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: string (nullable = true)</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cms_segid: integer (nullable = true)</span><br><span class="line"> |-- cms_group_id: integer (nullable = true)</span><br><span class="line"> |-- final_gender_code: integer (nullable = true)</span><br><span class="line"> |-- age_level: integer (nullable = true)</span><br><span class="line"> |-- pvalue_level: string (nullable = true)</span><br><span class="line"> |-- shopping_level: integer (nullable = true)</span><br><span class="line"> |-- occupation: integer (nullable = true)</span><br><span class="line"> |-- new_user_class_level: string (nullable = true)</span><br><span class="line"> |-- pl_onehot_feature: double (nullable = false)</span><br><span class="line"> |-- pl_onehot_value: vector (nullable = true)</span><br><span class="line"></span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>使用热编码转换new_user_class_level的一维数据为多维</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stringindexer = StringIndexer(inputCol=<span class="string">&#x27;new_user_class_level&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>)</span><br><span class="line">encoder = OneHotEncoder(dropLast=<span class="literal">False</span>, inputCol=<span class="string">&#x27;nucl_onehot_feature&#x27;</span>, outputCol=<span class="string">&#x27;nucl_onehot_value&#x27;</span>)</span><br><span class="line">pipeline = Pipeline(stages=[stringindexer, encoder])</span><br><span class="line">pipeline_fit = pipeline.fit(user_profile_df2)</span><br><span class="line">user_profile_df3 = pipeline_fit.transform(user_profile_df2)</span><br><span class="line">user_profile_df3.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|nucl_onehot_feature|nucl_onehot_value|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|                4.0|    (5,[4],[1.0])|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|                2.0|    (5,[2],[1.0])|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>用户特征合并<ul><li>LR回归用的是 <code>pyspark.ml</code>它要求所有的特征放在一个向量里面。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line">feature_df = VectorAssembler().setInputCols([<span class="string">&quot;age_level&quot;</span>, <span class="string">&quot;pl_onehot_value&quot;</span>, <span class="string">&quot;nucl_onehot_value&quot;</span>]).setOutputCol(<span class="string">&quot;features&quot;</span>).transform(user_profile_df3)</span><br><span class="line">feature_df.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+--------------------+</span><br><span class="line">|userId|cms_segid|cms_group_id|final_gender_code|age_level|pvalue_level|shopping_level|occupation|new_user_class_level|pl_onehot_feature|pl_onehot_value|nucl_onehot_feature|nucl_onehot_value|            features|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+--------------------+</span><br><span class="line">|   234|        0|           5|                2|        5|          -1|             3|         0|                   3|              0.0|  (4,[0],[1.0])|                2.0|    (5,[2],[1.0])|(10,[0,1,7],[5.0,...|</span><br><span class="line">|   523|        5|           2|                2|        2|           1|             3|         1|                   2|              2.0|  (4,[2],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,3,6],[2.0,...|</span><br><span class="line">|   612|        0|           8|                1|        2|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,2,5],[2.0,...|</span><br><span class="line">|  1670|        0|           4|                2|        4|          -1|             1|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,1,5],[4.0,...|</span><br><span class="line">|  2545|        0|          10|                1|        4|          -1|             3|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,1,5],[4.0,...|</span><br><span class="line">|  3644|       49|           6|                2|        6|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[6.0,...|</span><br><span class="line">|  5777|       44|           5|                2|        5|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[5.0,...|</span><br><span class="line">|  6211|        0|           9|                1|        3|          -1|             3|         0|                   2|              0.0|  (4,[0],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,1,6],[3.0,...|</span><br><span class="line">|  6355|        2|           1|                2|        1|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,3,8],[1.0,...|</span><br><span class="line">|  6823|       43|           5|                2|        5|           2|             3|         0|                   1|              1.0|  (4,[1],[1.0])|                4.0|    (5,[4],[1.0])|(10,[0,2,9],[5.0,...|</span><br><span class="line">|  6972|        5|           2|                2|        2|           2|             3|         1|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[2.0,...|</span><br><span class="line">|  9293|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,1,8],[5.0,...|</span><br><span class="line">|  9510|       55|           8|                1|        2|           2|             2|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[2.0,...|</span><br><span class="line">| 10122|       33|           4|                2|        4|           2|             3|         0|                   2|              1.0|  (4,[1],[1.0])|                1.0|    (5,[1],[1.0])|(10,[0,2,6],[4.0,...|</span><br><span class="line">| 10549|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,2,5],[4.0,...|</span><br><span class="line">| 10812|        0|           4|                2|        4|          -1|             2|         0|                  -1|              0.0|  (4,[0],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,1,5],[4.0,...|</span><br><span class="line">| 10912|        0|           4|                2|        4|           2|             3|         0|                  -1|              1.0|  (4,[1],[1.0])|                0.0|    (5,[0],[1.0])|(10,[0,2,5],[4.0,...|</span><br><span class="line">| 10996|        0|           5|                2|        5|          -1|             3|         0|                   4|              0.0|  (4,[0],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,1,8],[5.0,...|</span><br><span class="line">| 11256|        8|           2|                2|        2|           1|             3|         0|                   3|              2.0|  (4,[2],[1.0])|                2.0|    (5,[2],[1.0])|(10,[0,3,7],[2.0,...|</span><br><span class="line">| 11310|       31|           4|                2|        4|           1|             3|         0|                   4|              2.0|  (4,[2],[1.0])|                3.0|    (5,[3],[1.0])|(10,[0,3,8],[4.0,...|</span><br><span class="line">+------+---------+------------+-----------------+---------+------------+--------------+----------+--------------------+-----------------+---------------+-------------------+-----------------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">feature_df.select(<span class="string">&quot;features&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+</span><br><span class="line">|            features|</span><br><span class="line">+--------------------+</span><br><span class="line">|(10,[0,1,7],[5.0,...|</span><br><span class="line">|(10,[0,3,6],[2.0,...|</span><br><span class="line">|(10,[0,2,5],[2.0,...|</span><br><span class="line">|(10,[0,1,5],[4.0,...|</span><br><span class="line">|(10,[0,1,5],[4.0,...|</span><br><span class="line">|(10,[0,2,6],[6.0,...|</span><br><span class="line">|(10,[0,2,6],[5.0,...|</span><br><span class="line">|(10,[0,1,6],[3.0,...|</span><br><span class="line">|(10,[0,3,8],[1.0,...|</span><br><span class="line">|(10,[0,2,9],[5.0,...|</span><br><span class="line">|(10,[0,2,6],[2.0,...|</span><br><span class="line">|(10,[0,1,8],[5.0,...|</span><br><span class="line">|(10,[0,2,6],[2.0,...|</span><br><span class="line">|(10,[0,2,6],[4.0,...|</span><br><span class="line">|(10,[0,2,5],[4.0,...|</span><br><span class="line">|(10,[0,1,5],[4.0,...|</span><br><span class="line">|(10,[0,2,5],[4.0,...|</span><br><span class="line">|(10,[0,1,8],[5.0,...|</span><br><span class="line">|(10,[0,3,7],[2.0,...|</span><br><span class="line">|(10,[0,3,8],[4.0,...|</span><br><span class="line">+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>特征选取</li></ul><p>除了前面处理的pvalue_level和new_user_class_level需要作为特征以外，(能体现出用户的购买力特征)，还有：</p><p>前面分析的以下几个分类特征值个数情况:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- cms_segid:  97</span><br><span class="line">- cms_group_id:  13</span><br><span class="line">- final_gender_code:  2</span><br><span class="line">- age_level:  7</span><br><span class="line">- shopping_level:  3</span><br><span class="line">- occupation:  2</span><br><span class="line">-pvalue_level</span><br><span class="line">-new_user_class_level</span><br><span class="line">-price</span><br></pre></td></tr></table></figure><p>根据经验，以上几个分类特征都一定程度能体现用户在购物方面的特征，且类别都较少，都可以用来作为用户特征</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><ul><li>连续的特征<ul><li>缺失比例比较严重 可以考虑舍弃</li><li>可以考虑使用平均值 中位数 分位数填充</li><li>算法预测 （利用样本中的其它特征作为 特征值，有缺失的特征作为目标值）</li></ul></li><li>分类的特征<ul><li>缺失比例比较严重 可以考虑舍弃</li><li>把缺失作为单独的分类， 如果之前的数据只有两个分类，那么把缺失考虑进来就变成3个分类</li><li>算法预测</li></ul></li><li>利用算法预测缺失值<ul><li>其它特征和要预测的特征之间是否有联系</li><li>样本数据是否足够</li><li>利用算法预测缺失值会引入噪声</li></ul></li></ul><h3 id="利用随机森林预测缺失值"><a href="#利用随机森林预测缺失值" class="headerlink" title="利用随机森林预测缺失值"></a>利用随机森林预测缺失值</h3><ul><li>pyspark MLlib<ul><li>基于RDD的</li><li>监督学习的样本数据要创建成LabeledPoint对象，MLlib通过LabeledPoint来训练模型</li><li>pos = LabeledPoint(目标, [特征list])<ul><li>目标值是分类情况 分类值从0开始连续增加</li><li>所有特征是double类型</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;CTR预估数据准备&quot;&gt;&lt;a href=&quot;#CTR预估数据准备&quot; class=&quot;headerlink&quot; title=&quot;CTR预估数据准备&quot;&gt;&lt;/a&gt;CTR预估数据准备&lt;/h2&gt;&lt;h3 id=&quot;1-分析并预处理raw-sample数据集&quot;&gt;&lt;a href=&quot;#1-分析</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>12-二叉树的路径问题汇总</title>
    <link href="https://xxren8218.github.io/20210709/12-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html"/>
    <id>https://xxren8218.github.io/20210709/12-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html</id>
    <published>2021-07-09T13:51:32.000Z</published>
    <updated>2021-07-09T14:01:05.938Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的路径问题"><a href="#二叉树的路径问题" class="headerlink" title="二叉树的路径问题"></a>二叉树的路径问题</h2><p>对于刚刚接触树的问题的新手而言，路径问题是一个比较棘手的问题。题解中关于二叉树路径问题的总结还偏少，今天我用一篇文章总结一下二叉树的路径问题。学透这篇文章，二叉树路径题可以秒杀</p><h3 id="1-问题分类"><a href="#1-问题分类" class="headerlink" title="1.问题分类"></a>1.问题分类</h3><p>二叉树路径的问题大致可以分为两类：</p><ul><li><p>自顶向下：<br>顾名思义，就是从某一个节点(不一定是根节点)，从上向下寻找路径，到某一个节点(不一定是叶节点)结束<br>具体题目如下：</p><p>257.二叉树的所有路径</p><p>面试题 04.12. 求和路径</p><p>112.路径总和</p><p>113.路径总和 II</p><p>437.路径总和 III</p><p>988.从叶结点开始的最小字符串</p></li></ul><p>而继续细分的话还可以分成一般路径与给定和的路径</p><ul><li>非自顶向下：<br>就是从任意节点到任意节点的路径，不需要自顶向下<br>124.二叉树中的最大路径和<br>125.最长同值路径<br>126.二叉树的直径</li></ul><h3 id="2-解题模板"><a href="#2-解题模板" class="headerlink" title="2.解题模板"></a>2.解题模板</h3><p>这类题通常用深度优先搜索(DFS)和广度优先搜索(BFS)解决，BFS较DFS繁琐，这里为了简洁只展现DFS代码<br>下面是我对两类题目的分析与模板</p><h4 id="一、自顶而下："><a href="#一、自顶而下：" class="headerlink" title="一、自顶而下："></a>一、自顶而下：</h4><p>DFS</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##########</span></span><br><span class="line"><span class="comment">#一般路径：#</span></span><br><span class="line"><span class="comment">##########</span></span><br><span class="line">res = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, path</span>)：</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span>  <span class="comment"># 根节点为空直接返回</span></span><br><span class="line">    path.append(root.val)  <span class="comment"># 作出选择</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right: <span class="comment"># 如果到叶节点  </span></span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    dfs(root.left,path)   <span class="comment"># 继续递归</span></span><br><span class="line">    dfs(root.right,path) </span><br><span class="line"></span><br><span class="line"><span class="comment">##############</span></span><br><span class="line"><span class="comment"># 给定和的路径：#</span></span><br><span class="line"><span class="comment">##############</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, Sum, path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    Sum -= root.val</span><br><span class="line">    path.append(root.val)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> Sum == <span class="number">0</span>:</span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"> </span><br><span class="line">    dfs(root.left, Sum, path)</span><br><span class="line">    dfs(root.right, Sum, path)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>这类题型DFS注意点：</strong></p><ol><li><p>如果是找路径和等于给定target的路径的，那么可以不用新增一个临时变量cursum来判断当前路径和，<br>只需要用给定和target减去节点值，最终结束条件判断 target==0 即可</p></li><li><p>是否要回溯：二叉树的问题大部分是不需要回溯的，原因如下：<br>二叉树的递归部分：dfs(root.left),dfs(root.right)已经把可能的路径穷尽了,<br>因此到任意叶节点的路径只可能有一条，绝对不可能出现另外的路径也到这个满足条件的叶节点的;</p><p>而对比二维数组(例如迷宫问题)的DFS,for循环向四个方向查找每次只能朝向一个方向，并没有穷尽路径，<br>因此某一个满足条件的点可能是有多条路径到该点的</p><p>并且visited数组标记已经走过的路径是会受到另外路径是否访问的影响，这时候必须回溯</p></li><li><p>找到路径后是否要return:<br>取决于题目是否要求找到叶节点满足条件的路径,如果必须到叶节点,那么就要return;<br>但如果是到任意节点都可以，那么必不能return,因为这条路径下面还可能有更深的路径满足条件，还要在此基础上继续递归</p></li><li><p>是否要双重递归(即调用根节点的dfs函数后，继续调用根左右节点的pathsum函数)：看题目要不要求从根节点开始的，还是从任意节点开始</p></li></ol><h4 id="二、非自顶而下："><a href="#二、非自顶而下：" class="headerlink" title="二、非自顶而下："></a>二、非自顶而下：</h4><p>这类题目一般解题思路如下：<br>设计一个辅助函数<code>maxpath</code>，调用自身求出以一个节点为根节点的左侧最长路径left和右侧最长路径right，那么经过该节点的最长路径就是left+right<br>接着只需要从根节点开始dfs,不断比较更新全局变量即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">root</span>) # 以<span class="title">root</span>为路径起始点的最长路径</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = maxPath(root.left)</span><br><span class="line">    right = maxPath(root.right)</span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right + root.val) <span class="comment"># 更新全局变量  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left, right)   <span class="comment"># 返回左右路径较长者</span></span><br></pre></td></tr></table></figure><p>这类题型DFS注意点：</p><ol><li><p>left,right代表的含义要根据题目所求设置，比如最长路径、最大路径和等等</p></li><li><p>全局变量res的初值设置是0还是INT_MIN要看题目节点是否存在负值,如果存在就用INT_MIN，否则就是0</p></li><li><p>注意两点之间路径为1，因此一个点是不能构成路径的</p></li></ol><h4 id="题目分析"><a href="#题目分析" class="headerlink" title="题目分析"></a>题目分析</h4><p>下面是对具体题目的分析和代码呈现</p><h4 id="一、自顶向下"><a href="#一、自顶向下" class="headerlink" title="一、自顶向下"></a>一、自顶向下</h4><p>257.二叉树的所有路径</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215304.PNG" alt=""></p><p>直接套用模板1即可，注意把”-&gt;”放在递归调用中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">root</span>):</span></span><br><span class="line">    dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    path += <span class="built_in">str</span>(root.val)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    dfs(root.left, path+<span class="string">&quot;-&gt;&quot;</span>)</span><br><span class="line">    dfs(root.right, path+<span class="string">&quot;-&gt;&quot;</span>)</span><br></pre></td></tr></table></figure><p>答题代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        path = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        self.dfs(root, path)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, root, path</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        path += <span class="built_in">str</span>(root.val)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">            self.res.append(path)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.dfs(root.left, path + <span class="string">&#x27;-&gt;&#x27;</span>)</span><br><span class="line">        self.dfs(root.right, path + <span class="string">&#x27;-&gt;&#x27;</span>)</span><br></pre></td></tr></table></figure><p>113.路径总和 II</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215332.PNG" alt=""></p><p>直接套用模板2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">res = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">root, targetSum</span>):</span></span><br><span class="line">    path = []</span><br><span class="line">    dfs(root, path, targetSum)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, path, Sum</span>)</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    Sum -= root.val</span><br><span class="line">    <span class="comment"># path.append(root.val)</span></span><br><span class="line">    <span class="comment"># 注意此处传递的是引用，用append方法path的地址不会变，所以，出栈以后的函数的path值并不会减小，这里使用一个赋值语句来存储新增加的值。</span></span><br><span class="line">    <span class="comment"># ＋相当于extend方法。</span></span><br><span class="line">    path = path + [root.val]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> Sum == <span class="number">0</span>:</span><br><span class="line">        res.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">   </span><br><span class="line">    dfs(root.left, path, Sum)</span><br><span class="line">    dfs(root.right, path, Sum)</span><br></pre></td></tr></table></figure><p>完成代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">self, root, targetSum</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :type targetSum: int</span></span><br><span class="line"><span class="string">        :rtype: List[List[int]]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        path = []</span><br><span class="line">        self.dfs(root, path, targetSum)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, root, path, Sum</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        Sum -= root.val</span><br><span class="line">        path = path + [root.val]</span><br><span class="line">        <span class="comment"># path.append(root.val)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> Sum == <span class="number">0</span>:</span><br><span class="line">            self.res.append(path)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.dfs(root.left, path, Sum)</span><br><span class="line">        self.dfs(root.right, path, Sum)</span><br></pre></td></tr></table></figure><p>437.路径总和 III</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215348.PNG" alt=""></p><p>双重递归：先调用dfs函数从root开始查找路径，再调用pathsum函数到root左右子树开始查找<br>套用模板2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">root, targetSum</span>)</span></span><br><span class="line"><span class="function">    <span class="title">if</span> <span class="title">not</span> <span class="title">root</span>:</span> <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dfs1(root, targetSum)            <span class="comment"># 以root为起始点查找路径</span></span><br><span class="line">    pathSum(root.left, targetSum)    <span class="comment"># 左子树递归</span></span><br><span class="line">    pathSum(root.right, targetSum)   <span class="comment"># 右子树递归</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, Sum</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    Sum -= root.val</span><br><span class="line">    <span class="keyword">if</span> Sum == <span class="number">0</span>:    <span class="comment"># 注意不要return,因为不要求到叶节点结束,所以一条路径下面还可能有另一条</span></span><br><span class="line">        count += <span class="number">1</span>  <span class="comment"># 如果找到了一个路径全局变量就+1</span></span><br><span class="line">    dfs1(root.left, Sum)</span><br><span class="line">    dfs1(root.right, Sum)</span><br></pre></td></tr></table></figure><p>完成代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.count = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">self, root, targetSum</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :type targetSum: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        self.dfs1(root, targetSum)</span><br><span class="line">        self.pathSum(root.left, targetSum)</span><br><span class="line">        self.pathSum(root.right, targetSum)</span><br><span class="line">        <span class="keyword">return</span> self.count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs1</span>(<span class="params">self, root, <span class="built_in">sum</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        <span class="built_in">sum</span> -= root.val</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span> == <span class="number">0</span>:</span><br><span class="line">            self.count += <span class="number">1</span></span><br><span class="line">        self.dfs1(root.left, <span class="built_in">sum</span>)</span><br><span class="line">        self.dfs1(root.right, <span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure><p>988.从叶结点开始的最小字符串</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215401.PNG" alt=""></p><p>换汤不换药，套用模板1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">path = []</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smallestFromLeaf</span>(<span class="params">root</span>):</span></span><br><span class="line"></span><br><span class="line">    dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    path = path.sort() <span class="comment"># 升序排序</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> path[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, s</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">    s += <span class="built_in">chr</span>(<span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>) + root.val)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">        </span><br><span class="line">        s = s[::-<span class="number">1</span>]  <span class="comment"># 题目要求从叶子节点到根节点，因此反转</span></span><br><span class="line">        path.append(s)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    dfs(root.left, s)</span><br><span class="line">    dfs(root.right, s)</span><br></pre></td></tr></table></figure><p>整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.path = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">smallestFromLeaf</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        self.dfs(root, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line">        self.path.sort() <span class="comment"># 升序排序</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.path[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, root, s</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        s += <span class="built_in">chr</span>(<span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>) + root.val)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">            </span><br><span class="line">            s = s[::-<span class="number">1</span>]  <span class="comment"># 题目要求从叶子节点到根节点，因此反转</span></span><br><span class="line">            self.path.append(s)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        self.dfs(root.left, s)</span><br><span class="line">        self.dfs(root.right, s)</span><br></pre></td></tr></table></figure><h4 id="二、非自顶向下"><a href="#二、非自顶向下" class="headerlink" title="二、非自顶向下"></a>二、非自顶向下</h4><p>124.二叉树中的最大路径和right分别为根节点左右子树最大路径和,</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215415.PNG" alt=""></p><p>注意：如果最大路径和&lt;0,意味着该路径和对总路径和做负贡献，因此不要计入到总路径中，将它设置为0</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">res = -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="comment"># 注意节点值可能为负数，因此要设置为最小值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPathSum</span>(<span class="params">root</span>):</span></span><br><span class="line">    maxPath(root)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">root</span>):</span> <span class="comment"># 以root为路径起始点的最长路径</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = <span class="built_in">max</span>(maxPath(root.left), <span class="number">0</span>)</span><br><span class="line">    right = <span class="built_in">max</span>(maxPath(root.right), <span class="number">0</span>)</span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right + root.val)  <span class="comment"># 比较当前最大路径和与左右子树最长路径加上根节点值的较大值，更新全局变量</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left + root.val, right + root.val) <span class="comment"># 返回左右子树较大的路径和加上根节点值</span></span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = -<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxPathSum</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        self.maxPath(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left = <span class="built_in">max</span>(self.maxPath(root.left), <span class="number">0</span>)</span><br><span class="line">        right = <span class="built_in">max</span>(self.maxPath(root.right), <span class="number">0</span>)</span><br><span class="line">        self.res = <span class="built_in">max</span>(self.res, left + right + root.val)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(left + root.val, right + root.val)</span><br></pre></td></tr></table></figure><p>687.最长同值路径</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215433.PNG" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">longestUnivaluePath</span>(<span class="params">root</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    longestPath(root)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">longestPath</span>(<span class="params">root</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    left = longestPath(root.left) </span><br><span class="line">    right = longestPath(root.right)</span><br><span class="line">    <span class="comment"># 如果存在左子节点和根节点同值，更新左最长路径;否则左最长路径为0</span></span><br><span class="line">    <span class="keyword">if</span> root.left <span class="keyword">and</span> root.val == root.left.val:</span><br><span class="line">        left += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> root.right <span class="keyword">and</span> root.val == root.right.val:</span><br><span class="line">        right += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left, right)</span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestUnivaluePath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        self.longestPath(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestPath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left = self.longestPath(root.left)</span><br><span class="line">        right = self.longestPath(root.right)</span><br><span class="line">        <span class="keyword">if</span> root.left <span class="keyword">and</span> root.left.val == root.val:</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            left = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> root.right <span class="keyword">and</span> root.right.val == root.val:</span><br><span class="line">            right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right = <span class="number">0</span></span><br><span class="line">        self.res = <span class="built_in">max</span>(self.res, left + right)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(left, right)</span><br></pre></td></tr></table></figure><p>543.二叉树的直径</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709215446.PNG" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">diameterOfBinaryTree</span>(<span class="params">root</span>):</span></span><br><span class="line">    maxPath(root)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">root</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里递归结束条件要特别注意：不能是not root(而且不需要判断root为空,因为只有非空才会进入递归)，因为单个节点路径长也是0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right: </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 判断左子节点是否为空，从而更新左边最长路径</span></span><br><span class="line">    <span class="keyword">if</span> root.left:</span><br><span class="line">        left = maxPath(root.left) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> root.right:</span><br><span class="line">        right = maxPath(root.right) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    res = <span class="built_in">max</span>(res, left + right) <span class="comment"># 更新全局变量</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(left, right)      <span class="comment"># 返回左右路径较大者</span></span><br></pre></td></tr></table></figure><p>完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.res = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">diameterOfBinaryTree</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.maxPath(root)</span><br><span class="line">        <span class="keyword">return</span> self.res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxPath</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right: </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 判断左子节点是否为空，从而更新左边最长路径</span></span><br><span class="line">        <span class="keyword">if</span> root.left:</span><br><span class="line">            left = self.maxPath(root.left) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            left = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> root.right:</span><br><span class="line">            right = self.maxPath(root.right) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            right = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        self.res = <span class="built_in">max</span>(self.res, left + right) <span class="comment"># 更新全局变量</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(left, right)                <span class="comment"># 返回左右路径较大者</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的路径问题&quot;&gt;&lt;a href=&quot;#二叉树的路径问题&quot; class=&quot;headerlink&quot; title=&quot;二叉树的路径问题&quot;&gt;&lt;/a&gt;二叉树的路径问题&lt;/h2&gt;&lt;p&gt;对于刚刚接触树的问题的新手而言，路径问题是一个比较棘手的问题。题解中关于二叉树路径问题的总结</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>02-推荐系统实战之根据用户行为数据创建ALS模型并召回商品</title>
    <link href="https://xxren8218.github.io/20210709/02-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E6%A0%B9%E6%8D%AE%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E5%88%9B%E5%BB%BAALS%E6%A8%A1%E5%9E%8B%E5%B9%B6%E5%8F%AC%E5%9B%9E%E5%95%86%E5%93%81.html"/>
    <id>https://xxren8218.github.io/20210709/02-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E6%A0%B9%E6%8D%AE%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E6%95%B0%E6%8D%AE%E5%88%9B%E5%BB%BAALS%E6%A8%A1%E5%9E%8B%E5%B9%B6%E5%8F%AC%E5%9B%9E%E5%95%86%E5%93%81.html</id>
    <published>2021-07-08T17:00:30.000Z</published>
    <updated>2021-07-08T17:03:25.325Z</updated>
    
    <content type="html"><![CDATA[<h2 id="根据用户行为数据创建ALS模型并召回商品"><a href="#根据用户行为数据创建ALS模型并召回商品" class="headerlink" title="根据用户行为数据创建ALS模型并召回商品"></a>根据用户行为数据创建ALS模型并召回商品</h2><ul><li>打开HDFS，Hadoop下的sbin目录下的./start-dfs.sh</li><li>打开Spark, <ul><li>Spark下的sbin目录下的./start-master.sh -h 192.168.19.2</li><li>Spark下的sbin目录下的./start-slave.sh spark://192.168.19.2:7077</li><li>可以使用192.168.19.2:8080进行可视化查看</li></ul></li><li>进入虚拟环境 workon 虚拟环境名字（有所需的工具包：如jupyter notebook）<ul><li>jupyter notebook —ip 0.0.0.0</li></ul></li></ul><h3 id="0-用户行为数据拆分"><a href="#0-用户行为数据拆分" class="headerlink" title="0. 用户行为数据拆分"></a>0. 用户行为数据拆分</h3><ul><li><p>海量数据处理应该怎么办？2T数据的处理，不至于在Excel中处理吧。</p><ul><li>这里说一个面试题：给你2T的邮箱数据，如何去重排序？</li><li>外排序：分成多块，去重排序，然后再合并。</li></ul></li><li><p>方便练习可以对数据做拆分处理</p><ul><li>pandas的数据分批读取  chunk 厚厚的一块 相当大的数量或部分</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">reader = pd.read_csv(<span class="string">&#x27;behavior_log.csv&#x27;</span>,chunksize=<span class="number">100</span>,iterator=<span class="literal">True</span>) </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">chunksize  一次数据读多少条。</span></span><br><span class="line"><span class="string">iterator   是否返回可迭代对象。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> reader:</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">1</span>:</span><br><span class="line">        chunk.to_csv(<span class="string">&#x27;test4.csv&#x27;</span>,index = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># index = False 去掉自动添加行索引。保留列索引</span></span><br><span class="line">    <span class="keyword">elif</span> count &gt; <span class="number">1</span> <span class="keyword">and</span> count &lt; <span class="number">1000</span>:</span><br><span class="line">        chunk.to_csv(<span class="string">&#x27;test4.csv&#x27;</span>,index = <span class="literal">False</span>, mode = <span class="string">&#x27;a&#x27;</span>, header = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># mode = ‘a’ 表示追加模式，去掉自动添加行索引，去掉列索引。</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">pd.read_csv(<span class="string">&#x27;test4.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></li></ul><h3 id="1-预处理behavior-log数据集"><a href="#1-预处理behavior-log数据集" class="headerlink" title="1. 预处理behavior_log数据集"></a>1. 预处理behavior_log数据集</h3><p>创建Spark的连接，通过SparkSQL将数据加载进来，进行简单分析。</p><ul><li>创建spark session</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line"><span class="comment"># spark配置信息</span></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">SPARK_APP_NAME = <span class="string">&quot;preprocessingBehaviorLog&quot;</span></span><br><span class="line">SPARK_URL = <span class="string">&quot;spark://192.168.19.2:7077&quot;</span></span><br><span class="line"></span><br><span class="line">conf = SparkConf()    <span class="comment"># 创建spark config对象</span></span><br><span class="line">config = (</span><br><span class="line">(<span class="string">&quot;spark.app.name&quot;</span>, SPARK_APP_NAME),    <span class="comment"># 设置启动的spark的app名称，没有提供，将随机产生一个名称</span></span><br><span class="line">(<span class="string">&quot;spark.executor.memory&quot;</span>, <span class="string">&quot;6g&quot;</span>),    <span class="comment"># 设置该app启动时占用的内存用量，默认1g</span></span><br><span class="line">(<span class="string">&quot;spark.master&quot;</span>, SPARK_URL),    <span class="comment"># spark master的地址</span></span><br><span class="line">    (<span class="string">&quot;spark.executor.cores&quot;</span>, <span class="string">&quot;4&quot;</span>),    <span class="comment"># 设置spark executor使用的CPU核心数</span></span><br><span class="line">    <span class="comment"># 以下三项配置，可以控制执行器数量</span></span><br><span class="line"><span class="comment">#     (&quot;spark.dynamicAllocation.enabled&quot;, True),</span></span><br><span class="line"><span class="comment">#     (&quot;spark.dynamicAllocation.initialExecutors&quot;, 1),    # 1个执行器</span></span><br><span class="line"><span class="comment">#     (&quot;spark.shuffle.service.enabled&quot;, True)</span></span><br><span class="line"><span class="comment"># (&#x27;spark.sql.pivotMaxValues&#x27;, &#x27;99999&#x27;),  # 当需要pivot DF，且值很多时，需要修改，默认是10000</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 查看更详细配置及说明：https://spark.apache.org/docs/latest/configuration.html</span></span><br><span class="line"></span><br><span class="line">conf.setAll(config)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用config对象，创建spark session</span></span><br><span class="line">spark = SparkSession.builder.config(conf=conf).getOrCreate()</span><br></pre></td></tr></table></figure><ul><li>从hdfs中加载csv文件为DataFrame</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从hdfs加载CSV文件为DataFrame</span></span><br><span class="line">df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/datasets/behavior_log.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">df.show()    <span class="comment"># 查看dataframe，默认显示前20条</span></span><br><span class="line"><span class="comment"># 大致查看一下数据类型</span></span><br><span class="line">df.printSchema()    <span class="comment"># 打印当前dataframe的结构</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----+-----+------+</span><br><span class="line">|  user|time_stamp|btag| cate| brand|</span><br><span class="line">+------+----------+----+-----+------+</span><br><span class="line">|558157|1493741625|  pv| 6250| 91286|</span><br><span class="line">|558157|1493741626|  pv| 6250| 91286|</span><br><span class="line">|558157|1493741627|  pv| 6250| 91286|</span><br><span class="line">|728690|1493776998|  pv|11800| 62353|</span><br><span class="line">|332634|1493809895|  pv| 1101|365477|</span><br><span class="line">|857237|1493816945|  pv| 1043|110616|</span><br><span class="line">|619381|1493774638|  pv|  385|428950|</span><br><span class="line">|467042|1493772641|  pv| 8237|301299|</span><br><span class="line">|467042|1493772644|  pv| 8237|301299|</span><br><span class="line">|991528|1493780710|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780712|  pv| 7270|274795|</span><br><span class="line">|991528|1493780714|  pv| 7270|274795|</span><br><span class="line">|991528|1493780765|  pv| 7270|274795|</span><br><span class="line">|991528|1493780714|  pv| 7270|274795|</span><br><span class="line">|991528|1493780765|  pv| 7270|274795|</span><br><span class="line">|991528|1493780764|  pv| 7270|274795|</span><br><span class="line">|991528|1493780633|  pv| 7270|274795|</span><br><span class="line">|991528|1493780764|  pv| 7270|274795|</span><br><span class="line">+------+----------+----+-----+------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- user: string (nullable = true)</span><br><span class="line"> |-- time_stamp: string (nullable = true)</span><br><span class="line"> |-- btag: string (nullable = true)</span><br><span class="line"> |-- cate: string (nullable = true)</span><br><span class="line"> |-- brand: string (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>从hdfs加载数据为dataframe，并设置结构—schema </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType</span><br><span class="line"><span class="comment"># 构建结构对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;timestamp&quot;</span>, LongType()),</span><br><span class="line">    StructField(<span class="string">&quot;btag&quot;</span>, StringType()),</span><br><span class="line">    StructField(<span class="string">&quot;cateId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;brandId&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 从hdfs加载数据为dataframe，并设置结构</span></span><br><span class="line">behavior_log_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/datasets/behavior_log.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">behavior_log_df.show()</span><br><span class="line">behavior_log_df.count() </span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">+------+----------+----+------+-------+</span><br><span class="line">|userId| timestamp|btag|cateId|brandId|</span><br><span class="line">+------+----------+----+------+-------+</span><br><span class="line">|558157|1493741625|  pv|  6250|  91286|</span><br><span class="line">|558157|1493741626|  pv|  6250|  91286|</span><br><span class="line">|558157|1493741627|  pv|  6250|  91286|</span><br><span class="line">|728690|1493776998|  pv| 11800|  62353|</span><br><span class="line">|332634|1493809895|  pv|  1101| 365477|</span><br><span class="line">|857237|1493816945|  pv|  1043| 110616|</span><br><span class="line">|619381|1493774638|  pv|   385| 428950|</span><br><span class="line">|467042|1493772641|  pv|  8237| 301299|</span><br><span class="line">|467042|1493772644|  pv|  8237| 301299|</span><br><span class="line">|991528|1493780710|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780712|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780714|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780765|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780714|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780765|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780764|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780633|  pv|  7270| 274795|</span><br><span class="line">|991528|1493780764|  pv|  7270| 274795|</span><br><span class="line">+------+----------+----+------+-------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- timestamp: long (nullable = true)</span><br><span class="line"> |-- btag: string (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- brandId: integer (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>分析数据集字段的类型和格式<ul><li>查看是否有空值</li><li>查看每列数据的类型</li><li>查看每列数据的类别情况</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看userId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;userId&quot;</span>).count().count()) <span class="comment"># 第一个count是将相同的用户放在同一组内。，再count数数。</span></span><br><span class="line"><span class="comment"># 约113w用户</span></span><br><span class="line"><span class="comment">#注意：behavior_log_df.groupBy(&quot;userId&quot;).count()  返回的是一个dataframe，这里的count计算的是每一个分组的个数，但当前还没有进行计算</span></span><br><span class="line"><span class="comment"># 当调用df.count()时才开始进行计算，这里的count计算的是dataframe的条目数，也就是共有多少个分组</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看user的数据情况： 1136340</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看btag的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;btag&quot;</span>).count().collect())    <span class="comment"># collect会把计算结果全部加载到内存，谨慎使用</span></span><br><span class="line"><span class="comment"># 只有四种类型数据：pv、fav、cart、buy</span></span><br><span class="line"><span class="comment"># 这里由于类型只有四个，所以直接使用collect，把数据全部加载出来</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看btag的数据情况： [Row(btag=&#x27;buy&#x27;, count=9115919), Row(btag=&#x27;fav&#x27;, count=9301837), Row(btag=&#x27;cart&#x27;, count=15946033), Row(btag=&#x27;pv&#x27;, count=688904345)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看cateId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;cateId&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约12968类别id</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看cateId的数据情况： 12968</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;查看brandId的数据情况：&quot;</span>, behavior_log_df.groupBy(<span class="string">&quot;brandId&quot;</span>).count().count())</span><br><span class="line"><span class="comment"># 约460561品牌id</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">查看brandId的数据情况： 460561</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&quot;判断数据是否有空值：&quot;</span>, behavior_log_df.count(), behavior_log_df.dropna().count())</span><br><span class="line"><span class="comment"># 约7亿条目723268134 723268134</span></span><br><span class="line"><span class="comment"># 本数据集无空值条目，可放心处理</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">判断数据是否有空值： 723268134 723268134</span><br></pre></td></tr></table></figure><ul><li>pivot透视操作，把某列里的字段值转换成行并进行聚合运算(pyspark.sql.GroupedData.pivot)<ul><li>如果透视的字段中的不同属性值超过10000个，则需要设置spark.sql.pivotMaxValues，否则计算过程中会出现错误。<a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=pivot#pyspark.sql.GroupedData.pivot">文档介绍</a>。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户对各类商品的pv、fav、cart、buy数量</span></span><br><span class="line">cate_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.cateId).pivot(<span class="string">&quot;btag&quot;</span>,[<span class="string">&quot;pv&quot;</span>,<span class="string">&quot;fav&quot;</span>,<span class="string">&quot;cart&quot;</span>,<span class="string">&quot;buy&quot;</span>]).count() <span class="comment"># 默认按照字典排序的，想要按重要程度排序，在里面穿值。此处已经传了。[&quot;pv&quot;,&quot;fav&quot;,&quot;cart&quot;,&quot;buy&quot;]</span></span><br><span class="line">cate_count_df.printSchema()    <span class="comment"># 此时还没有开始计算</span></span><br></pre></td></tr></table></figure><p>显示效果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- pv: long (nullable = true)</span><br><span class="line"> |-- fav: long (nullable = true)</span><br><span class="line"> |-- cart: long (nullable = true)</span><br><span class="line"> |-- buy: long (nullable = true)</span><br></pre></td></tr></table></figure><ul><li>统计每个用户对各个品牌的pv、fav、cart、buy数量并保存结果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每个用户对各个品牌的pv、fav、cart、buy数量</span></span><br><span class="line">brand_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.brandId).pivot(<span class="string">&quot;btag&quot;</span>,[<span class="string">&quot;pv&quot;</span>,<span class="string">&quot;fav&quot;</span>,<span class="string">&quot;cart&quot;</span>,<span class="string">&quot;buy&quot;</span>]).count()</span><br><span class="line"><span class="comment"># brand_count_df.show()    # 同上</span></span><br><span class="line"><span class="comment"># 113w * 46w</span></span><br><span class="line"><span class="comment"># 由于运算时间比较长，所以这里先将结果存储起来，供后续其他操作使用</span></span><br><span class="line"><span class="comment"># 写入数据时才开始计算</span></span><br><span class="line">cate_count_df.write.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="literal">True</span>)</span><br><span class="line">brand_count_df.write.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="2-根据用户对类目偏好打分训练ALS模型"><a href="#2-根据用户对类目偏好打分训练ALS模型" class="headerlink" title="2. 根据用户对类目偏好打分训练ALS模型"></a>2. 根据用户对类目偏好打分训练ALS模型</h3><ul><li>根据您统计的次数 + 打分规则 ==&gt; 偏好打分数据集 ==&gt; ALS模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># spark ml的模型训练是基于内存的，如果数据过大，内存空间小，迭代次数过多的化，可能会造成内存溢出，报错</span></span><br><span class="line"><span class="comment"># 设置Checkpoint的话，会把所有数据落盘，这样如果异常退出，下次重启后，可以接着上次的训练节点继续运行</span></span><br><span class="line"><span class="comment"># 但该方法其实指标不治本，因为无法防止内存溢出，所以还是会报错</span></span><br><span class="line"><span class="comment"># 如果数据量大，应考虑的是增加内存、或限制迭代次数和训练数据量级等</span></span><br><span class="line">spark.sparkContext.setCheckpointDir(<span class="string">&quot;/checkPoint/&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建结构对象</span></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cateId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pv&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;fav&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cart&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;buy&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从hdfs加载CSV文件</span></span><br><span class="line">cate_count_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line">cate_count_df.printSchema()</span><br><span class="line">cate_count_df.first()    <span class="comment"># 第一行数据</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line"> |-- userId: integer (nullable = true)</span><br><span class="line"> |-- cateId: integer (nullable = true)</span><br><span class="line"> |-- pv: integer (nullable = true)</span><br><span class="line"> |-- fav: integer (nullable = true)</span><br><span class="line"> |-- cart: integer (nullable = true)</span><br><span class="line"> |-- buy: integer (nullable = true)</span><br><span class="line"></span><br><span class="line">Row(userId=1061650, cateId=4520, pv=2326, fav=None, cart=53, buy=None)</span><br></pre></td></tr></table></figure><ul><li>处理每一行数据：r表示row对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="comment"># 处理每一行数据：r表示row对象</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 偏好评分规则：</span></span><br><span class="line"><span class="comment">#     m: 用户对应的行为次数</span></span><br><span class="line">    <span class="comment">#     该偏好权重比例，次数上限仅供参考，具体数值应根据产品业务场景权衡</span></span><br><span class="line"><span class="comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span></span><br><span class="line"><span class="comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span></span><br><span class="line"><span class="comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span></span><br><span class="line"><span class="comment">#     buy: if m&lt;=20: score=1*m; else score=20</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 注意这里要全部设为浮点数，spark运算时对类型比较敏感，要保持数据类型都一致</span></span><br><span class="line">pv_count = r.pv <span class="keyword">if</span> r.pv <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">fav_count = r.fav <span class="keyword">if</span> r.fav <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">cart_count = r.cart <span class="keyword">if</span> r.cart <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">buy_count = r.buy <span class="keyword">if</span> r.buy <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">pv_score = <span class="number">0.2</span>*pv_count <span class="keyword">if</span> pv_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">4.0</span></span><br><span class="line">fav_score = <span class="number">0.4</span>*fav_count <span class="keyword">if</span> fav_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">8.0</span></span><br><span class="line">cart_score = <span class="number">0.6</span>*cart_count <span class="keyword">if</span> cart_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">12.0</span></span><br><span class="line">buy_score = <span class="number">1.0</span>*buy_count <span class="keyword">if</span> buy_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">20.0</span></span><br><span class="line"></span><br><span class="line">rating = pv_score + fav_score + cart_score + buy_score</span><br><span class="line"><span class="comment"># 返回用户ID、分类ID、用户对分类的偏好打分</span></span><br><span class="line"><span class="keyword">return</span> r.userId, r.cateId, rating</span><br></pre></td></tr></table></figure><ul><li>返回一个PythonRDD类型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个PythonRDD类型，此时还没开始计算</span></span><br><span class="line"><span class="comment"># 先转化为RDD再进行map，一条数据一条数据算。虽然DF也可以用UDF，但是麻烦！处理好好再转为DF</span></span><br><span class="line"><span class="comment"># 并不是所有的RDD都能转为DF，必须有结构的才行。Schema才可以。此处可以是因为，他就是DF转过去的。</span></span><br><span class="line">cate_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;cateId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: bigint, cateId: bigint, rating: double]</span><br></pre></td></tr></table></figure><ul><li>用户对商品类别的打分数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用户对商品类别的打分数据</span></span><br><span class="line"><span class="comment"># map返回的结果是rdd类型，需要调用toDF方法转换为Dataframe</span></span><br><span class="line">cate_rating_df = cate_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;cateId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line"><span class="comment"># 注意：toDF不是每个rdd都有的方法，仅局限于此处的rdd</span></span><br><span class="line"><span class="comment"># 可通过该方法获得 user-cate-matrix</span></span><br><span class="line"><span class="comment"># 但由于cateId字段过多，这里运算量比很大，机器内存要求很高才能执行，否则无法完成任务</span></span><br><span class="line"><span class="comment"># 请谨慎使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但好在我们训练ALS模型时，不需要转换为user-cate-matrix，所以这里可以不用运行</span></span><br><span class="line"><span class="comment"># cate_rating_df.groupBy(&quot;userId&quot;).povit(&quot;cateId&quot;).min(&quot;rating&quot;)</span></span><br><span class="line"><span class="comment"># 用户对类别的偏好打分数据</span></span><br><span class="line">cate_rating_df</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame[userId: bigint, cateId: bigint, rating: double]</span><br></pre></td></tr></table></figure><ul><li>通常如果USER-ITEM打分数据应该是通过一下方式进行处理转换为USER-ITEM-MATRIX</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210709010230.png" alt=""></p><p><strong>但这里我们将使用的Spark的ALS模型进行CF推荐，因此注意这里数据输入不需要提前转换为矩阵，直接是 USER-ITEM-RATE的数据</strong></p><ul><li><p>基于Spark的ALS隐因子模型进行CF评分预测</p><ul><li><p>ALS的意思是交替最小二乘法（Alternating Least Squares），是Spark2.*中加入的进行基于模型的协同过滤（model-based CF）的推荐系统算法。</p><p>同SVD，它也是一种矩阵分解技术，对数据进行降维处理。</p></li><li><p>详细使用方法：<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation">pyspark.ml.recommendation.ALS</a></p></li><li><p><strong>注意：由于数据量巨大，因此这里也不考虑基于内存的CF算法</strong></p><p>参考：<a href="https://www.cnblogs.com/mooba/p/6539142.html">为什么Spark中只有ALS</a></p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pyspark中的ALS矩阵分解方法实现CF评分预测</span></span><br><span class="line"><span class="comment"># 文档地址：https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS   <span class="comment"># ml：dataframe， mllib：rdd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用打分数据，训练ALS模型</span></span><br><span class="line">als = ALS(userCol=<span class="string">&#x27;userId&#x27;</span>, itemCol=<span class="string">&#x27;cateId&#x27;</span>, ratingCol=<span class="string">&#x27;rating&#x27;</span>, checkpointInterval=<span class="number">5</span>)   <span class="comment"># 训练五步缓存一次。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处训练时间较长</span></span><br><span class="line">model = als.fit(cate_rating_df)</span><br></pre></td></tr></table></figure><ul><li>模型训练好后，调用方法进行使用，<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=alsmodel#pyspark.ml.recommendation.ALSModel">具体API查看</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给所有用户推荐TOP-N个物品</span></span><br><span class="line">ret = model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 由于是给所有用户进行推荐，此处运算时间也较长</span></span><br><span class="line">ret.show()</span><br><span class="line"><span class="comment"># 推荐结果存放在recommendations列中，</span></span><br><span class="line">ret.select(<span class="string">&quot;recommendations&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|   148|[[3347, 12.547271...|</span><br><span class="line">|   463|[[1610, 9.250818]...|</span><br><span class="line">|   471|[[1610, 10.246621...|</span><br><span class="line">|   496|[[1610, 5.162216]...|</span><br><span class="line">|   833|[[5607, 9.065482]...|</span><br><span class="line">|  1088|[[104, 6.886987],...|</span><br><span class="line">|  1238|[[5631, 14.51981]...|</span><br><span class="line">|  1342|[[5720, 10.89842]...|</span><br><span class="line">|  1580|[[5731, 8.466453]...|</span><br><span class="line">|  1591|[[1610, 12.835257...|</span><br><span class="line">|  1645|[[1610, 11.968531...|</span><br><span class="line">|  1829|[[1610, 17.576496...|</span><br><span class="line">|  1959|[[1610, 8.353473]...|</span><br><span class="line">|  2122|[[1610, 12.652732...|</span><br><span class="line">|  2142|[[1610, 12.48068]...|</span><br><span class="line">|  2366|[[1610, 11.904813...|</span><br><span class="line">|  2659|[[5607, 11.699315...|</span><br><span class="line">|  2866|[[1610, 7.752719]...|</span><br><span class="line">|  3175|[[3347, 2.3429515...|</span><br><span class="line">|  3749|[[1610, 3.641833]...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br><span class="line"></span><br><span class="line">+--------------------+</span><br><span class="line">|     recommendations|</span><br><span class="line">+--------------------+</span><br><span class="line">|[[3347, 12.547271...|</span><br><span class="line">|[[1610, 9.250818]...|</span><br><span class="line">|[[1610, 10.246621...|</span><br><span class="line">|[[1610, 5.162216]...|</span><br><span class="line">|[[5607, 9.065482]...|</span><br><span class="line">|[[104, 6.886987],...|</span><br><span class="line">|[[5631, 14.51981]...|</span><br><span class="line">|[[5720, 10.89842]...|</span><br><span class="line">|[[5731, 8.466453]...|</span><br><span class="line">|[[1610, 12.835257...|</span><br><span class="line">|[[1610, 11.968531...|</span><br><span class="line">|[[1610, 17.576496...|</span><br><span class="line">|[[1610, 8.353473]...|</span><br><span class="line">|[[1610, 12.652732...|</span><br><span class="line">|[[1610, 12.48068]...|</span><br><span class="line">|[[1610, 11.904813...|</span><br><span class="line">|[[5607, 11.699315...|</span><br><span class="line">|[[1610, 7.752719]...|</span><br><span class="line">|[[3347, 2.3429515...|</span><br><span class="line">|[[1610, 3.641833]...|</span><br><span class="line">+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>model.recommendForUserSubset 给部分用户推荐TOP-N个物品</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：recommendForUserSubset API，2.2.2版本中无法使用</span></span><br><span class="line">dataset = spark.createDataFrame([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line"><span class="comment"># 若不指定行索引，会有个默认的&#x27;_1&#x27;,将其改为&#x27;userId&#x27;</span></span><br><span class="line">dataset = dataset.withColumnRenamed(<span class="string">&quot;_1&quot;</span>, <span class="string">&quot;userId&quot;</span>) </span><br><span class="line"><span class="comment"># 指定用户 推荐物品 参数1 要给哪些用户推荐（用户id的dataframe） 参数2 给这些用户推荐几个物品</span></span><br><span class="line">ret = model.recommendForUserSubset(dataset, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只给部分用推荐，运算时间短</span></span><br><span class="line">ret.show()</span><br><span class="line">ret.collect()    <span class="comment"># 注意： collect会将所有数据加载到内存，慎用</span></span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|     1|[[1610, 25.4989],...|</span><br><span class="line">|     3|[[5607, 13.665942...|</span><br><span class="line">|     2|[[5579, 5.9051886...|</span><br><span class="line">+------+--------------------+</span><br><span class="line"></span><br><span class="line">[Row(userId=1, recommendations=[Row(cateId=1610, rating=25.498899459838867), Row(cateId=5737, rating=24.901548385620117), Row(cateId=3347, rating=20.736785888671875)]),</span><br><span class="line"> Row(userId=3, recommendations=[Row(cateId=5607, rating=13.665942192077637), Row(cateId=1610, rating=11.770171165466309), Row(cateId=3347, rating=10.35690689086914)]),</span><br><span class="line"> Row(userId=2, recommendations=[Row(cateId=5579, rating=5.90518856048584), Row(cateId=2447, rating=5.624575138092041), Row(cateId=5690, rating=5.2555742263793945)])]</span><br></pre></td></tr></table></figure><ul><li>transform中提供userId和cateId可以对打分进行预测，利用打分结果排序后</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transform中提供userId和cateId可以对打分进行预测，利用打分结果排序后，同样可以实现TOP-N的推荐</span></span><br><span class="line">model.transform</span><br><span class="line"><span class="comment"># 将模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 测试存储的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载之前存储的模型</span></span><br><span class="line">als_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:8020/models/userCateRatingALSModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">result = als_model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line">result.show()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|   148|[[3347, 12.547271...|</span><br><span class="line">|   463|[[1610, 9.250818]...|</span><br><span class="line">|   471|[[1610, 10.246621...|</span><br><span class="line">|   496|[[1610, 5.162216]...|</span><br><span class="line">|   833|[[5607, 9.065482]...|</span><br><span class="line">|  1088|[[104, 6.886987],...|</span><br><span class="line">|  1238|[[5631, 14.51981]...|</span><br><span class="line">|  1342|[[5720, 10.89842]...|</span><br><span class="line">|  1580|[[5731, 8.466453]...|</span><br><span class="line">|  1591|[[1610, 12.835257...|</span><br><span class="line">|  1645|[[1610, 11.968531...|</span><br><span class="line">|  1829|[[1610, 17.576496...|</span><br><span class="line">|  1959|[[1610, 8.353473]...|</span><br><span class="line">|  2122|[[1610, 12.652732...|</span><br><span class="line">|  2142|[[1610, 12.48068]...|</span><br><span class="line">|  2366|[[1610, 11.904813...|</span><br><span class="line">|  2659|[[5607, 11.699315...|</span><br><span class="line">|  2866|[[1610, 7.752719]...|</span><br><span class="line">|  3175|[[3347, 2.3429515...|</span><br><span class="line">|  3749|[[1610, 3.641833]...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top 20 rows</span><br></pre></td></tr></table></figure><ul><li>召回到redis</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis</span><br><span class="line">host = <span class="string">&quot;192.168.19.8&quot;</span></span><br><span class="line">port = <span class="number">6379</span>    </span><br><span class="line"><span class="comment"># 召回到redis</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recall_cate_by_cf</span>(<span class="params">partition</span>):</span></span><br><span class="line">    <span class="comment"># 建立redis 连接池</span></span><br><span class="line">    pool = redis.ConnectionPool(host=host, port=port)</span><br><span class="line">    <span class="comment"># 建立redis客户端</span></span><br><span class="line">    client = redis.Redis(connection_pool=pool)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> partition:</span><br><span class="line">        client.hset(<span class="string">&quot;recall_cate&quot;</span>, row.userId, [i.cateId <span class="keyword">for</span> i <span class="keyword">in</span> row.recommendations])</span><br><span class="line"><span class="comment"># 对每个分片的数据进行处理 #mapPartition Transformation   map（一条一条走，和数据库建立链接耗时间）  而此处的partation是多块走，transformer的操作（）</span></span><br><span class="line"><span class="comment"># foreachPartition Action操作             foreachRDD       一块一块的走。是action的操作（一块召回一次）</span></span><br><span class="line">result.foreachPartition(recall_cate_by_cf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：这里这是召回的是用户最感兴趣的n个类别</span></span><br><span class="line"><span class="comment"># 总的条目数，查看redis中总的条目数是否一致</span></span><br><span class="line">result.count()</span><br></pre></td></tr></table></figure><p>显示结果:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1136340</span><br></pre></td></tr></table></figure><h3 id="3-根据用户对品牌偏好打分训练ALS模型-与上面的套路一样"><a href="#3-根据用户对品牌偏好打分训练ALS模型-与上面的套路一样" class="headerlink" title="3. 根据用户对品牌偏好打分训练ALS模型(与上面的套路一样)"></a>3. 根据用户对品牌偏好打分训练ALS模型(与上面的套路一样)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StructType, StructField, StringType, IntegerType</span><br><span class="line"></span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;userId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;brandId&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;pv&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;fav&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;cart&quot;</span>, IntegerType()),</span><br><span class="line">    StructField(<span class="string">&quot;buy&quot;</span>, IntegerType())</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 从hdfs加载预处理好的品牌的统计数据</span></span><br><span class="line">brand_count_df = spark.read.csv(<span class="string">&quot;hdfs://localhost:8020/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="literal">True</span>, schema=schema)</span><br><span class="line"><span class="comment"># brand_count_df.show()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_row</span>(<span class="params">r</span>):</span></span><br><span class="line">    <span class="comment"># 处理每一行数据：r表示row对象</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 偏好评分规则：</span></span><br><span class="line"><span class="comment">#     m: 用户对应的行为次数</span></span><br><span class="line">    <span class="comment">#     该偏好权重比例，次数上限仅供参考，具体数值应根据产品业务场景权衡</span></span><br><span class="line"><span class="comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span></span><br><span class="line"><span class="comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span></span><br><span class="line"><span class="comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span></span><br><span class="line"><span class="comment">#     buy: if m&lt;=20: score=1*m; else score=20</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 注意这里要全部设为浮点数，spark运算时对类型比较敏感，要保持数据类型都一致</span></span><br><span class="line">pv_count = r.pv <span class="keyword">if</span> r.pv <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">fav_count = r.fav <span class="keyword">if</span> r.fav <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">cart_count = r.cart <span class="keyword">if</span> r.cart <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">buy_count = r.buy <span class="keyword">if</span> r.buy <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">pv_score = <span class="number">0.2</span>*pv_count <span class="keyword">if</span> pv_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">4.0</span></span><br><span class="line">fav_score = <span class="number">0.4</span>*fav_count <span class="keyword">if</span> fav_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">8.0</span></span><br><span class="line">cart_score = <span class="number">0.6</span>*cart_count <span class="keyword">if</span> cart_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">12.0</span></span><br><span class="line">buy_score = <span class="number">1.0</span>*buy_count <span class="keyword">if</span> buy_count&lt;=<span class="number">20</span> <span class="keyword">else</span> <span class="number">20.0</span></span><br><span class="line"></span><br><span class="line">rating = pv_score + fav_score + cart_score + buy_score</span><br><span class="line"><span class="comment"># 返回用户ID、品牌ID、用户对品牌的偏好打分</span></span><br><span class="line"><span class="keyword">return</span> r.userId, r.brandId, rating</span><br><span class="line"><span class="comment"># 用户对品牌的打分数据</span></span><br><span class="line">brand_rating_df = brand_count_df.rdd.<span class="built_in">map</span>(process_row).toDF([<span class="string">&quot;userId&quot;</span>, <span class="string">&quot;brandId&quot;</span>, <span class="string">&quot;rating&quot;</span>])</span><br><span class="line"><span class="comment"># brand_rating_df.show()</span></span><br></pre></td></tr></table></figure><ul><li><p>基于Spark的ALS隐因子模型进行CF评分预测</p><ul><li><p>ALS的意思是交替最小二乘法（Alternating Least Squares），是Spark中进行基于模型的协同过滤（model-based CF）的推荐系统算法，也是目前Spark内唯一一个推荐算法。</p><p>同SVD，它也是一种矩阵分解技术，但理论上，ALS在海量数据的处理上要优于SVD。</p><p>更多了解：<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation">pyspark.ml.recommendation.ALS</a></p><p>注意：由于数据量巨大，因此这里不考虑基于内存的CF算法</p><p>参考：<a href="https://www.cnblogs.com/mooba/p/6539142.html">为什么Spark中只有ALS</a></p></li></ul></li><li><p>使用pyspark中的ALS矩阵分解方法实现CF评分预测</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pyspark中的ALS矩阵分解方法实现CF评分预测</span></span><br><span class="line"><span class="comment"># 文档地址：https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"></span><br><span class="line">als = ALS(userCol=<span class="string">&#x27;userId&#x27;</span>, itemCol=<span class="string">&#x27;brandId&#x27;</span>, ratingCol=<span class="string">&#x27;rating&#x27;</span>, checkpointInterval=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 利用打分数据，训练ALS模型</span></span><br><span class="line"><span class="comment"># 此处训练时间较长</span></span><br><span class="line">model = als.fit(brand_rating_df)</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">model.recommendForAllUsers(<span class="number">3</span>).show()</span><br><span class="line"><span class="comment"># 将模型进行存储</span></span><br><span class="line">model.save(<span class="string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)</span><br><span class="line"><span class="comment"># 测试存储的模型</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALSModel</span><br><span class="line"><span class="comment"># 从hdfs加载模型</span></span><br><span class="line">my_model = ALSModel.load(<span class="string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)</span><br><span class="line">my_model</span><br><span class="line"><span class="comment"># model.recommendForAllUsers(N) 给用户推荐TOP-N个物品</span></span><br><span class="line">my_model.recommendForAllUsers(<span class="number">3</span>).first()</span><br></pre></td></tr></table></figure><h3 id="4-小结"><a href="#4-小结" class="headerlink" title="4.小结"></a>4.小结</h3><h3 id="spark-训练-ALS-模型"><a href="#spark-训练-ALS-模型" class="headerlink" title="spark 训练 ALS 模型"></a>spark 训练 ALS 模型</h3><ul><li><p>spark 机器学习相关的库</p><ul><li>spark MLlib<ul><li>最早开发的</li><li><strong>基于RDD 的api</strong></li><li>目前已经停止维护了 （从2.3开始停止维护）</li><li>还可以使用</li></ul></li><li>spark ML<ul><li>目前在更新的是这个库</li><li><strong>基于dataframe</strong></li></ul></li></ul></li><li><p>ALS 模型训练</p><ul><li><p>spark ML的库中封装了 协同过滤的 ALS模型</p></li><li><p>from pyspark.ml.recommendation import ALS</p></li><li><p>需要准备一个dataframe 包含 用户id 物品id 用户-物品评分 这三列，利用这三列数据就可以使用spark ALS模块训练ALS模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line">als = ALS(userCol = <span class="string">&#x27;userId&#x27;</span>,itemCol=<span class="string">&#x27;cateId&#x27;</span>,ratingCol = <span class="string">&#x27;rating&#x27;</span>,checkpointInterval = <span class="number">5</span>)</span><br><span class="line">model = als.fit(dataframe)</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li><p>训练出模型之后就可以为用户召回物品</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.recommendForAllUsers(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#为指定用户推荐物品</span></span><br><span class="line">dataset = spark.createDataFrame([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>]])</span><br><span class="line">dataset = dataset.withColumnRenamed(<span class="string">&quot;_1&quot;</span>, <span class="string">&quot;userId&quot;</span>)</span><br><span class="line">ret = model.recommendForUserSubset(dataset, <span class="number">3</span>)</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;根据用户行为数据创建ALS模型并召回商品&quot;&gt;&lt;a href=&quot;#根据用户行为数据创建ALS模型并召回商品&quot; class=&quot;headerlink&quot; title=&quot;根据用户行为数据创建ALS模型并召回商品&quot;&gt;&lt;/a&gt;根据用户行为数据创建ALS模型并召回商品&lt;/h2&gt;&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>01-推荐系统实战之个性化电商广告推荐系统介绍</title>
    <link href="https://xxren8218.github.io/20210708/01%E2%80%94%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E4%B8%AA%E6%80%A7%E5%8C%96%E7%94%B5%E5%95%86%E5%B9%BF%E5%91%8A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D.html"/>
    <id>https://xxren8218.github.io/20210708/01%E2%80%94%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E4%B9%8B%E4%B8%AA%E6%80%A7%E5%8C%96%E7%94%B5%E5%95%86%E5%B9%BF%E5%91%8A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D.html</id>
    <published>2021-07-07T17:10:24.000Z</published>
    <updated>2021-07-08T17:03:13.109Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一-个性化电商广告推荐系统介绍"><a href="#一-个性化电商广告推荐系统介绍" class="headerlink" title="一 个性化电商广告推荐系统介绍"></a>一 个性化电商广告推荐系统介绍</h2><h3 id="1-数据集介绍"><a href="#1-数据集介绍" class="headerlink" title="1 数据集介绍"></a>1 数据集介绍</h3><ul><li><p>Ali_Display_Ad_Click是阿里巴巴提供的一个淘宝展示广告点击率预估数据集</p><p>数据集来源：天池竞赛 <a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=56">数据集-阿里云天池 (aliyun.com)</a></p></li><li><p>原始样本骨架raw_sample</p><p>淘宝网站中随机抽样了114万用户8天内的广告展示/点击日志（2600万条记录），构成原始的样本骨架。 字段说明如下：</p><ol><li>user_id：脱敏过的用户ID；</li><li>adgroup_id：脱敏过的广告单元ID；</li><li>time_stamp：时间戳；</li><li>pid：资源位；</li><li>noclk：为1代表没有点击；为0代表点击；</li><li>clk：为0代表没有点击；为1代表点击；<ul><li>此处的点与没点通过埋点来实现（JS代码）。</li><li>有两个点和没点数据，是记录展示了什么数据，他没点。（看了没点与压根没看到区别）</li><li>得通过两个埋点对比得到结果，一个记录曝光，一个记录点击的。</li></ul></li></ol><p>用前面7天的做训练样本（20170506-20170512），用第8天的做测试样本（20170513）</p></li><li><p>广告基本信息表ad_feature</p><p>本数据集涵盖了raw_sample中全部广告的基本信息(约80万条目)。字段说明如下：</p><ol><li>adgroup_id：脱敏过的广告ID；</li><li>cate_id：脱敏过的商品类目ID；</li><li>campaign_id：脱敏过的广告计划ID；</li><li>customer_id: 脱敏过的广告主ID；</li><li>brand_id：脱敏过的品牌ID；</li><li>price: 宝贝的价格</li></ol><p>其中一个广告ID对应一个商品（宝贝），一个宝贝属于一个类目，一个宝贝属于一个品牌。</p></li><li><p>用户基本信息表user_profile</p><p>本数据集涵盖了raw_sample中全部用户的基本信息(约100多万用户)。字段说明如下：</p><ol><li>userid：脱敏过的用户ID；</li><li>cms_segid：微群ID；</li><li>cms_group_id：cms_group_id；</li><li>final_gender_code：性别 1:男,2:女；</li><li>age_level：年龄层次； 1234</li><li>pvalue_level：消费档次，1:低档，2:中档，3:高档；</li><li>shopping_level：购物深度，1:浅层用户,2:中度用户,3:深度用户</li><li>occupation：是否大学生 ，1:是,0:否</li><li>new_user_class_level：城市层级</li></ol></li><li><p>用户的行为日志behavior_log</p><p>本数据集涵盖了raw_sample中全部用户22天内的购物行为(共七亿条记录)。字段说明如下：</p><p>user：脱敏过的用户ID；<br>time_stamp：时间戳；<br>btag：行为类型, 包括以下四种：<br>​    类型 | 说明<br>​    pv | 浏览<br>​    cart | 加入购物车<br>​    fav | 收藏<br>​    buy | 购买<br>cate_id：脱敏过的商品类目id；<br>brand_id: 脱敏过的品牌id；<br>这里以user + time_stamp为key，会有很多重复的记录；这是因为我们的不同的类型的行为数据是不同部门记录的，在打包到一起的时候，实际上会有小的偏差（即两个一样的time_stamp实际上是差异比较小的两个时间）</p></li></ul><h3 id="2-项目效果展示"><a href="#2-项目效果展示" class="headerlink" title="2. 项目效果展示"></a>2. 项目效果展示</h3><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210708011249.png" alt=""></p><h3 id="3-项目实现分析"><a href="#3-项目实现分析" class="headerlink" title="3. 项目实现分析"></a>3. 项目实现分析</h3><ul><li><p>主要包括</p><ul><li>一份广告点击的样本数据raw_sample.csv：体现的是用户对不同位置广告点击、没点击的情况</li><li>一份广告基本信息数据ad_feature.csv：体现的是每个广告的类目(id)、品牌(id)、价格特征</li><li>一份用户基本信息数据user_profile.csv：体现的是用户群组、性别、年龄、消费购物档次、所在城市级别等特征</li><li>一份用户行为日志数据behavior_log.csv：体现用户对商品类目(id)、品牌(id)的浏览、加购物车、收藏、购买等信息</li></ul><p>我们是在对非搜索类型的广告进行点击率预测和推荐(没有搜索词、没有广告的内容特征信息)</p><ol><li>推荐业务处理主要流程： 召回 ===&gt; 排序 ===&gt; 过滤<ul><li>离线处理业务流（<strong>①训练逻辑回归模型，②为每个用户召回感兴趣的广告</strong>）<ul><li>raw_sample.csv ==&gt; 历史样本数据</li><li>ad_feature.csv ==&gt; 广告特征数据</li><li>user_profile.csv ==&gt; 用户特征数据</li><li>raw_sample.csv + ad_feature.csv + user_profile.csv ==&gt; CTR点击率预测模型</li><li>behavior_log.csv ==&gt; 评分数据 ==&gt; user-cate/brand评分数据 ==&gt; 协同过滤 ==&gt; top-N cate/brand ==&gt; 关联广告（找到感兴趣的广告）</li><li>协同过滤召回 ==&gt; top-N cate/brand ==&gt; 关联对应的广告完成召回</li></ul></li><li>在线处理业务流<ul><li>数据处理部分：<ul><li>实时行为日志 ==&gt; 实时特征 ==&gt; 缓存</li><li>实时行为日志 ==&gt; 实时商品类别/品牌 ==&gt; 实时广告召回集 ==&gt; 缓存</li></ul></li><li>推荐任务部分：<ul><li>CTR点击率预测模型 + 广告/用户特征(缓存) + 对应的召回集(缓存) ==&gt; 点击率排序 ==&gt; top-N 广告推荐结果</li></ul></li></ul></li></ul></li><li>涉及技术：Flume、Kafka、Spark-streming\HDFS、Spark SQL、Spark ML、Redis<ul><li>Flume：日志数据收集</li><li>Kafka：实时日志数据处理队列</li><li>HDFS：存储数据</li><li>Spark SQL：离线处理</li><li>Spark ML：模型训练</li><li>Redis：缓存</li></ul></li></ol></li></ul><h3 id="4-点击率预测-CTR—Click-Through-Rate-概念"><a href="#4-点击率预测-CTR—Click-Through-Rate-概念" class="headerlink" title="4. 点击率预测(CTR—Click-Through-Rate)概念"></a>4. 点击率预测(CTR—Click-Through-Rate)概念</h3><ul><li><p>电商广告推荐通常使用广告点击率(CTR—Click-Through-Rate)预测来实现</p><p><strong>点击率预测 VS 推荐算法</strong></p><p>点击率预测需要给出精准的点击概率，比如广告A点击率0.5%、广告B的点击率0.12%等；而推荐算法很多时候只需要得出一个最优的次序A&gt;B&gt;C即可。</p><p>点击率预测使用的算法通常是如逻辑回归(Logic Regression)这样的机器学习算法，而推荐算法则是一些基于协同过滤推荐、基于内容的推荐等思想实现的算法</p><p><strong>点击率 VS 转化率</strong></p><p>点击率预测是对每次广告的点击情况做出预测，可以判定这次为点击或不点击，也可以给出点击或不点击的概率</p><p>转化率指的是从状态A进入到状态B的概率，电商的转化率通常是指到达网站后，进而有成交记录的用户比率，如用户成交量/用户访问量</p><p><strong>搜索和非搜索广告点击率预测的区别</strong></p><p>搜索中有很强的搜索信号-“查询词(Query)”，查询词和广告内容的匹配程度很大程度影响了点击概率，<strong>搜索广告的点击率普遍较高</strong></p><p>非搜索广告（例如展示广告，信息流广告）的点击率的计算很多就来源于用户的兴趣和广告自身的特征，以及上下文环境。通常好<strong>位置能达到百分之几的点击率</strong>（5%左右就很不错了）。对于很多底部的广告，点击率非常低，常常是千分之几，甚至更低。</p></li></ul><h2 id="5-小结："><a href="#5-小结：" class="headerlink" title="5.小结："></a>5.小结：</h2><h3 id="数据集分析"><a href="#数据集分析" class="headerlink" title="数据集分析"></a>数据集分析</h3><ul><li><p>召回</p><ul><li>采用用户的行为日志 behavior_log 创建召回模型</li><li>协同过滤   <strong>ALS</strong>——Spark有封装<ul><li>协同过滤需需要用户对物品的评分。</li><li>用户-物品 评分<ul><li>这里没有。只有对品类、品牌的数据。</li><li>用户-品类 评分</li><li>用户-品牌 评分</li></ul></li><li>pv  cart fav buy通过四种行为转化成 -&gt; 评分<ul><li>评分的设定是根据具体的业务来的。如买给的评分最高，看最低。以及不同行为的上限，看了100次，那最多评分50.</li></ul></li></ul></li></ul></li><li><p>排序</p><ul><li>LR 逻辑回归</li><li>以  <strong>raw_sample</strong>  为骨架 把ad_feature 广告信息和user_profile用户信息拼接过来 训练逻辑回归模型</li><li>训练逻辑回归模型时 ：<ul><li>用到user_profile中会影响到用户是否会点击广告的用户特征 </li></ul></li><li>用到ad_feature会影响到用户是否会点击广告的特征 <ul><li>点/不点作为目标值</li></ul></li></ul></li><li>预测的是点击的概率<ul><li>若预测是0,1的话全部都是0.（实际广告100个人，有5个人点，正负样本极度不均衡，那我模型直接预测成全部不点也很好。所以需要调整阈值，概率不能以0.5划分了。得到结果处理：如果几个物品不点的概率分别为，0.87 0.88 0.91），那我先推荐的是点的概率大的0.13那个物品。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一-个性化电商广告推荐系统介绍&quot;&gt;&lt;a href=&quot;#一-个性化电商广告推荐系统介绍&quot; class=&quot;headerlink&quot; title=&quot;一 个性化电商广告推荐系统介绍&quot;&gt;&lt;/a&gt;一 个性化电商广告推荐系统介绍&lt;/h2&gt;&lt;h3 id=&quot;1-数据集介绍&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>33-Spark Streaming的状态操作</title>
    <link href="https://xxren8218.github.io/20210707/33-Spark-Streaming%E7%9A%84%E7%8A%B6%E6%80%81%E6%93%8D%E4%BD%9C.html"/>
    <id>https://xxren8218.github.io/20210707/33-Spark-Streaming%E7%9A%84%E7%8A%B6%E6%80%81%E6%93%8D%E4%BD%9C.html</id>
    <published>2021-07-06T16:39:56.000Z</published>
    <updated>2021-07-06T16:42:23.690Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、Spark-Streaming的状态操作"><a href="#1、Spark-Streaming的状态操作" class="headerlink" title="1、Spark Streaming的状态操作"></a>1、Spark Streaming的状态操作</h2><p>在Spark Streaming中存在两种状态操作</p><ul><li>UpdateStateByKey</li><li>Windows操作</li></ul><p>使用有状态的transformation，需要开启Checkpoint</p><ul><li>spark streaming 的容错机制</li><li>它将足够多的信息checkpoint到某些具备容错性的存储系统如hdfs上，以便出错时能够迅速恢复</li></ul><h3 id="1-1-updateStateByKey"><a href="#1-1-updateStateByKey" class="headerlink" title="1.1 updateStateByKey"></a>1.1 updateStateByKey</h3><p>Spark Streaming实现的是一个实时批处理操作，每隔一段时间将数据进行打包，封装成RDD，是无状态的。</p><p>无状态：指的是每个时间片段的数据之间是没有关联的。</p><p>需求：想要将一个大时间段（1天），即多个小时间段的数据内的数据持续进行累积操作</p><p>一般超过一天都是用RDD或Spark SQL来进行离线批处理</p><p>如果没有UpdateStateByKey，我们需要将每一秒的数据计算好放入mysql中取，再用mysql来进行统计计算</p><p>Spark Streaming中提供这种状态保护机制，即updateStateByKey</p><p>步骤：</p><ul><li>首先，要定义一个state，可以是任意的数据类型</li><li>其次，要定义state更新函数—指定一个函数如何使用之前的state和新值来更新state</li><li>对于每个batch，Spark都会为每个之前已经存在的key去应用一次state更新函数，无论这个key在batch中是否有新的数据。如果state更新函数返回none，那么key对应的state就会被删除</li><li>对于每个新出现的key，也会执行state更新函数</li></ul><p>举例：词统计。</p><h3 id="案例：updateStateByKey"><a href="#案例：updateStateByKey" class="headerlink" title="案例：updateStateByKey"></a>案例：updateStateByKey</h3><p>需求：监听网络端口的数据，获取到每个批次的出现的单词数量，并且需要把每个批次的信息保留下来</p><p><strong>代码</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SparkContext</span></span><br><span class="line">spark = SparkSession.builder.master(<span class="string">&quot;local[2]&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">ssc = StreamingContext(sc, <span class="number">3</span>)</span><br><span class="line"><span class="comment">##### 开启检查点 #####</span></span><br><span class="line">ssc.checkpoint(<span class="string">&quot;checkpoint&quot;</span>) <span class="comment"># 默认会在Hadoop的/user/root下有个Chekpoint</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义state更新函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateFunc</span>(<span class="params">new_values, last_sum</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(new_values) + (last_sum <span class="keyword">or</span> <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">lines = ssc.socketTextStream(<span class="string">&quot;localhost&quot;</span>, <span class="number">9999</span>)</span><br><span class="line"><span class="comment"># 对数据以空格进行拆分，分为多个单词</span></span><br><span class="line">counts = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>)) \</span><br><span class="line">    .<span class="built_in">map</span>(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>)) \</span><br><span class="line">    .updateStateByKey(updateFunc=updateFunc) <span class="comment"># 应用updateStateByKey函数</span></span><br><span class="line">    </span><br><span class="line">counts.pprint()</span><br><span class="line"></span><br><span class="line">ssc.start()</span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure><h3 id="1-2-Windows"><a href="#1-2-Windows" class="headerlink" title="1.2 Windows"></a>1.2 Windows</h3><ul><li><p>实时热搜</p></li><li><p>窗口长度L：运算的数据量</p></li><li>滑动间隔G：控制每隔多长时间做一次运算</li><li>两个函数：<ul><li>删除的数据怎么处理</li><li>新加入的数据怎么处理</li></ul></li></ul><p>每隔G秒，统计最近L秒的数据</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004109.png" alt=""></p><p><strong>操作细节</strong></p><ul><li>Window操作是基于窗口长度和滑动间隔来工作的</li><li>窗口的长度控制考虑前几批次数据量</li><li>默认为批处理的滑动间隔来确定计算结果的频率</li></ul><p><strong>相关函数</strong></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004126.png" alt=""></p><ul><li>Smart computation</li><li>invAddFunc</li></ul><p>reduceByKeyAndWindow(func,invFunc,windowLength,slideInterval,[num,Tasks])</p><ul><li>func:正向操作，类似于updateStateByKey</li><li>invFunc：反向操作，移除的数据如何处理</li><li>windowLength 窗口长度，统计一小时的热搜关键词，窗口长度就是1h。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004144.png" alt=""></p><p>例如在热词时，在上一个窗口中可能是热词，这个一个窗口中可能不是热词，就需要在这个窗口中把该次剔除掉</p><p>典型案例：热点搜索词滑动统计，每隔10秒，统计最近60秒钟的搜索词的搜索频次，并打印出最靠前的3个搜索词出现次数。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210707004200.png" alt=""></p><p><strong>案例</strong></p><p>监听网络端口的数据，每隔3秒统计前6秒出现的单词数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.session <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_countryname</span>(<span class="params">line</span>):</span></span><br><span class="line">    country_name = line.strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> country_name == <span class="string">&#x27;usa&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;USA&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> country_name == <span class="string">&#x27;ind&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;India&#x27;</span></span><br><span class="line">    <span class="keyword">elif</span> country_name == <span class="string">&#x27;aus&#x27;</span>:</span><br><span class="line">        output = <span class="string">&#x27;Australia&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = <span class="string">&#x27;Unknown&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (output, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="comment"># 定义处理的时间间隔</span></span><br><span class="line">    batch_interval = <span class="number">1</span> <span class="comment"># base time unit (in seconds)</span></span><br><span class="line">    <span class="comment"># 定义窗口长度</span></span><br><span class="line">    window_length = <span class="number">6</span> * batch_interval</span><br><span class="line">    <span class="comment"># 定义滑动时间间隔</span></span><br><span class="line">    frequency = <span class="number">3</span> * batch_interval</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取StreamingContext</span></span><br><span class="line">    spark = SparkSession.builder.master(<span class="string">&quot;local[2]&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">ssc = StreamingContext(sc, batch_interval)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 需要设置检查点</span></span><br><span class="line">    ssc.checkpoint(<span class="string">&quot;checkpoint&quot;</span>)</span><br><span class="line"></span><br><span class="line">    lines = ssc.socketTextStream(<span class="string">&#x27;localhost&#x27;</span>, <span class="number">9999</span>)</span><br><span class="line">    addFunc = <span class="keyword">lambda</span> x, y: x + y</span><br><span class="line">    invAddFunc = <span class="keyword">lambda</span> x, y: x - y</span><br><span class="line">    <span class="comment"># 调用reduceByKeyAndWindow，来进行窗口函数的调用</span></span><br><span class="line">    window_counts = lines.<span class="built_in">map</span>(get_countryname) \</span><br><span class="line">        .reduceByKeyAndWindow(addFunc, invAddFunc, window_length, frequency)</span><br><span class="line"><span class="comment"># 输出处理结果信息</span></span><br><span class="line">    window_counts.pprint()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1、Spark-Streaming的状态操作&quot;&gt;&lt;a href=&quot;#1、Spark-Streaming的状态操作&quot; class=&quot;headerlink&quot; title=&quot;1、Spark Streaming的状态操作&quot;&gt;&lt;/a&gt;1、Spark Streaming的状态</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>11-二叉树的左下角的值</title>
    <link href="https://xxren8218.github.io/20210706/11-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E4%B8%8B%E8%A7%92%E7%9A%84%E5%80%BC.html"/>
    <id>https://xxren8218.github.io/20210706/11-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E4%B8%8B%E8%A7%92%E7%9A%84%E5%80%BC.html</id>
    <published>2021-07-06T14:01:31.000Z</published>
    <updated>2021-07-06T14:02:16.681Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的左下角的值"><a href="#二叉树的左下角的值" class="headerlink" title="二叉树的左下角的值"></a>二叉树的左下角的值</h2><ul><li>513.找树左下角的值</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706220206.PNG" alt=""></p><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>所要求的的是</p><h4 id="1-递归法"><a href="#1-递归法" class="headerlink" title="1.递归法"></a>1.递归法</h4><p>可以用一个字典来保护每行第一个节点，使用前序遍历。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.dic = &#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findBottomLeftValue</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.leftValue(root, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">leftValue</span>(<span class="params">self, node, index</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> index <span class="keyword">not</span> <span class="keyword">in</span> self.dic:</span><br><span class="line">            self.dic[index] = node.val</span><br><span class="line">        <span class="comment">##########################################</span></span><br><span class="line">        <span class="comment"># 只需要把下面的两行代码互换，就可以找右边的元素了#</span></span><br><span class="line">        <span class="comment">##########################################</span></span><br><span class="line">        self.leftValue(node.left, index + <span class="number">1</span>)</span><br><span class="line">        self.leftValue(node.right, index + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 由于是数字hash，所以其实是有序的，直接values.pop()即可。</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(self.dic.values()).pop()</span><br></pre></td></tr></table></figure><h4 id="2-迭代法"><a href="#2-迭代法" class="headerlink" title="2.迭代法"></a>2.迭代法</h4><p>可以套用框架。在每层判断时，只讲第一个值赋值给结果即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findBottomLeftValue</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        result = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 保存这行第一个元素即可</span></span><br><span class="line">                <span class="comment">#####################################################</span></span><br><span class="line">                <span class="comment">#只需要把i == 0，换成 i == len(queue),就可以找右边的元素了#</span></span><br><span class="line">                <span class="comment">#####################################################</span></span><br><span class="line">                <span class="keyword">if</span> i == <span class="number">0</span>: result = cur_node.val</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本题同样采用了递归和迭代的方式进行求解。</p><ul><li>迭代法直接套框架。用一个临时变量存值。</li><li>递归法可以用字典对每一层的第一个值进行保护。而字典的键可以用数字（每层的层数），使得无序的字典有序，直接取最后一个值即可。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的左下角的值&quot;&gt;&lt;a href=&quot;#二叉树的左下角的值&quot; class=&quot;headerlink&quot; title=&quot;二叉树的左下角的值&quot;&gt;&lt;/a&gt;二叉树的左下角的值&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;513.找树左下角的值&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>10-二叉树的左叶子之和</title>
    <link href="https://xxren8218.github.io/20210706/10-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E5%8F%B6%E5%AD%90%E4%B9%8B%E5%92%8C.html"/>
    <id>https://xxren8218.github.io/20210706/10-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B7%A6%E5%8F%B6%E5%AD%90%E4%B9%8B%E5%92%8C.html</id>
    <published>2021-07-06T14:00:10.000Z</published>
    <updated>2021-07-06T14:01:14.305Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的左叶子之和"><a href="#二叉树的左叶子之和" class="headerlink" title="二叉树的左叶子之和"></a>二叉树的左叶子之和</h2><ul><li>404 左叶子之和</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706220041.PNG" alt=""></p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1.思路"></a>1.思路</h3><p><strong>「首先要注意是判断左叶子，不是二叉树左侧节点，所以不要上来想着层序遍历。」</strong></p><p>其实题目说的也很清晰了，左和叶子我们都知道表示什么，那么左叶子也应该知道了，但为了大家不会疑惑，我还是来给出左叶子的明确定义：<strong>「如果左节点不为空，且左节点没有左右孩子，那么这个节点就是左叶子」</strong></p><p><strong>「判断当前节点是不是左叶子是无法判断的，必须要通过节点的父节点来判断其左孩子是不是左叶子。」</strong></p><p>思考一下如下图中二叉树，左叶子之和究竟是多少？</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706220101.jpg" alt=""></p><p><strong>「其实是0，因为这棵树根本没有左叶子！」</strong></p><p>那么<strong>「判断当前节点是不是左叶子是无法判断的，必须要通过节点的父节点来判断其左孩子是不是左叶子。」</strong></p><p>如果该节点的左节点不为空，该节点的左节点的左节点为空，该节点的左节点的右节点为空，则找到了一个左叶子，判断代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.left.left <span class="keyword">and</span> <span class="keyword">not</span> node.left.right:</span><br><span class="line">    左叶子节点处理逻辑</span><br></pre></td></tr></table></figure><h4 id="1-1递归法"><a href="#1-1递归法" class="headerlink" title="1.1递归法"></a>1.1递归法</h4><p>递归的遍历顺序为后序遍历（左右中），是因为要通过递归函数的返回值来累加求取左叶子数值之和。</p><p>递归三部曲：</p><ol><li>确定递归函数的参数和返回值</li></ol><p>判断一个树的左叶子节点之和，那么一定要传入树的根节点，递归函数的返回值为数值之和。</p><ol><li>确定终止条件</li></ol><p>依然是</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑</li></ol><p>当遇到左叶子节点的时候，记录数值，然后通过递归求取左子树左叶子之和，和 右子树左叶子之和，相加便是整个树的左叶子之和。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sumOfLeftLeaves</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        leftValue = self.sumOfLeftLeaves(root.left)                  <span class="comment"># 左</span></span><br><span class="line">        rightValue = self.sumOfLeftLeaves(root.right)                <span class="comment"># 右</span></span><br><span class="line"></span><br><span class="line">        midValue = <span class="number">0</span>                                                    </span><br><span class="line">        <span class="keyword">if</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.left.left <span class="keyword">and</span> <span class="keyword">not</span> root.left.right: <span class="comment"># 中</span></span><br><span class="line">            midValue = root.left.val</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> leftValue + rightValue + midValue</span><br></pre></td></tr></table></figure><h4 id="1-2-迭代法"><a href="#1-2-迭代法" class="headerlink" title="1.2 迭代法"></a>1.2 迭代法</h4><p>我们可以使用一个辅助函数来判断此节点是否是叶子节点。然后按照层序遍历的框架进行判断即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sumOfLeftLeaves</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 来判断此节点是否是叶子结点</span></span><br><span class="line">        isLeafNode = <span class="keyword">lambda</span> node: <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right</span><br><span class="line"></span><br><span class="line">        queue = [root]</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                <span class="comment"># 若此节点为叶子结点，加入结果</span></span><br><span class="line">                <span class="keyword">if</span> isLeafNode(cur_node.left):</span><br><span class="line">                    result += cur_node.left.val</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                <span class="comment"># 若此节点为叶子结点，不用管它，若不是，则加入队列中。</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> isLeafNode(cur_node.right):</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>我觉得这道题还是有一定难度的，不知道为什么给划分为简单，</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的左叶子之和&quot;&gt;&lt;a href=&quot;#二叉树的左叶子之和&quot; class=&quot;headerlink&quot; title=&quot;二叉树的左叶子之和&quot;&gt;&lt;/a&gt;二叉树的左叶子之和&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;404 左叶子之和&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;ht</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>09-二叉树的所有路径</title>
    <link href="https://xxren8218.github.io/20210706/09-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84.html"/>
    <id>https://xxren8218.github.io/20210706/09-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84.html</id>
    <published>2021-07-06T13:58:48.000Z</published>
    <updated>2021-07-06T13:59:43.736Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的所有路径"><a href="#二叉树的所有路径" class="headerlink" title="二叉树的所有路径"></a>二叉树的所有路径</h2><ul><li>257.二叉树的所有路径</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706215924.PNG" alt=""></p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1. 思路"></a>1. 思路</h3><h4 id="1-1递归法"><a href="#1-1递归法" class="headerlink" title="1.1递归法"></a>1.1递归法</h4><p>最直观的方法是使用深度优先搜索。在深度优先搜索遍历二叉树时，我们需要考虑当前的节点以及它的孩子节点。</p><ul><li><p>如果当前节点不是叶子节点，则在当前的路径末尾添加该节点，并继续递归遍历该节点的每一个孩子节点。</p></li><li><p>如果当前节点是叶子节点，则在当前路径末尾添加该节点后我们就得到了一条从根节点到叶子节点的路径，将</p><p>该路径加入到答案即可。</p></li></ul><p>如此，当遍历完整棵二叉树以后我们就得到了所有从根节点到叶子节点的路径。当然，深度优先搜索也可以使用非递归的方式实现，这里不再赘述。</p><ul><li>注意字符串的拼接是  += （公共方法）</li><li>列表的extend和append的区别。+= 与 extend类似。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">return</span> self.traversal(root, <span class="string">&#x27;&#x27;</span>, result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">traversal</span>(<span class="params">self, node, path, result</span>):</span></span><br><span class="line">        <span class="comment"># 如果当前节点不存在</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># 否则当前节点存在</span></span><br><span class="line">        path += <span class="built_in">str</span>(node.val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 判断是否到达叶子节点</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 到达叶子节点</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">            <span class="comment"># 将路径增加到答案中</span></span><br><span class="line">            result.append(path)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 未到达叶子节点</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            path += <span class="string">&quot;-&gt;&quot;</span></span><br><span class="line">            self.traversal(node.left, path, result)</span><br><span class="line">            self.traversal(node.right, path, result)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>时间复杂度：O(N^2)</p><p>空间复杂度：O(N^2)</p><h4 id="1-2-迭代法"><a href="#1-2-迭代法" class="headerlink" title="1.2 迭代法"></a>1.2 迭代法</h4><p>这里的迭代法采用广度优先搜索来实现。我们维护一个队列，存储节点以及根到该节点的路径。一开始这个队列里只有根节点。在每一步迭代中，我们取出队列中的首节点，如果它是叶子节点，则将它对应的路径加入到答案中。如果它不是叶子节点，则将它的所有孩子节点加入到队列的末尾。当队列为空时广度优先搜索结束，我们即能得到答案。</p><p>这种方式不能保证从左到右的输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">binaryTreePaths</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: List[str]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        result = []</span><br><span class="line">        node_queue = [root]</span><br><span class="line">        path_queue = [<span class="built_in">str</span>(root.val)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> node_queue:</span><br><span class="line">            node = node_queue.pop(<span class="number">0</span>)</span><br><span class="line">            path = path_queue.pop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">                result.append(path)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                node_queue.append(node.left)</span><br><span class="line">                path_queue.append(path + <span class="string">&quot;-&gt;&quot;</span> + <span class="built_in">str</span>(node.left.val))</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                node_queue.append(node.right)</span><br><span class="line">                path_queue.append(path + <span class="string">&quot;-&gt;&quot;</span> + <span class="built_in">str</span>(node.right.val))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h3 id="2-总结"><a href="#2-总结" class="headerlink" title="2. 总结"></a>2. 总结</h3><p>可以看出来，不管是递归的前序遍历还是广度的迭代遍历，都有我们模板的影子。实际上还是在模板上的一些小改进而已。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的所有路径&quot;&gt;&lt;a href=&quot;#二叉树的所有路径&quot; class=&quot;headerlink&quot; title=&quot;二叉树的所有路径&quot;&gt;&lt;/a&gt;二叉树的所有路径&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;257.二叉树的所有路径&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;htt</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>32-Spark Streaming概述及编码实战</title>
    <link href="https://xxren8218.github.io/20210706/32-Spark-Streaming%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%BC%96%E7%A0%81%E5%AE%9E%E6%88%98.html"/>
    <id>https://xxren8218.github.io/20210706/32-Spark-Streaming%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%BC%96%E7%A0%81%E5%AE%9E%E6%88%98.html</id>
    <published>2021-07-05T17:04:53.000Z</published>
    <updated>2021-07-05T17:06:32.231Z</updated>
    
    <content type="html"><![CDATA[<h1 id="掌握目标"><a href="#掌握目标" class="headerlink" title="掌握目标"></a>掌握目标</h1><ul><li>说出Spark Streaming的特点</li><li>说出DStreaming的常见操作api</li><li>能够应用Spark Streaming实现实时数据处理</li><li>能够应用Spark Streaming的状态操作解决实际问题</li><li>独立实现foreachRDD向mysql数据库的数据写入</li><li>独立实现Spark Streaming对接kafka实现实时数据处理</li></ul><h2 id="1、sparkStreaming概述"><a href="#1、sparkStreaming概述" class="headerlink" title="1、sparkStreaming概述"></a>1、sparkStreaming概述</h2><h3 id="1-1-SparkStreaming是什么"><a href="#1-1-SparkStreaming是什么" class="headerlink" title="1.1 SparkStreaming是什么"></a>1.1 SparkStreaming是什么</h3><ul><li><p>它是一个<strong>可扩展</strong>，<strong>高吞吐</strong>具有<strong>容错性</strong>的<strong>流式计算框架</strong></p><p>吞吐量：单位时间内成功传输数据的数量</p></li></ul><p>之前我们接触的spark-core和spark-sql都是处理属于<strong>离线批处理</strong>任务，数据一般都是在固定位置上，通常我们写好一个脚本，每天定时去处理数据，计算，保存数据结果。这类任务通常是T+1(一天一个任务)，对实时性要求不高。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706010555.png" alt=""></p><p>但在企业中存在很多实时性处理的需求，例如：双十一的京东阿里，通常会做一个实时的数据大屏，显示实时订单。这种情况下，对数据实时性要求较高，仅仅能够容忍到延迟1分钟或几秒钟。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210706010619.PNG" alt=""></p><p><strong>实时计算框架对比</strong></p><p>Storm</p><ul><li>流式计算框架</li><li>以record为单位处理数据</li><li>也支持micro-batch方式（Trident）</li><li>没有处理机器学习的生态</li><li>没有离线计算的框架</li><li>对python不友好</li></ul><p>Spark</p><ul><li>批处理计算框架</li><li>以RDD为单位处理数据</li><li>支持micro-batch流式处理数据（Spark Streaming）</li><li>有机器学习相关的库</li></ul><p>对比：</p><ul><li>吞吐量：Spark Streaming优于Storm</li><li>延迟：Spark Streaming差于Storm</li></ul><h3 id="1-2-Spark-Streaming的组件"><a href="#1-2-Spark-Streaming的组件" class="headerlink" title="1.2 Spark Streaming的组件"></a>1.2 Spark Streaming的组件</h3><ul><li>Streaming Context<ul><li>一旦一个Context已经启动(调用了Streaming Context的start()),就不能有新的流算子(Dstream)建立或者是添加到context中</li><li>一旦一个context已经停止,不能重新启动(Streaming Context调用了stop方法之后 就不能再次调 start())</li><li>在JVM(java虚拟机)中, 同一时间只能有一个Streaming Context处于活跃状态, 一个SparkContext创建一个Streaming Context</li><li>在Streaming Context上调用Stop方法, 也会关闭SparkContext对象, 如果只想仅关闭Streaming Context对象,设置stop()的可选参数为false</li><li>一个SparkContext对象可以重复利用去创建多个Streaming Context对象(不关闭SparkContext前提下), 但是需要关一个再开下一个</li></ul></li><li>DStream (离散流)<ul><li>代表一个连续的数据流</li><li>在内部, DStream由一系列连续的RDD组成</li><li>DStreams中的每个RDD都包含确定时间间隔内的数据</li><li>任何对DStreams的操作都转换成了对DStreams隐含的RDD的操作</li><li>数据源<ul><li>基本源<ul><li>TCP/IP Socket</li><li>FileSystem</li></ul></li><li>高级源<ul><li>Kafka</li><li>Flume</li></ul></li></ul></li></ul></li></ul><h2 id="2、Spark-Streaming编码实践"><a href="#2、Spark-Streaming编码实践" class="headerlink" title="2、Spark Streaming编码实践"></a>2、Spark Streaming编码实践</h2><p><strong>Spark Streaming编码步骤：</strong></p><ul><li>1，创建一个StreamingContext</li><li>2，从StreamingContext中创建一个数据对象</li><li>3，对数据对象进行Transformations操作</li><li>4，输出结果</li><li>5，开始和停止</li></ul><p><strong>利用Spark Streaming实现WordCount</strong></p><p>需求：监听某个端口上的网络数据，实时统计出现的不同单词个数。</p><p>1，需要安装一个nc工具：sudo yum install -y nc</p><p>2，执行指令：nc -lk 9999 -v</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置spark driver和pyspark运行时，所使用的python解释器路径</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/home/hadoop/miniconda3/envs/datapy365spark23/bin/python&quot;</span></span><br><span class="line">JAVA_HOME=<span class="string">&#x27;/home/hadoop/app/jdk1.8.0_191&#x27;</span></span><br><span class="line">SPARK_HOME = <span class="string">&quot;/home/hadoop/app/spark-2.3.0-bin-2.6.0-cdh5.7.0&quot;</span></span><br><span class="line"><span class="comment"># 当存在多个版本时，不指定很可能会导致出错</span></span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>]=JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    </span><br><span class="line">    sc = SparkContext(<span class="string">&quot;local[2]&quot;</span>,appName=<span class="string">&quot;NetworkWordCount&quot;</span>)</span><br><span class="line">    <span class="comment"># 参数2：指定执行计算的时间间隔</span></span><br><span class="line">    ssc = StreamingContext(sc, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 监听ip，端口上的上的数据 （需要打开端口）【nc -lk 9999 -v】</span></span><br><span class="line">    lines = ssc.socketTextStream(<span class="string">&#x27;localhost&#x27;</span>,<span class="number">9999</span>) </span><br><span class="line">    <span class="comment"># 将数据按空格进行拆分为多个单词</span></span><br><span class="line">    words = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    <span class="comment"># 将单词转换为(单词，1)的形式</span></span><br><span class="line">    pairs = words.<span class="built_in">map</span>(<span class="keyword">lambda</span> word:(word,<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 统计单词个数</span></span><br><span class="line">    wordCounts = pairs.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)</span><br><span class="line">    <span class="comment"># 打印结果信息，会使得前面的transformation操作执行</span></span><br><span class="line">    wordCounts.pprint() <span class="comment"># pprint() 对RDD的操作</span></span><br><span class="line">    <span class="comment"># 启动StreamingContext</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    <span class="comment"># 等待计算结束(不是交互式环境的话需要加这个参数，不然很快就停了)</span></span><br><span class="line">    ssc.awaitTermination()</span><br></pre></td></tr></table></figure><p>可视化查看效果：<a href="http://192.168.199.188:4040">http://192.168.199.188:4040</a></p><p>点击streaming，查看效果</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;掌握目标&quot;&gt;&lt;a href=&quot;#掌握目标&quot; class=&quot;headerlink&quot; title=&quot;掌握目标&quot;&gt;&lt;/a&gt;掌握目标&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;说出Spark Streaming的特点&lt;/li&gt;
&lt;li&gt;说出DStreaming的常见操作api&lt;/li&gt;
</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>31-Spark JSON数据处理 &amp; 数据清洗</title>
    <link href="https://xxren8218.github.io/20210706/31-Spark-JSON%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97.html"/>
    <id>https://xxren8218.github.io/20210706/31-Spark-JSON%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97.html</id>
    <published>2021-07-05T17:03:02.000Z</published>
    <updated>2021-07-05T17:04:23.493Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、JSON数据的处理"><a href="#1、JSON数据的处理" class="headerlink" title="1、JSON数据的处理"></a>1、JSON数据的处理</h1><h2 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h2><p><strong>JSON数据</strong></p><ul><li>网页和后端数据交互所用我的格式。</li><li><p>在Spark中能自动化的把结构加载进来，并且能推断数据类型。（CSV将所有都处理成 String）</p></li><li><p><code>Spark SQL can automatically infer the schema of a JSON dataset and load it as a DataFrame</code></p><p>Spark SQL能够自动将JSON数据集以结构化的形式加载为一个DataFrame</p></li><li><p>This conversion can be done using SparkSession.read.json on a JSON file</p><p>读取一个JSON文件可以用SparkSession.read.json方法</p></li></ul><p><strong>从JSON到DataFrame</strong></p><ul><li><p>指定DataFrame的schema</p><p>1，通过反射自动推断，适合静态数据</p><p>2，程序指定，适合程序运行中动态生成的数据</p></li></ul><p><strong>加载json数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用内部的schema</span></span><br><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line">jsonDF = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;json&#x27;</span>).load(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定schema</span></span><br><span class="line">jsonDF = spark.read.schema(jsonSchema).json(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>嵌套结构的JSON</strong></p><ul><li><p>重要的方法</p><p>1，get_json_object</p><p>2，get_json</p><p>3，explode</p></li></ul><h2 id="1-2-实践"><a href="#1-2-实践" class="headerlink" title="1.2 实践"></a>1.2 实践</h2><h3 id="1-2-1-静态json数据的读取和操作"><a href="#1-2-1-静态json数据的读取和操作" class="headerlink" title="1.2.1 静态json数据的读取和操作"></a>1.2.1 静态json数据的读取和操作</h3><p><strong>无嵌套结构的json数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark =  SparkSession.builder.appName(<span class="string">&#x27;json_demo&#x27;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==========================================</span></span><br><span class="line"><span class="comment">#                无嵌套结构的json</span></span><br><span class="line"><span class="comment"># ==========================================</span></span><br><span class="line">jsonString = [</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01001&quot;, &quot;city&quot; : &quot;AGAWAM&quot;,  &quot;pop&quot; : 15338, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span>,</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01002&quot;, &quot;city&quot; : &quot;CUSHMAN&quot;, &quot;pop&quot; : 36963, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><strong>从json字符串数组得到DataFrame</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从json字符串数组得到rdd有两种方法</span></span><br><span class="line"><span class="comment"># 1. 转换为rdd，再从rdd到DataFrame</span></span><br><span class="line"><span class="comment"># 2. 直接利用spark.createDataFrame()，见后面例子</span></span><br><span class="line"></span><br><span class="line">jsonRDD = sc.parallelize(jsonString)   <span class="comment"># stringJSONRDD</span></span><br><span class="line">jsonDF =  spark.read.json(jsonRDD)  <span class="comment"># convert RDD into DataFrame</span></span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show()</span><br></pre></td></tr></table></figure><p><strong>直接从文件生成DataFrame</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -- 直接从文件生成DataFrame</span></span><br><span class="line"><span class="comment"># 只有被压缩后的json文件内容，才能被spark-sql正确读取，否则格式化后的数据读取会出现问题</span></span><br><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="comment"># jsonDF = spark.read.format(&#x27;json&#x27;).load(&#x27;xxx.json&#x27;)</span></span><br><span class="line"></span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show(truncate=<span class="literal">False</span>) <span class="comment"># truncate=False 数据较长的时候不会...进行省略。默认会以...替换行内过长的数据</span></span><br><span class="line"></span><br><span class="line">jsonDF.<span class="built_in">filter</span>(jsonDF.pop&gt;<span class="number">4000</span>).show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 依照已有的DataFrame，创建一个临时的表(相当于mysql数据库中的一个表)，这样就可以用纯sql语句进行数据操作</span></span><br><span class="line">jsonDF.createOrReplaceTempView(<span class="string">&quot;tmp_table&quot;</span>)</span><br><span class="line"></span><br><span class="line">resultDF = spark.sql(<span class="string">&quot;select * from tmp_table where pop&gt;4000&quot;</span>)</span><br><span class="line">resultDF.show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="1-2-1-动态json数据的读取和操作"><a href="#1-2-1-动态json数据的读取和操作" class="headerlink" title="1.2.1 动态json数据的读取和操作"></a>1.2.1 动态json数据的读取和操作</h3><p><strong>指定DataFrame的Schema</strong></p><p>上面的例子为通过反射自动推断schema，适合静态数据</p><p>下面我们来讲解如何进行程序指定schema</p><p><strong>没有嵌套结构的json</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">jsonString = [</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01001&quot;, &quot;city&quot; : &quot;AGAWAM&quot;,  &quot;pop&quot; : 15338, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span>,</span><br><span class="line"><span class="string">&quot;&quot;&quot;&#123; &quot;id&quot; : &quot;01002&quot;, &quot;city&quot; : &quot;CUSHMAN&quot;, &quot;pop&quot; : 36963, &quot;state&quot; : &quot;MA&quot; &#125;&quot;&quot;&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">jsonRDD = sc.parallelize(jsonString)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义结构类型</span></span><br><span class="line"><span class="comment"># StructType：schema的整体结构，表示JSON的对象结构</span></span><br><span class="line"><span class="comment"># XXXStype:指的是某一列的数据类型</span></span><br><span class="line">jsonSchema = StructType() \</span><br><span class="line">  .add(<span class="string">&quot;id&quot;</span>, StringType(),<span class="literal">True</span>) \</span><br><span class="line">  .add(<span class="string">&quot;city&quot;</span>, StringType()) \</span><br><span class="line">  .add(<span class="string">&quot;pop&quot;</span> , LongType()) \</span><br><span class="line">  .add(<span class="string">&quot;state&quot;</span>,StringType())</span><br><span class="line"></span><br><span class="line">jsonSchema = StructType() \</span><br><span class="line">  .add(<span class="string">&quot;id&quot;</span>, LongType(),<span class="literal">True</span>) \</span><br><span class="line">  .add(<span class="string">&quot;city&quot;</span>, StringType()) \</span><br><span class="line">  .add(<span class="string">&quot;pop&quot;</span> , DoubleType()) \</span><br><span class="line">  .add(<span class="string">&quot;state&quot;</span>,StringType())</span><br><span class="line"></span><br><span class="line">reader = spark.read.schema(jsonSchema)</span><br><span class="line"></span><br><span class="line">jsonDF = reader.json(jsonRDD)</span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show()</span><br></pre></td></tr></table></figure><p><strong>带有嵌套结构的json</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line">jsonSchema = StructType([</span><br><span class="line">    StructField(<span class="string">&quot;id&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;city&quot;</span>, StringType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;loc&quot;</span> , ArrayType(DoubleType())),</span><br><span class="line">    StructField(<span class="string">&quot;pop&quot;</span>, LongType(), <span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">&quot;state&quot;</span>, StringType(), <span class="literal">True</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">reader = spark.read.schema(jsonSchema)</span><br><span class="line">jsonDF = reader.json(<span class="string">&#x27;data/nest.json&#x27;</span>)</span><br><span class="line">jsonDF.printSchema()</span><br><span class="line">jsonDF.show(<span class="number">2</span>)</span><br><span class="line">jsonDF.<span class="built_in">filter</span>(jsonDF.pop&gt;<span class="number">4000</span>).show(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h1 id="2、数据清洗"><a href="#2、数据清洗" class="headerlink" title="2、数据清洗"></a>2、数据清洗</h1><ul><li>处理重复数据</li><li>处理缺失情况</li><li>处理异常值</li></ul><p>前面我们处理的数据实际上都是已经被处理好的规整数据，但是在大数据整个生产过程中，需要先对数据进行数据清洗，将杂乱无章的数据整理为符合后面处理要求的规整数据。</p><h2 id="2-1-数据去重"><a href="#2-1-数据去重" class="headerlink" title="2.1 数据去重"></a>2.1 数据去重</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">1.删除重复数据</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">groupby().count()：可以看到数据的重复情况</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">  (<span class="number">1</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">2</span>, <span class="number">167.2</span>, <span class="number">5.4</span>, <span class="number">45</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="number">23</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.7</span>, <span class="number">54</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">3</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="number">23</span>, <span class="string">&#x27;F&#x27;</span>),</span><br><span class="line">  (<span class="number">5</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>, <span class="string">&#x27;M&#x27;</span>),</span><br><span class="line">], [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看重复记录</span></span><br><span class="line"><span class="comment"># 无意义重复数据去重：数据中行与行完全重复</span></span><br><span class="line"><span class="comment"># 1.首先删除完全一样的记录</span></span><br><span class="line">df2 = df.dropDuplicates()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 有意义去重：删除除去无意义字段之外的完全重复的行数据</span></span><br><span class="line"><span class="comment"># 2.其次，关键字段值完全一模一样的记录（在这个例子中，是指除了id之外的列一模一样）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除某些字段值完全一样的重复记录，subset参数定义这些字段</span></span><br><span class="line">df3 = df2.dropDuplicates(subset = [c <span class="keyword">for</span> c <span class="keyword">in</span> df2.columns <span class="keyword">if</span> c!=<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.有意义的重复记录去重之后，再看某个无意义字段的值是否有重复（在这个例子中，是看id是否重复）</span></span><br><span class="line"><span class="comment"># 查看某一列是否有重复值</span></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> fn</span><br><span class="line">df3.agg(fn.count(<span class="string">&#x27;id&#x27;</span>).alias(<span class="string">&#x27;id_count&#x27;</span>),fn.countDistinct(<span class="string">&#x27;id&#x27;</span>).alias(<span class="string">&#x27;distinct_id_count&#x27;</span>)).collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.对于id这种无意义的列重复，添加另外一列自增id——不连续。</span></span><br><span class="line">df3.withColumn(<span class="string">&#x27;new_id&#x27;</span>,fn.monotonically_increasing_id()).show()</span><br></pre></td></tr></table></figure><h3 id="2-2-缺失值处理"><a href="#2-2-缺失值处理" class="headerlink" title="2.2 缺失值处理"></a>2.2 缺失值处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">2.处理缺失值</span></span><br><span class="line"><span class="string">2.1 对缺失值进行删除操作(行，列)</span></span><br><span class="line"><span class="string">2.2 对缺失值进行填充操作(列的均值)</span></span><br><span class="line"><span class="string">2.3 对缺失值对应的行或列进行标记</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df_miss = spark.createDataFrame([</span><br><span class="line">(<span class="number">1</span>, <span class="number">143.5</span>, <span class="number">5.6</span>, <span class="number">28</span>,<span class="string">&#x27;M&#x27;</span>, <span class="number">100000</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="number">167.2</span>, <span class="number">5.4</span>, <span class="number">45</span>,<span class="string">&#x27;M&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="literal">None</span> , <span class="number">5.2</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.9</span>, <span class="number">33</span>, <span class="string">&#x27;M&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.7</span>, <span class="number">54</span>, <span class="string">&#x27;F&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="number">124.1</span>, <span class="number">5.2</span>, <span class="literal">None</span>, <span class="string">&#x27;F&#x27;</span>, <span class="literal">None</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">76000</span>),],</span><br><span class="line"> [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.计算每条记录的缺失值情况</span></span><br><span class="line"><span class="comment"># 将DataFrame转换成RDD，这样写自定义函数方便些。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从行的角度统计缺失情况.</span></span><br><span class="line">df_miss.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> row:(row[<span class="string">&#x27;id&#x27;</span>], <span class="built_in">sum</span>([c==<span class="literal">None</span> <span class="keyword">for</span> c <span class="keyword">in</span> row]))).collect()</span><br><span class="line">[(<span class="number">1</span>, <span class="number">0</span>), (<span class="number">2</span>, <span class="number">1</span>), (<span class="number">3</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">1</span>), (<span class="number">5</span>, <span class="number">1</span>), (<span class="number">6</span>, <span class="number">2</span>), (<span class="number">7</span>, <span class="number">0</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.计算各列的缺失情况百分比</span></span><br><span class="line">df_miss.agg(*[(<span class="number">1</span> - (fn.count(c) / fn.count(<span class="string">&#x27;*&#x27;</span>))).alias(c + <span class="string">&#x27;_missing&#x27;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> df_miss.columns]).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、删除缺失值过于严重的列</span></span><br><span class="line"><span class="comment"># 其实是先建一个DF，不要缺失值的列</span></span><br><span class="line">df_miss_no_income = df_miss.select([</span><br><span class="line">c <span class="keyword">for</span> c <span class="keyword">in</span> df_miss.columns <span class="keyword">if</span> c != <span class="string">&#x27;income&#x27;</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、按照缺失值删除行（threshold是根据一行记录中，缺失字段的百分比的定义）</span></span><br><span class="line">df_miss_no_income.dropna(thresh=<span class="number">3</span>).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5、填充缺失值，可以用fillna来填充缺失值，</span></span><br><span class="line"><span class="comment"># 对于bool类型、或者分类类型，可以为缺失值单独设置一个类型，missing</span></span><br><span class="line"><span class="comment"># 对于数值类型，可以用均值或者中位数等填充</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fillna可以接收两种类型的参数：</span></span><br><span class="line"><span class="comment"># 一个数字、字符串，这时整个DataSet中所有的缺失值都会被填充为相同的值。</span></span><br><span class="line"><span class="comment"># 也可以接收一个字典｛列名：值｝这样</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先计算均值，并组织成一个字典(除去性别这一列。)</span></span><br><span class="line">means = df_miss_no_income.agg( *[fn.mean(c).alias(c) <span class="keyword">for</span> c <span class="keyword">in</span> df_miss_no_income.columns <span class="keyword">if</span> c != <span class="string">&#x27;gender&#x27;</span>]).toPandas().to_dict(<span class="string">&#x27;records&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后添加其它的列——非数值型</span></span><br><span class="line">means[<span class="string">&#x27;gender&#x27;</span>] = <span class="string">&#x27;missing&#x27;</span></span><br><span class="line"></span><br><span class="line">df_miss_no_income.fillna(means).show()</span><br></pre></td></tr></table></figure><h3 id="2-3-异常值处理——年龄等。"><a href="#2-3-异常值处理——年龄等。" class="headerlink" title="2.3 异常值处理——年龄等。"></a>2.3 异常值处理——年龄等。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">3、异常值处理</span></span><br><span class="line"><span class="string">异常值：不属于正常的值 包含：缺失值，超过正常范围内的较大值或较小值</span></span><br><span class="line"><span class="string">分位数去极值</span></span><br><span class="line"><span class="string">中位数绝对偏差去极值</span></span><br><span class="line"><span class="string">正态分布去极值</span></span><br><span class="line"><span class="string">上述三种操作的核心都是：通过原始数据设定一个正常的范围，超过此范围的就是一个异常值</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df_outliers = spark.createDataFrame([</span><br><span class="line">(<span class="number">1</span>, <span class="number">143.5</span>, <span class="number">5.3</span>, <span class="number">28</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="number">154.2</span>, <span class="number">5.5</span>, <span class="number">45</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="number">342.3</span>, <span class="number">5.1</span>, <span class="number">99</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="number">144.5</span>, <span class="number">5.5</span>, <span class="number">33</span>),</span><br><span class="line">(<span class="number">5</span>, <span class="number">133.2</span>, <span class="number">5.4</span>, <span class="number">54</span>),</span><br><span class="line">(<span class="number">6</span>, <span class="number">124.1</span>, <span class="number">5.1</span>, <span class="number">21</span>),</span><br><span class="line">(<span class="number">7</span>, <span class="number">129.2</span>, <span class="number">5.3</span>, <span class="number">42</span>),</span><br><span class="line">], [<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>])</span><br><span class="line"><span class="comment"># 设定范围 超出这个范围的 用边界值替换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># approxQuantile方法接收三个参数：参数1，列名；参数2：想要计算的分位点，可以是一个点，也可以是一个列表（0和1之间的小数），第三个参数是能容忍的误差，如果是0，代表百分百精确计算。</span></span><br><span class="line"></span><br><span class="line">cols = [<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]</span><br><span class="line"></span><br><span class="line">bounds = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">    quantiles = df_outliers.approxQuantile(col, [<span class="number">0.25</span>, <span class="number">0.75</span>], <span class="number">0.05</span>)</span><br><span class="line">    IQR = quantiles[<span class="number">1</span>] - quantiles[<span class="number">0</span>]</span><br><span class="line">    bounds[col] = [</span><br><span class="line">        quantiles[<span class="number">0</span>] - <span class="number">1.5</span> * IQR,</span><br><span class="line">        quantiles[<span class="number">1</span>] + <span class="number">1.5</span> * IQR</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bounds</span><br><span class="line">&#123;<span class="string">&#x27;age&#x27;</span>: [-<span class="number">11.0</span>, <span class="number">93.0</span>], <span class="string">&#x27;height&#x27;</span>: [<span class="number">4.499999999999999</span>, <span class="number">6.1000000000000005</span>], <span class="string">&#x27;weight&#x27;</span>: [<span class="number">91.69999999999999</span>, <span class="number">191.7</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为异常值字段打标志</span></span><br><span class="line">outliers = df_outliers.select(*[<span class="string">&#x27;id&#x27;</span>] + [( (df_outliers[c] &lt; bounds[c][<span class="number">0</span>]) | (df_outliers[c] &gt; bounds[c][<span class="number">1</span>]) ).alias(c + <span class="string">&#x27;_o&#x27;</span>) <span class="keyword">for</span> c <span class="keyword">in</span> cols ])</span><br><span class="line">outliers.show()</span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"><span class="comment"># | id|weight_o|height_o|age_o|</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"><span class="comment"># |  1|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  2|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  3|    true|   false| true|</span></span><br><span class="line"><span class="comment"># |  4|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  5|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  6|   false|   false|false|</span></span><br><span class="line"><span class="comment"># |  7|   false|   false|false|</span></span><br><span class="line"><span class="comment"># +---+--------+--------+-----+</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再回头看看这些异常值的值，重新和原始数据关联</span></span><br><span class="line"></span><br><span class="line">df_outliers = df_outliers.join(outliers, on=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line">df_outliers.<span class="built_in">filter</span>(<span class="string">&#x27;weight_o&#x27;</span>).select(<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;weight&#x27;</span>).show()</span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"><span class="comment"># | id|weight|</span></span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"><span class="comment"># |  3| 342.3|</span></span><br><span class="line"><span class="comment"># +---+------+</span></span><br><span class="line"></span><br><span class="line">df_outliers.<span class="built_in">filter</span>(<span class="string">&#x27;age_o&#x27;</span>).select(<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;age&#x27;</span>).show()</span><br><span class="line"><span class="comment"># +---+---+</span></span><br><span class="line"><span class="comment"># | id|age|</span></span><br><span class="line"><span class="comment"># +---+---+</span></span><br><span class="line"><span class="comment"># |  3| 99|</span></span><br><span class="line"><span class="comment"># +---+---+</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、JSON数据的处理&quot;&gt;&lt;a href=&quot;#1、JSON数据的处理&quot; class=&quot;headerlink&quot; title=&quot;1、JSON数据的处理&quot;&gt;&lt;/a&gt;1、JSON数据的处理&lt;/h1&gt;&lt;h2 id=&quot;1-1-介绍&quot;&gt;&lt;a href=&quot;#1-1-介绍&quot; cla</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>08-平衡二叉树</title>
    <link href="https://xxren8218.github.io/20210705/08-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91.html"/>
    <id>https://xxren8218.github.io/20210705/08-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91.html</id>
    <published>2021-07-05T10:36:20.000Z</published>
    <updated>2021-07-05T10:37:28.881Z</updated>
    
    <content type="html"><![CDATA[<h2 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h2><ul><li>110.平衡二叉树</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183701.PNG" alt=""></p><p>咋眼一看这道题目和[二叉树的最大深度]很像，其实有很大区别。</p><p>这里强调一波概念：</p><ul><li>二叉树节点的深度：指从根节点到该节点的最长简单路径边的条数。</li><li>二叉树节点的高度：指从该节点到叶子节点的最长简单路径边的条数。</li></ul><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>这道题中的平衡二叉树的定义是：二叉树的每个节点的左右子树的高度差的绝对值不超过 1，则二叉树是平衡二叉树。根据定义，一棵二叉树是平衡二叉树，当且仅当其所有子树也都是平衡二叉树，因此可以使用递归的方式判断二叉树是不是平衡二叉树，递归的顺序可以是自顶向下或者自底向上。</p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1.思路"></a>1.思路</h3><h4 id="1-1递归法——自上而下（前序遍历）"><a href="#1-1递归法——自上而下（前序遍历）" class="headerlink" title="1.1递归法——自上而下（前序遍历）"></a>1.1递归法——自上而下（前序遍历）</h4><p>定义函数 height，用于计算二叉树中的任意一个节点 p 的高度：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183719.PNG" alt=""></p><p>有了计算节点高度的函数，即可判断二叉树是否平衡。具体做法类似于二叉树的前序遍历，即对于当前遍历到的节点，首先计算左右子树的高度，如果左右子树的高度差是否不超过 1，再分别递归地遍历左右子节点，并判断左子树和右子树是否平衡。这是一个自顶向下的递归的过程。也就是前序遍历。</p><ul><li><strong>实际上就是写找最大深度即可(后序遍历写出)</strong>。再前序递归进行计算。</li></ul><p>递归三步曲分析：</p><ol><li>明确递归函数的参数和返回值</li></ol><p>参数的话为传入的节点指针，就没有其他参数需要传递了，返回值要返回传入节点为根节点树的高度。</p><p>那么如何标记左右子树是否差值大于1呢。</p><p>只需要单独判断</p><ul><li>左右子树是否为平衡树，</li><li>左子树是否为平衡树</li><li>右子树是否为平衡树即可</li></ul><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义函数找深度当前节点为根节点的树的深度。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Height</span>(<span class="params">node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>明确终止条件</li></ol><p>递归的过程中依然是遇到空节点了为终止，返回0，表示当前节点为根节点的高度为0</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>明确单层递归的逻辑</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只要一个不满足就不是平衡树了。</span></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">abs</span>(leftHeight - rightHeight) &lt;= <span class="number">1</span> <span class="keyword">and</span> isBalanced(root.left) <span class="keyword">and</span> </span><br><span class="line">isBalanced(root.right)</span><br></pre></td></tr></table></figure><p>整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isBalanced</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="comment">##   前序在这里体现   ##</span></span><br><span class="line">        <span class="comment">######################</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">abs</span>(self.Height(root.left) - self.Height(root.right)) &lt;= <span class="number">1</span> <span class="keyword">and</span> \</span><br><span class="line">                self.isBalanced(root.left) <span class="keyword">and</span> \</span><br><span class="line">                self.isBalanced(root.right)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Height</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftHeight = self.Height(node.left)</span><br><span class="line">        rightHeight = self.Height(node.right)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + <span class="built_in">max</span>(leftHeight, rightHeight)</span><br></pre></td></tr></table></figure><p>时间复杂度：O(n^2)，其中 n 是二叉树中的节点个数。</p><p>空间复杂度：O(n)。</p><h4 id="1-2-递归法——自下而上（后序遍历）"><a href="#1-2-递归法——自下而上（后序遍历）" class="headerlink" title="1.2 递归法——自下而上（后序遍历）"></a>1.2 递归法——自下而上（后序遍历）</h4><p>方法一由于是自顶向下递归，因此对于同一个节点，函数 height 会被重复调用，导致时间复杂度较高。如果使用自底向上的做法，则对于每个节点，函数 height 只会被调用一次。</p><p>自底向上递归的做法类似于后序遍历，对于当前遍历到的节点，先递归地判断其左右子树是否平衡，再判断以当前节点为根的子树是否平衡。如果一棵子树是平衡的，则返回其高度（高度一定是非负整数），否则返回 -1−1。如果存在一棵子树不平衡，则整个二叉树一定不平衡。</p><p>只需修改后序遍历的代码，相当于在子函数（Height()）递归时进行判断了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isBalanced</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> self.Height(root) &gt;= <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Height</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        此处的单层递归的逻辑是：</span></span><br><span class="line"><span class="string">        若是平衡二叉树，直接返回深度</span></span><br><span class="line"><span class="string">        若不是平衡二叉树，返回 -1。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftHeight = self.Height(node.left)</span><br><span class="line">        rightHeight = self.Height(node.right)</span><br><span class="line">        <span class="comment">####################</span></span><br><span class="line">        <span class="comment">##  后序在这里体现  ## </span></span><br><span class="line">        <span class="comment">####################</span></span><br><span class="line">        <span class="keyword">if</span> leftHeight == -<span class="number">1</span> <span class="keyword">or</span> rightHeight == -<span class="number">1</span> <span class="keyword">or</span> <span class="built_in">abs</span>(leftHeight - rightHeight) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(leftHeight, rightHeight) + <span class="number">1</span></span><br></pre></td></tr></table></figure><p>时间复杂度：O(n)，其中 nn 是二叉树中的节点个数。使用自底向上的递归，每个节点的计算高度和判断是否平衡都只需要处理一次，最坏情况下需要遍历二叉树中的所有节点，因此时间复杂度是 O(n)。</p><p>空间复杂度：O(n)，其中 nn 是二叉树中的节点个数。空间复杂度主要取决于递归调用的层数，递归调用的层数不会超过 n。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本题没有给迭代的解法，说实话我觉得有点难，懒得想了！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;平衡二叉树&quot;&gt;&lt;a href=&quot;#平衡二叉树&quot; class=&quot;headerlink&quot; title=&quot;平衡二叉树&quot;&gt;&lt;/a&gt;平衡二叉树&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;110.平衡二叉树&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdeli</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>07-完全二叉树的节点个数</title>
    <link href="https://xxren8218.github.io/20210705/07-%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%AA%E6%95%B0.html"/>
    <id>https://xxren8218.github.io/20210705/07-%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%AA%E6%95%B0.html</id>
    <published>2021-07-05T10:34:49.000Z</published>
    <updated>2021-07-05T10:35:49.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="完全二叉树的节点个数"><a href="#完全二叉树的节点个数" class="headerlink" title="完全二叉树的节点个数"></a>完全二叉树的节点个数</h2><ul><li>222.完全二叉树的节点个数</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183522.PNG" alt=""></p><h3 id="1-思路"><a href="#1-思路" class="headerlink" title="1.思路"></a>1.思路</h3><p>这道题目其实没有必要强调是完全二叉树，就是求二叉树节点的个数。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705183536.png" alt=""></p><p>依然可以使用递归法和迭代法来解决。</p><p>这道题目的递归法和求二叉树的深度写法类似， 而迭代法：二叉树层序遍历模板稍稍修改一下，记录遍历的节点数量就可以了。</p><p>递归遍历的顺序依然是后序（左右中）。</p><h3 id="2-递归法"><a href="#2-递归法" class="headerlink" title="2.递归法"></a>2.递归法</h3><ol><li>确定递归函数的参数和返回值：参数就是传入树的根节点，返回就返回以该节点为根节点二叉树的节点数量。</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTreeNumber</span>(<span class="params">node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>确定终止条件：如果为空节点的话，就返回0，表示节点数为0</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑：先求它的左子树的节点数量，再求的右子树的节点数量，最后取总和再加一 （加1是因为算上当前中间节点）就是目前节点为根节点的节点数量。</li></ol><p>整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countNodes</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getTreeNumber(root)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTreeNumber</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftnum = self.getTreeNumber(node.left)</span><br><span class="line">        rightnum = self.getTreeNumber(node.right)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + leftnum + rightnum</span><br></pre></td></tr></table></figure><h3 id="3-迭代法"><a href="#3-迭代法" class="headerlink" title="3.迭代法"></a>3.迭代法</h3><p>层序迭代法也很简单。只要模板少做改动，加一个变量result，统计节点数量就可以了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countNodes</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                queue.append(cur_node.left)</span><br><span class="line">            <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                queue.append(cur_node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h3 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h3><p>一样的分析套路，代码也差不多，估计此时大家最这一类求二叉树节点数量以及求深度应该非常熟练了。</p><p>没有做过这道题目的同学可以愉快的刷了它。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;完全二叉树的节点个数&quot;&gt;&lt;a href=&quot;#完全二叉树的节点个数&quot; class=&quot;headerlink&quot; title=&quot;完全二叉树的节点个数&quot;&gt;&lt;/a&gt;完全二叉树的节点个数&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;222.完全二叉树的节点个数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;im</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>30-Spark SQL概述 &amp; Spark DataFrame</title>
    <link href="https://xxren8218.github.io/20210705/30-Spark-SQL%E6%A6%82%E8%BF%B0-Spark-DataFrame.html"/>
    <id>https://xxren8218.github.io/20210705/30-Spark-SQL%E6%A6%82%E8%BF%B0-Spark-DataFrame.html</id>
    <published>2021-07-04T17:00:41.000Z</published>
    <updated>2021-07-04T17:04:20.780Z</updated>
    
    <content type="html"><![CDATA[<h1 id="掌握目标"><a href="#掌握目标" class="headerlink" title="掌握目标"></a>掌握目标</h1><ul><li>说出Spark Sql的相关概念</li><li>说出DataFrame与RDD的联系</li><li>独立实现Spark Sql对JSON数据的处理</li><li>独立实现Spark Sql进行数据清洗</li></ul><h2 id="1、Spark-SQL-概述"><a href="#1、Spark-SQL-概述" class="headerlink" title="1、Spark SQL 概述"></a>1、Spark SQL 概述</h2><p><strong>Spark SQL概念</strong></p><ul><li>Spark SQL is Apache Spark’s module for working with structured data.<ul><li>它是spark中用于处理结构化数据的一个模块</li></ul></li></ul><p><strong>Spark SQL历史</strong></p><ul><li>Hive是目前大数据领域，事实上的数据仓库标准。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010211.PNG" alt=""></p><ul><li>Shark：shark底层使用spark的基于内存的计算模型，从而让性能比Hive提升了数倍到上百倍。</li><li>底层很多东西还是依赖于Hive，修改了内存管理、物理计划、执行三个模块</li><li>2014年6月1日的时候，Spark宣布了不再开发Shark，全面转向Spark SQL的开发</li></ul><p><strong>Spark SQL优势</strong></p><ul><li>Write Less Code</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010243.PNG" alt=""></p><ul><li>Performance</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010304.PNG" alt=""></p><p>python操作RDD，转换为可执行代码，运行在java虚拟机，涉及两个不同语言引擎之间的切换，进行进程间        通信很耗费性能。</p><p>DataFrame</p><ul><li>是RDD为基础的分布式数据集，类似于传统关系型数据库的二维表，dataframe记录了对应列的名称和类型</li><li>dataFrame引入schema和off-heap(使用操作系统层面上的内存)<ul><li>1、解决了RDD的缺点</li><li>序列化和反序列化开销大</li><li>频繁的创建和销毁对象造成大量的GC</li><li>2、丢失了RDD的优点</li><li>RDD编译时进行类型检查</li><li>RDD具有面向对象编程的特性</li></ul></li></ul><p>用scala/python编写的RDD比Spark SQL编写转换的RDD慢，涉及到执行计划</p><ul><li>CatalystOptimizer：Catalyst优化器</li><li>ProjectTungsten：钨丝计划，为了提高RDD的效率而制定的计划</li><li>Code gen：代码生成器</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010321.PNG" alt=""></p><p>直接编写RDD也可以自实现优化代码，但是远不及SparkSQL前面的优化操作后转换的RDD效率高，快1倍左右</p><p>优化引擎：类似mysql等关系型数据库基于成本的优化器</p><p>首先执行逻辑执行计划，然后转换为物理执行计划(选择成本最小的)，通过Code Generation最终生成为RDD</p><ul><li><p>Language-independent API</p><p>用任何语言编写生成的RDD都一样，而使用spark-core编写的RDD，不同的语言生成不同的RDD</p></li></ul><ul><li><p>Schema</p><p>结构化数据，可以直接看出数据的详情</p><p>在RDD中无法看出，解释性不强，无法告诉引擎信息，没法详细优化。</p></li></ul><p><strong>为什么要学习sparksql </strong></p><p>sparksql特性</p><ul><li>1、易整合</li><li>2、统一的数据源访问</li><li>3、兼容hive</li><li>4、提供了标准的数据库连接（jdbc/odbc）</li></ul><h1 id="2、DataFrame"><a href="#2、DataFrame" class="headerlink" title="2、DataFrame"></a>2、DataFrame</h1><h2 id="2-1-介绍"><a href="#2-1-介绍" class="headerlink" title="2.1 介绍"></a>2.1 介绍</h2><p>在Spark语义中，DataFrame是一个分布式的<strong>行集合</strong>，可以想象为一个关系型数据库的表，或者一个带有列名的Excel表格。它和RDD一样，有这样一些特点：</p><ul><li>Immuatable：一旦RDD、DataFrame被创建，就不能更改，只能通过transformation生成新的RDD、DataFrame</li><li>Lazy Evaluations：只有action才会触发Transformation的执行</li><li>Distributed：DataFrame和RDD一样都是分布式的</li><li>dataframe和dataset（没有python版本,没法做类型校验。python是若类型语言）统一，dataframe只是dataset[ROW]的类型别名。由于Python是弱类型语言，只能使用DataFrame</li></ul><p><strong>DataFrame vs RDD</strong></p><ul><li>RDD：分布式的对象的集合，Spark并不知道对象的详细模式信息</li><li>DataFrame：分布式的Row对象的集合，其提供了由列组成的详细模式信息，使得Spark SQL可以进行某些形式的执行优化。</li><li>DataFrame和普通的RDD的逻辑框架区别如下所示：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010339.PNG" alt=""></p><ul><li><p>左侧的RDD Spark框架本身不了解 Person类的内部结构。</p></li><li><p>右侧的DataFrame提供了详细的结构信息（schema——每列的名称，类型）</p></li><li>DataFrame还配套了新的操作数据的方法，DataFrame API（如df.select())和SQL(select id, name from xx_table where …)。</li><li><p>DataFrame还引入了off-heap,意味着JVM堆以外的内存, 这些内存直接受操作系统管理（而不是JVM）。</p></li><li><p>RDD是分布式的Java对象的集合。DataFrame是分布式的Row对象的集合。DataFrame除了提供了比RDD更丰富的算子以外，更重要的特点是提升执行效率、减少数据读取以及执行计划的优化。</p></li><li>DataFrame的抽象后，我们处理数据更加简单了，甚至可以用SQL来处理数据了</li><li>通过DataFrame API或SQL处理数据，会自动经过Spark 优化器（Catalyst）的优化，即使你写的程序或SQL不仅高效，也可以运行的很快。</li><li><strong>DataFrame相当于是一个带着schema的RDD</strong></li></ul><p><strong>Pandas DataFrame vs Spark DataFrame</strong></p><ul><li>Cluster Parallel：集群并行执行</li><li>Lazy Evaluations: 只有action才会触发Transformation的执行</li><li>Immutable：不可更改</li><li>Pandas rich API：比Spark SQL api丰富</li></ul><h2 id="2-2-创建DataFrame"><a href="#2-2-创建DataFrame" class="headerlink" title="2.2 创建DataFrame"></a>2.2 创建DataFrame</h2><p>0.创建之前必须有一个SparkSession.</p><p>1，创建dataFrame的步骤</p><p>​    调用方法例如：spark.read.xxx方法</p><p>2，其他方式创建dataframe</p><ul><li><p>createDataFrame：pandas dataframe、list、RDD</p></li><li><p>数据源：RDD、csv、json、parquet、orc、jdbc</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">jsonDF = spark.read.json(<span class="string">&quot;xxx.json&quot;</span>)</span><br><span class="line"></span><br><span class="line">jsonDF = spark.read.<span class="built_in">format</span>(<span class="string">&#x27;json&#x27;</span>).load(<span class="string">&#x27;xxx.json&#x27;</span>)</span><br><span class="line"></span><br><span class="line">parquetDF = spark.read.parquet(<span class="string">&quot;xxx.parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line">jdbcDF = spark.read.<span class="built_in">format</span>(<span class="string">&quot;jdbc&quot;</span>).option(<span class="string">&quot;url&quot;</span>,<span class="string">&quot;jdbc:mysql://localhost:3306/db_name&quot;</span>).option(<span class="string">&quot;dbtable&quot;</span>,<span class="string">&quot;table_name&quot;</span>).option(<span class="string">&quot;user&quot;</span>,<span class="string">&quot;xxx&quot;</span>).option(<span class="string">&quot;password&quot;</span>,<span class="string">&quot;xxx&quot;</span>).load()</span><br></pre></td></tr></table></figure></li><li><p>Transformation:延迟性操作</p></li><li><p>action：立即操作</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210705010358.PNG" alt=""></p></li></ul><h2 id="2-3-DataFrame-API实现"><a href="#2-3-DataFrame-API实现" class="headerlink" title="2.3 DataFrame API实现"></a>2.3 DataFrame API实现</h2><p><strong>基于RDD创建</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DatFrame需要有 Spark Session</span></span><br><span class="line"><span class="comment"># 创建RDD需要有SparkContext</span></span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&#x27;test&#x27;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line"><span class="comment"># spark.conf.set(&quot;spark.sql.shuffle.partitions&quot;, 6)</span></span><br><span class="line"><span class="comment"># ================直接创建==========================</span></span><br><span class="line">l = [(<span class="string">&#x27;Ankit&#x27;</span>,<span class="number">25</span>),(<span class="string">&#x27;Jalfaizy&#x27;</span>,<span class="number">22</span>),(<span class="string">&#x27;saurabh&#x27;</span>,<span class="number">20</span>),(<span class="string">&#x27;Bala&#x27;</span>,<span class="number">26</span>)]</span><br><span class="line">rdd = sc.parallelize(l)</span><br><span class="line"><span class="comment"># 为数据添加列名</span></span><br><span class="line">people = rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: Row(name=x[<span class="number">0</span>], age=<span class="built_in">int</span>(x[<span class="number">1</span>])))</span><br><span class="line"><span class="comment"># 通过SparkSession来创建DataFrame</span></span><br><span class="line">schemaPeople = spark.createDataFrame(people)</span><br></pre></td></tr></table></figure><p><strong>从csv中读取数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==================从csv读取======================</span></span><br><span class="line"><span class="comment"># 加载csv类型的数据并转换为DataFrame,默认是从hadoop的/user/root//下查找，目前我们用户是root</span></span><br><span class="line">df = spark.read.<span class="built_in">format</span>(<span class="string">&quot;csv&quot;</span>). \</span><br><span class="line">    option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>) \   <span class="comment"># header True,把最前面的展示出来。</span></span><br><span class="line">    .load(<span class="string">&quot;iris.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 显示数据结构</span></span><br><span class="line">df.printSchema()</span><br><span class="line"><span class="comment"># 显示前10条数据</span></span><br><span class="line">df.show(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 统计总量</span></span><br><span class="line">df.count()</span><br><span class="line"><span class="comment"># 列名</span></span><br><span class="line">df.columns</span><br></pre></td></tr></table></figure><p><strong>增加一列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ===============增加一列(或者替换) withColumn===========</span></span><br><span class="line"><span class="comment"># 定义一个新的列，数据为其他某列数据的两倍</span></span><br><span class="line"><span class="comment"># 如果操作的是原有列，可以替换原有列的数据</span></span><br><span class="line">df.withColumn(<span class="string">&#x27;newWidth&#x27;</span>,df.SepalWidth * <span class="number">2</span>).show()</span><br></pre></td></tr></table></figure><p><strong>删除一列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==========删除一列  drop=========================</span></span><br><span class="line"><span class="comment"># 删除一列</span></span><br><span class="line">df.drop(<span class="string">&#x27;newWidth&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>统计信息</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================ 统计信息 describe================</span></span><br><span class="line">df.describe().show()</span><br><span class="line"><span class="comment"># 计算某一列的描述信息</span></span><br><span class="line">df.describe(<span class="string">&#x27;newWidth&#x27;</span>).show()   </span><br></pre></td></tr></table></figure><p><strong>提取部分列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ===============提取部分列 select==============</span></span><br><span class="line">df.select(<span class="string">&#x27;SepalLength&#x27;</span>,<span class="string">&#x27;SepalWidth&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>基本统计功能</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ==================基本统计功能 distinct count=====</span></span><br><span class="line">df.select(<span class="string">&#x27;cls&#x27;</span>).distinct().count()</span><br></pre></td></tr></table></figure><p><strong>分组统计</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分组统计 groupby(colname).agg(&#123;&#x27;col&#x27;:&#x27;fun&#x27;,&#x27;col2&#x27;:&#x27;fun2&#x27;&#125;)</span></span><br><span class="line">df.groupby(<span class="string">&#x27;cls&#x27;</span>).agg(&#123;<span class="string">&#x27;SepalWidth&#x27;</span>:<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;SepalLength&#x27;</span>:<span class="string">&#x27;max&#x27;</span>&#125;).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># avg(), count(), countDistinct(), first(), kurtosis(),</span></span><br><span class="line"><span class="comment"># max(), mean(), min(), skewness(), stddev(), stddev_pop(),</span></span><br><span class="line"><span class="comment"># stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance()</span></span><br></pre></td></tr></table></figure><p><strong>自定义的汇总方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义的汇总方法</span></span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> fn</span><br><span class="line"><span class="comment"># 调用函数并起一个别名</span></span><br><span class="line">df.agg(fn.count(<span class="string">&#x27;SepalWidth&#x27;</span>).alias(<span class="string">&#x27;width_count&#x27;</span>),fn.countDistinct(<span class="string">&#x27;cls&#x27;</span>).alias(<span class="string">&#x27;distinct_cls_count&#x27;</span>)).show()</span><br></pre></td></tr></table></figure><p><strong>拆分数据集</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ====================数据集拆成两部分 randomSplit ===========</span></span><br><span class="line"><span class="comment"># 设置数据比例将数据划分为两部分</span></span><br><span class="line">trainDF, testDF = df.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>])</span><br></pre></td></tr></table></figure><p><strong>采样数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================采样数据 sample===========</span></span><br><span class="line"><span class="comment"># withReplacement：是否有放回的采样</span></span><br><span class="line"><span class="comment"># fraction：采样比例</span></span><br><span class="line"><span class="comment"># seed：随机种子</span></span><br><span class="line">sdf = df.sample(<span class="literal">False</span>,<span class="number">0.2</span>,<span class="number">100</span>)</span><br></pre></td></tr></table></figure><p><strong>查看两个数据集在类别上的差异</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看两个数据集在类别上的差异 subtract，确保训练数据集覆盖了所有分类</span></span><br><span class="line">diff_in_train_test = testDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(trainDF.select(<span class="string">&#x27;cls&#x27;</span>))</span><br><span class="line">diff_in_train_test.distinct().count()</span><br></pre></td></tr></table></figure><p><strong>交叉表</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================交叉表 crosstab=============</span></span><br><span class="line">df.crosstab(<span class="string">&#x27;cls&#x27;</span>,<span class="string">&#x27;SepalLength&#x27;</span>).show()</span><br></pre></td></tr></table></figure><p><strong>udf</strong></p><p>udf：自定义函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ================== 综合案例 + udf================</span></span><br><span class="line"><span class="comment"># 测试数据集中有些类别在训练集中是不存在的，找到这些数据集做后续处理</span></span><br><span class="line">trainDF,testDF = df.randomSplit([<span class="number">0.99</span>,<span class="number">0.01</span>])</span><br><span class="line"></span><br><span class="line">diff_in_train_test = trainDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(testDF.select(<span class="string">&#x27;cls&#x27;</span>)).distinct().show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先找到这些类，整理到一个列表</span></span><br><span class="line">not_exist_cls = trainDF.select(<span class="string">&#x27;cls&#x27;</span>).subtract(testDF.select(<span class="string">&#x27;cls&#x27;</span>)).distinct().rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> x :x[<span class="number">0</span>]).collect()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个方法，用于检测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">should_remove</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">in</span> not_exist_cls:</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建udf，udf函数需要两个参数：</span></span><br><span class="line"><span class="comment"># Function</span></span><br><span class="line"><span class="comment"># Return type (in my case StringType())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在RDD中可以直接定义函数，交给rdd的transformatioins方法进行执行</span></span><br><span class="line"><span class="comment"># 在DataFrame中 需要通过udf将自定义函数封装成udf函数，创建一个UDF对象，只有UDF对象 才可以DataFrame进行调用执行</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> udf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先封装成UDF函数。</span></span><br><span class="line">check = udf(should_remove,StringType())</span><br><span class="line"></span><br><span class="line">resultDF = trainDF.withColumn(<span class="string">&#x27;New_cls&#x27;</span>,check(trainDF[<span class="string">&#x27;cls&#x27;</span>])).<span class="built_in">filter</span>(<span class="string">&#x27;New_cls &lt;&gt; -1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">resultDF.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;掌握目标&quot;&gt;&lt;a href=&quot;#掌握目标&quot; class=&quot;headerlink&quot; title=&quot;掌握目标&quot;&gt;&lt;/a&gt;掌握目标&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;说出Spark Sql的相关概念&lt;/li&gt;
&lt;li&gt;说出DataFrame与RDD的联系&lt;/li&gt;
&lt;li&gt;独立</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>06-二叉树的最小深度</title>
    <link href="https://xxren8218.github.io/20210704/06-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%B0%8F%E6%B7%B1%E5%BA%A6.html"/>
    <id>https://xxren8218.github.io/20210704/06-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%B0%8F%E6%B7%B1%E5%BA%A6.html</id>
    <published>2021-07-04T13:36:56.000Z</published>
    <updated>2021-07-04T13:38:02.041Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二叉树的最小深度"><a href="#二叉树的最小深度" class="headerlink" title="二叉树的最小深度"></a>二叉树的最小深度</h2><ul><li>111.二叉树的最小深度</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213732.PNG" alt=""></p><p>直觉上好像和求最大深度差不多，其实还是差不少的。</p><p>遍历顺序上依然是后序遍历（因为要比较递归返回之后的结果），但在处理中间节点的逻辑上，最大深度很容易理解，最小深度可有一个误区，如图：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213744.png" alt=""></p><p>这就重新审题了，题目中说的是：<strong>「最小深度是从根节点到最近叶子节点的最短路径上的节点数量。」</strong>，注意是<strong>「叶子节点」</strong>。</p><p>什么是叶子节点，左右孩子都为空的节点才是叶子节点！</p><h4 id="1-递归法"><a href="#1-递归法" class="headerlink" title="1.递归法"></a>1.递归法</h4><p>来来来，一起递归三部曲：</p><ol><li>确定递归函数的参数和返回值</li></ol><p>参数为要传入的二叉树根节点。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>确定终止条件</li></ol><p>终止条件也是遇到空节点返回0，表示当前节点的高度为0。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑</li></ol><p>这块和求最大深度可就不一样了，一些同学可能会写如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftDepth = getDepth(node.left)</span><br><span class="line">rightDepth = getDepth(node.right)</span><br><span class="line">result = <span class="number">1</span> + <span class="built_in">min</span>(leftDepth, rightDepth)</span><br><span class="line"><span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>这个代码就犯了此图中的误区：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213744.png" alt=""></p><p>如果这么求的话，没有左孩子的分支会算为最短深度。</p><p>所以，如果左子树为空，右子树不为空，说明最小深度是 1 + 右子树的深度。</p><p>反之，右子树为空，左子树不为空，最小深度是 1 + 左子树的深度。最后如果左右子树都不为空，返回左右子树深度最小值 + 1 。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">leftDepth = getDepth(node.left)    <span class="comment"># 左</span></span><br><span class="line">rightDepth = getDepth(node.right)  <span class="comment"># 右</span></span><br><span class="line">                                   <span class="comment"># 中</span></span><br><span class="line"><span class="comment"># 当一个左子树为空，右不为空，这时并不是最低点</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> node.right: </span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + rightDepth</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当一个右子树为空，左不为空，这时并不是最低点</span></span><br><span class="line"><span class="keyword">if</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right: </span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> + leftDepth</span><br><span class="line">result = <span class="number">1</span> + <span class="built_in">min</span>(leftDepth, rightDepth)  </span><br><span class="line"><span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>遍历的顺序为后序（左右中），可以看出：<strong>「求二叉树的最小深度和求二叉树的最大深度的差别主要在于处理左右孩子不为空的逻辑。」</strong></p><p>整体递归代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getDepth(root)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftDpeth = self.getDepth(node.left)</span><br><span class="line">        rightDepth = self.getDepth(node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node.left <span class="keyword">and</span> node.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> + rightDepth</span><br><span class="line">        <span class="keyword">if</span> node.left <span class="keyword">and</span> <span class="keyword">not</span> node.right:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> + leftDpeth</span><br><span class="line">        result = <span class="number">1</span> + <span class="built_in">min</span>(leftDpeth, rightDepth)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h4 id="2-迭代法"><a href="#2-迭代法" class="headerlink" title="2. 迭代法"></a>2. 迭代法</h4><p>按照层序遍历的方法很好解决：直接套模板。用res来记录结果，每进入一层res加1，当左右孩子都为空的时候，说明为最小深度，直接返回结果即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> cur_node.left <span class="keyword">and</span> <span class="keyword">not</span> cur_node.right:</span><br><span class="line">                    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3></blockquote><p>最大深度与最小深度也不过如此嘛！可以用【递归法】和【迭代法分别实现】！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二叉树的最小深度&quot;&gt;&lt;a href=&quot;#二叉树的最小深度&quot; class=&quot;headerlink&quot; title=&quot;二叉树的最小深度&quot;&gt;&lt;/a&gt;二叉树的最小深度&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;111.二叉树的最小深度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;htt</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>05-二（N）叉树的最大深度</title>
    <link href="https://xxren8218.github.io/20210704/05-%E4%BA%8C%EF%BC%88N%EF%BC%89%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%A4%A7%E6%B7%B1%E5%BA%A6.html"/>
    <id>https://xxren8218.github.io/20210704/05-%E4%BA%8C%EF%BC%88N%EF%BC%89%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%A4%A7%E6%B7%B1%E5%BA%A6.html</id>
    <published>2021-07-04T13:35:05.000Z</published>
    <updated>2021-07-04T17:04:51.355Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二（N）叉树的最大深度"><a href="#二（N）叉树的最大深度" class="headerlink" title="二（N）叉树的最大深度"></a>二（N）叉树的最大深度</h2><blockquote><h3 id="1-二叉树的最大深度"><a href="#1-二叉树的最大深度" class="headerlink" title="1. 二叉树的最大深度"></a>1. 二叉树的最大深度</h3></blockquote><ul><li>104.二叉树的最大深度</li><li>559.N叉树的最大深度</li></ul><p>给定一个二叉树，找出其最大深度。</p><p>二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。</p><p>说明: 叶子节点是指没有子节点的节点。</p><p>示例：<br>给定二叉树 [3,9,20,null,null,15,7]，</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213548.png" alt=""></p><p>返回它的最大深度 3 。</p><h4 id="1-思路"><a href="#1-思路" class="headerlink" title="1. 思路"></a>1. 思路</h4><h4 id="1-1-递归法"><a href="#1-1-递归法" class="headerlink" title="1.1 递归法"></a>1.1 递归法</h4><p>本题其实也要后序遍历（左右中），依然是因为要通过递归函数的返回值做计算树的高度。</p><p>按照递归三部曲，来看看如何来写。</p><ol><li>确定递归函数的参数和返回值：参数就是传入树的根节点，返回就返回这棵树的深度。</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br></pre></td></tr></table></figure><ol><li>确定终止条件：如果为空节点的话，就返回0，表示高度为0。</li></ol><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> node == <span class="literal">None</span>: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><ol><li>确定单层递归的逻辑：先求它的左子树的深度，再求的右子树的深度，最后取左右深度最大的数值 再+1 （加1是因为算上当前中间节点）就是目前节点为根节点的树的深度。</li></ol><p>代码如下：后序遍历，按照左右中的顺序）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">leftDepth = getDepth(node.left);       <span class="comment"># 左</span></span><br><span class="line">rightDepth = getDepth(node.right);     <span class="comment"># 右</span></span><br><span class="line">depth = <span class="number">1</span> + <span class="built_in">max</span>(leftDepth, rightDepth); <span class="comment"># 中</span></span><br><span class="line"><span class="keyword">return</span> depth</span><br></pre></td></tr></table></figure><p>所以整体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getDepth(root)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        leftDepth = self.getDepth(node.left)</span><br><span class="line">        rightDepth = self.getDepth(node.right)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + <span class="built_in">max</span>(leftDepth, rightDepth) </span><br></pre></td></tr></table></figure><h4 id="1-2-迭代法"><a href="#1-2-迭代法" class="headerlink" title="1.2 迭代法"></a>1.2 迭代法</h4><p>使用迭代法的话，使用层序遍历是比较合适的，也是比较容易理解的。因为最大的深度就是二叉树的层数，和层序遍历的方式极其吻合。</p><p>在二叉树中，一层一层的来遍历二叉树，记录一下遍历的层数就是二叉树的深度，如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213601.png" alt=""></p><p>所以这道题的迭代法就是一道【模板题】，可以使用二叉树层序遍历的模板来解决的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 框架上改一行</span></span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            n = <span class="built_in">len</span>(queue)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> cur_node.left:</span><br><span class="line">                    queue.append(cur_node.left)</span><br><span class="line">                <span class="keyword">if</span> cur_node.right:</span><br><span class="line">                    queue.append(cur_node.right)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="2-N叉树的最大深度"><a href="#2-N叉树的最大深度" class="headerlink" title="2. N叉树的最大深度"></a>2. N叉树的最大深度</h3></blockquote><p>给定一个 N 叉树，找到其最大深度。</p><p>最大深度是指从根节点到最远叶子节点的最长路径上的节点总数。</p><p>例如，给定一个 3叉树 :</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213613.png" alt=""></p><p>我们应返回其最大深度，3。</p><h4 id="1-思路："><a href="#1-思路：" class="headerlink" title="1. 思路："></a>1. 思路：</h4><p>依然可以提供递归法和迭代法，来解决这个问题，思路是和二叉树思路一样的，直接给出代码如下：</p><h4 id="2-1-递归法"><a href="#2-1-递归法" class="headerlink" title="2.1 递归法"></a>2.1 递归法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val=None, children=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.children = children</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.getDepth(root)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getDepth</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        depth = <span class="number">0</span></span><br><span class="line">        <span class="comment"># leftDepth = self.getDepth(node.left)</span></span><br><span class="line">        <span class="comment"># rightDepth = self.getDepth(node.right)</span></span><br><span class="line">        <span class="comment"># return 1 + max(leftDepth, rightDepth)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(node.children)):</span><br><span class="line">            depth = <span class="built_in">max</span>(depth, self.getDepth(node.children[i]))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + depth</span><br></pre></td></tr></table></figure><h4 id="2-2-迭代法"><a href="#2-2-迭代法" class="headerlink" title="2.2 迭代法"></a>2.2 迭代法</h4><p>同样的也是套用模板。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"># Definition for a Node.</span></span><br><span class="line"><span class="string">class Node(object):</span></span><br><span class="line"><span class="string">    def __init__(self, val=None, children=None):</span></span><br><span class="line"><span class="string">        self.val = val</span></span><br><span class="line"><span class="string">        self.children = children</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: Node</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            n = <span class="built_in">len</span>(queue)</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                cur_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 只需要改变这里就可以了。</span></span><br><span class="line">                <span class="keyword">while</span> cur_node.children:</span><br><span class="line">                    queue.append(cur_node.children.pop(<span class="number">0</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><blockquote><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3></blockquote><p>至此，二（N）叉树的最大深度就完成了，分别采用了递归法和迭代法进行求解，递归法可以看到递归三部曲的身影，迭代法套用模板即可！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二（N）叉树的最大深度&quot;&gt;&lt;a href=&quot;#二（N）叉树的最大深度&quot; class=&quot;headerlink&quot; title=&quot;二（N）叉树的最大深度&quot;&gt;&lt;/a&gt;二（N）叉树的最大深度&lt;/h2&gt;&lt;blockquote&gt;
&lt;h3 id=&quot;1-二叉树的最大深度&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>04-对称二叉树</title>
    <link href="https://xxren8218.github.io/20210704/04-%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91.html"/>
    <id>https://xxren8218.github.io/20210704/04-%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91.html</id>
    <published>2021-07-04T13:32:41.000Z</published>
    <updated>2021-07-04T13:34:15.917Z</updated>
    
    <content type="html"><![CDATA[<h2 id="对称二叉树"><a href="#对称二叉树" class="headerlink" title="对称二叉树"></a>对称二叉树</h2><ul><li>101.对称二叉树</li></ul><p>给定一个二叉树，检查它是否是镜像对称的。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213329.PNG" alt=""></p><h3 id="一、思路"><a href="#一、思路" class="headerlink" title="一、思路"></a>一、思路</h3><p><strong>「首先想清楚，判断对称二叉树要比较的是哪两个节点，要比较的可不是左右节点！」</strong></p><p>对于二叉树是否对称，要比较的是根节点的左子树与右子树是不是相互翻转的，理解这一点就知道了<strong>「其实我们要比较的是两个树（这两个树是根节点的左右子树）」</strong>，所以在递归遍历的过程中，也是要同时遍历两棵树。</p><p>那么如果比较呢？</p><p>比较的是两个子树的里侧和外侧的元素是否相等。如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213343.jpg" alt=""></p><p>那么遍历的顺序应该是什么样的呢？</p><p>本题遍历只能是“后序遍历”，因为我们要通过递归函数的返回值来判断两个子树的内侧节点和外侧节点是否相等。</p><p><strong>「正是因为要遍历两棵树而且要比较内侧和外侧节点，所以准确的来说是一个树的遍历顺序是左右中，一个树的遍历顺序是右左中。」</strong></p><p>但都可以理解算是后序遍历，尽管已经不是严格上在一个树上进行遍历的后序遍历了。</p><p>说到这大家可能感觉我有点啰嗦，哪有这么多道理，上来就干就完事了。别急，我说的这些在下面的代码讲解中都有身影。</p><p>那么我们先来看看递归法的代码应该怎么写。</p><h3 id="二、递归法"><a href="#二、递归法" class="headerlink" title="二、递归法"></a>二、递归法</h3><p><strong>递归三部曲</strong></p><ul><li><p>确定递归函数的参数和返回值</p><p>因为我们要比较的是根节点的两个子树是否是相互翻转的，进而判断这个树是不是对称树，所以要比较的是两个树，参数自然也是左子树节点和右子树节点。</p><p>返回值自然是bool类型。</p></li></ul><p>代码如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def compare(left, right): -&gt; bool</span><br></pre></td></tr></table></figure><ul><li><p>确定终止条件</p><p>要比较两个节点数值相不相同，首先要把两个节点为空的情况弄清楚！否则后面比较数值的时候就会操作空指针了。</p><p>节点为空的情况有：（<strong>「注意我们比较的其实不是左孩子和右孩子，所以如下我称之为左节点右节点」</strong>）</p><ul><li><p>左节点为空，右节点不为空，不对称，return false</p></li><li><p>左不为空，右为空，不对称 return  false</p></li><li><p>左右都为空，对称，返回true</p></li></ul><p>此时已经排除掉了节点为空的情况，那么剩下的就是左右节点不为空：</p><ul><li>左右都不为空，比较节点数值，不相同就return false</li></ul><p>此时左右节点不为空，且数值也不相同的情况我们也处理了。</p></li></ul><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> left != <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right != <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> left.val != right.val: <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><ul><li><p>确定单层递归的逻辑</p><p>此时才进入单层递归的逻辑，单层递归的逻辑就是处理 右节点都不为空，且数值相同的情况。</p><ul><li>比较二叉树外侧是否对称：传入的是左节点的左孩子，右节点的右孩子。</li><li>比较内测是否对称，传入左节点的右孩子，右节点的左孩子。</li><li>如果左右都对称就返回true ，有一侧不对称就返回false 。</li></ul></li></ul><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">outside = compare(left.left, right.right)</span><br><span class="line">inside = compare(left.right, right.left)</span><br><span class="line">isSame = outside <span class="keyword">and</span> inside</span><br></pre></td></tr></table></figure><p>如上代码中，我们可以看出使用的遍历方式，左子树左右中，右子树右左中，所以我把这个遍历顺序也称之为“后序遍历”（尽管不是严格的后序遍历）.</p><p>最后看一下完整的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.compare(root.left, root.right)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compare</span>(<span class="params">self, left, right</span>):</span></span><br><span class="line">        <span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> left != <span class="literal">None</span> <span class="keyword">and</span> right == <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> left == <span class="literal">None</span> <span class="keyword">and</span> right != <span class="literal">None</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> left.val != right.val: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        outside = self.compare(left.left, right.right)</span><br><span class="line">        inside = self.compare(left.right, right.left)</span><br><span class="line">        isSame = outside <span class="keyword">and</span> inside</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> isSame</span><br></pre></td></tr></table></figure><p><strong>「建议大家做题的时候，一定要想清楚逻辑，每一步做什么。把道题目所有情况想到位，相应的代码写出来之后，再去追求简洁代码的效果。」</strong></p><h3 id="三、迭代法"><a href="#三、迭代法" class="headerlink" title="三、迭代法"></a>三、迭代法</h3><p>这道题目我们也可以使用迭代法，但要注意，这里的迭代法可不是前中后序的迭代写法，因为本题的本质是判断两个树是否是相互翻转的，其实已经不是所谓二叉树遍历的前中后序的关系了。</p><p>这里我们可以使用队列来比较两个树（根节点的左右子树）是否相互翻转，（<strong>「注意这不是层序遍历」</strong>）</p><h4 id="1-使用队列"><a href="#1-使用队列" class="headerlink" title="1.使用队列"></a>1.使用队列</h4><p>通过队列来判断根节点的左子树和右子树的内侧和外侧是否相等，如动画所示：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704213358.gif" alt=""></p><p>如下的条件判断和递归的逻辑是一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        queue = []</span><br><span class="line">        queue.append(root.left)</span><br><span class="line">        queue.append(root.right)</span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            <span class="comment"># 将左右节点分别加入队列</span></span><br><span class="line">            left_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">            right_node = queue.pop(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 两个都为空，则对称，继续。</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node: </span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 一个为空，另一个不为空，返回False</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">not</span> left_node <span class="keyword">and</span> right_node) <span class="keyword">or</span> \</span><br><span class="line">               (left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node):</span><br><span class="line">               <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 两个都不为空，值不相等，返回False</span></span><br><span class="line">            <span class="keyword">if</span> left_node.val != right_node.val:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line">            queue.append(left_node.left)</span><br><span class="line">            queue.append(right_node.right)</span><br><span class="line">            queue.append(left_node.right)</span><br><span class="line">            queue.append(right_node.left)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure><h4 id="2-使用栈"><a href="#2-使用栈" class="headerlink" title="2.使用栈"></a>2.使用栈</h4><p>细心的话，其实可以发现，这个迭代法，其实是把左右两个子树要比较的元素顺序放进一个容器，然后成对成对的取出来进行比较，那么其实使用栈也是可以的。——先判断里侧和先判断外侧的顺序不影响。</p><p>只要把队列原封不动的改成栈就可以了，我下面也给出了代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode(object):</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSymmetric</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: bool</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        stack = []</span><br><span class="line">        stack.append(root.left)</span><br><span class="line">        stack.append(root.right)</span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            <span class="comment"># 将左右节点分别加入队列</span></span><br><span class="line">            left_node = stack.pop()</span><br><span class="line">            right_node = stack.pop()</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 两个都为空，则对称，继续。</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node: </span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 一个为空，另一个不为空，返回False</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">not</span> left_node <span class="keyword">and</span> right_node) <span class="keyword">or</span> \</span><br><span class="line">               (left_node <span class="keyword">and</span> <span class="keyword">not</span> right_node):</span><br><span class="line">               <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 两个都不为空，值不相等，返回False</span></span><br><span class="line">            <span class="keyword">if</span> left_node.val != right_node.val:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            </span><br><span class="line">            stack.append(left_node.left)</span><br><span class="line">            stack.append(right_node.right)</span><br><span class="line">            stack.append(left_node.right)</span><br><span class="line">            stack.append(right_node.left)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure><blockquote><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3></blockquote><p>这次我们又深度剖析了一道二叉树的“简单题”，大家会发现，真正的把题目搞清楚其实并不简单，leetcode上accept了和真正掌握了还是有距离的。</p><p>我们介绍了递归法和迭代法，递归依然通过递归三部曲来解决了这道题目。</p><p>在迭代法中我们使用了队列，需要注意的是这不是层序遍历，而且仅仅通过一个容器来成对的存放我们要比较的元素，知道这一本质之后就发现：用队列，用栈，甚至用数组，都是可以的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;对称二叉树&quot;&gt;&lt;a href=&quot;#对称二叉树&quot; class=&quot;headerlink&quot; title=&quot;对称二叉树&quot;&gt;&lt;/a&gt;对称二叉树&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;101.对称二叉树&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;给定一个二叉树，检查它是否是镜像对称的。&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="二叉树" scheme="https://xxren8218.github.io/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
    
  </entry>
  
  <entry>
    <title>29-spark_core补充</title>
    <link href="https://xxren8218.github.io/20210704/29-spark-core%E8%A1%A5%E5%85%85.html"/>
    <id>https://xxren8218.github.io/20210704/29-spark-core%E8%A1%A5%E5%85%85.html</id>
    <published>2021-07-03T17:58:13.000Z</published>
    <updated>2021-07-03T18:01:52.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="spark-相关概念补充"><a href="#spark-相关概念补充" class="headerlink" title="spark 相关概念补充"></a>spark 相关概念补充</h2><p>掌握目标</p><ul><li>了解spark的安装部署</li><li>知道spark作业提交集群的过程</li></ul><h3 id="1-spark的安装部署"><a href="#1-spark的安装部署" class="headerlink" title="1. spark的安装部署"></a>1. spark的安装部署</h3><ul><li><p>1、下载spark安装包</p><p><a href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a></p><p>高版本不存在cdh的编译版本，可以从官网下载源码版本，指定高版本hadoop进行编译</p><p>编译步骤：</p><ul><li><p>1，安装java(JDK 1.7及以上)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;xxx</span><br><span class="line">export JRE_HOME&#x3D;&#x2F;xxx</span><br><span class="line">export CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar:$JRE_HOME&#x2F;lib:$CLASSPATH</span><br><span class="line">export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>2，安装Maven， 版本为3.3.9或者以上</p><p>下载地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache//maven/maven-3/3.3.9/binaries">https://mirrors.tuna.tsinghua.edu.cn/apache//maven/maven-3/3.3.9/binaries</a></p><p>配置MAVEN_HOME</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export MAVEN_HOME&#x3D;&#x2F;xxx</span><br><span class="line">export PATH&#x3D;$MAVEN_HOME&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure></li><li><p>3，下载spark源码</p></li><li><p>4，增加cdh的repository</p><p>解压spark的源码包，编辑pom.xml文件， 在repositories节点 加入如下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;repository&gt;</span><br><span class="line">          &lt;id&gt;cloudera&lt;&#x2F;id&gt;</span><br><span class="line">          &lt;url&gt;https:&#x2F;&#x2F;repository.cloudera.com&#x2F;artifactory&#x2F;cloudera-repos&#x2F;&lt;&#x2F;url&gt;&lt;&#x2F;repository&gt;</span><br></pre></td></tr></table></figure></li><li><p>5，编译</p><p>设置内存：</p><p>export MAVEN_OPTS=”-Xmx2g -XX:ReservedCodeCacheSize=512m”</p><p>开始编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;dev&#x2F;make-distribution.sh --name 2.6.0-cdh5.7.0 --tgz  -Pyarn -Phadoop-2.6 -Phive -Phive-thriftserver -Dhadoop.version&#x3D;2.6.0-cdh5.7.0 -DskipTests clean package</span><br></pre></td></tr></table></figure><p>源码编译后，bin目录下的文件可能不存在可执行权限，需要通过chmod指令添加可执行权限</p><p>chmod +x xxx</p></li></ul></li><li><p>2、规划spark安装目录</p></li><li><p>3、解压安装包</p></li><li><p>4、重命名安装目录</p></li><li><p>5、修改配置文件</p><ul><li>spark-env.sh(需要将spark-env.sh.template重命名)<ul><li>配置java环境变量<ul><li>export JAVA_HOME=java_home_path</li></ul></li><li>配置PYTHON环境<ul><li>export PYSPARK_PYTHON=/xx/pythonx_home/bin/pythonx</li></ul></li><li>配置master的地址<ul><li>export SPARK_MASTER_HOST=node-teach</li></ul></li><li>配置master的端口<ul><li>export SPARK_MASTER_PORT=7077</li></ul></li></ul></li></ul></li><li><p>6、配置spark环境变量</p><ul><li>export SPARK_HOME=/xxx/spark2.x</li><li>export PATH=\$PATH:\$SPARK_HOME/bin</li></ul></li></ul><h3 id="2-启动Spark集群"><a href="#2-启动Spark集群" class="headerlink" title="2. 启动Spark集群"></a>2. 启动Spark集群</h3><ul><li>进入到$SPARK_HOME/sbin目录</li><li>启动Master    </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-master.sh -h 192.168.19.137</span><br></pre></td></tr></table></figure><ul><li>启动Slave</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-slave.sh spark://192.168.19.137:7077</span><br></pre></td></tr></table></figure><ul><li>jps查看进程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">27073 Master</span><br><span class="line">27151 Worker</span><br></pre></td></tr></table></figure><ul><li>关闭防火墙</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><ul><li>通过SPARK WEB UI查看Spark集群及Spark<ul><li><a href="http://192.168.199.188:8080/">http://192.168.199.188:8080/</a>  监控Spark集群</li><li><a href="http://192.168.199.188:4040/">http://192.168.199.188:4040/</a>  监控Spark Job</li></ul></li></ul><h3 id="3-spark-集群相关概念"><a href="#3-spark-集群相关概念" class="headerlink" title="3. spark 集群相关概念"></a>3. spark 集群相关概念</h3><ul><li><p>spark集群架构(Standalone模式)</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704015921.png" alt=""></p><ul><li><p>Application</p><p>用户自己写的Spark应用程序，批处理作业的集合。Application的main方法为应用程序的入口，用户通过Spark的API，定义了RDD和对RDD的操作。</p></li><li><p>Master和Worker</p><p>整个集群分为 Master 节点和 Worker 节点，相当于 Hadoop 的 Master 和 Slave 节点。</p><ul><li>Master：Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动Driver和Executor。</li><li>Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。</li></ul></li><li><p>Client：客户端进程，负责提交作业到Master。</p></li><li><p>Driver： 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGSchedule（负责作业的拆解），TaskScheduler（负责把对应的Task发到对应的Worker上，交给Executor求执行）。</p></li><li><p>Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。</p></li></ul></li><li><p>Spark作业相关概念</p><ul><li><p>Stage：一个Spark作业一般包含一到多个Stage。</p></li><li><p>Task：一个Stage包含一到多个Task，通过多个Task实现并行运行的功能（可能算的结果不一样，前面有讲）。</p></li><li><p>DAGScheduler： 实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。</p></li><li><p>TaskScheduler：实现Task分配到Executor上执行。</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704015938.png" alt=""></p></li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210704020004.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;spark-相关概念补充&quot;&gt;&lt;a href=&quot;#spark-相关概念补充&quot; class=&quot;headerlink&quot; title=&quot;spark 相关概念补充&quot;&gt;&lt;/a&gt;spark 相关概念补充&lt;/h2&gt;&lt;p&gt;掌握目标&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解spark的安装部署</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>28-spark_core 实战案例</title>
    <link href="https://xxren8218.github.io/20210703/28-spark-core-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B.html"/>
    <id>https://xxren8218.github.io/20210703/28-spark-core-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B.html</id>
    <published>2021-07-02T17:03:57.000Z</published>
    <updated>2021-07-02T17:07:57.328Z</updated>
    
    <content type="html"><![CDATA[<h2 id="spark-core-实战案例"><a href="#spark-core-实战案例" class="headerlink" title="spark-core 实战案例"></a>spark-core 实战案例</h2><p>掌握目标：</p><ul><li>独立实现Spark RDD的word count案例</li><li>独立实现spark RDD的PV UV统计案例</li><li>说出广播变量的概念</li></ul><p>对于数据在shell里面写，没有交互，对于数据分析而言不好，将其用PyCharm编写可进行交互，便于分析。</p><ul><li>即在PyCharm上编写，然后数据同步到Centos上面运行，运行结束后，还在PyCharm上面显示。</li></ul><h3 id="1-0-Pycharm编写spark代码环境配置"><a href="#1-0-Pycharm编写spark代码环境配置" class="headerlink" title="1.0 Pycharm编写spark代码环境配置"></a>1.0 Pycharm编写spark代码环境配置</h3><p>准备pycharm环境</p><ul><li><p>1.PyCharm的配置</p><ul><li>file-&gt;new-project-&gt;pure Python-&gt;exiting interpreter-&gt;add remote-&gt;SSH Crederitals-&gt;填写Host(192.168.19.137)-&gt;Username(root)-&gt;密码-&gt;选择python的解释器路径为(/miniconda2/envs/py365/bin/python)-&gt;Remote project location(/root/bigdata/code)</li></ul></li><li><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个是链接用的哪种环境，若几个集群的话，传递的应该是master节点的RL地址</span></span><br><span class="line">sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>)</span><br><span class="line"></span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/code/test.txt&quot;</span>).\</span><br><span class="line">    flatMap(<span class="keyword">lambda</span> x: x.split()).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> a,b: a+b)</span><br><span class="line"></span><br><span class="line">print(rdd1.collect())</span><br></pre></td></tr></table></figure><p>运行出现了错误：</p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210703010459.PNG" alt=""></p></li></ul><p>解决方法：</p><ul><li>在centos上面查找JAVA_HOME所在位置(vi ~/.bash_profile)，添加到环境变量中：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####################################</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">JAVA_HOME = <span class="string">&#x27;/root/bigdata/jdk&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>] = JAVA_HOME</span><br><span class="line"><span class="comment">####################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个master的位置，第二个是spark作业的名字。</span></span><br><span class="line">sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>) <span class="comment"># 第一个是链接用的哪种环境，若几个集群的话，传递的应该是master节点的RL地址</span></span><br><span class="line"></span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/code/test.txt&quot;</span>).\</span><br><span class="line">    flatMap(<span class="keyword">lambda</span> x: x.split()).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> a,b: a+b)</span><br><span class="line"></span><br><span class="line">print(rdd1.collect())</span><br></pre></td></tr></table></figure><p>  还会出现python的版本不一致的问题，再添加python的环境。以及pyspark的版本问题。</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####################################</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">JAVA_HOME = <span class="string">&#x27;/root/bigdata/jdk&#x27;</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/miniconda2/envs/py365/bin/python&quot;</span></span><br><span class="line">os.environ[<span class="string">&#x27;JAVA_HOME&#x27;</span>] = JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&#x27;PYSPARK_PYTHON&#x27;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&#x27;PYSPARK_DRIVER_PYTHON&#x27;</span>] = PYSPARK_PYTHON</span><br><span class="line"><span class="comment">####################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"></span><br><span class="line">sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>)</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/code/test.txt&quot;</span>).\</span><br><span class="line">    flatMap(<span class="keyword">lambda</span> x: x.split()).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x,<span class="number">1</span>)).\</span><br><span class="line">    reduceByKey(<span class="keyword">lambda</span> a,b: a+b)</span><br><span class="line"></span><br><span class="line">print(rdd1.collect())</span><br></pre></td></tr></table></figure><h3 id="1-1利用PyCharm编写spark-wordcount程序"><a href="#1-1利用PyCharm编写spark-wordcount程序" class="headerlink" title="1.1利用PyCharm编写spark wordcount程序"></a>1.1利用PyCharm编写spark wordcount程序</h3><ul><li>代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">JAVA_HOME = <span class="string">&#x27;/root/bigdata/jdk&#x27;</span></span><br><span class="line">PYSPARK_PYTHON = <span class="string">&quot;/miniconda2/envs/py365/bin/python&quot;</span></span><br><span class="line">os.environ[<span class="string">&quot;JAVA_HOME&quot;</span>] = JAVA_HOME</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line">os.environ[<span class="string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 创建spark context</span></span><br><span class="line">    sc = SparkContext(<span class="string">&#x27;local[2]&#x27;</span>,<span class="string">&#x27;wordcount&#x27;</span>)</span><br><span class="line">    <span class="comment"># 通过spark context 获取rdd</span></span><br><span class="line">    rdd1 = sc.textFile(<span class="string">&#x27;file:///root/tmp/test.txt&#x27;</span>)</span><br><span class="line">    rdd2 = rdd1.flatMap(<span class="keyword">lambda</span> line:line.split())</span><br><span class="line">    rdd3 = rdd2.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x,<span class="number">1</span>))</span><br><span class="line">    rdd4 = rdd3.reduceByKey(<span class="keyword">lambda</span> x,y:x+y)</span><br><span class="line">    print(rdd4.collect())</span><br></pre></td></tr></table></figure><h3 id="1-2-通过spark实现点击流日志分析"><a href="#1-2-通过spark实现点击流日志分析" class="headerlink" title="1.2 通过spark实现点击流日志分析"></a>1.2 通过spark实现点击流日志分析</h3><p>在新闻类网站中，经常要衡量一条网络新闻的页面访问量，最常见的就是uv和pv，如果在所有新闻中找到访问最多的前几条新闻，topN是最常见的指标。</p><ul><li>数据示例</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 每条数据代表一次访问记录 包含了ip 访问时间 访问的请求方式 访问的地址...信息</span></span><br><span class="line">194.237.142.21 - - [18/Sep/2013:06:49:18 +0000] &quot;GET /wp-content/uploads/2013/07/rstudio-git3.png HTTP/1.1&quot; 304 0 &quot;-&quot; &quot;Mozilla/4.0 (compatible;)&quot;</span><br><span class="line">183.49.46.228 - - [18/Sep/2013:06:49:23 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</span><br><span class="line">163.177.71.12 - - [18/Sep/2013:06:49:33 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">163.177.71.12 - - [18/Sep/2013:06:49:36 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">101.226.68.137 - - [18/Sep/2013:06:49:42 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">101.226.68.137 - - [18/Sep/2013:06:49:45 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</span><br><span class="line">60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span><br><span class="line">222.68.172.190 - - [18/Sep/2013:06:49:57 +0000] &quot;GET /images/my.jpg HTTP/1.1&quot; 200 19939 &quot;http://www.angularjs.cn/A00n&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</span><br><span class="line">222.68.172.190 - - [18/Sep/2013:06:50:08 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</span><br></pre></td></tr></table></figure><ul><li><p>访问的pv</p><p>pv：网站的总访问量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;pv&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment"># 把每一行数据记为(&quot;pv&quot;,1)</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(<span class="string">&quot;pv&quot;</span>,<span class="number">1</span>)).reduceByKey(<span class="keyword">lambda</span> a,b:a+b)</span><br><span class="line">rdd2.collect()</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>访问的uv</p><p>uv：网站的独立用户访问量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;pv&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment"># 对每一行按照空格拆分，将ip地址取出</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot; &quot;</span>)).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 把每个ur记为1</span></span><br><span class="line">rdd3 = rdd2.distinct().<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(<span class="string">&quot;uv&quot;</span>,<span class="number">1</span>))</span><br><span class="line">rdd4 = rdd3.reduceByKey(<span class="keyword">lambda</span> a,b:a+b)</span><br><span class="line">rdd4.saveAsTextFile(<span class="string">&quot;hdfs:///uv/result&quot;</span>)</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li><li><p>访问的topN</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;topN&quot;</span>).getOrCreate()</span><br><span class="line">sc = spark.sparkContext</span><br><span class="line">rdd1 = sc.textFile(<span class="string">&quot;file:///root/bigdata/data/access.log&quot;</span>)</span><br><span class="line"><span class="comment"># 对每一行按照空格拆分，将url数据取出，把每个url记为1</span></span><br><span class="line">rdd2 = rdd1.<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot; &quot;</span>)).<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:<span class="built_in">len</span>(x)&gt;<span class="number">10</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:(x[<span class="number">10</span>],<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 对数据进行累加，按照url出现次数的降序排列</span></span><br><span class="line">rdd3 = rdd2.reduceByKey(<span class="keyword">lambda</span> a,b:a+b).sortBy(<span class="keyword">lambda</span> x:x[<span class="number">1</span>],ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 取出序列数据中的前n个</span></span><br><span class="line">rdd4 = rdd3.take(<span class="number">5</span>)</span><br><span class="line">rdd4.collect()</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure></li></ul><h3 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h3><p>这里不懂的可以去上篇看数据的具体格式！</p><h3 id="2-通过spark实现ip地址查询"><a href="#2-通过spark实现ip地址查询" class="headerlink" title="2. 通过spark实现ip地址查询"></a>2. 通过spark实现ip地址查询</h3><p><strong>需求</strong></p><p>在互联网中，我们经常会见到城市热点图这样的报表数据，例如在百度统计中，会统计今年的热门旅游城市、热门报考学校等，会将这样的信息显示在热点图中。</p><p>因此，我们需要通过日志信息（运行商或者网站自己生成）和城市ip段信息来判断用户的ip段，统计热点经纬度。</p><p><strong>ip日志信息</strong></p><p>在ip日志信息中，我们只需要关心ip这一个维度就可以了，其他的不做介绍</p><p><strong>思路</strong></p><p>1、 加载城市ip段信息，获取ip起始数字和结束数字，经度，纬度</p><p>2、 加载日志数据，获取ip信息，然后转换为数字，和ip段比较</p><p>3、 比较的时候采用二分法查找，找到对应的经度和纬度</p><p>4，对相同的经度和纬度做累计求和</p><p>5， 取出最终的topN的经纬度</p><p><strong>启动Spark集群</strong></p><ul><li><p>进入到$SPARK_HOME/sbin目录</p><ul><li>启动Master    </li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-master.sh -h 192.168.199.188</span><br></pre></td></tr></table></figure><ul><li>启动Slave</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-slave.sh spark://192.168.199.188:7077</span><br></pre></td></tr></table></figure><ul><li>jps查看进程</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">27073 Master</span><br><span class="line">27151 Worker</span><br></pre></td></tr></table></figure><ul><li>关闭防火墙</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><ul><li>通过SPARK WEB UI查看Spark集群及Spark<ul><li><a href="http://192.168.199.188:8080/">http://192.168.199.188:8080/</a>  监控Spark集群</li><li><a href="http://192.168.199.188:4040/">http://192.168.199.188:4040/</a>  监控Spark Job</li></ul></li></ul></li><li><p>代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="comment"># 255.255.255.255 0~255 256个数  2^8 是8位2进制数  ——&gt;转化成32位的二进制数</span></span><br><span class="line"><span class="comment">#将ip转换为特殊的数字形式  223.243.0.0|223.243.191.255|  255 2^8</span></span><br><span class="line"><span class="comment">#‭11011111‬</span></span><br><span class="line"><span class="comment">#00000000</span></span><br><span class="line"><span class="comment">#1101111100000000</span></span><br><span class="line"><span class="comment">#‭        11110011‬</span></span><br><span class="line"><span class="comment">#11011111111100110000000000000000</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ip_transform</span>(<span class="params">ip</span>):</span>     </span><br><span class="line">    ips = ip.split(<span class="string">&quot;.&quot;</span>) <span class="comment"># [223,243,0,0] 32位二进制数</span></span><br><span class="line">    ip_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> ips:</span><br><span class="line">        ip_num = <span class="built_in">int</span>(i) | ip_num &lt;&lt; <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> ip_num</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二分法查找ip对应的行的索引</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">binary_search</span>(<span class="params">ip_num, broadcast_value</span>):</span></span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    end = <span class="built_in">len</span>(broadcast_value) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> (start &lt;= end):</span><br><span class="line">        mid = <span class="built_in">int</span>((start + end) / <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> ip_num &gt;= <span class="built_in">int</span>(broadcast_value[mid][<span class="number">0</span>]) <span class="keyword">and</span> ip_num &lt;= <span class="built_in">int</span>(broadcast_value[mid][<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">return</span> mid</span><br><span class="line">        <span class="keyword">if</span> ip_num &lt; <span class="built_in">int</span>(broadcast_value[mid][<span class="number">0</span>]):</span><br><span class="line">            end = mid</span><br><span class="line">        <span class="keyword">if</span> ip_num &gt; <span class="built_in">int</span>(broadcast_value[mid][<span class="number">1</span>]):</span><br><span class="line">            start = mid</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    spark = SparkSession.builder.appName(<span class="string">&quot;test&quot;</span>).getOrCreate()</span><br><span class="line">    sc = spark.sparkContext</span><br><span class="line">    city_id_rdd = sc.textFile(<span class="string">&quot;file:///home/hadoop/app/tmp/data/ip.txt&quot;</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> x:x.split(<span class="string">&quot;|&quot;</span>)).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x[<span class="number">2</span>], x[<span class="number">3</span>], x[<span class="number">13</span>], x[<span class="number">14</span>]))</span><br><span class="line">    <span class="comment"># 创建一个广播变量</span></span><br><span class="line">    city_broadcast = sc.broadcast(city_id_rdd.collect())</span><br><span class="line">    dest_data = sc.textFile(<span class="string">&quot;file:///home/hadoop/app/tmp/data/20090121000132.394251.http.format&quot;</span>).<span class="built_in">map</span>(</span><br><span class="line">        <span class="keyword">lambda</span> x: x.split(<span class="string">&quot;|&quot;</span>)[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 根据取出对应的位置信息</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_pos</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="comment"># 从广播变量中获取ip地址库</span></span><br><span class="line">        city_broadcast_value = city_broadcast.value</span><br><span class="line">        <span class="comment"># 根据单个ip获取对应经纬度信息</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_result</span>(<span class="params">ip</span>):</span></span><br><span class="line">            ip_num = ip_transform(ip)</span><br><span class="line">            index = binary_search(ip_num, city_broadcast_value)</span><br><span class="line">            <span class="comment"># ((纬度,精度),1)</span></span><br><span class="line">            <span class="keyword">return</span> ((city_broadcast_value[index][<span class="number">2</span>], city_broadcast_value[index][<span class="number">3</span>]), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = <span class="built_in">map</span>(<span class="built_in">tuple</span>,[get_result(ip) <span class="keyword">for</span> ip <span class="keyword">in</span> x])</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    dest_rdd = dest_data.mapPartitions(<span class="keyword">lambda</span> x: get_pos(x)) <span class="comment"># ((纬度,精度),1)</span></span><br><span class="line">    result_rdd = dest_rdd.reduceByKey(<span class="keyword">lambda</span> a, b: a + b).sortBy(<span class="keyword">lambda</span> x:x[<span class="number">1</span>],ascending=<span class="literal">False</span>)</span><br><span class="line">    print(result_rdd.collect())</span><br><span class="line">    sc.stop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></li><li><p><strong>广播变量的使用</strong></p><ul><li>要统计Ip所对应的经纬度, 每一条数据都会去查询ip表</li><li>每一个task 都需要这一个ip表, 默认情况下, 所有task都会去复制ip表</li><li>实际上 每一个Worker上会有多个task, 数据也是只需要进行查询操作的, 所以这份数据可以共享,没必要每个task复制一份</li><li>可以通过广播变量, 通知当前worker上所有的task, 来共享这个数据,避免数据的多次复制,可以大大降低内存的开销</li><li>sparkContext.broadcast(要共享的数据)</li></ul></li><li><p><strong>mapPartitions</strong> </p><ul><li>transformation操作 </li><li>类似map 但是map是一条一条传给里面函数的 mapPartitions 数据是一部分一部分传给函数的</li><li>应用场景 数据处理的时候 需要连接其它资源 如果一条一条处理 会处理一条连一次， 一份一份处理可以很多条数据连一次其它资源 可以提高效率</li></ul></li><li><p><strong>二分法查找</strong></p></li><li><p>ip_transform 把223.243.0.0 转换成10进制的数字——位运算。 </p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;spark-core-实战案例&quot;&gt;&lt;a href=&quot;#spark-core-实战案例&quot; class=&quot;headerlink&quot; title=&quot;spark-core 实战案例&quot;&gt;&lt;/a&gt;spark-core 实战案例&lt;/h2&gt;&lt;p&gt;掌握目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="大数据的lambda架构" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/"/>
    
    
    <category term="推荐系统基础" scheme="https://xxren8218.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
</feed>
