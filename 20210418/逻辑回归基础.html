<!DOCTYPE html>
<html lang=zh>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>逻辑回归基础 | X.X.Ren的个人博客</title>
  <meta name="description" content="Logistic RegressionThe data我们将建立一个逻辑回归模型来预测一个学生是否被大学录取。假设你是一个大学系的管理员，你想根据两次考试的结果来决定每个申请人的录取机会。你有以前的申请人的历史数据，你可以用它作为逻辑回归的训练集。对于每一个培训例子，你有两个考试的申请人的分数和录取决定。为了做到这一点，我们将建立一个分类模型，根据考试成绩估计入学概率。 12345# 三大件 #">
<meta property="og:type" content="article">
<meta property="og:title" content="逻辑回归基础">
<meta property="og:url" content="https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html">
<meta property="og:site_name" content="X.X.Ren">
<meta property="og:description" content="Logistic RegressionThe data我们将建立一个逻辑回归模型来预测一个学生是否被大学录取。假设你是一个大学系的管理员，你想根据两次考试的结果来决定每个申请人的录取机会。你有以前的申请人的历史数据，你可以用它作为逻辑回归的训练集。对于每一个培训例子，你有两个考试的申请人的分数和录取决定。为了做到这一点，我们将建立一个分类模型，根据考试成绩估计入学概率。 12345# 三大件 #">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/61.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/11_1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/35_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/38_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/41_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/44_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/46_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/49_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/51_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/53_2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/55_1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/57_2.png">
<meta property="article:published_time" content="2021-04-17T17:13:29.000Z">
<meta property="article:modified_time" content="2021-04-29T15:50:02.753Z">
<meta property="article:author" content="任晓雄">
<meta property="article:tag" content="机器学习基础">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/61.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html">
  
    <link rel="alternate" href="/atom.xml" title="X.X.Ren" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" rel="stylesheet">
  
  
  
  
<meta name="generator" content="Hexo 5.4.0"></head>


<body class="main-center theme-purple# 主题颜色 theme-black theme-blue theme-green theme-purple" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://xxren888.gitee.io" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">任晓雄</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">机器学习 &amp; 人工智能</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> 陕西, 西安</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="搜索" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="想要查找什么..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav menu-highlight">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">首页</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">归档</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">分类</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">标签</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">项目</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">关于</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/xxren8218/xxren8218.github.io" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://weibo.com/u/5824042330" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="/" target="_blank" title="Facebook" data-toggle=tooltip data-placement=top><i class="icon icon-facebook"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-stackexchange"></i>公告</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-folder-open"></i>分类</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/">二分查找</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/">传统算法</a><span class="category-list-count">38</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">动态规划</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">41</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/">大数据的lambda架构</a><span class="category-list-count">10</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/">机器学习基础实战</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-tags"></i>标签云</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/python%E5%9F%BA%E7%A1%80/" style="font-size: 13.9px; color: #fff">python基础</a> <a href="/tags/vim/" style="font-size: 13px; color: #fff">vim</a> <a href="/tags/%E4%BA%8C%E5%88%86%E6%B3%95/" style="font-size: 13.1px; color: #fff">二分法</a> <a href="/tags/%E4%BC%AA%E5%A4%B4%E8%8A%82%E7%82%B9/" style="font-size: 13px; color: #fff">伪头节点</a> <a href="/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/" style="font-size: 13.2px; color: #fff">位运算</a> <a href="/tags/%E5%85%B6%E4%BB%96/" style="font-size: 13.1px; color: #fff">其他</a> <a href="/tags/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/" style="font-size: 13px; color: #fff">内置函数</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 13px; color: #fff">动态规划</a> <a href="/tags/%E5%8D%95%E8%B0%83%E6%A0%88/" style="font-size: 13px; color: #fff">单调栈</a> <a href="/tags/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97/" style="font-size: 13px; color: #fff">单调队列</a> <a href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/" style="font-size: 13.5px; color: #fff">双指针</a> <a href="/tags/%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97/" style="font-size: 13px; color: #fff">双端队列</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 13.4px; color: #fff">哈希表</a> <a href="/tags/%E5%A4%9A%E6%8C%87%E9%92%88/" style="font-size: 13.4px; color: #fff">多指针</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 13.1px; color: #fff">字符串</a> <a href="/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/" style="font-size: 13px; color: #fff">归并排序</a> <a href="/tags/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88/" style="font-size: 13.1px; color: #fff">快慢指针</a> <a href="/tags/%E5%BF%AB%E9%80%9F%E5%B9%82/" style="font-size: 13px; color: #fff">快速幂</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 13.3px; color: #fff">排序</a> <a href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80/" style="font-size: 14px; color: #fff">推荐系统基础</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 13.3px; color: #fff">数学</a> <a href="/tags/%E6%95%B0%E7%BB%84/" style="font-size: 13.7px; color: #fff">数组</a> <a href="/tags/%E6%9C%80%E5%B0%8F%E5%A0%86/" style="font-size: 13.1px; color: #fff">最小堆</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" style="font-size: 13.8px; color: #fff">机器学习基础</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/" style="font-size: 13.1px; color: #fff">机器学习基础实战</a> <a href="/tags/%E6%9F%A5%E6%89%BE/" style="font-size: 13px; color: #fff">查找</a> <a href="/tags/%E6%A0%88/" style="font-size: 13px; color: #fff">栈</a> <a href="/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/" style="font-size: 13px; color: #fff">滑动窗口</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E5%88%97%E8%A1%A8/" style="font-size: 13.1px; color: #fff">辅助列表</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E6%A0%88/" style="font-size: 13.1px; color: #fff">辅助栈</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E7%B4%A0%E7%BB%84/" style="font-size: 13px; color: #fff">辅助素组</a> <a href="/tags/%E8%BE%85%E5%8A%A9%E9%98%9F%E5%88%97/" style="font-size: 13px; color: #fff">辅助队列</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 13.3px; color: #fff">递归</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 13.6px; color: #fff">链表</a>
    </div>
  </div>

<script type="text/javascript">
    var everytag=document.getElementsByClassName("widget-body tagcloud")[0].children;
    for (var i = everytag.length - 1; i >= 0; i--) {
        var r= Math.floor(Math.random()*255);
        var g= Math.floor(Math.random()*255);
        var b= Math.floor(Math.random()*255);
        everytag[i].style.background = "rgb("+r+","+g+","+b+")";
    }
</script>

    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-archives-fill"></i>归档</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">七月 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">六月 2021</a><span class="archive-list-count">51</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a><span class="archive-list-count">36</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a><span class="archive-list-count">18</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title"><i style="color:#9400D3" class="icon icon-shu-fill"></i>最新文章</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled ">
        
          <li>
            
            <div class="item-thumb">
              <a href="/20210701/00-%E4%BA%8C-N-%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86%E2%80%94%E2%80%94%E8%AE%AD%E7%BB%83.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210302194723.jpeg)" alt="00-二(N)叉树的层序遍历——训练" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a>
              </p>
              <p class="item-title">
                <a href="/20210701/00-%E4%BA%8C-N-%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86%E2%80%94%E2%80%94%E8%AE%AD%E7%BB%83.html" class="title">00-二(N)叉树的层序遍历——训练</a>
              </p>
              <p class="item-date">
                <time datetime="2021-07-01T11:02:04.000Z" itemprop="datePublished">2021-07-01 19:02:04</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210701/26-HBase%E6%A6%82%E8%BF%B0.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210405011431.jpg)" alt="26-HBase概述" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/">大数据的lambda架构</a>
              </p>
              <p class="item-title">
                <a href="/20210701/26-HBase%E6%A6%82%E8%BF%B0.html" class="title">26-HBase概述</a>
              </p>
              <p class="item-date">
                <time datetime="2021-06-30T16:54:44.000Z" itemprop="datePublished">2021-07-01 00:54:44</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210630/25-Sqoop%E6%A6%82%E8%BF%B0.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210405011431.jpg)" alt="25-Sqoop概述" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/">大数据的lambda架构</a>
              </p>
              <p class="item-title">
                <a href="/20210630/25-Sqoop%E6%A6%82%E8%BF%B0.html" class="title">25-Sqoop概述</a>
              </p>
              <p class="item-date">
                <time datetime="2021-06-29T16:51:29.000Z" itemprop="datePublished">2021-06-30 00:51:29</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210629/02-%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B9%8B%E6%B7%B1%E5%BA%A6%E9%81%8D%E5%8E%86%E6%80%9D%E6%83%B3%E8%AE%AD%E7%BB%83.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210302194723.jpeg)" alt="02_二叉树之深度遍历思想训练" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a>
              </p>
              <p class="item-title">
                <a href="/20210629/02-%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B9%8B%E6%B7%B1%E5%BA%A6%E9%81%8D%E5%8E%86%E6%80%9D%E6%83%B3%E8%AE%AD%E7%BB%83.html" class="title">02_二叉树之深度遍历思想训练</a>
              </p>
              <p class="item-date">
                <time datetime="2021-06-29T10:19:29.000Z" itemprop="datePublished">2021-06-29 18:19:29</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-thumb">
              <a href="/20210629/24-Hive%E6%A6%82%E8%BF%B0.html" class="thumb">
    
    
        <span style="background-image:url(https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210405011431.jpg)" alt="24-Hive概述" class="thumb-image"></span>
    
</a>

            </div>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84lambda%E6%9E%B6%E6%9E%84/">大数据的lambda架构</a>
              </p>
              <p class="item-title">
                <a href="/20210629/24-Hive%E6%A6%82%E8%BF%B0.html" class="title">24-Hive概述</a>
              </p>
              <p class="item-date">
                <time datetime="2021-06-28T16:47:32.000Z" itemprop="datePublished">2021-06-29 00:47:32</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <nav id="toc" class="article-toc">
      <h3 class="toc-title">文章目录</h3>
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Logistic-Regression"><span class="toc-text">Logistic Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#The-data"><span class="toc-text">The data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-logistic-regression"><span class="toc-text">The logistic regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A6%81%E5%AE%8C%E6%88%90%E7%9A%84%E6%A8%A1%E5%9D%97"><span class="toc-text">要完成的模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sigmoid-%E5%87%BD%E6%95%B0"><span class="toc-text">sigmoid 函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sigmoid"><span class="toc-text">Sigmoid</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-%E5%AE%8C%E6%88%90%E9%A2%84%E6%B5%8B%E5%87%BD%E6%95%B0-h-theta-x"><span class="toc-text">model 完成预测函数 $h_\theta(x)$</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%88%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%EF%BC%89"><span class="toc-text">损失函数（代价函数）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6-%E2%80%94-%E6%9C%80%E9%9A%BE%E7%9A%84%E9%83%A8%E5%88%86"><span class="toc-text">计算梯度 — 最难的部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gradient-descent"><span class="toc-text">Gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E7%9A%84%E5%81%9C%E6%AD%A2%E7%AD%96%E7%95%A5"><span class="toc-text">不同的停止策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E5%AE%9A%E8%BF%AD%E4%BB%A3%E6%AC%A1%E6%95%B0"><span class="toc-text">设定迭代次数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E6%8D%9F%E5%A4%B1%E5%80%BC%E5%81%9C%E6%AD%A2"><span class="toc-text">根据损失值停止</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B9%E6%8D%AE%E6%A2%AF%E5%BA%A6%E5%8F%98%E5%8C%96%E5%81%9C%E6%AD%A2"><span class="toc-text">根据梯度变化停止</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E4%B8%8D%E5%90%8C%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%96%B9%E6%B3%95"><span class="toc-text">对比不同的梯度下降方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Stochastic-descent"><span class="toc-text">Stochastic descent</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Mini-batch-descent"><span class="toc-text">Mini-batch descent</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B2%BE%E5%BA%A6"><span class="toc-text">精度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%88%B0%E8%BF%99%E9%87%8C%E5%B0%B1%E7%BB%93%E6%9D%9F%E4%BA%86%EF%BC%81"><span class="toc-text">逻辑回归到这里就结束了！</span></a></li></ol></li></ol>
    </nav>
  </div>
</aside>

<main class="main" role="main">
  <div class="content">
  <article id="post-逻辑回归基础" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      逻辑回归基础
    </h1>
  


      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar"></i>
    <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html" class="article-date">
        发布于<time datetime="2021-04-17T17:13:29.000Z" itemprop="datePublished">
            2021-04-18 01:13:29
        </time>
    </a>
</span>

<span class="article-date">
    <i class="icon icon-calendar-check"></i>
    <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html" class="article-date">
        更新于<time datetime="2021-04-29T15:50:02.753Z" itemprop="dateUpdated">
            2021-04-29 23:50:02
        </time>
    </a>
</span>


        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" rel="tag">机器学习基础</a>
  </span>


        

	<span class="article-read hidden-xs">
    	<i class="icon icon-eye-fill" aria-hidden="true"></i>
    	<span id="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html" class="leancloud_visitors"  data-flag-title="逻辑回归基础">0</span>
    </span>

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html#comments" class="article-comment-link">评论</a></span>
        
      </div>
    </div>
	<div style="background-color:#D7BDE2;border:1px solid #D7BDE2;border-radius:10px;padding:5px">
    		<b>温馨提示</b>：点击页面下方<i style="color:red" class="icon icon-anchor"></i>以展开或折叠目录~
	</div>
    <div class="article-entry marked-body" itemprop="articleBody">
      
        <h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><h2 id="The-data"><a href="#The-data" class="headerlink" title="The data"></a>The data</h2><p>我们将建立一个逻辑回归模型来预测一个学生是否被大学录取。假设你是一个大学系的管理员，你想根据两次考试的结果来决定每个申请人的录取机会。你有以前的申请人的历史数据，你可以用它作为逻辑回归的训练集。对于每一个培训例子，你有两个考试的申请人的分数和录取决定。为了做到这一点，我们将建立一个分类模型，根据考试成绩估计入学概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三大件 # 可以直接在你的python console里面生成图像。不需要plt.show()就可进行展示</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline  </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">path = <span class="string">&#x27;data&#x27;</span> + os.sep + <span class="string">&#x27;LogiReg_data.txt&#x27;</span>  <span class="comment"># 为了让代码在不同的平台上都能运行，路径应该写&#x27;\&#x27;还是&#x27;/&#x27;无所谓。</span></span><br><span class="line">pdData = pd.read_csv(path, header=<span class="literal">None</span>, names=[<span class="string">&#x27;Exam 1&#x27;</span>, <span class="string">&#x27;Exam 2&#x27;</span>, <span class="string">&#x27;Admitted&#x27;</span>])  <span class="comment"># header = None自己制定列名</span></span><br><span class="line">pdData.head()</span><br></pre></td></tr></table></figure>
<div style="overflow: scroll;">
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Exam 1</th>
      <th>Exam 2</th>
      <th>Admitted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>34.623660</td>
      <td>78.024693</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>30.286711</td>
      <td>43.894998</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35.847409</td>
      <td>72.902198</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>60.182599</td>
      <td>86.308552</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>79.032736</td>
      <td>75.344376</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pdData.shape <span class="comment"># 看数据的维度。</span></span><br></pre></td></tr></table></figure>
<pre><code>(100, 3)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">positive = pdData[pdData[<span class="string">&#x27;Admitted&#x27;</span>] == <span class="number">1</span>] <span class="comment"># returns the subset of rows such Admitted = 1, i.e. the set of *positive* examples</span></span><br><span class="line">negative = pdData[pdData[<span class="string">&#x27;Admitted&#x27;</span>] == <span class="number">0</span>] <span class="comment"># returns the subset of rows such Admitted = 0, i.e. the set of *negative* examples</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">ax.scatter(positive[<span class="string">&#x27;Exam 1&#x27;</span>], positive[<span class="string">&#x27;Exam 2&#x27;</span>], s=<span class="number">30</span>, c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;Admitted&#x27;</span>)</span><br><span class="line">ax.scatter(negative[<span class="string">&#x27;Exam 1&#x27;</span>], negative[<span class="string">&#x27;Exam 2&#x27;</span>], s=<span class="number">30</span>, c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;Not Admitted&#x27;</span>)</span><br><span class="line">ax.legend()  <span class="comment">#  legend（）有一个loc参数，用于控制图例的位置。 比如 plot.legend(loc=2) , 这个位置就是4象项中的第二象项，也就是左上角。 loc可以为1,2,3,4 这四个数字。</span></span><br><span class="line">            <span class="comment"># 如果把那句legend() 的语句去掉，那么图形上的图例也就会消失了。</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Exam 1 Score&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Exam 2 Score&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Text(0,0.5,&#39;Exam 2 Score&#39;)
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/61.png" alt=""></p>
<h2 id="The-logistic-regression"><a href="#The-logistic-regression" class="headerlink" title="The logistic regression"></a>The logistic regression</h2><p>目标：建立分类器—即决策边界（求解出三个参数 $\theta_0         \theta_1         \theta_2 $）</p>
<p>设定<strong>阈值</strong>，根据阈值判断录取结果—就是分类的概率判断，一般为 0.5</p>
<h3 id="要完成的模块"><a href="#要完成的模块" class="headerlink" title="要完成的模块"></a>要完成的模块</h3><ul>
<li><p><code>sigmoid</code> : 映射到概率的函数</p>
</li>
<li><p><code>model</code> : 返回预测结果值</p>
</li>
<li><p><code>cost</code> : 根据参数计算损失</p>
</li>
<li><p><code>gradient</code> : 计算每个参数的梯度方向</p>
</li>
<li><p><code>descent</code> : 进行参数更新</p>
</li>
<li><p><code>accuracy</code>: 计算精度</p>
</li>
</ul>
<h3 id="sigmoid-函数"><a href="#sigmoid-函数" class="headerlink" title="sigmoid 函数"></a><code>sigmoid</code> 函数</h3><script type="math/tex; mode=display">
g(z) = \frac{1}{1+e^{-z}}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">z</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))  <span class="comment"># np.exp(-z)表示e的多少次幂</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nums = np.arange(-<span class="number">10</span>, <span class="number">10</span>, step=<span class="number">1</span>) <span class="comment">#creates a vector containing 20 equally spaced values from -10 to 10</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">ax.plot(nums, sigmoid(nums), <span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x244554b2b70&gt;]
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/11_1.png" alt=""></p>
<h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><ul>
<li>$g:\mathbb{R} \to [0,1]$</li>
<li>$g(0)=0.5$</li>
<li>$g(- \infty)=0$</li>
<li>$g(+ \infty)=1$</li>
</ul>
<h3 id="model-完成预测函数-h-theta-x"><a href="#model-完成预测函数-h-theta-x" class="headerlink" title="model 完成预测函数 $h_\theta(x)$"></a><code>model</code> <strong>完成预测函数 $h_\theta(x)$</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span>(<span class="params">X, theta</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> sigmoid(np.dot(X, theta.T))  <span class="comment"># np.dot是矩阵的乘法,也可以用 @ </span></span><br><span class="line">                                        <span class="comment"># 求出的 model是 m行1列.m--样本数目：</span></span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
\begin{array}{ccc}
\begin{pmatrix}\theta_{0} & \theta_{1} & \theta_{2}\end{pmatrix} & \times & \begin{pmatrix}1\\
x_{1}\\
x_{2}
\end{pmatrix}\end{array}=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pdData.insert(<span class="number">0</span>, <span class="string">&#x27;Ones&#x27;</span>, <span class="number">1</span>) <span class="comment"># 插入零的一列，列指标为 Ones</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set X (training data) and y (target variable)</span></span><br><span class="line">orig_data = pdData.as_matrix() <span class="comment"># 习惯性的操作。很多时候取得的数据是DataFrame的形式(直接转换csv格式的数据以后)，这个时候要记得转换成数组</span></span><br><span class="line">cols = orig_data.shape[<span class="number">1</span>]  <span class="comment"># 看数据有几列。</span></span><br><span class="line">X = orig_data[:,<span class="number">0</span>:cols-<span class="number">1</span>]</span><br><span class="line">y = orig_data[:,cols-<span class="number">1</span>:cols]</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert to numpy arrays and initalize the parameter array theta</span></span><br><span class="line"><span class="comment">#X = np.matrix(X.values)</span></span><br><span class="line"><span class="comment">#y = np.matrix(data.iloc[:,3:4].values) #np.array(y.values)</span></span><br><span class="line">theta = np.zeros([<span class="number">1</span>, <span class="number">3</span>])  <span class="comment"># 参数theta 一般先构造出来，用zero来占位，构造1行3列的数据。即三个theta参数 （1,3）[1,4]都可以。</span></span><br></pre></td></tr></table></figure>
<p><strong>来看看数据的样子吧</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[:<span class="number">5</span>]  <span class="comment"># 前 5 行的数据</span></span><br></pre></td></tr></table></figure>
<pre><code>array([[ 1.        , 34.62365962, 78.02469282],
       [ 1.        , 30.28671077, 43.89499752],
       [ 1.        , 35.84740877, 72.90219803],
       [ 1.        , 60.18259939, 86.3085521 ],
       [ 1.        , 79.03273605, 75.34437644]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.],
       [0.],
       [0.],
       [1.],
       [1.]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theta</span><br></pre></td></tr></table></figure>
<pre><code>array([[0., 0., 0.]])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.shape, y.shape, theta.shape</span><br></pre></td></tr></table></figure>
<pre><code>((100, 3), (100, 1), (1, 3))
</code></pre><h3 id="损失函数（代价函数）"><a href="#损失函数（代价函数）" class="headerlink" title="损失函数（代价函数）"></a>损失函数（代价函数）</h3><p>将对数似然函数去负号</p>
<script type="math/tex; mode=display">
D(h_\theta(x), y) = -y\log(h_\theta(x)) - (1-y)\log(1-h_\theta(x))</script><p>求平均损失</p>
<script type="math/tex; mode=display">
J(\theta)=\frac{1}{m}\sum_{i=1}^{m} D(h_\theta(x_i), y_i)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span>(<span class="params">X, y, theta</span>):</span></span><br><span class="line">    left = np.multiply(-y, np.log(model(X, theta)))  <span class="comment"># np.multiply对数据完成的乘的操作</span></span><br><span class="line">    right = np.multiply(<span class="number">1</span> - y, np.log(<span class="number">1</span> - model(X, theta)))</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(left - right) / (<span class="built_in">len</span>(X))   <span class="comment"># np.sum完成对数据的加和</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cost(X, y, theta)</span><br></pre></td></tr></table></figure>
<pre><code>0.6931471805599453
</code></pre><h3 id="计算梯度-—-最难的部分"><a href="#计算梯度-—-最难的部分" class="headerlink" title="计算梯度 — 最难的部分"></a>计算梯度 — 最难的部分</h3><script type="math/tex; mode=display">
\frac{\partial J}{\partial \theta_j}=-\frac{1}{m}\sum_{i=1}^n (y_i - h_\theta (x_i))x_{ij}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">X, y, theta</span>):</span></span><br><span class="line">    grad = np.zeros(theta.shape)  <span class="comment"># 梯度计算需要考虑 theta 的个数（维度）</span></span><br><span class="line">    error = (model(X, theta)- y).ravel()  <span class="comment"># 把负号提取到里面了，revel()将数据降为1维！(1,m)</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(theta.ravel())):   <span class="comment"># theta降低为 1 维度，[1,2,3,4]这样,就可以求theta的个数了，按列进行遍历</span></span><br><span class="line">        term = np.multiply(error, X[:,j]) <span class="comment"># 矩阵的乘法，取第j列。  (1,m)@(m,1)</span></span><br><span class="line">        grad[<span class="number">0</span>, j] = np.<span class="built_in">sum</span>(term) / <span class="built_in">len</span>(X) <span class="comment"># 每一个梯度j算一个值。取[0, j]</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> grad</span><br></pre></td></tr></table></figure>
<h3 id="Gradient-descent"><a href="#Gradient-descent" class="headerlink" title="Gradient descent"></a>Gradient descent</h3><p>比较3种不同梯度下降方法—<strong>批量、随机、小批量</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">STOP_ITER = <span class="number">0</span>  <span class="comment"># 根据迭代次数停止</span></span><br><span class="line">STOP_COST = <span class="number">1</span>  <span class="comment"># 根据损失值目标函数的变化停止</span></span><br><span class="line">STOP_GRAD = <span class="number">2</span>  <span class="comment"># 根据梯度的变化（很小）停止</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stopCriterion</span>(<span class="params"><span class="built_in">type</span>, value, threshold</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;设定三种不同的停止策略&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span> == STOP_ITER:        <span class="keyword">return</span> value &gt; threshold</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">type</span> == STOP_COST:      <span class="keyword">return</span> <span class="built_in">abs</span>(value[-<span class="number">1</span>]-value[-<span class="number">2</span>]) &lt; threshold <span class="comment"># abs()返回绝对值</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">type</span> == STOP_GRAD:      <span class="keyword">return</span> np.linalg.norm(value) &lt; threshold  <span class="comment"># np.linalg.norm默认是 2 范数--平方和开根号。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy.random</span><br><span class="line"><span class="comment"># 洗牌，将数据随机化，泛化能力变强</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shuffleData</span>(<span class="params">data</span>):</span></span><br><span class="line">    np.random.shuffle(data)  <span class="comment"># np.random.shuffle()将数据进行洗牌。</span></span><br><span class="line">    cols = data.shape[<span class="number">1</span>]</span><br><span class="line">    X = data[:, <span class="number">0</span>:cols-<span class="number">1</span>]</span><br><span class="line">    y = data[:, cols-<span class="number">1</span>:]</span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">descent</span>(<span class="params">data, theta, batchSize, stopType, thresh, alpha</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;梯度下降求解&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 参数的初始化，第一次计算各个值。</span></span><br><span class="line">    init_time = time.time()</span><br><span class="line">    i = <span class="number">0</span> <span class="comment"># 迭代次数</span></span><br><span class="line">    k = <span class="number">0</span> <span class="comment"># batch</span></span><br><span class="line">    X, y = shuffleData(data)</span><br><span class="line">    grad = np.zeros(theta.shape) <span class="comment"># 计算的梯度</span></span><br><span class="line">    costs = [cost(X, y, theta)] <span class="comment"># 损失值</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        grad = gradient(X[k:k+batchSize], y[k:k+batchSize], theta)</span><br><span class="line">        k += batchSize <span class="comment"># 取batch个数据，每次取batchSize个数据进行计算。</span></span><br><span class="line">        <span class="keyword">if</span> k &gt;= n: </span><br><span class="line">            k = <span class="number">0</span> </span><br><span class="line">            X, y = shuffleData(data) <span class="comment"># 重新洗牌</span></span><br><span class="line">        theta = theta - alpha*grad <span class="comment"># 参数更新</span></span><br><span class="line">        costs.append(cost(X, y, theta)) <span class="comment"># 计算新的损失</span></span><br><span class="line">        i += <span class="number">1</span> </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stopType == STOP_ITER:       value = i</span><br><span class="line">        <span class="keyword">elif</span> stopType == STOP_COST:     value = costs</span><br><span class="line">        <span class="keyword">elif</span> stopType == STOP_GRAD:     value = grad</span><br><span class="line">        <span class="keyword">if</span> stopCriterion(stopType, value, thresh): <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> theta, i-<span class="number">1</span>, costs, grad, time.time() - init_time</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runExpe</span>(<span class="params">data, theta, batchSize, stopType, thresh, alpha</span>):</span></span><br><span class="line">    <span class="comment">#import pdb; pdb.set_trace();</span></span><br><span class="line">    theta, <span class="built_in">iter</span>, costs, grad, dur = descent(data, theta, batchSize, stopType, thresh, alpha)</span><br><span class="line">    name = <span class="string">&quot;Original&quot;</span> <span class="keyword">if</span> (data[:,<span class="number">1</span>]&gt;<span class="number">2</span>).<span class="built_in">sum</span>() &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="string">&quot;Scaled&quot;</span>  <span class="comment"># 归一化时的区分</span></span><br><span class="line">    name += <span class="string">&quot; data - learning rate: &#123;&#125; - &quot;</span>.<span class="built_in">format</span>(alpha)</span><br><span class="line">    <span class="keyword">if</span> batchSize==n: strDescType = <span class="string">&quot;Gradient&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> batchSize==<span class="number">1</span>:  strDescType = <span class="string">&quot;Stochastic&quot;</span></span><br><span class="line">    <span class="keyword">else</span>: strDescType = <span class="string">&quot;Mini-batch (&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(batchSize)</span><br><span class="line">    name += strDescType + <span class="string">&quot; descent - Stop: &quot;</span></span><br><span class="line">    <span class="keyword">if</span> stopType == STOP_ITER: strStop = <span class="string">&quot;&#123;&#125; iterations&quot;</span>.<span class="built_in">format</span>(thresh)</span><br><span class="line">    <span class="keyword">elif</span> stopType == STOP_COST: strStop = <span class="string">&quot;costs change &lt; &#123;&#125;&quot;</span>.<span class="built_in">format</span>(thresh)</span><br><span class="line">    <span class="keyword">else</span>: strStop = <span class="string">&quot;gradient norm &lt; &#123;&#125;&quot;</span>.<span class="built_in">format</span>(thresh)</span><br><span class="line">    name += strStop</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;***&#123;&#125;\nTheta: &#123;&#125; - Iter: &#123;&#125; - Last cost: &#123;:03.2f&#125; - Duration: &#123;:03.2f&#125;s&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">        name, theta, <span class="built_in">iter</span>, costs[-<span class="number">1</span>], dur))</span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">    ax.plot(np.arange(<span class="built_in">len</span>(costs)), costs, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&#x27;Iterations&#x27;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&#x27;Cost&#x27;</span>)</span><br><span class="line">    ax.set_title(name.upper() + <span class="string">&#x27; - Error vs. Iteration&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure>
<h3 id="不同的停止策略"><a href="#不同的停止策略" class="headerlink" title="不同的停止策略"></a>不同的停止策略</h3><h4 id="设定迭代次数"><a href="#设定迭代次数" class="headerlink" title="设定迭代次数"></a>设定迭代次数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#选择的梯度下降方法是基于所有样本的</span></span><br><span class="line">n=<span class="number">100</span></span><br><span class="line">runExpe(orig_data, theta, n, STOP_ITER, thresh=<span class="number">5000</span>, alpha=<span class="number">0.000001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Original data - learning rate: 1e-06 - Gradient descent - Stop: 5000 iterations
Theta: [[-0.00027127  0.00705232  0.00376711]] - Iter: 5000 - Last cost: 0.63 - Duration: 0.82s





array([[-0.00027127,  0.00705232,  0.00376711]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/35_2.png" alt=""></p>
<h4 id="根据损失值停止"><a href="#根据损失值停止" class="headerlink" title="根据损失值停止"></a>根据损失值停止</h4><p>设定阈值 1E-6, 差不多需要110 000次迭代 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runExpe(orig_data, theta, n, STOP_COST, thresh=<span class="number">0.000001</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Original data - learning rate: 0.001 - Gradient descent - Stop: costs change &lt; 1e-06
Theta: [[-5.13364014  0.04771429  0.04072397]] - Iter: 109901 - Last cost: 0.38 - Duration: 17.97s





array([[-5.13364014,  0.04771429,  0.04072397]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/38_2.png" alt=""></p>
<h4 id="根据梯度变化停止"><a href="#根据梯度变化停止" class="headerlink" title="根据梯度变化停止"></a>根据梯度变化停止</h4><p>设定阈值 0.05,差不多需要40 000次迭代</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runExpe(orig_data, theta, n, STOP_GRAD, thresh=<span class="number">0.05</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Original data - learning rate: 0.001 - Gradient descent - Stop: gradient norm &lt; 0.05
Theta: [[-2.37033409  0.02721692  0.01899456]] - Iter: 40045 - Last cost: 0.49 - Duration: 6.87s





array([[-2.37033409,  0.02721692,  0.01899456]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/41_2.png" alt=""></p>
<h3 id="对比不同的梯度下降方法"><a href="#对比不同的梯度下降方法" class="headerlink" title="对比不同的梯度下降方法"></a>对比不同的梯度下降方法</h3><h4 id="Stochastic-descent"><a href="#Stochastic-descent" class="headerlink" title="Stochastic descent"></a>Stochastic descent</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runExpe(orig_data, theta, <span class="number">1</span>, STOP_ITER, thresh=<span class="number">5000</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Original data - learning rate: 0.001 - Stochastic descent - Stop: 5000 iterations
Theta: [[-0.39253059  0.04095984 -0.07371051]] - Iter: 5000 - Last cost: 1.84 - Duration: 0.27s





array([[-0.39253059,  0.04095984, -0.07371051]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/44_2.png" alt=""></p>
<p>有点爆炸。。。很不稳定,再来试试把学习率调小一些</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runExpe(orig_data, theta, <span class="number">1</span>, STOP_ITER, thresh=<span class="number">15000</span>, alpha=<span class="number">0.000002</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Original data - learning rate: 2e-06 - Stochastic descent - Stop: 15000 iterations
Theta: [[-0.00202238  0.00995606  0.00088035]] - Iter: 15000 - Last cost: 0.63 - Duration: 0.77s





array([[-0.00202238,  0.00995606,  0.00088035]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/46_2.png" alt=""></p>
<p>速度快，但稳定性差，需要很小的学习率</p>
<h4 id="Mini-batch-descent"><a href="#Mini-batch-descent" class="headerlink" title="Mini-batch descent"></a>Mini-batch descent</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runExpe(orig_data, theta, <span class="number">16</span>, STOP_ITER, thresh=<span class="number">15000</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Original data - learning rate: 0.001 - Mini-batch (16) descent - Stop: 15000 iterations
Theta: [[-1.0364887   0.02542788  0.00549476]] - Iter: 15000 - Last cost: 0.57 - Duration: 1.04s





array([[-1.0364887 ,  0.02542788,  0.00549476]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/49_2.png" alt=""></p>
<p>浮动仍然比较大，我们来尝试下对数据进行标准化<br>将数据按其属性(按列进行)减去其均值，然后除以其方差。最后得到的结果是，对每个属性/每列来说所有数据都聚集在0附近，方差值为1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing <span class="keyword">as</span> pp</span><br><span class="line"></span><br><span class="line">scaled_data = orig_data.copy()</span><br><span class="line">scaled_data[:, <span class="number">1</span>:<span class="number">3</span>] = pp.scale(orig_data[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">runExpe(scaled_data, theta, n, STOP_ITER, thresh=<span class="number">5000</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Scaled data - learning rate: 0.001 - Gradient descent - Stop: 5000 iterations
Theta: [[0.3080807  0.86494967 0.77367651]] - Iter: 5000 - Last cost: 0.38 - Duration: 0.88s





array([[0.3080807 , 0.86494967, 0.77367651]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/51_2.png" alt=""></p>
<p>它好多了！原始数据，只能达到达到0.61，而我们得到了0.38个在这里！<br>所以对数据做预处理是非常重要的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runExpe(scaled_data, theta, n, STOP_GRAD, thresh=<span class="number">0.02</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Scaled data - learning rate: 0.001 - Gradient descent - Stop: gradient norm &lt; 0.02
Theta: [[1.0707921  2.63030842 2.41079787]] - Iter: 59422 - Last cost: 0.22 - Duration: 10.67s





array([[1.0707921 , 2.63030842, 2.41079787]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/53_2.png" alt=""></p>
<p>更多的迭代次数会使得损失下降的更多！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theta = runExpe(scaled_data, theta, <span class="number">1</span>, STOP_GRAD, thresh=<span class="number">0.002</span>/<span class="number">5</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Scaled data - learning rate: 0.001 - Stochastic descent - Stop: gradient norm &lt; 0.0004
Theta: [[1.14814786 2.79253048 2.56596963]] - Iter: 72591 - Last cost: 0.22 - Duration: 4.82s
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/55_1.png" alt=""></p>
<p>随机梯度下降更快，但是我们需要迭代的次数也需要更多，所以还是用batch的比较合适！！！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runExpe(scaled_data, theta, <span class="number">16</span>, STOP_GRAD, thresh=<span class="number">0.002</span>*<span class="number">2</span>, alpha=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<pre><code>***Scaled data - learning rate: 0.001 - Mini-batch (16) descent - Stop: gradient norm &lt; 0.004
Theta: [[1.14982001 2.79586036 2.56934533]] - Iter: 307 - Last cost: 0.22 - Duration: 0.03s





array([[1.14982001, 2.79586036, 2.56934533]])
</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/57_2.png" alt=""></p>
<h2 id="精度"><a href="#精度" class="headerlink" title="精度"></a>精度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设定阈值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">X, theta</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="number">1</span> <span class="keyword">if</span> x &gt;= <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> model(X, theta)]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scaled_X = scaled_data[:, :<span class="number">3</span>]</span><br><span class="line">y = scaled_data[:, <span class="number">3</span>]</span><br><span class="line">predictions = predict(scaled_X, theta)</span><br><span class="line">correct = [<span class="number">1</span> <span class="keyword">if</span> ((a == <span class="number">1</span> <span class="keyword">and</span> b == <span class="number">1</span>) <span class="keyword">or</span> (a == <span class="number">0</span> <span class="keyword">and</span> b == <span class="number">0</span>)) <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> (a, b) <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, y)] </span><br><span class="line"><span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">zip(itertion1, iteration2)</span></span><br><span class="line"><span class="string"> A[1,2,3]</span></span><br><span class="line"><span class="string"> B[4,5,6]</span></span><br><span class="line"><span class="string"> zip[A,B] = [(1,4),(2,5),(3,6)] 可用list()进行转换</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">accuracy = (<span class="built_in">sum</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, correct)) / <span class="built_in">len</span>(correct))  <span class="comment"># map (func, iterations)</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;accuracy = &#123;&#125;%&#x27;</span>.<span class="built_in">format</span>(accuracy*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<pre><code>accuracy = 89.0%
</code></pre><h2 id="逻辑回归到这里就结束了！"><a href="#逻辑回归到这里就结束了！" class="headerlink" title="逻辑回归到这里就结束了！"></a>逻辑回归到这里就结束了！</h2>
      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
<!--  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html" title="逻辑回归基础" target="_blank" rel="external">https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80.html</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul> -->
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://xxren888.gitee.io" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://xxren888.gitee.io" target="_blank"><span class="text-dark">任晓雄</span><small class="ml-1x">机器学习 &amp; 人工智能</small></a></h3>
        <div>西安交通大学19级研究生一枚，研究计算机纯属兴趣。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html" title="逻辑回归实战--信用卡诈骗检测"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;上一篇</span></a>
    </li>
    
    
    <li class="next">
      <a href="/20210405/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0.html" title="机器学习数学基础-线性代数"><span>下一篇&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
    <li class="toggle-toc">
      <a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="文章目录" role="button">
        <span>[&nbsp;</span><span>文章目录</span>
        <i class="text-collapsed icon icon-anchor"></i>
        <i class="text-in icon icon-close"></i>
        <span>]</span>
      </a>
    </li>
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>赏</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>感谢您的支持，我会继续努力的!</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/alipayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开支付宝扫一扫，即可进行扫码打赏哦</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/wechatpayimg.png" alt="扫码支持" title="扫一扫" />
              </div>
              <p class="text-muted mv">扫码打赏，你说多少就多少</p>
              <p class="text-grey">打开微信扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> 支付宝</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> 微信支付</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>




</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/xxren8218/xxren8218.github.io" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="https://weibo.com/u/5824042330" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="/" target="_blank" title="Facebook" data-toggle=tooltip data-placement=top><i class="icon icon-facebook"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/xxren8218" target="_blank"> xxren </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>

  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>

<script src="/js/plugin.min.js"></script>


<script src="/js/application.js"></script>


    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>






   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: 'q31vlhOeBIWHbSnIN669vDYF-gzGzoHsz',
    appKey: 'r0sWX8dHj6ThrIus2L589jr9',
    placeholder: '说点什么吧...',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: true
  });
  </script>

     







<div id="go-top"></div>

<style type="text/css">
#go-top {
 width:40px;height:36px;
 background-color:#DDA0DD;
 position:relative;
 border-radius:2px;
 position:fixed;right:10px;bottom:60px;
 cursor:pointer;display:none;
}
#go-top:after {
 content:" ";
 position:absolute;left:14px;top:14px;
 border-top:2px solid #fff;border-right:2px solid #fff;
 width:12px;height:12px;
 transform:rotate(-45deg);
}
#go-top:hover {
 background-color:#8A2BE2;
}
</style>
<script>
$(function () {
  var top=$("#go-top");
  $(window).scroll(function () {
    ($(window).scrollTop() > 300) ? top.show(300) : top.hide(200);
    $("#go-top").click(function () {
      $('body,html').animate({scrollTop:0});
      return false();
    })
  });
});
</script>


  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
      z-index: 2;
    }

    .highlight-wrap:hover .copy-btn,
        .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  
  <script>
    addLoadEvent(()=>{
      $('.highlight').each(function (i, e) {
        var $wrap = $('<div>').addClass('highlight-wrap')
        $(e).after($wrap)
        $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
          var code = $(this).parent().find(".code")[0].innerText
          
          var ta = document.createElement('textarea')
          document.body.appendChild(ta)
          ta.style.position = 'absolute'
          ta.style.top = '0px'
          ta.style.left = '0px'
          ta.value = code
          ta.select()
          ta.focus()
          var result = document.execCommand('copy')
          document.body.removeChild(ta)
          
            if(result)$(this).text('复制成功')
            else $(this).text('复制失败')
          
          $(this).blur()
        })).on('mouseleave', function (e) {
          var $b = $(this).find('.copy-btn')
          setTimeout(function () {
            $b.text('复制')
          }, 300)
        }).append(e)
      })
    })
  </script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>



</body>
</html>
