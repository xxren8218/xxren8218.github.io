<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>X.X.Ren</title>
  
  <subtitle>个人博客</subtitle>
  <link href="https://xxren8218.github.io/atom.xml" rel="self"/>
  
  <link href="https://xxren8218.github.io/"/>
  <updated>2021-05-15T06:39:58.519Z</updated>
  <id>https://xxren8218.github.io/</id>
  
  <author>
    <name>任晓雄</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>降维算法——PCA(主成分分析)</title>
    <link href="https://xxren8218.github.io/20210515/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E2%80%94%E2%80%94PCA-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90.html"/>
    <id>https://xxren8218.github.io/20210515/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E2%80%94%E2%80%94PCA-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90.html</id>
    <published>2021-05-15T06:31:02.000Z</published>
    <updated>2021-05-15T06:39:58.519Z</updated>
    
    <content type="html"><![CDATA[<h1 id="鸢尾花数据集的降维——PCA"><a href="#鸢尾花数据集的降维——PCA" class="headerlink" title="鸢尾花数据集的降维——PCA"></a>鸢尾花数据集的降维——PCA</h1><ul><li>PCA的降维是不依赖标签（分类的），而是依赖样本的方差（协方差）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;iris.data&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>5.1</th>      <th>3.5</th>      <th>1.4</th>      <th>0.2</th>      <th>Iris-setosa</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>4.9</td>      <td>3.0</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>1</th>      <td>4.7</td>      <td>3.2</td>      <td>1.3</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>2</th>      <td>4.6</td>      <td>3.1</td>      <td>1.5</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>3</th>      <td>5.0</td>      <td>3.6</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>4</th>      <td>5.4</td>      <td>3.9</td>      <td>1.7</td>      <td>0.4</td>      <td>Iris-setosa</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.columns=[<span class="string">&#x27;sepal_len&#x27;</span>, <span class="string">&#x27;sepal_wid&#x27;</span>, <span class="string">&#x27;petal_len&#x27;</span>, <span class="string">&#x27;petal_wid&#x27;</span>, <span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>sepal_len</th>      <th>sepal_wid</th>      <th>petal_len</th>      <th>petal_wid</th>      <th>class</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>4.9</td>      <td>3.0</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>1</th>      <td>4.7</td>      <td>3.2</td>      <td>1.3</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>2</th>      <td>4.6</td>      <td>3.1</td>      <td>1.5</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>3</th>      <td>5.0</td>      <td>3.6</td>      <td>1.4</td>      <td>0.2</td>      <td>Iris-setosa</td>    </tr>    <tr>      <th>4</th>      <td>5.4</td>      <td>3.9</td>      <td>1.7</td>      <td>0.4</td>      <td>Iris-setosa</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split data table into data X and class labels y</span></span><br><span class="line"></span><br><span class="line">X = df.ix[:,<span class="number">0</span>:<span class="number">4</span>].values</span><br><span class="line">y = df.ix[:,<span class="number">4</span>].values</span><br></pre></td></tr></table></figure><p><strong> 数据的可视化 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">label_dict = &#123;<span class="number">1</span>: <span class="string">&#x27;Iris-Setosa&#x27;</span>,</span><br><span class="line">              <span class="number">2</span>: <span class="string">&#x27;Iris-Versicolor&#x27;</span>,</span><br><span class="line">              <span class="number">3</span>: <span class="string">&#x27;Iris-Virgnica&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">feature_dict = &#123;<span class="number">0</span>: <span class="string">&#x27;sepal length [cm]&#x27;</span>,</span><br><span class="line">                <span class="number">1</span>: <span class="string">&#x27;sepal width [cm]&#x27;</span>,</span><br><span class="line">                <span class="number">2</span>: <span class="string">&#x27;petal length [cm]&#x27;</span>,</span><br><span class="line">                <span class="number">3</span>: <span class="string">&#x27;petal width [cm]&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> cnt <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">2</span>, cnt+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> lab <span class="keyword">in</span> (<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>):</span><br><span class="line">        plt.hist(X[y==lab, cnt],</span><br><span class="line">                     label=lab,</span><br><span class="line">                     bins=<span class="number">10</span>,</span><br><span class="line">                     alpha=<span class="number">0.3</span>,)</span><br><span class="line">    plt.xlabel(feature_dict[cnt])</span><br><span class="line">    plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, fancybox=<span class="literal">True</span>, fontsize=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515143327.png" alt=""></p><p><strong> 一般要先进行数据的标准化，归一化，或正态化的预处理 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X_std = StandardScaler().fit_transform(X)</span><br><span class="line"><span class="built_in">print</span> (X_std)</span><br></pre></td></tr></table></figure><pre><code>[[-1.1483555  -0.11805969 -1.35396443 -1.32506301] [-1.3905423   0.34485856 -1.41098555 -1.32506301] [-1.51163569  0.11339944 -1.29694332 -1.32506301] [-1.02726211  1.27069504 -1.35396443 -1.32506301] [-0.54288852  1.9650724  -1.18290109 -1.0614657 ] [-1.51163569  0.8077768  -1.35396443 -1.19326436] [-1.02726211  0.8077768  -1.29694332 -1.32506301] [-1.75382249 -0.34951881 -1.35396443 -1.32506301] [-1.1483555   0.11339944 -1.29694332 -1.45686167] [-0.54288852  1.50215416 -1.29694332 -1.32506301] [-1.2694489   0.8077768  -1.23992221 -1.32506301] [-1.2694489  -0.11805969 -1.35396443 -1.45686167] [-1.87491588 -0.11805969 -1.52502777 -1.45686167] [-0.05851493  2.19653152 -1.46800666 -1.32506301] ... [-0.54288852  1.9650724  -1.41098555 -1.0614657 ] [-0.90616871  1.03923592 -1.35396443 -1.19326436] [-0.17960833  1.73361328 -1.18290109 -1.19326436] [-0.90616871  1.73361328 -1.29694332 -1.19326436] [ 1.15241904  0.34485856  1.21198569  1.4427088 ] [ 1.03132564  0.57631768  1.09794346  1.70630611] [ 1.03132564 -0.11805969  0.81283789  1.4427088 ] [ 0.54695205 -1.27535529  0.69879566  0.91551417] [ 0.78913885 -0.11805969  0.81283789  1.04731282] [ 0.42585866  0.8077768   0.92688012  1.4427088 ] [ 0.06257847 -0.11805969  0.75581678  0.78371551]]</code></pre><p><strong> 手撕协方差 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mean_vec = np.mean(X_std, axis=<span class="number">0</span>)</span><br><span class="line">cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[<span class="number">0</span>]-<span class="number">1</span>)</span><br><span class="line">print(<span class="string">&#x27;Covariance matrix \n%s&#x27;</span> %cov_mat)</span><br></pre></td></tr></table></figure><pre><code>Covariance matrix [[ 1.00675676 -0.10448539  0.87716999  0.82249094] [-0.10448539  1.00675676 -0.41802325 -0.35310295] [ 0.87716999 -0.41802325  1.00675676  0.96881642] [ 0.82249094 -0.35310295  0.96881642  1.00675676]]</code></pre><p><strong> 直接可以在numpy中调用cov（）,协方差函数 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;NumPy covariance matrix: \n%s&#x27;</span> %np.cov(X_std.T))</span><br></pre></td></tr></table></figure><pre><code>NumPy covariance matrix: [[ 1.00675676 -0.10448539  0.87716999  0.82249094] [-0.10448539  1.00675676 -0.41802325 -0.35310295] [ 0.87716999 -0.41802325  1.00675676  0.96881642] [ 0.82249094 -0.35310295  0.96881642  1.00675676]]</code></pre><p>可以看到对角线上的都为1，因为自身与自身的协方差肯定是1</p><ul><li>标准化以后是1。——相关系数。</li><li>没有标准化的数据，仅仅是方差。</li></ul><h3 id="计算协方差矩阵的特征值和特征向量"><a href="#计算协方差矩阵的特征值和特征向量" class="headerlink" title="计算协方差矩阵的特征值和特征向量"></a>计算协方差矩阵的特征值和特征向量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cov_mat = np.cov(X_std.T)</span><br><span class="line"></span><br><span class="line">eig_vals, eig_vecs = np.linalg.eig(cov_mat)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Eigenvectors \n%s&#x27;</span> %eig_vecs)</span><br><span class="line">print(<span class="string">&#x27;\nEigenvalues \n%s&#x27;</span> %eig_vals)</span><br></pre></td></tr></table></figure><pre><code>Eigenvectors [[ 0.52308496 -0.36956962 -0.72154279  0.26301409] [-0.25956935 -0.92681168  0.2411952  -0.12437342] [ 0.58184289 -0.01912775  0.13962963 -0.80099722] [ 0.56609604 -0.06381646  0.63380158  0.52321917]]Eigenvalues [ 2.92442837  0.93215233  0.14946373  0.02098259]</code></pre><p><strong> 特征值的大小代表特征向量的重要程度 </strong></p><p>下面的代码将其进行排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make a list of (eigenvalue, eigenvector) tuples</span></span><br><span class="line">eig_pairs = [(np.<span class="built_in">abs</span>(eig_vals[i]), eig_vecs[:,i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(eig_vals))]</span><br><span class="line"><span class="built_in">print</span> (eig_pairs)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;----------&#x27;</span>)</span><br><span class="line"><span class="comment"># Sort the (eigenvalue, eigenvector) tuples from high to low</span></span><br><span class="line">eig_pairs.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visually confirm that the list is correctly sorted by decreasing eigenvalues</span></span><br><span class="line">print(<span class="string">&#x27;Eigenvalues in descending order:&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> eig_pairs:</span><br><span class="line">    print(i[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>[(2.9244283691111144, array([ 0.52308496, -0.25956935,  0.58184289,  0.56609604])), (0.93215233025350641, array([-0.36956962, -0.92681168, -0.01912775, -0.06381646])), (0.14946373489813314, array([-0.72154279,  0.2411952 ,  0.13962963,  0.63380158])), (0.020982592764270606, array([ 0.26301409, -0.12437342, -0.80099722,  0.52321917]))]----------Eigenvalues in descending order:2.924428369110.9321523302540.1494637348980.0209825927643</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tot = <span class="built_in">sum</span>(eig_vals)</span><br><span class="line">var_exp = [(i / tot)*<span class="number">100</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">sorted</span>(eig_vals, reverse=<span class="literal">True</span>)]</span><br><span class="line"><span class="built_in">print</span> (var_exp)</span><br><span class="line">cum_var_exp = np.cumsum(var_exp)  <span class="comment"># 来验证最后的和是否为100% 以及维度的选择——cumsum()的解释在下面。</span></span><br><span class="line">cum_var_exp</span><br></pre></td></tr></table></figure><pre><code>[72.620033326920336, 23.147406858644135, 3.7115155645845164, 0.52104424985101538]array([  72.62003333,   95.76744019,   99.47895575,  100.        ])</code></pre><h3 id="cumsum-函数的解释："><a href="#cumsum-函数的解释：" class="headerlink" title="cumsum()函数的解释："></a>cumsum()函数的解释：</h3><ul><li>为什么要用它呢？<ul><li>可以判断到底降维到几维。（设置阈值。比如百分之95%，那么降到2维即可）</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span> (a)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;-----------&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> (np.cumsum(a))</span><br></pre></td></tr></table></figure><pre><code>[1 2 3 4]-----------[ 1  3  6 10]</code></pre><p><strong> 作图展示特征值所占的百分比 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">plt.bar(<span class="built_in">range</span>(<span class="number">4</span>), var_exp, alpha=<span class="number">0.5</span>, align=<span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">            label=<span class="string">&#x27;individual explained variance&#x27;</span>)</span><br><span class="line">plt.step(<span class="built_in">range</span>(<span class="number">4</span>), cum_var_exp, where=<span class="string">&#x27;mid&#x27;</span>,                <span class="comment"># 阶梯图。where，表示在哪里开始跳跃。</span></span><br><span class="line">             label=<span class="string">&#x27;cumulative explained variance&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Explained variance ratio&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Principal components&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.tight_layout() <span class="comment"># 最自动调整图的大小。使其填满图像区域。</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515143458.png" alt=""></p><p><strong> 确定w的维度 </strong></p><ul><li>拿前两个特征向量。——基变换:w.T * x0 = x1</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix_w = np.hstack((eig_pairs[<span class="number">0</span>][<span class="number">1</span>].reshape(<span class="number">4</span>,<span class="number">1</span>),</span><br><span class="line">                      eig_pairs[<span class="number">1</span>][<span class="number">1</span>].reshape(<span class="number">4</span>,<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Matrix W:\n&#x27;</span>, matrix_w)</span><br></pre></td></tr></table></figure><pre><code>Matrix W: [[ 0.52308496 -0.36956962] [-0.25956935 -0.92681168] [ 0.58184289 -0.01912775] [ 0.56609604 -0.06381646]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Y = X_std.dot(matrix_w)</span><br><span class="line">Y</span><br></pre></td></tr></table></figure><pre><code>array([[-2.10795032,  0.64427554],       [-2.38797131,  0.30583307],       [-2.32487909,  0.56292316],       [-2.40508635, -0.687591  ],       [-2.08320351, -1.53025171],       [-2.4636848 , -0.08795413],       [-2.25174963, -0.25964365],       [-2.3645813 ,  1.08255676],       [-2.20946338,  0.43707676],       [-2.17862017, -1.08221046],       [-2.34525657, -0.17122946],       ...       [ 2.00701161, -0.60663655],       [ 1.89319854, -0.68227708],       [ 1.13831104,  0.70171953],       [ 2.03519535, -0.86076914],       [ 1.99464025, -1.04517619],       [ 1.85977129, -0.37934387],       [ 1.54200377,  0.90808604],       [ 1.50925493, -0.26460621],       [ 1.3690965 , -1.01583909],       [ 0.94680339,  0.02182097]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> lab, col <span class="keyword">in</span> <span class="built_in">zip</span>((<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>),</span><br><span class="line">                        (<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>)):</span><br><span class="line">     plt.scatter(X[y==lab, <span class="number">0</span>],</span><br><span class="line">                X[y==lab, <span class="number">1</span>],</span><br><span class="line">                label=lab,</span><br><span class="line">                c=col)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal_len&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal_wid&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515143541.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> lab, col <span class="keyword">in</span> <span class="built_in">zip</span>((<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>),</span><br><span class="line">                        (<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>)):</span><br><span class="line">     plt.scatter(Y[y==lab, <span class="number">0</span>],</span><br><span class="line">                Y[y==lab, <span class="number">1</span>],</span><br><span class="line">                label=lab,</span><br><span class="line">                c=col)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Principal Component 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Principal Component 2&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;lower center&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515143554.png" alt=""></p><h2 id="PCA使得结果更容易分类"><a href="#PCA使得结果更容易分类" class="headerlink" title="PCA使得结果更容易分类"></a>PCA使得结果更容易分类</h2><p><strong> 降维后数据的意义不存在了 </strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;鸢尾花数据集的降维——PCA&quot;&gt;&lt;a href=&quot;#鸢尾花数据集的降维——PCA&quot; class=&quot;headerlink&quot; title=&quot;鸢尾花数据集的降维——PCA&quot;&gt;&lt;/a&gt;鸢尾花数据集的降维——PCA&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;PCA的降维是不依赖标签（分类的</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习基础" scheme="https://xxren8218.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>降维算法——LDA(线性判别分析)</title>
    <link href="https://xxren8218.github.io/20210515/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E2%80%94%E2%80%94LDA-%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90.html"/>
    <id>https://xxren8218.github.io/20210515/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95%E2%80%94%E2%80%94LDA-%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90.html</id>
    <published>2021-05-15T06:16:53.000Z</published>
    <updated>2021-05-15T06:29:10.304Z</updated>
    
    <content type="html"><![CDATA[<h1 id="鸢尾花的数据集进行降维"><a href="#鸢尾花的数据集进行降维" class="headerlink" title="鸢尾花的数据集进行降维"></a>鸢尾花的数据集进行降维</h1><ul><li>有四个维度，萼片的长度。萼片的宽度，花瓣的长度，花瓣的宽度——将其降低维度为2维</li><li>数据集大概有150条</li><li>数据集没有列名，给其进行指定，使用zip()函数，将其进行对应</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">feature_dict = &#123;i:label <span class="keyword">for</span> i,label <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                <span class="built_in">range</span>(<span class="number">4</span>),</span><br><span class="line">                  (<span class="string">&#x27;sepal length in cm&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;sepal width in cm&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;petal length in cm&#x27;</span>,                <span class="comment"># 用到了字典推导式！</span></span><br><span class="line">                  <span class="string">&#x27;petal width in cm&#x27;</span>, ))&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#########################################</span></span><br><span class="line"><span class="comment"># feature_dict = &#123;0: &#x27;sepal length in cm&#x27;, </span></span><br><span class="line"><span class="comment">#                 1: &#x27;sepal width in cm&#x27;, </span></span><br><span class="line"><span class="comment">#                 2: &#x27;petal length in cm&#x27;, </span></span><br><span class="line"><span class="comment">#                 3: &#x27;petal width in cm&#x27;&#125;</span></span><br><span class="line"><span class="comment">#########################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.io.parsers.read_csv(</span><br><span class="line">    filepath_or_buffer=<span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span>,</span><br><span class="line">    header=<span class="literal">None</span>,</span><br><span class="line">    sep=<span class="string">&#x27;,&#x27;</span>,</span><br><span class="line">    )</span><br><span class="line"><span class="comment"># 数据加列名</span></span><br><span class="line">df.columns = [l <span class="keyword">for</span> i,l <span class="keyword">in</span> <span class="built_in">sorted</span>(feature_dict.items())] + [<span class="string">&#x27;class label&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">sorted()得到的是一个列表，需要接收，而list.sort()原地排序。O(nlogn)</span></span><br><span class="line"><span class="string">若排序的是字典，会将字典的键值，放入元祖中，则可以通过 i,j 进行取元祖里的值。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#######################################</span></span><br><span class="line"><span class="string">z = [i for i in sorted(feature_dict.items())]</span></span><br><span class="line"><span class="string"># [(0, &#x27;sepal length in cm&#x27;), (1, &#x27;sepal width in cm&#x27;), (2, &#x27;petal length in cm&#x27;), (3, &#x27;petal width in cm&#x27;)]</span></span><br><span class="line"><span class="string">#######################################</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#######################################</span></span><br><span class="line"><span class="string">x = [l for i,l in sorted(feature_dict.items())]</span></span><br><span class="line"><span class="string"># [&#x27;sepal length in cm&#x27;, &#x27;sepal width in cm&#x27;, &#x27;petal length in cm&#x27;, &#x27;petal width in cm&#x27;]</span></span><br><span class="line"><span class="string">#######################################</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">df.dropna(how=<span class="string">&quot;all&quot;</span>, inplace=<span class="literal">True</span>) <span class="comment"># to drop the empty line at file-end</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">#######################################</span></span><br><span class="line"><span class="string">dropna()方法，能够找到DataFrame类型数据的空值（缺失值），将空值所在的行/列删除后，将新的DataFrame作为返回值返回。</span></span><br><span class="line"><span class="string">#######################################</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">axis：轴。0或&#x27;index&#x27;，表示按行删除；1或&#x27;columns&#x27;，表示按列删除。</span></span><br><span class="line"><span class="string">how：筛选方式。‘any’，表示该行/列只要有一个以上的空值，就删除该行/列；</span></span><br><span class="line"><span class="string">    ‘all’，表示该行/列全部都为空值，就删除该行/列。</span></span><br><span class="line"><span class="string">thresh：非空元素最低数量。int型，默认为None。如果该行/列中，非空元素数量小于这个值，就删除该行/列</span></span><br><span class="line"><span class="string">inplace：是否原地替换。布尔值，默认为False。如果为True，则在原DataFrame上进行操作，返回值为None</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">df.tail()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>sepal length in cm</th>      <th>sepal width in cm</th>      <th>petal length in cm</th>      <th>petal width in cm</th>      <th>class label</th>    </tr>  </thead>  <tbody>    <tr>      <th>145</th>      <td>6.7</td>      <td>3.0</td>      <td>5.2</td>      <td>2.3</td>      <td>Iris-virginica</td>    </tr>    <tr>      <th>146</th>      <td>6.3</td>      <td>2.5</td>      <td>5.0</td>      <td>1.9</td>      <td>Iris-virginica</td>    </tr>    <tr>      <th>147</th>      <td>6.5</td>      <td>3.0</td>      <td>5.2</td>      <td>2.0</td>      <td>Iris-virginica</td>    </tr>    <tr>      <th>148</th>      <td>6.2</td>      <td>3.4</td>      <td>5.4</td>      <td>2.3</td>      <td>Iris-virginica</td>    </tr>    <tr>      <th>149</th>      <td>5.9</td>      <td>3.0</td>      <td>5.1</td>      <td>1.8</td>      <td>Iris-virginica</td>    </tr>  </tbody></table></div><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142217.png" alt=""></p><p><strong> 可以看到y数据的（lebal）是字符串，不好。可以将其转化成数字。</strong></p><ul><li>使用sklearn.preprocessing的LabelEncoder模块实现 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">X = df[[<span class="string">&#x27;sepal length in cm&#x27;</span>,<span class="string">&#x27;sepal width in cm&#x27;</span>,<span class="string">&#x27;petal length in cm&#x27;</span>,<span class="string">&#x27;petal width in cm&#x27;</span>]].values</span><br><span class="line">y = df[<span class="string">&#x27;class label&#x27;</span>].values</span><br><span class="line"></span><br><span class="line">enc = LabelEncoder()</span><br><span class="line">label_encoder = enc.fit(y)  <span class="comment"># 与之前不同的是，它在y上进行 fit !</span></span><br><span class="line">y = label_encoder.transform(y) + <span class="number">1</span> <span class="comment"># 默认从零开始，可以改为从一开始，</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># label_dict = &#123;1: &#x27;Setosa&#x27;, 2: &#x27;Versicolor&#x27;, 3:&#x27;Virginica&#x27;&#125;</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142251.png" alt=""></p><h3 id="分别求三种鸢尾花数据在不同特征维度上的均值向量-mi"><a href="#分别求三种鸢尾花数据在不同特征维度上的均值向量-mi" class="headerlink" title="分别求三种鸢尾花数据在不同特征维度上的均值向量 mi"></a>分别求三种鸢尾花数据在不同特征维度上的均值向量 mi</h3><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142312.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.set_printoptions(precision=<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 输出时，小数点后面四位，若没有四位的话，不输出。（0不输出！）</span></span><br><span class="line"></span><br><span class="line">mean_vectors = []</span><br><span class="line"><span class="keyword">for</span> cl <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">4</span>):</span><br><span class="line">    mean_vectors.append(np.mean(X[y==cl], axis=<span class="number">0</span>))</span><br><span class="line">    print(<span class="string">&#x27;Mean Vector class %s: %s\n&#x27;</span> %(cl, mean_vectors[cl-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><pre><code>Mean Vector class 1: [ 5.006  3.418  1.464  0.244]Mean Vector class 2: [ 5.936  2.77   4.26   1.326]Mean Vector class 3: [ 6.588  2.974  5.552  2.026]</code></pre><h3 id="计算两个-4×4-维矩阵：类内散布矩阵和类间散布矩阵"><a href="#计算两个-4×4-维矩阵：类内散布矩阵和类间散布矩阵" class="headerlink" title="计算两个 4×4 维矩阵：类内散布矩阵和类间散布矩阵"></a>计算两个 4×4 维矩阵：类内散布矩阵和类间散布矩阵</h3><ul><li><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142459.png" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">S_W = np.zeros((<span class="number">4</span>,<span class="number">4</span>))                               <span class="comment"># 每个类有4个特征值。即协方差矩阵——收藏的！</span></span><br><span class="line"><span class="keyword">for</span> cl,mv <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">4</span>), mean_vectors):         <span class="comment"># 3个类</span></span><br><span class="line">    class_sc_mat = np.zeros((<span class="number">4</span>,<span class="number">4</span>))                  <span class="comment"># scatter matrix for every class 由协方差决定其是4x4的！</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> X[y == cl]:                          <span class="comment"># 选取第 c1 类的 X</span></span><br><span class="line">        row, mv = row.reshape(<span class="number">4</span>,<span class="number">1</span>), mv.reshape(<span class="number">4</span>,<span class="number">1</span>) <span class="comment"># make column vectors 将矩阵组成 4x4 的形式！</span></span><br><span class="line">        class_sc_mat += (row-mv).dot((row-mv).T)</span><br><span class="line">    S_W += class_sc_mat                             <span class="comment"># sum class scatter matrices</span></span><br><span class="line">print(<span class="string">&#x27;within-class Scatter Matrix:\n&#x27;</span>, S_W)</span><br></pre></td></tr></table></figure><pre><code>within-class Scatter Matrix: [[ 38.9562  13.683   24.614    5.6556] [ 13.683   17.035    8.12     4.9132] [ 24.614    8.12    27.22     6.2536] [  5.6556   4.9132   6.2536   6.1756]]</code></pre><ul><li><p>类间的散布矩阵进行简化。不是m1-m2了，而是与全局均值的作比较</p></li><li><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142528.png" alt=""></p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">overall_mean = np.mean(X, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">zip()和enumerate()类似，但是有所不同。</span></span><br><span class="line"><span class="string">zip()可以跟多对象，</span></span><br><span class="line"><span class="string">########################</span></span><br><span class="line"><span class="string">names = [&#x27;张三&#x27;,&#x27;李四&#x27;,&#x27;王五&#x27;]</span></span><br><span class="line"><span class="string">sexs = [&#x27;boy&#x27;,&#x27;girl&#x27;,&#x27;boy&#x27;]</span></span><br><span class="line"><span class="string">scores = [86, 92]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">for name, sex, score in zip(names,sexs,scores):</span></span><br><span class="line"><span class="string">    print(&#x27;&#123;&#125;: &#123;&#125;, &#123;&#125;&#x27;.format(name, sex, score))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">out[]:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">张三: boy, 86</span></span><br><span class="line"><span class="string">李四: girl, 92</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">########################</span></span><br><span class="line"><span class="string">enumerate()不可以。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">S_B = np.zeros((<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i,mean_vec <span class="keyword">in</span> <span class="built_in">enumerate</span>(mean_vectors):  </span><br><span class="line">    n = X[y==i+<span class="number">1</span>,:].shape[<span class="number">0</span>]  <span class="comment"># 获得数据的个数</span></span><br><span class="line">    mean_vec = mean_vec.reshape(<span class="number">4</span>,<span class="number">1</span>) <span class="comment"># make column vector</span></span><br><span class="line">    overall_mean = overall_mean.reshape(<span class="number">4</span>,<span class="number">1</span>) <span class="comment"># make column vector</span></span><br><span class="line">    S_B += n * (mean_vec - overall_mean).dot((mean_vec - overall_mean).T)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;between-class Scatter Matrix:\n&#x27;</span>, S_B)</span><br></pre></td></tr></table></figure><pre><code>between-class Scatter Matrix: [[  63.2121  -19.534   165.1647   71.3631] [ -19.534    10.9776  -56.0552  -22.4924] [ 165.1647  -56.0552  436.6437  186.9081] [  71.3631  -22.4924  186.9081   80.6041]]</code></pre><ul><li><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142553.png" alt=""></li></ul><p><strong> np.linalg.inv()可以求逆，np.linalg.eig()可以求特征值，特征向量 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(eig_vals)):</span><br><span class="line">    eigvec_sc = eig_vecs[:,i].reshape(<span class="number">4</span>,<span class="number">1</span>)   </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回的v是归一化后的特征向量（length为1）。特征向量v[:,i]对应特征值w[i]。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    print(<span class="string">&#x27;\nEigenvector &#123;&#125;: \n&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>, eigvec_sc.real))  <span class="comment"># 取实部</span></span><br><span class="line">    print(<span class="string">&#x27;Eigenvalue &#123;:&#125;: &#123;:.2e&#125;&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>, eig_vals[i].real))</span><br></pre></td></tr></table></figure><pre><code>Eigenvector 1: [[ 0.2049] [ 0.3871] [-0.5465] [-0.7138]]Eigenvalue 1: 3.23e+01Eigenvector 2: [[-0.009 ] [-0.589 ] [ 0.2543] [-0.767 ]]Eigenvalue 2: 2.78e-01Eigenvector 3: [[-0.7113] [ 0.0353] [-0.0267] [ 0.7015]]Eigenvalue 3: -5.76e-15Eigenvector 4: [[ 0.422 ] [-0.4364] [-0.4851] [ 0.6294]]Eigenvalue 4: 7.80e-15</code></pre><h3 id="特征值与特征向量："><a href="#特征值与特征向量：" class="headerlink" title="特征值与特征向量："></a>特征值与特征向量：</h3><ul><li>特征向量：表示映射方向</li><li>特征值：特征向量的重要程度</li><li>假设我们投影到的低维空间的维度为d，(n-&gt;d维的转换)对应的基向量为：W = (w1,w2,w3…wd)——收藏的！<ul><li>将x = W.T * x ((d,n) x (n,1)=(d,1))</li><li>这里是先求整体的四个映射方向，再进行筛选，选择两个，特征值大的。(具体看收藏的多分类LDA),然后进行降维。</li></ul></li></ul><p><strong>对本征值进行排序</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Make a list of (eigenvalue, eigenvector) tuples</span></span><br><span class="line">eig_pairs = [(np.<span class="built_in">abs</span>(eig_vals[i]), eig_vecs[:,i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(eig_vals))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sort the (eigenvalue, eigenvector) tuples from high to low</span></span><br><span class="line">eig_pairs = <span class="built_in">sorted</span>(eig_pairs, key=<span class="keyword">lambda</span> k: k[<span class="number">0</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">key = lambda k:k[0]的意义：</span></span><br><span class="line"><span class="string">若可迭代对象是单个数字等，则可以直接排序。</span></span><br><span class="line"><span class="string">若是元祖，字典等，则需要指定根据什么进行排序了。即k[0]的第零个元素进行排序。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Visually confirm that the list is correctly sorted by decreasing eigenvalues</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Eigenvalues in decreasing order:\n&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> eig_pairs:</span><br><span class="line">    print(i[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>Eigenvalues in decreasing order:32.27195779970.277566863847.7995841654e-155.76433252705e-15</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;Variance explained:\n&#x27;</span>)</span><br><span class="line">eigv_sum = <span class="built_in">sum</span>(eig_vals)</span><br><span class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> <span class="built_in">enumerate</span>(eig_pairs):</span><br><span class="line">    print(<span class="string">&#x27;eigenvalue &#123;0:&#125;: &#123;1:.2%&#125;&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>, (j[<span class="number">0</span>]/eigv_sum).real))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">     ###############################################</span></span><br><span class="line"><span class="string">     print  &#x27;hello &#123;&#125; i am &#123;&#125;&#x27;.format(&#x27;Kevin&#x27;,&#x27;Tom&#x27;)</span></span><br><span class="line"><span class="string">                             </span></span><br><span class="line"><span class="string">     # hello Kevin i am Tom    </span></span><br><span class="line"><span class="string">     ###############################################</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     ###############################################</span></span><br><span class="line"><span class="string">     print  &#x27;&#123;0&#125; i am &#123;1&#125; . my name is &#123;0&#125;&#x27;.format(&#x27;Kevin&#x27;,&#x27;Tom&#x27;)</span></span><br><span class="line"><span class="string">                             </span></span><br><span class="line"><span class="string">     # hello Kevin i am Tom . my name is Kevin</span></span><br><span class="line"><span class="string">     ###############################################</span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     </span></span><br><span class="line"><span class="string">     ###############################################</span></span><br><span class="line"><span class="string">     &#123;0:&#125;冒号后面可以跟需要的操作，如保留两位小数</span></span><br><span class="line"><span class="string">     ###############################################</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><pre><code>Variance explained:eigenvalue 1: 99.15%eigenvalue 2: 0.85%eigenvalue 3: 0.00%eigenvalue 4: 0.00%</code></pre><p>选择前两维特征</p><p>x ((1,n)-&gt;(1,d))</p><p>x1 = x0 * W ((1,n) x (n,d)) =&gt; 所以W为(n,d)，此题为(4,2) </p><ul><li>理解意思即可，此题x=(1,n)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">W = np.hstack((eig_pairs[<span class="number">0</span>][<span class="number">1</span>].reshape(<span class="number">4</span>,<span class="number">1</span>), eig_pairs[<span class="number">1</span>][<span class="number">1</span>].reshape(<span class="number">4</span>,<span class="number">1</span>)))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">np.vstack():在竖直方向上堆叠</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">np.hstack():在水平方向上平铺</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">print(<span class="string">&#x27;Matrix W:\n&#x27;</span>, W.real)</span><br></pre></td></tr></table></figure><pre><code>Matrix W: [[ 0.2049 -0.009 ] [ 0.3871 -0.589 ] [-0.5465  0.2543] [-0.7138 -0.767 ]]</code></pre><h3 id="进行数据的降维"><a href="#进行数据的降维" class="headerlink" title="进行数据的降维"></a>进行数据的降维</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_lda = X.dot(W)</span><br><span class="line"><span class="keyword">assert</span> X_lda.shape == (<span class="number">150</span>,<span class="number">2</span>), <span class="string">&quot;The matrix is not 150x2 dimensional.&quot;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_step_lda</span>():</span></span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="keyword">for</span> label,marker,color <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">        <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">4</span>),(<span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;o&#x27;</span>),(<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>)):</span><br><span class="line"></span><br><span class="line">        plt.scatter(x=X_lda[:,<span class="number">0</span>].real[y == label],</span><br><span class="line">                y=X_lda[:,<span class="number">1</span>].real[y == label],</span><br><span class="line">                marker=marker,</span><br><span class="line">                color=color,</span><br><span class="line">                alpha=<span class="number">0.5</span>,</span><br><span class="line">                label=label_dict[label]</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;LD1&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;LD2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    leg = plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, fancybox=<span class="literal">True</span>)</span><br><span class="line">    leg.get_frame().set_alpha(<span class="number">0.5</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;LDA: Iris projection onto the first 2 linear discriminants&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hide axis ticks</span></span><br><span class="line">    plt.tick_params(axis=<span class="string">&quot;both&quot;</span>, which=<span class="string">&quot;both&quot;</span>, bottom=<span class="string">&quot;off&quot;</span>, top=<span class="string">&quot;off&quot;</span>,  </span><br><span class="line">            labelbottom=<span class="string">&quot;on&quot;</span>, left=<span class="string">&quot;off&quot;</span>, right=<span class="string">&quot;off&quot;</span>, labelleft=<span class="string">&quot;on&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># remove axis spines</span></span><br><span class="line">    ax.spines[<span class="string">&quot;top&quot;</span>].set_visible(<span class="literal">False</span>)  </span><br><span class="line">    ax.spines[<span class="string">&quot;right&quot;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.spines[<span class="string">&quot;bottom&quot;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.spines[<span class="string">&quot;left&quot;</span>].set_visible(<span class="literal">False</span>)    </span><br><span class="line"></span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.tight_layout</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_step_lda()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142652.png" alt=""></p><h3 id="sklearn-有LDA模块可以调用。"><a href="#sklearn-有LDA模块可以调用。" class="headerlink" title="sklearn 有LDA模块可以调用。"></a>sklearn 有LDA模块可以调用。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis <span class="keyword">as</span> LDA</span><br><span class="line"></span><br><span class="line"><span class="comment"># LDA</span></span><br><span class="line">sklearn_lda = LDA(n_components=<span class="number">2</span>) <span class="comment"># 降低成2D</span></span><br><span class="line">X_lda_sklearn = sklearn_lda.fit_transform(X, y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis <span class="keyword">as</span> LDA</span><br><span class="line"></span><br><span class="line"><span class="comment"># LDA</span></span><br><span class="line">sklearn_lda = LDA(n_components=<span class="number">2</span>)</span><br><span class="line">X_lda_sklearn = sklearn_lda.fit_transform(X, y)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_scikit_lda</span>(<span class="params">X, title</span>):</span></span><br><span class="line"></span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="keyword">for</span> label,marker,color <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">        <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">4</span>),(<span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;o&#x27;</span>),(<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>)):</span><br><span class="line"></span><br><span class="line">        plt.scatter(x=X[:,<span class="number">0</span>][y == label],</span><br><span class="line">                    y=X[:,<span class="number">1</span>][y == label] * -<span class="number">1</span>, <span class="comment"># flip the figure</span></span><br><span class="line">                    marker=marker,</span><br><span class="line">                    color=color,</span><br><span class="line">                    alpha=<span class="number">0.5</span>,</span><br><span class="line">                    label=label_dict[label])</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;LD1&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;LD2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    leg = plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, fancybox=<span class="literal">True</span>)</span><br><span class="line">    leg.get_frame().set_alpha(<span class="number">0.5</span>)</span><br><span class="line">    plt.title(title)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hide axis ticks</span></span><br><span class="line">    plt.tick_params(axis=<span class="string">&quot;both&quot;</span>, which=<span class="string">&quot;both&quot;</span>, bottom=<span class="string">&quot;off&quot;</span>, top=<span class="string">&quot;off&quot;</span>,  </span><br><span class="line">            labelbottom=<span class="string">&quot;on&quot;</span>, left=<span class="string">&quot;off&quot;</span>, right=<span class="string">&quot;off&quot;</span>, labelleft=<span class="string">&quot;on&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># remove axis spines</span></span><br><span class="line">    ax.spines[<span class="string">&quot;top&quot;</span>].set_visible(<span class="literal">False</span>)  </span><br><span class="line">    ax.spines[<span class="string">&quot;right&quot;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.spines[<span class="string">&quot;bottom&quot;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.spines[<span class="string">&quot;left&quot;</span>].set_visible(<span class="literal">False</span>)    </span><br><span class="line"></span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.tight_layout</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_step_lda()</span><br><span class="line">plot_scikit_lda(X_lda_sklearn, title=<span class="string">&#x27;Default LDA via scikit-learn&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142828.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515142842.png" alt=""></p><p><strong> 可以看出来sklearn和自己做的效果是差不多的 </strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;鸢尾花的数据集进行降维&quot;&gt;&lt;a href=&quot;#鸢尾花的数据集进行降维&quot; class=&quot;headerlink&quot; title=&quot;鸢尾花的数据集进行降维&quot;&gt;&lt;/a&gt;鸢尾花的数据集进行降维&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;有四个维度，萼片的长度。萼片的宽度，花瓣的长度，花瓣的宽</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习基础" scheme="https://xxren8218.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>聚类基础——KMEANS &amp; DBSCAN</title>
    <link href="https://xxren8218.github.io/20210513/%E8%81%9A%E7%B1%BB%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94KMEANS-DBSCAN.html"/>
    <id>https://xxren8218.github.io/20210513/%E8%81%9A%E7%B1%BB%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94KMEANS-DBSCAN.html</id>
    <published>2021-05-13T10:05:21.000Z</published>
    <updated>2021-05-13T10:34:24.724Z</updated>
    
    <content type="html"><![CDATA[<h1 id="聚类——啤酒分类"><a href="#聚类——啤酒分类" class="headerlink" title="聚类——啤酒分类"></a>聚类——啤酒分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># beer dataset</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">beer = pd.read_csv(<span class="string">&#x27;data.txt&#x27;</span>, sep=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">beer</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name</th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Budweiser</td>      <td>144</td>      <td>15</td>      <td>4.7</td>      <td>0.43</td>    </tr>    <tr>      <th>1</th>      <td>Schlitz</td>      <td>151</td>      <td>19</td>      <td>4.9</td>      <td>0.43</td>    </tr>    <tr>      <th>2</th>      <td>Lowenbrau</td>      <td>157</td>      <td>15</td>      <td>0.9</td>      <td>0.48</td>    </tr>    <tr>      <th>3</th>      <td>Kronenbourg</td>      <td>170</td>      <td>7</td>      <td>5.2</td>      <td>0.73</td>    </tr>    <tr>      <th>4</th>      <td>Heineken</td>      <td>152</td>      <td>11</td>      <td>5.0</td>      <td>0.77</td>    </tr>    <tr>      <th>5</th>      <td>Old_Milwaukee</td>      <td>145</td>      <td>23</td>      <td>4.6</td>      <td>0.28</td>    </tr>    <tr>      <th>6</th>      <td>Augsberger</td>      <td>175</td>      <td>24</td>      <td>5.5</td>      <td>0.40</td>    </tr>    <tr>      <th>7</th>      <td>Srohs_Bohemian_Style</td>      <td>149</td>      <td>27</td>      <td>4.7</td>      <td>0.42</td>    </tr>    <tr>      <th>8</th>      <td>Miller_Lite</td>      <td>99</td>      <td>10</td>      <td>4.3</td>      <td>0.43</td>    </tr>    <tr>      <th>9</th>      <td>Budweiser_Light</td>      <td>113</td>      <td>8</td>      <td>3.7</td>      <td>0.40</td>    </tr>    <tr>      <th>10</th>      <td>Coors</td>      <td>140</td>      <td>18</td>      <td>4.6</td>      <td>0.44</td>    </tr>    <tr>      <th>11</th>      <td>Coors_Light</td>      <td>102</td>      <td>15</td>      <td>4.1</td>      <td>0.46</td>    </tr>    <tr>      <th>12</th>      <td>Michelob_Light</td>      <td>135</td>      <td>11</td>      <td>4.2</td>      <td>0.50</td>    </tr>    <tr>      <th>13</th>      <td>Becks</td>      <td>150</td>      <td>19</td>      <td>4.7</td>      <td>0.76</td>    </tr>    <tr>      <th>14</th>      <td>Kirin</td>      <td>149</td>      <td>6</td>      <td>5.0</td>      <td>0.79</td>    </tr>    <tr>      <th>15</th>      <td>Pabst_Extra_Light</td>      <td>68</td>      <td>15</td>      <td>2.3</td>      <td>0.38</td>    </tr>    <tr>      <th>16</th>      <td>Hamms</td>      <td>139</td>      <td>19</td>      <td>4.4</td>      <td>0.43</td>    </tr>    <tr>      <th>17</th>      <td>Heilemans_Old_Style</td>      <td>144</td>      <td>24</td>      <td>4.9</td>      <td>0.43</td>    </tr>    <tr>      <th>18</th>      <td>Olympia_Goled_Light</td>      <td>72</td>      <td>6</td>      <td>2.9</td>      <td>0.46</td>    </tr>    <tr>      <th>19</th>      <td>Schlitz_Light</td>      <td>97</td>      <td>7</td>      <td>4.2</td>      <td>0.47</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = beer[[<span class="string">&quot;calories&quot;</span>,<span class="string">&quot;sodium&quot;</span>,<span class="string">&quot;alcohol&quot;</span>,<span class="string">&quot;cost&quot;</span>]]</span><br></pre></td></tr></table></figure><h2 id="K-means-clustering"><a href="#K-means-clustering" class="headerlink" title="K-means clustering"></a>K-means clustering</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line">km = KMeans(n_clusters=<span class="number">3</span>).fit(X) <span class="comment"># n_cluster就是聚集成几个簇</span></span><br><span class="line">km2 = KMeans(n_clusters=<span class="number">2</span>).fit(X)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">km.labels_  <span class="comment"># 调用函数直接返回结果了！</span></span><br></pre></td></tr></table></figure><pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">beer[<span class="string">&#x27;cluster&#x27;</span>] = km.labels_</span><br><span class="line">beer[<span class="string">&#x27;cluster2&#x27;</span>] = km2.labels_</span><br><span class="line">beer.sort_values(<span class="string">&#x27;cluster&#x27;</span>)</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name</th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>      <th>cluster</th>      <th>cluster2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Budweiser</td>      <td>144</td>      <td>15</td>      <td>4.7</td>      <td>0.43</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>1</th>      <td>Schlitz</td>      <td>151</td>      <td>19</td>      <td>4.9</td>      <td>0.43</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>Lowenbrau</td>      <td>157</td>      <td>15</td>      <td>0.9</td>      <td>0.48</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>3</th>      <td>Kronenbourg</td>      <td>170</td>      <td>7</td>      <td>5.2</td>      <td>0.73</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>4</th>      <td>Heineken</td>      <td>152</td>      <td>11</td>      <td>5.0</td>      <td>0.77</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>5</th>      <td>Old_Milwaukee</td>      <td>145</td>      <td>23</td>      <td>4.6</td>      <td>0.28</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>6</th>      <td>Augsberger</td>      <td>175</td>      <td>24</td>      <td>5.5</td>      <td>0.40</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>7</th>      <td>Srohs_Bohemian_Style</td>      <td>149</td>      <td>27</td>      <td>4.7</td>      <td>0.42</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>17</th>      <td>Heilemans_Old_Style</td>      <td>144</td>      <td>24</td>      <td>4.9</td>      <td>0.43</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>16</th>      <td>Hamms</td>      <td>139</td>      <td>19</td>      <td>4.4</td>      <td>0.43</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>10</th>      <td>Coors</td>      <td>140</td>      <td>18</td>      <td>4.6</td>      <td>0.44</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>14</th>      <td>Kirin</td>      <td>149</td>      <td>6</td>      <td>5.0</td>      <td>0.79</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>12</th>      <td>Michelob_Light</td>      <td>135</td>      <td>11</td>      <td>4.2</td>      <td>0.50</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>13</th>      <td>Becks</td>      <td>150</td>      <td>19</td>      <td>4.7</td>      <td>0.76</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>9</th>      <td>Budweiser_Light</td>      <td>113</td>      <td>8</td>      <td>3.7</td>      <td>0.40</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>8</th>      <td>Miller_Lite</td>      <td>99</td>      <td>10</td>      <td>4.3</td>      <td>0.43</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>11</th>      <td>Coors_Light</td>      <td>102</td>      <td>15</td>      <td>4.1</td>      <td>0.46</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>19</th>      <td>Schlitz_Light</td>      <td>97</td>      <td>7</td>      <td>4.2</td>      <td>0.47</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>15</th>      <td>Pabst_Extra_Light</td>      <td>68</td>      <td>15</td>      <td>2.3</td>      <td>0.38</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <th>18</th>      <td>Olympia_Goled_Light</td>      <td>72</td>      <td>6</td>      <td>2.9</td>      <td>0.46</td>      <td>2</td>      <td>0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.tools.plotting <span class="keyword">import</span> scatter_matrix  <span class="comment"># 导入scatter_matrix可以画多福图形。</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">cluster_centers = km.cluster_centers_</span><br><span class="line"></span><br><span class="line">cluster_centers_2 = km2.cluster_centers_</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beer.groupby(<span class="string">&quot;cluster&quot;</span>).mean()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>      <th>cluster2</th>    </tr>    <tr>      <th>cluster</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>150.00</td>      <td>17.0</td>      <td>4.521429</td>      <td>0.520714</td>      <td>1</td>    </tr>    <tr>      <th>1</th>      <td>102.75</td>      <td>10.0</td>      <td>4.075000</td>      <td>0.440000</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>70.00</td>      <td>10.5</td>      <td>2.600000</td>      <td>0.420000</td>      <td>0</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beer.groupby(<span class="string">&quot;cluster2&quot;</span>).mean()</span><br></pre></td></tr></table></figure><div><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>      <th>cluster</th>    </tr>    <tr>      <th>cluster2</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>91.833333</td>      <td>10.166667</td>      <td>3.583333</td>      <td>0.433333</td>      <td>1.333333</td>    </tr>    <tr>      <th>1</th>      <td>150.000000</td>      <td>17.000000</td>      <td>4.521429</td>      <td>0.520714</td>      <td>0.000000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">centers = beer.groupby(<span class="string">&quot;cluster&quot;</span>).mean().reset_index() <span class="comment"># 中心点，为后面作图做准备！</span></span><br><span class="line">                                        <span class="comment"># reset_index(默认drop=False)，表示获取新的索引，并保留原来索引</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.size&#x27;</span>] = <span class="number">14</span>  <span class="comment"># rcParams 可以设置图形整体的字体大小等。</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">colors = np.array([<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>])</span><br></pre></td></tr></table></figure><p><strong> 先看其中两个特征的分布情况 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(beer[<span class="string">&quot;calories&quot;</span>], beer[<span class="string">&quot;alcohol&quot;</span>],c=colors[beer[<span class="string">&quot;cluster&quot;</span>]])</span><br><span class="line"></span><br><span class="line">plt.scatter(centers.calories, centers.alcohol, linewidths=<span class="number">3</span>, marker=<span class="string">&#x27;+&#x27;</span>, s=<span class="number">300</span>, c=<span class="string">&#x27;black&#x27;</span>) <span class="comment"># centers.calories获取质心</span></span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;Calories&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Alcohol&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.text.Text at 0x18a25af4ac8&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210513181033.png" alt=""></p><p><strong> 再看其中各个维度特征的分布 </strong> scatter_matrix</p><ul><li><p>数据是多维的，要么PCA，要么这种方式进行可视化</p></li><li><p>条形图代表自身的特征的分布情况</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scatter_matrix(beer[[<span class="string">&quot;calories&quot;</span>,<span class="string">&quot;sodium&quot;</span>,<span class="string">&quot;alcohol&quot;</span>,<span class="string">&quot;cost&quot;</span>]],s=<span class="number">100</span>, alpha=<span class="number">1</span>, c=colors[beer[<span class="string">&quot;cluster&quot;</span>]], figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.suptitle(<span class="string">&quot;With 3 centroids initialized&quot;</span>)</span><br></pre></td></tr></table></figure><div style="color: red">    C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:1: FutureWarning: 'pandas.tools.plotting.scatter_matrix' is deprecated, import 'pandas.plotting.scatter_matrix' instead.      if __name__ == '__main__':</div><pre><code>&lt;matplotlib.text.Text at 0x18a25b67e80&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210513181104.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scatter_matrix(beer[[<span class="string">&quot;calories&quot;</span>,<span class="string">&quot;sodium&quot;</span>,<span class="string">&quot;alcohol&quot;</span>,<span class="string">&quot;cost&quot;</span>]],s=<span class="number">100</span>, alpha=<span class="number">1</span>, c=colors[beer[<span class="string">&quot;cluster2&quot;</span>]], figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.suptitle(<span class="string">&quot;With 2 centroids initialized&quot;</span>)</span><br></pre></td></tr></table></figure><div style="color: red">    C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:1: FutureWarning: 'pandas.tools.plotting.scatter_matrix' is deprecated, import 'pandas.plotting.scatter_matrix' instead.      if __name__ == '__main__':</div><pre><code>&lt;matplotlib.text.Text at 0x18a2613c710&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210513181130.png" alt=""></p><h3 id="Scaled-data"><a href="#Scaled-data" class="headerlink" title="Scaled data"></a>Scaled data</h3><p><strong> sklearn进行数据标准化 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br><span class="line">X_scaled</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.38791334,  0.00779468,  0.43380786, -0.45682969],       [ 0.6250656 ,  0.63136906,  0.62241997, -0.45682969],       [ 0.82833896,  0.00779468, -3.14982226, -0.10269815],       [ 1.26876459, -1.23935408,  0.90533814,  1.66795955],       [ 0.65894449, -0.6157797 ,  0.71672602,  1.95126478],       [ 0.42179223,  1.25494344,  0.3395018 , -1.5192243 ],       [ 1.43815906,  1.41083704,  1.1882563 , -0.66930861],       [ 0.55730781,  1.87851782,  0.43380786, -0.52765599],       [-1.1366369 , -0.7716733 ,  0.05658363, -0.45682969],       [-0.66233238, -1.08346049, -0.5092527 , -0.66930861],       [ 0.25239776,  0.47547547,  0.3395018 , -0.38600338],       [-1.03500022,  0.00779468, -0.13202848, -0.24435076],       [ 0.08300329, -0.6157797 , -0.03772242,  0.03895447],       [ 0.59118671,  0.63136906,  0.43380786,  1.88043848],       [ 0.55730781, -1.39524768,  0.71672602,  2.0929174 ],       [-2.18688263,  0.00779468, -1.82953748, -0.81096123],       [ 0.21851887,  0.63136906,  0.15088969, -0.45682969],       [ 0.38791334,  1.41083704,  0.62241997, -0.45682969],       [-2.05136705, -1.39524768, -1.26370115, -0.24435076],       [-1.20439469, -1.23935408, -0.03772242, -0.17352445]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">km = KMeans(n_clusters=<span class="number">3</span>).fit(X_scaled)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">beer[<span class="string">&quot;scaled_cluster&quot;</span>] = km.labels_</span><br><span class="line">beer.sort_values(<span class="string">&quot;scaled_cluster&quot;</span>)</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name</th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>      <th>cluster</th>      <th>cluster2</th>      <th>scaled_cluster</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Budweiser</td>      <td>144</td>      <td>15</td>      <td>4.7</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>Schlitz</td>      <td>151</td>      <td>19</td>      <td>4.9</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>17</th>      <td>Heilemans_Old_Style</td>      <td>144</td>      <td>24</td>      <td>4.9</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>16</th>      <td>Hamms</td>      <td>139</td>      <td>19</td>      <td>4.4</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>5</th>      <td>Old_Milwaukee</td>      <td>145</td>      <td>23</td>      <td>4.6</td>      <td>0.28</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>6</th>      <td>Augsberger</td>      <td>175</td>      <td>24</td>      <td>5.5</td>      <td>0.40</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>7</th>      <td>Srohs_Bohemian_Style</td>      <td>149</td>      <td>27</td>      <td>4.7</td>      <td>0.42</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>10</th>      <td>Coors</td>      <td>140</td>      <td>18</td>      <td>4.6</td>      <td>0.44</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>15</th>      <td>Pabst_Extra_Light</td>      <td>68</td>      <td>15</td>      <td>2.3</td>      <td>0.38</td>      <td>2</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>12</th>      <td>Michelob_Light</td>      <td>135</td>      <td>11</td>      <td>4.2</td>      <td>0.50</td>      <td>0</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>11</th>      <td>Coors_Light</td>      <td>102</td>      <td>15</td>      <td>4.1</td>      <td>0.46</td>      <td>1</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>9</th>      <td>Budweiser_Light</td>      <td>113</td>      <td>8</td>      <td>3.7</td>      <td>0.40</td>      <td>1</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>8</th>      <td>Miller_Lite</td>      <td>99</td>      <td>10</td>      <td>4.3</td>      <td>0.43</td>      <td>1</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>Lowenbrau</td>      <td>157</td>      <td>15</td>      <td>0.9</td>      <td>0.48</td>      <td>0</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>18</th>      <td>Olympia_Goled_Light</td>      <td>72</td>      <td>6</td>      <td>2.9</td>      <td>0.46</td>      <td>2</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>19</th>      <td>Schlitz_Light</td>      <td>97</td>      <td>7</td>      <td>4.2</td>      <td>0.47</td>      <td>1</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>13</th>      <td>Becks</td>      <td>150</td>      <td>19</td>      <td>4.7</td>      <td>0.76</td>      <td>0</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <th>14</th>      <td>Kirin</td>      <td>149</td>      <td>6</td>      <td>5.0</td>      <td>0.79</td>      <td>0</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <th>4</th>      <td>Heineken</td>      <td>152</td>      <td>11</td>      <td>5.0</td>      <td>0.77</td>      <td>0</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <th>3</th>      <td>Kronenbourg</td>      <td>170</td>      <td>7</td>      <td>5.2</td>      <td>0.73</td>      <td>0</td>      <td>1</td>      <td>2</td>    </tr>  </tbody></table></div><p>What are the “characteristics” of each cluster?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beer.groupby(<span class="string">&quot;scaled_cluster&quot;</span>).mean()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>      <th>cluster</th>      <th>cluster2</th>    </tr>    <tr>      <th>scaled_cluster</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>148.375</td>      <td>21.125</td>      <td>4.7875</td>      <td>0.4075</td>      <td>0.0</td>      <td>1.00</td>    </tr>    <tr>      <th>1</th>      <td>105.375</td>      <td>10.875</td>      <td>3.3250</td>      <td>0.4475</td>      <td>1.0</td>      <td>0.25</td>    </tr>    <tr>      <th>2</th>      <td>155.250</td>      <td>10.750</td>      <td>4.9750</td>      <td>0.7625</td>      <td>0.0</td>      <td>1.00</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.scatter_matrix(X, c=colors[beer.scaled_cluster], alpha=<span class="number">1</span>, figsize=(<span class="number">10</span>,<span class="number">10</span>), s=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><div style="color: red">    C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:1: FutureWarning: pandas.scatter_matrix is deprecated. Use pandas.plotting.scatter_matrix instead      if __name__ == '__main__':</div>    <pre><code>array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A279F8F28&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A282989B0&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27B5E2E8&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27B94F60&gt;],       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27BE41D0&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27C19F28&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27C61F60&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27C71C88&gt;],       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27CF1860&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27D3B7B8&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27D7C5C0&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27DC6F98&gt;],       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27E02748&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27E4FEB8&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27E8D588&gt;,        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000018A27ED47B8&gt;]], dtype=object)</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210513181223.png" alt=""></p><h2 id="聚类评估：轮廓系数（Silhouette-Coefficient-）（常用）"><a href="#聚类评估：轮廓系数（Silhouette-Coefficient-）（常用）" class="headerlink" title="聚类评估：轮廓系数（Silhouette Coefficient ）（常用）"></a>聚类评估：轮廓系数（Silhouette Coefficient ）（常用）</h2><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210513183410.png" alt=""></p><ul><li>计算样本i到同簇其他样本的平均距离ai。ai 越小，说明样本i越应该被聚类到该簇。将ai 称为样本i的簇内不相似度。越小越好。</li><li>计算样本i到其他某簇Cj 的所有样本的平均距离bij，称为样本i与簇Cj 的不相似度。定义为样本i的簇间不相似度：bi =min{bi1, bi2, …, bik}。越大越好。</li></ul><ul><li>si接近1，则说明样本i聚类合理</li><li>si接近-1，则说明样本i更应该分类到另外的簇</li><li>若si 近似为0，则说明样本i在两个簇的边界上。</li></ul><p><strong> 使用sklearn模块的metrics进行聚类评估 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">score_scaled = metrics.silhouette_score(X,beer.scaled_cluster) <span class="comment"># 做归一化的结果</span></span><br><span class="line">score = metrics.silhouette_score(X,beer.cluster) <span class="comment"># 不做归一化的结果</span></span><br><span class="line">print(score_scaled, score)</span><br></pre></td></tr></table></figure><pre><code>0.179780680894 0.673177504646</code></pre><p><strong> 做归一化的结果反而低了。</strong> 做归一化不一定会得到好结果。</p><h2 id="尝试计算不同的k值对结果的影响。"><a href="#尝试计算不同的k值对结果的影响。" class="headerlink" title="尝试计算不同的k值对结果的影响。"></a>尝试计算不同的k值对结果的影响。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scores = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">20</span>):</span><br><span class="line">    labels = KMeans(n_clusters=k).fit(X).labels_</span><br><span class="line">    score = metrics.silhouette_score(X, labels)</span><br><span class="line">    scores.append(score)</span><br><span class="line"></span><br><span class="line">scores</span><br></pre></td></tr></table></figure><pre><code>[0.69176560340794857, 0.67317750464557957, 0.58570407211277953, 0.42254873351720201, 0.4559182167013377, 0.43776116697963124, 0.38946337473125997, 0.39746405172426014, 0.33061511213823314, 0.34131096180393328, 0.34597752371272478, 0.31221439248428434, 0.30707782144770296, 0.31834561839139497, 0.28495140011748982, 0.23498077333071996, 0.15880910174962809, 0.084230513801511767]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">2</span>,<span class="number">20</span>)), scores)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Number of Clusters Initialized&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Sihouette Score&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.text.Text at 0x18a288239e8&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210513181248.png" alt=""></p><p><strong> 可以看出K=2的时候比较合适 </strong></p><h2 id="DBSCAN-clustering"><a href="#DBSCAN-clustering" class="headerlink" title="DBSCAN clustering"></a>DBSCAN clustering</h2><ul><li>在不规则的数据集上比较强大，简单数据集可能还不如kmeans.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line">db = DBSCAN(eps=<span class="number">10</span>, min_samples=<span class="number">2</span>).fit(X)  <span class="comment"># eps半径，min_samples指密度</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">labels = db.labels_</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">beer[<span class="string">&#x27;cluster_db&#x27;</span>] = labels</span><br><span class="line">beer.sort_values(<span class="string">&#x27;cluster_db&#x27;</span>)</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>name</th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>      <th>cluster</th>      <th>cluster2</th>      <th>scaled_cluster</th>      <th>cluster_db</th>    </tr>  </thead>  <tbody>    <tr>      <th>9</th>      <td>Budweiser_Light</td>      <td>113</td>      <td>8</td>      <td>3.7</td>      <td>0.40</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>-1</td>    </tr>    <tr>      <th>3</th>      <td>Kronenbourg</td>      <td>170</td>      <td>7</td>      <td>5.2</td>      <td>0.73</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>-1</td>    </tr>    <tr>      <th>6</th>      <td>Augsberger</td>      <td>175</td>      <td>24</td>      <td>5.5</td>      <td>0.40</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>-1</td>    </tr>    <tr>      <th>17</th>      <td>Heilemans_Old_Style</td>      <td>144</td>      <td>24</td>      <td>4.9</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>16</th>      <td>Hamms</td>      <td>139</td>      <td>19</td>      <td>4.4</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>14</th>      <td>Kirin</td>      <td>149</td>      <td>6</td>      <td>5.0</td>      <td>0.79</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <th>13</th>      <td>Becks</td>      <td>150</td>      <td>19</td>      <td>4.7</td>      <td>0.76</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <th>12</th>      <td>Michelob_Light</td>      <td>135</td>      <td>11</td>      <td>4.2</td>      <td>0.50</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>10</th>      <td>Coors</td>      <td>140</td>      <td>18</td>      <td>4.6</td>      <td>0.44</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>0</th>      <td>Budweiser</td>      <td>144</td>      <td>15</td>      <td>4.7</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>7</th>      <td>Srohs_Bohemian_Style</td>      <td>149</td>      <td>27</td>      <td>4.7</td>      <td>0.42</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>5</th>      <td>Old_Milwaukee</td>      <td>145</td>      <td>23</td>      <td>4.6</td>      <td>0.28</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>Heineken</td>      <td>152</td>      <td>11</td>      <td>5.0</td>      <td>0.77</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>Lowenbrau</td>      <td>157</td>      <td>15</td>      <td>0.9</td>      <td>0.48</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>Schlitz</td>      <td>151</td>      <td>19</td>      <td>4.9</td>      <td>0.43</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>8</th>      <td>Miller_Lite</td>      <td>99</td>      <td>10</td>      <td>4.3</td>      <td>0.43</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>11</th>      <td>Coors_Light</td>      <td>102</td>      <td>15</td>      <td>4.1</td>      <td>0.46</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>19</th>      <td>Schlitz_Light</td>      <td>97</td>      <td>7</td>      <td>4.2</td>      <td>0.47</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>15</th>      <td>Pabst_Extra_Light</td>      <td>68</td>      <td>15</td>      <td>2.3</td>      <td>0.38</td>      <td>2</td>      <td>0</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <th>18</th>      <td>Olympia_Goled_Light</td>      <td>72</td>      <td>6</td>      <td>2.9</td>      <td>0.46</td>      <td>2</td>      <td>0</td>      <td>1</td>      <td>2</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beer.groupby(<span class="string">&#x27;cluster_db&#x27;</span>).mean()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>calories</th>      <th>sodium</th>      <th>alcohol</th>      <th>cost</th>      <th>cluster</th>      <th>cluster2</th>      <th>scaled_cluster</th>    </tr>    <tr>      <th>cluster_db</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>-1</th>      <td>152.666667</td>      <td>13.000000</td>      <td>4.800000</td>      <td>0.510000</td>      <td>0.333333</td>      <td>0.666667</td>      <td>1.000000</td>    </tr>    <tr>      <th>0</th>      <td>146.250000</td>      <td>17.250000</td>      <td>4.383333</td>      <td>0.513333</td>      <td>0.000000</td>      <td>1.000000</td>      <td>0.666667</td>    </tr>    <tr>      <th>1</th>      <td>99.333333</td>      <td>10.666667</td>      <td>4.200000</td>      <td>0.453333</td>      <td>1.000000</td>      <td>0.000000</td>      <td>1.000000</td>    </tr>    <tr>      <th>2</th>      <td>70.000000</td>      <td>10.500000</td>      <td>2.600000</td>      <td>0.420000</td>      <td>2.000000</td>      <td>0.000000</td>      <td>1.000000</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.scatter_matrix(X, c=colors[beer.cluster_db], figsize=(<span class="number">10</span>,<span class="number">10</span>), s=<span class="number">100</span>)</span><br></pre></td></tr></table></figure><div style="color: red">    C:\Anaconda3\lib\site-packages\ipykernel\__main__.py:1: FutureWarning: pandas.scatter_matrix is deprecated. Use pandas.plotting.scatter_matrix instead      if __name__ == '__main__':</div>    <div style="overflow: scroll;">    array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000018A278A3940>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A284C56D8>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A28501CF8>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A28550080>],           [<matplotlib.axes._subplots.AxesSubplot object at 0x0000018A2856C588>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A285D1F60>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A286211D0>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A2865AF98>],           [<matplotlib.axes._subplots.AxesSubplot object at 0x0000018A286AABA8>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A286E7278>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A2872E390>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A287396A0>],           [<matplotlib.axes._subplots.AxesSubplot object at 0x0000018A287BC358>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A28B356A0>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A28B71240>,            <matplotlib.axes._subplots.AxesSubplot object at 0x0000018A28BBC470>]], dtype=object)</div><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210513181312.png" alt=""></p><p><strong> DBSCAN的后续过程一样，可以用轮廓系数进行评估。for循环eps和min_samples。也可以做数据增强。（看哪个数据的维度对结果有比较好的影响） </strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;聚类——啤酒分类&quot;&gt;&lt;a href=&quot;#聚类——啤酒分类&quot; class=&quot;headerlink&quot; title=&quot;聚类——啤酒分类&quot;&gt;&lt;/a&gt;聚类——啤酒分类&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td c</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习基础" scheme="https://xxren8218.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（六十七）：剪绳子</title>
    <link href="https://xxren8218.github.io/20210512/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89%EF%BC%9A%E5%89%AA%E7%BB%B3%E5%AD%90.html"/>
    <id>https://xxren8218.github.io/20210512/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%83%EF%BC%89%EF%BC%9A%E5%89%AA%E7%BB%B3%E5%AD%90.html</id>
    <published>2021-05-12T08:49:55.000Z</published>
    <updated>2021-05-12T09:07:26.535Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><div style="color: red;">    给你一根长度为n的绳子，请把绳子剪成整数长的m段（m、n都是整数，n>1并且m>1，m<=n），每段绳子的长度记为k[1],...,k[m]。请问k[1]x...xk[m]可能的最大乘积是多少？例如，当绳子的长度是8时，我们把它剪成长度分别为2、3、3的三段，此时得到的最大乘积是18。</div><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><p>这道题可以用数学的方法来解决——基本不等式。如下图<br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210512165604.JPG" alt=""><br>即将 x1+x2+…+xm=n 分成 m 份，然后求导得到极大值<br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210512170104.JPG" alt=""><br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210512170218.JPG" alt=""><br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210512170240.JPG" alt=""><br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210512170257.JPG" alt=""><br>得到应该均分成3份，又分三种情况，能整除。余数为1时，（4=2+2=1+3），明显2x2&gt;1x3，余数为2时正常写（5的话2x3是最大的。）<br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210512170344.JPG" alt=""></p><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cutRope</span>(<span class="params">self, number</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> number &lt;= <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> number-<span class="number">1</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        a, b = number//<span class="number">3</span>, number%<span class="number">3</span></span><br><span class="line">        <span class="keyword">if</span> b == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">3</span>**a</span><br><span class="line">        <span class="keyword">if</span> b == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">3</span>**(a-<span class="number">1</span>)*<span class="number">4</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">3</span>**a*<span class="number">2</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;div style=&quot;color: red;&quot;&gt;
    给你一根长度为n的绳子，请把绳子剪成整数长的m段（m、n都是整数，n&gt;</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（六十三）：数据流中的中位数</title>
    <link href="https://xxren8218.github.io/20210512/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%89%EF%BC%89%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0.html"/>
    <id>https://xxren8218.github.io/20210512/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%85%AD%E5%8D%81%E4%B8%89%EF%BC%89%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E4%B8%AD%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0.html</id>
    <published>2021-05-12T08:38:58.000Z</published>
    <updated>2021-05-15T13:52:18.331Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><div style="color: red">    如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。</div><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><p><div style="color: red">    可以建立一个列表来append所给的数据    然后将列表排序，计算列表的长度。只需要区分奇数和偶数情况即可。</div></p><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.s = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Insert</span>(<span class="params">self, num</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        self.s.append(num)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetMedian</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        self.s = <span class="built_in">sorted</span>(self.s)</span><br><span class="line">        n = <span class="built_in">len</span>(self.s)</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> n % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 奇数</span></span><br><span class="line">            <span class="keyword">return</span> self.s[n/<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 偶数</span></span><br><span class="line">            <span class="keyword">return</span> (self.s[n/<span class="number">2</span>]+self.s[n/<span class="number">2</span>-<span class="number">1</span>])/<span class="number">2.0</span> <span class="comment"># 注意如果这里写2的话，得到的是向下取整的整数，所以需要写成浮点型。</span></span><br><span class="line">            </span><br></pre></td></tr></table></figure><h2 id="上述的代码虽然可以，但是在力扣上执行时间长。提出另一种思路——最大堆，最小堆。"><a href="#上述的代码虽然可以，但是在力扣上执行时间长。提出另一种思路——最大堆，最小堆。" class="headerlink" title="上述的代码虽然可以，但是在力扣上执行时间长。提出另一种思路——最大堆，最小堆。"></a>上述的代码虽然可以，但是在力扣上执行时间长。提出另一种思路——最大堆，最小堆。</h2><ol><li><p>如果我们可以对数据进行排序，分成小的一半和大的一半。找小的最大值和大的最小值即可。这个不就是最小、最大堆嘛！</p><ul><li>最大堆（找出最小的k个元素）</li><li>最小堆（找出最大的k个元素）</li></ul></li></ol><p>如图所示过程。用最大堆存最小的k个元素，最小堆存最大k个元素。我们就可以用O（1）的复杂度找到值max和min了<br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515205757.JPG" alt=""></p><ol><li><p>在数据存放的时候我们可以这样，当最小堆和最大堆的尺寸相等时，存放进入最大堆maxheap，不等时，存放进最小堆minheap。<br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515211539.JPG" alt=""></p></li><li><p>但是这存在一个问题，若将a1存放进入minheap的时候，若a1的值比maxheap的一些数字还要小，则不满足我们之前的假设——maxheap的数字比minheap的数字小；若将a2的存放到maxheap的时候，若a2比minheap的某些值还要大，那么也不符合我们的假定；那么我们可以这样做；</p><ul><li>将a1先插入到maxheap中，再将maxheap的队顶元素插入到minheap，这样就保证了maxheap始终为最小的元素。</li><li>同理，将a2先放入到minheap中，再将minheap的队顶元素放入maxheap中</li><li>python没有最大堆，只需要把最小堆取反。</li></ul></li></ol><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515211558.JPG" alt=""><br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210515211618.JPG" alt=""></p><p><strong> heappushpop()相当于先推后弹出，这意味着堆大小可能会在进程中发生变化. </strong></p><p><strong> heapreplace()相当于先弹出，然后推送，附加的限制是保证堆大小在这个过程中不会改变。</strong></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MedianFinder</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        initialize your data structure here.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.maxheap = []</span><br><span class="line">        self.minheap = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addNum</span>(<span class="params">self, num</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type num: int</span></span><br><span class="line"><span class="string">        :rtype: None</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 为了使得数据平均分配到两个堆，当两个堆的尺寸一样时，将新增加的元素放到minheap中</span></span><br><span class="line">        <span class="comment"># 具体做法分两步：1.现将新元素放到maxheap中，2.再将maxheap的堆顶元素放入minheap</span></span><br><span class="line">        <span class="comment"># python没有最大堆，可以用最小堆取反实现</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.maxheap) == <span class="built_in">len</span>(self.minheap):</span><br><span class="line">            heapq.heappush(self.minheap,-heapq.heappushpop(self.maxheap,-num))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            heapq.heappush(self.maxheap,-heapq.heappushpop(self.minheap,num))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMedian</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :rtype: float</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.maxheap) == <span class="built_in">len</span>(self.minheap):</span><br><span class="line">            <span class="keyword">return</span> (-self.maxheap[<span class="number">0</span>]+self.minheap[<span class="number">0</span>])/<span class="number">2.0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.minheap[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Your MedianFinder object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"># obj = MedianFinder()</span></span><br><span class="line"><span class="comment"># obj.addNum(num)</span></span><br><span class="line"><span class="comment"># param_2 = obj.findMedian()</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;div style=&quot;color: red&quot;&gt;
    如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="排序" scheme="https://xxren8218.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
    <category term="最小堆" scheme="https://xxren8218.github.io/tags/%E6%9C%80%E5%B0%8F%E5%A0%86/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（六十四）：滑动窗口的最大值</title>
    <link href="https://xxren8218.github.io/20210512/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%85%AD%E5%8D%81%E5%9B%9B%EF%BC%89%EF%BC%9A%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC.html"/>
    <id>https://xxren8218.github.io/20210512/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%85%AD%E5%8D%81%E5%9B%9B%EF%BC%89%EF%BC%9A%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%BC.html</id>
    <published>2021-05-12T08:25:59.000Z</published>
    <updated>2021-05-15T16:08:55.800Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><div style="color: red;">    给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如果输入数组{2,3,4,2,6,2,5,1}及滑动窗口的大小3，那么一共存在6个滑动窗口，他们的最大值分别为{4,4,6,6,6,5}。</div><h2 id="2-思路—暴力解法"><a href="#2-思路—暴力解法" class="headerlink" title="2.思路—暴力解法"></a>2.思路—暴力解法</h2><div style="color: red">    创建一个列表res来存储最终结果    创建一个临时列表temp来存储目前窗口内的数字    python有内置的max()函数可以找出列表中的最大数字。将其放入结果列表中即可。    while循环，直到窗口的右边界到达给定列表长度时，停止。</div>  ## 3.代码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxInWindows</span>(<span class="params">self, num, size</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> num <span class="keyword">or</span> size &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        res = []</span><br><span class="line">        start = <span class="number">0</span></span><br><span class="line">        end = start + size</span><br><span class="line">        <span class="keyword">while</span> end &lt;= <span class="built_in">len</span>(num):</span><br><span class="line">            temp_list = num[start:end]</span><br><span class="line">            res.append(<span class="built_in">max</span>(temp_list)) <span class="comment"># 其实可以和上面一步的合并在一起。</span></span><br><span class="line">            start += <span class="number">1</span></span><br><span class="line">            end += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>- max的时间复杂度为O(n)<div style="color: red;">对于每个滑动窗口，我们可以使用 O(k)的时间遍历其中的每一个元素，找出其中的最大值。对于长度为 nn 的数组 \textit{nums}nums 而言，窗口的数量为 n-k+1n−k+1，因此该算法的时间复杂度为 O((n-k+1)k)=O(nk)O((n−k+1)k)=O(nk)，会超出时间限制，因此我们需要进行一些优化。——需要将取最大值的操作进行降低时间复杂度。</div><h2 id="在力扣上提交时，超时，时间复杂度为O-nk-想办法对其进行改进。"><a href="#在力扣上提交时，超时，时间复杂度为O-nk-想办法对其进行改进。" class="headerlink" title="在力扣上提交时，超时，时间复杂度为O(nk),想办法对其进行改进。"></a>在力扣上提交时，超时，时间复杂度为O(nk),想办法对其进行改进。</h2><p>对于实现栈min函数的题目使用 单调栈 实现了随意入栈、出栈情况下的 O(1)时间获取 “栈内最小值” 。本题同理，不同点在于 “出栈操作” 删除的是 “列表尾部元素” ，而 “窗口滑动” 删除的是 “列表首部元素” ——为单调递减队列。</p><p>** 理解了栈的min函数，再理解队的最大函数，再写这道题容易些。</p><p>队的最大函数的理解</p><p>入队顺序为：                 [5]-&gt;[5,-1]-&gt;[5,-1,3]-&gt;[5,-1,3,6]-&gt;[5,-1,3,6,2]<br>队的最大函数时的辅助队列：     [5]-&gt;[5,-1]-&gt;[5,3]   -&gt;[6]       -&gt;[6,2]<br>最大值为：                   [5]-&gt;[5]  -&gt;[5]     -&gt;[6]      -&gt;[6]</p><p>出队顺序为：(先进先出)。        [5,-1,3,6,2]-&gt;[-1,3,6,2]-&gt;[3,6,2]-&gt;[6,2]-&gt;[6]<br>队的最大函数时的辅助队列：       [6,2]      -&gt;[6,2]     -&gt;[6,2]  -&gt;[6,2]-&gt;[2]</p><ul><li>(若出队和辅助队的元素相同-删除)<br>最大值为：                    [6]        -&gt;[6]       -&gt;[6]    -&gt;[6]  -&gt;[2]</li></ul><p>还有一点不同的是：在未形成窗口时是不需要“出队操作”的</p><ol><li>未形成窗口时：相当于一直为进队的操作。并保障其单调.</li><li>形成窗口后：相当于进队和出队操作同时进行。需要用到双端队列。——能使得leftpop为O(1)<ul><li>在向右移动一次后，相当于最右边值入队，使新队列满足单调。</li><li>如果在移动一次后的最左边-1值等于队列的最大的值，则将其删除</li></ul></li></ol><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSlidingWindow</span>(<span class="params">self, nums, k</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="comment"># 当窗口未形成的时候：将nums的元素加入双端队列中，并保证其单调（增减都可，只不过后面处理一个头一个尾而已，我这里取递减）</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">0</span> <span class="keyword">or</span> k &gt; n:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        dq = deque()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            <span class="keyword">while</span> dq <span class="keyword">and</span> dq[-<span class="number">1</span>] &lt; nums[i]:</span><br><span class="line">                dq.pop()</span><br><span class="line">            dq.append(nums[i])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 此时窗口形成。因为加了k个数字到dq了</span></span><br><span class="line">        res.append(dq[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 窗口形成以后相当于队列的入队和出队同时进行了。需要进行两步</span></span><br><span class="line">        <span class="comment"># 1.移动以后的窗口的最左边值若等于dp[0]，则dp[0]需删除</span></span><br><span class="line">        <span class="comment"># 2.入队的元素与dp保证递减</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k,n):</span><br><span class="line">            <span class="keyword">if</span> nums[i-k] == dq[<span class="number">0</span>]:</span><br><span class="line">                dq.popleft()</span><br><span class="line">            <span class="keyword">while</span> dq <span class="keyword">and</span> dq[-<span class="number">1</span>] &lt; nums[i]:</span><br><span class="line">                dq.pop()</span><br><span class="line">            dq.append(nums[i])</span><br><span class="line">            res.append(dq[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">        </span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;div style=&quot;color: red;&quot;&gt;
    给定一个数组和滑动窗口的大小，找出所有滑动窗口里数值的最大值。例如，如</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="双指针" scheme="https://xxren8218.github.io/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"/>
    
    <category term="双端队列" scheme="https://xxren8218.github.io/tags/%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97/"/>
    
    <category term="单调队列" scheme="https://xxren8218.github.io/tags/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97/"/>
    
    <category term="辅助队列" scheme="https://xxren8218.github.io/tags/%E8%BE%85%E5%8A%A9%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯实战-新闻分类</title>
    <link href="https://xxren8218.github.io/20210511/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9E%E6%88%98-%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB.html"/>
    <id>https://xxren8218.github.io/20210511/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9E%E6%88%98-%E6%96%B0%E9%97%BB%E5%88%86%E7%B1%BB.html</id>
    <published>2021-05-11T06:25:35.000Z</published>
    <updated>2021-05-11T10:39:40.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文本分析——新闻分类"><a href="#文本分析——新闻分类" class="headerlink" title="文本分析——新闻分类"></a>文本分析——新闻分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="comment"># pip install jieba</span></span><br></pre></td></tr></table></figure><h3 id="数据来源：http-www-sogou-com-labs-resource-ca-php"><a href="#数据来源：http-www-sogou-com-labs-resource-ca-php" class="headerlink" title="数据来源：http://www.sogou.com/labs/resource/ca.php"></a>数据来源：<a href="http://www.sogou.com/labs/resource/ca.php">http://www.sogou.com/labs/resource/ca.php</a></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_news = pd.read_table(<span class="string">&#x27;./data/val.txt&#x27;</span>,names=[<span class="string">&#x27;category&#x27;</span>,<span class="string">&#x27;theme&#x27;</span>,<span class="string">&#x27;URL&#x27;</span>,<span class="string">&#x27;content&#x27;</span>],encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="comment"># 涉及中文，用encoding</span></span><br><span class="line">df_news = df_news.dropna() <span class="comment"># 缺失值直接drop掉</span></span><br><span class="line">df_news.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>category</th>      <th>theme</th>      <th>URL</th>      <th>content</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>汽车</td>      <td>新辉腾　４．２　Ｖ８　４座加长Ｉｎｄｉｖｉｄｕａｌ版２０１１款　最新报价</td>      <td>http://auto.data.people.com.cn/model_15782/</td>      <td>经销商　电话　试驾／订车Ｕ憬杭州滨江区江陵路１７８０号４００８－１１２２３３转５８６４＃保常...</td>    </tr>    <tr>      <th>1</th>      <td>汽车</td>      <td>９１８　Ｓｐｙｄｅｒ概念车</td>      <td>http://auto.data.people.com.cn/prdview_165423....</td>      <td>呼叫热线　４００８－１００－３００　服务邮箱　ｋｆ＠ｐｅｏｐｌｅｄａｉｌｙ．ｃｏｍ．ｃｎ</td>    </tr>    <tr>      <th>2</th>      <td>汽车</td>      <td>日内瓦亮相　ＭＩＮＩ性能版／概念车－１．６Ｔ引擎</td>      <td>http://auto.data.people.com.cn/news/story_5249...</td>      <td>ＭＩＮＩ品牌在二月曾经公布了最新的ＭＩＮＩ新概念车Ｃｌｕｂｖａｎ效果图，不过现在在日内瓦车展...</td>    </tr>    <tr>      <th>3</th>      <td>汽车</td>      <td>清仓大甩卖一汽夏利Ｎ５威志Ｖ２低至３．３９万</td>      <td>http://auto.data.people.com.cn/news/story_6144...</td>      <td>清仓大甩卖！一汽夏利Ｎ５、威志Ｖ２低至３．３９万＝日，启新中国一汽强势推出一汽夏利Ｎ５、威志...</td>    </tr>    <tr>      <th>4</th>      <td>汽车</td>      <td>大众敞篷家族新成员　高尔夫敞篷版实拍</td>      <td>http://auto.data.people.com.cn/news/story_5686...</td>      <td>在今年３月的日内瓦车展上，我们见到了高尔夫家族的新成员，高尔夫敞篷版，这款全新敞篷车受到了众...</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_news.shape</span><br></pre></td></tr></table></figure><pre><code>(5000, 4)</code></pre><h3 id="分词：使用结吧分词器"><a href="#分词：使用结吧分词器" class="headerlink" title="分词：使用结吧分词器"></a>分词：使用结吧分词器</h3><p><strong> 结巴分词器需要转换成list的格式 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">content = df_news.content.values.tolist()</span><br><span class="line"><span class="built_in">print</span> (content[<span class="number">1000</span>])</span><br></pre></td></tr></table></figure><div style="overflow: scroll;">      阿里巴巴集团昨日宣布，将在集团管理层面设立首席数据官岗位（Ｃｈｉｅｆ　Ｄａｔａ　Ｏｆｆｉｃｅｒ），阿里巴巴Ｂ２Ｂ公司ＣＥＯ陆兆禧将会出任上述职务，向集团ＣＥＯ马云直接汇报。＞菹ぃ和６月初的首席风险官职务任命相同，首席数据官亦为阿里巴巴集团在完成与雅虎股权谈判，推进“ｏｎｅ　ｃｏｍｐａｎｙ”目标后，在集团决策层面新增的管理岗位。０⒗锛团昨日表示，“变成一家真正意义上的数据公司”已是战略共识。记者刘夏</div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">content_S = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> content:</span><br><span class="line">    current_segment = jieba.lcut(line)  <span class="comment"># lcut可以进行分词</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(current_segment) &gt; <span class="number">1</span> <span class="keyword">and</span> current_segment != <span class="string">&#x27;\r\n&#x27;</span>: <span class="comment"># \n换行符,\r回车符号</span></span><br><span class="line">        content_S.append(current_segment)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">content_S[<span class="number">1000</span>]</span><br></pre></td></tr></table></figure><pre><code>[&#39;阿里巴巴&#39;, &#39;集团&#39;, &#39;昨日&#39;, &#39;宣布&#39;, &#39;，&#39;, &#39;将&#39;, &#39;在&#39;, &#39;集团&#39;, &#39;管理&#39;, &#39;层面&#39;, &#39;设立&#39;, &#39;首席&#39;, &#39;数据&#39;, &#39;官&#39;, &#39;岗位&#39;, &#39;（&#39;, &#39;Ｃ&#39;, &#39;ｈ&#39;, &#39;ｉ&#39;, &#39;ｅ&#39;, &#39;ｆ&#39;, &#39;\u3000&#39;, &#39;Ｄ&#39;, &#39;ａ&#39;, &#39;ｔ&#39;, &#39;ａ&#39;, &#39;\u3000&#39;, &#39;Ｏ&#39;, &#39;ｆ&#39;, &#39;ｆ&#39;, &#39;ｉ&#39;, &#39;ｃ&#39;, &#39;ｅ&#39;, &#39;ｒ&#39;, &#39;）&#39;, &#39;，&#39;, &#39;阿里巴巴&#39;, &#39;Ｂ&#39;, &#39;２&#39;, &#39;Ｂ&#39;, &#39;公司&#39;, &#39;Ｃ&#39;, &#39;Ｅ&#39;, &#39;Ｏ&#39;, &#39;陆兆禧&#39;, &#39;将&#39;, &#39;会&#39;, &#39;出任&#39;, &#39;上述&#39;, &#39;职务&#39;, &#39;，&#39;, &#39;向&#39;, &#39;集团&#39;, &#39;Ｃ&#39;, &#39;Ｅ&#39;, &#39;Ｏ&#39;, &#39;马云&#39;, &#39;直接&#39;, &#39;汇报&#39;, &#39;。&#39;, &#39;＞&#39;, &#39;菹&#39;, &#39;ぃ&#39;, &#39;和&#39;, &#39;６&#39;, &#39;月初&#39;, &#39;的&#39;, &#39;首席&#39;, &#39;风险&#39;, &#39;官&#39;, &#39;职务&#39;, &#39;任命&#39;, &#39;相同&#39;, &#39;，&#39;, &#39;首席&#39;, &#39;数据&#39;, &#39;官亦为&#39;, &#39;阿里巴巴&#39;, &#39;集团&#39;, &#39;在&#39;, &#39;完成&#39;, &#39;与&#39;, &#39;雅虎&#39;, &#39;股权&#39;, &#39;谈判&#39;, &#39;，&#39;, &#39;推进&#39;, &#39;“&#39;, &#39;ｏ&#39;, &#39;ｎ&#39;, &#39;ｅ&#39;, &#39;\u3000&#39;, &#39;ｃ&#39;, &#39;ｏ&#39;, &#39;ｍ&#39;, &#39;ｐ&#39;, &#39;ａ&#39;, &#39;ｎ&#39;, &#39;ｙ&#39;, &#39;”&#39;, &#39;目标&#39;, &#39;后&#39;, &#39;，&#39;, &#39;在&#39;, &#39;集团&#39;, &#39;决策&#39;, &#39;层面&#39;, &#39;新增&#39;, &#39;的&#39;, &#39;管理&#39;, &#39;岗位&#39;, &#39;。&#39;, &#39;０&#39;, &#39;⒗&#39;, &#39;锛&#39;, &#39;团&#39;, &#39;昨日&#39;, &#39;表示&#39;, &#39;，&#39;, &#39;“&#39;, &#39;变成&#39;, &#39;一家&#39;, &#39;真正&#39;, &#39;意义&#39;, &#39;上&#39;, &#39;的&#39;, &#39;数据&#39;, &#39;公司&#39;, &#39;”&#39;, &#39;已&#39;, &#39;是&#39;, &#39;战略&#39;, &#39;共识&#39;, &#39;。&#39;, &#39;记者&#39;, &#39;刘夏&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_content=pd.DataFrame(&#123;<span class="string">&#x27;content_S&#x27;</span>:content_S&#125;) <span class="comment"># DataFrame可以使用键值对的方式来获得下面的数据形式。</span></span><br><span class="line">df_content.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"> <style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>content_S</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>[经销商, 　, 电话, 　, 试驾, ／, 订车, Ｕ, 憬, 杭州, 滨江区, 江陵, ...</td>    </tr>    <tr>      <th>1</th>      <td>[呼叫, 热线, 　, ４, ０, ０, ８, －, １, ０, ０, －, ３, ０, ０...</td>    </tr>    <tr>      <th>2</th>      <td>[Ｍ, Ｉ, Ｎ, Ｉ, 品牌, 在, 二月, 曾经, 公布, 了, 最新, 的, Ｍ, Ｉ...</td>    </tr>    <tr>      <th>3</th>      <td>[清仓, 大, 甩卖, ！, 一汽, 夏利, Ｎ, ５, 、, 威志, Ｖ, ２, 低至, ...</td>    </tr>    <tr>      <th>4</th>      <td>[在, 今年, ３, 月, 的, 日内瓦, 车展, 上, ，, 我们, 见到, 了, 高尔夫...</td>    </tr>  </tbody></table></div><h3 id="进行数据的清洗，去掉停用词。—停用词表，可以网上下载。"><a href="#进行数据的清洗，去掉停用词。—停用词表，可以网上下载。" class="headerlink" title="进行数据的清洗，去掉停用词。—停用词表，可以网上下载。"></a>进行数据的清洗，去掉停用词。—停用词表，可以网上下载。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stopwords=pd.read_csv(<span class="string">&quot;stopwords.txt&quot;</span>,index_col=<span class="literal">False</span>,sep=<span class="string">&quot;\t&quot;</span>,quoting=<span class="number">3</span>,names=[<span class="string">&#x27;stopword&#x27;</span>], encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">stopwords.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>stopword</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>!</td>    </tr>    <tr>      <th>1</th>      <td>"</td>    </tr>    <tr>      <th>2</th>      <td>#</td>    </tr>    <tr>      <th>3</th>      <td>$</td>    </tr>    <tr>      <th>4</th>      <td>%</td>    </tr>    <tr>      <th>5</th>      <td>&amp;</td>    </tr>    <tr>      <th>6</th>      <td>'</td>    </tr>    <tr>      <th>7</th>      <td>(</td>    </tr>    <tr>      <th>8</th>      <td>)</td>    </tr>    <tr>      <th>9</th>      <td>*</td>    </tr>    <tr>      <th>10</th>      <td>+</td>    </tr>    <tr>      <th>11</th>      <td>,</td>    </tr>    <tr>      <th>12</th>      <td>-</td>    </tr>    <tr>      <th>13</th>      <td>--</td>    </tr>    <tr>      <th>14</th>      <td>.</td>    </tr>    <tr>      <th>15</th>      <td>..</td>    </tr>    <tr>      <th>16</th>      <td>...</td>    </tr>    <tr>      <th>17</th>      <td>......</td>    </tr>    <tr>      <th>18</th>      <td>...................</td>    </tr>    <tr>      <th>19</th>      <td>./</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drop_stopwords</span>(<span class="params">contents,stopwords</span>):</span></span><br><span class="line">    contents_clean = []</span><br><span class="line">    all_words = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> contents:</span><br><span class="line">        line_clean = []</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> line:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> stopwords:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            line_clean.append(word)</span><br><span class="line">            all_words.append(<span class="built_in">str</span>(word)) <span class="comment"># 一会做一个词云。有现成的库，可以轻松实现出来。</span></span><br><span class="line">        contents_clean.append(line_clean)</span><br><span class="line">    <span class="keyword">return</span> contents_clean,all_words</span><br><span class="line">    <span class="comment"># print (contents_clean)</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">contents = df_content.content_S.values.tolist()    </span><br><span class="line">stopwords = stopwords.stopword.values.tolist()</span><br><span class="line">contents_clean,all_words = drop_stopwords(contents,stopwords)</span><br><span class="line"></span><br><span class="line"><span class="comment"># df_content.content_S.isin(stopwords.stopword)</span></span><br><span class="line"><span class="comment"># df_content=df_content[~df_content.content_S.isin(stopwords.stopword)]</span></span><br><span class="line"><span class="comment"># df_content.head()</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_content=pd.DataFrame(&#123;<span class="string">&#x27;contents_clean&#x27;</span>:contents_clean&#125;)</span><br><span class="line">df_content.head() <span class="comment"># 也可以在停用词里面增加字母，将字母去掉。</span></span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>contents_clean</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>[经销商, 电话, 试驾, 订车, Ｕ, 憬, 杭州, 滨江区, 江陵, 路, 号, 转, ...</td>    </tr>    <tr>      <th>1</th>      <td>[呼叫, 热线, 服务, 邮箱, ｋ, ｆ, ｐ, ｅ, ｏ, ｐ, ｌ, ｅ, ｄ, ａ,...</td>    </tr>    <tr>      <th>2</th>      <td>[Ｍ, Ｉ, Ｎ, Ｉ, 品牌, 二月, 公布, 最新, Ｍ, Ｉ, Ｎ, Ｉ, 新, 概念...</td>    </tr>    <tr>      <th>3</th>      <td>[清仓, 甩卖, 一汽, 夏利, Ｎ, 威志, Ｖ, 低至, 万, 启新, 中国, 一汽, ...</td>    </tr>    <tr>      <th>4</th>      <td>[日内瓦, 车展, 见到, 高尔夫, 家族, 新, 成员, 高尔夫, 敞篷版, 款, 全新,...</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_all_words=pd.DataFrame(&#123;<span class="string">&#x27;all_words&#x27;</span>:all_words&#125;)</span><br><span class="line">df_all_words.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>all_words</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>经销商</td>    </tr>    <tr>      <th>1</th>      <td>电话</td>    </tr>    <tr>      <th>2</th>      <td>试驾</td>    </tr>    <tr>      <th>3</th>      <td>订车</td>    </tr>    <tr>      <th>4</th>      <td>Ｕ</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">words_count=df_all_words.groupby(by=[<span class="string">&#x27;all_words&#x27;</span>])[<span class="string">&#x27;all_words&#x27;</span>].agg(&#123;<span class="string">&quot;count&quot;</span>:numpy.size&#125;) <span class="comment"># 先分组再agg求和。</span></span><br><span class="line">words_count=words_count.reset_index().sort_values(by=[<span class="string">&quot;count&quot;</span>],ascending=<span class="literal">False</span>) <span class="comment"># 按值进行排序</span></span><br><span class="line">words_count.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>all_words</th>      <th>count</th>    </tr>  </thead>  <tbody>    <tr>      <th>4077</th>      <td>中</td>      <td>5199</td>    </tr>    <tr>      <th>4209</th>      <td>中国</td>      <td>3115</td>    </tr>    <tr>      <th>88255</th>      <td>说</td>      <td>3055</td>    </tr>    <tr>      <th>104747</th>      <td>Ｓ</td>      <td>2646</td>    </tr>    <tr>      <th>1373</th>      <td>万</td>      <td>2390</td>    </tr>  </tbody></table></div><p><strong> 词云的展示 </strong> ——在github上面直接搜wordcloud就行！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud <span class="comment"># 导入词云</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10.0</span>, <span class="number">5.0</span>)</span><br><span class="line"></span><br><span class="line">wordcloud=WordCloud(font_path=<span class="string">&quot;./data/simhei.ttf&quot;</span>,background_color=<span class="string">&quot;white&quot;</span>,max_font_size=<span class="number">80</span>)</span><br><span class="line">word_frequence = &#123;x[<span class="number">0</span>]:x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> words_count.head(<span class="number">100</span>).values&#125; <span class="comment"># 画前100个词</span></span><br><span class="line">wordcloud=wordcloud.fit_words(word_frequence)</span><br><span class="line">plt.imshow(wordcloud)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.image.AxesImage at 0x186064c64e0&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210511142559.png" alt=""></p><h3 id="TF-IDF-：提取关键词"><a href="#TF-IDF-：提取关键词" class="headerlink" title="TF-IDF ：提取关键词"></a>TF-IDF ：提取关键词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse <span class="comment"># jieba和sklearn都可以进行词频的提取</span></span><br><span class="line">index = <span class="number">2400</span></span><br><span class="line"><span class="built_in">print</span> (df_news[<span class="string">&#x27;content&#x27;</span>][index])</span><br><span class="line">content_S_str = <span class="string">&quot;&quot;</span>.join(content_S[index])  <span class="comment"># 将分词完的数据拿出来！</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;  &quot;</span>.join(jieba.analyse.extract_tags(content_S_str, topK=<span class="number">5</span>, withWeight=<span class="literal">False</span>))) <span class="comment"># jieba里面有提取关键词的模块</span></span><br></pre></td></tr></table></figure><div style="overflow: scroll;">    法国ＶＳ西班牙、里贝里ＶＳ哈维，北京时间６月２４日凌晨一场的大战举世瞩目，而这场胜利不仅仅关乎两支顶级强队的命运，同时也是他们背后的球衣赞助商耐克和阿迪达斯之间的一次角逐。Ｔ谌胙”窘炫分薇的１６支球队之中，阿迪达斯和耐克的势力范围也是几乎旗鼓相当：其中有５家球衣由耐克提供，而阿迪达斯则赞助了６家，此外茵宝有３家，而剩下的两家则由彪马赞助。而当比赛进行到现在，率先挺进四强的两支球队分别被耐克支持的葡萄牙和阿迪达斯支持的德国占据，而由于最后一场１／４决赛是茵宝（英格兰）和彪马（意大利）的对决，这也意味着明天凌晨西班牙同法国这场阿迪达斯和耐克在１／４决赛的唯一一次直接交手将直接决定两家体育巨头在此次欧洲杯上的胜负。８据评估，在２０１２年足球商品的销售额能总共超过４０亿欧元，而单单是不足一个月的欧洲杯就有高达５亿的销售额，也就是说在欧洲杯期间将有７００万件球衣被抢购一空。根据市场评估，两大巨头阿迪达斯和耐克的市场占有率也是并驾齐驱，其中前者占据３８％，而后者占据３６％。体育权利顾问奥利弗－米歇尔在接受《队报》采访时说：“欧洲杯是耐克通过法国翻身的一个绝佳机会！”Ｃ仔尔接着谈到两大赞助商的经营策略：“竞技体育的成功会燃起球衣购买的热情，不过即便是水平相当，不同国家之间的欧洲杯效应却存在不同。在德国就很出色，大约１／４的德国人通过电视观看了比赛，而在西班牙效果则差很多，由于民族主义高涨的加泰罗尼亚地区只关注巴萨和巴萨的球衣，他们对西班牙国家队根本没什么兴趣。”因此尽管西班牙接连拿下欧洲杯和世界杯，但是阿迪达斯只为西班牙足协支付每年２６００万的赞助费＃相比之下尽管最近两届大赛表现糟糕法国足协将从耐克手中每年可以得到４０００万欧元。米歇尔解释道：“法国创纪录的４０００万欧元赞助费得益于阿迪达斯和耐克竞逐未来１５年欧洲市场的竞争。耐克需要笼络一个大国来打赢这场欧洲大陆的战争，而尽管德国拿到的赞助费并不太高，但是他们却显然牢牢掌握在民族品牌阿迪达斯手中。从长期投资来看，耐克给法国的赞助并不算过高。”    耐克  阿迪达斯  欧洲杯  球衣  西班牙</div><h3 id="LDA-：主题模型"><a href="#LDA-：主题模型" class="headerlink" title="LDA ：主题模型"></a>LDA ：主题模型</h3><p>格式要求（很重要）：list（分好词的语料） of list（不同的文章）形式，分词好的的整个语料</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora, models, similarities</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="comment"># http://radimrehurek.com/gensim/</span></span><br></pre></td></tr></table></figure><pre><code>C:\Anaconda3\lib\site-packages\gensim\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial  warnings.warn(&quot;detected Windows; aliasing chunkize to chunkize_serial&quot;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 做映射，相当于词袋</span></span><br><span class="line">dictionary = corpora.Dictionary(contents_clean)</span><br><span class="line">corpus = [dictionary.doc2bow(sentence) <span class="keyword">for</span> sentence <span class="keyword">in</span> contents_clean]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=<span class="number">20</span>) <span class="comment"># 类似Kmeans自己指定K值。无监督</span></span><br><span class="line">                                                                                        <span class="comment">#    自定义主题数目</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一号分类结果</span></span><br><span class="line"><span class="built_in">print</span> (lda.print_topic(<span class="number">1</span>, topn=<span class="number">5</span>))</span><br></pre></td></tr></table></figure><pre><code>0.007*&quot;中&quot; + 0.006*&quot;说&quot; + 0.004*&quot;观众&quot; + 0.002*&quot;赛区&quot; + 0.002*&quot;岁&quot;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> topic <span class="keyword">in</span> lda.print_topics(num_topics=<span class="number">20</span>, num_words=<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span> (topic[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>0.007*&quot;女人&quot; + 0.006*&quot;男人&quot; + 0.006*&quot;Ｍ&quot; + 0.004*&quot;Ｓ&quot; + 0.004*&quot;说&quot;0.004*&quot;中&quot; + 0.004*&quot;训练&quot; + 0.003*&quot;说&quot; + 0.003*&quot;学校&quot; + 0.002*&quot;研究生&quot;0.006*&quot;戏&quot; + 0.006*&quot;导演&quot; + 0.005*&quot;该剧&quot; + 0.004*&quot;中&quot; + 0.004*&quot;演员&quot;0.007*&quot;中&quot; + 0.006*&quot;说&quot; + 0.004*&quot;观众&quot; + 0.002*&quot;赛区&quot; + 0.002*&quot;岁&quot;0.004*&quot;万&quot; + 0.003*&quot;号&quot; + 0.003*&quot;中&quot; + 0.002*&quot;Ｓ&quot; + 0.002*&quot;Ｒ&quot;0.014*&quot;电影&quot; + 0.009*&quot;导演&quot; + 0.007*&quot;影片&quot; + 0.006*&quot;中国&quot; + 0.005*&quot;中&quot;0.006*&quot;中&quot; + 0.005*&quot;比赛&quot; + 0.004*&quot;说&quot; + 0.003*&quot;撒&quot; + 0.002*&quot;时间&quot;0.006*&quot;赛季&quot; + 0.005*&quot;中&quot; + 0.003*&quot;联赛&quot; + 0.003*&quot;中国&quot; + 0.002*&quot;航母&quot;0.005*&quot;李小璐&quot; + 0.004*&quot;中&quot; + 0.002*&quot;贾乃亮&quot; + 0.002*&quot;Ｗ&quot; + 0.002*&quot;皮肤&quot;0.004*&quot;万&quot; + 0.003*&quot;号&quot; + 0.003*&quot;Ｖ&quot; + 0.003*&quot;Ｔ&quot; + 0.003*&quot;刘涛&quot;0.021*&quot;男人&quot; + 0.008*&quot;女人&quot; + 0.007*&quot;考生&quot; + 0.004*&quot;说&quot; + 0.003*&quot;中&quot;0.005*&quot;中&quot; + 0.005*&quot;食物&quot; + 0.004*&quot;ｉ&quot; + 0.004*&quot;ａ&quot; + 0.004*&quot;吃&quot;0.006*&quot;中&quot; + 0.004*&quot;电影&quot; + 0.004*&quot;说&quot; + 0.002*&quot;中国&quot; + 0.002*&quot;高考&quot;0.007*&quot;中&quot; + 0.006*&quot;孩子&quot; + 0.004*&quot;说&quot; + 0.003*&quot;教育&quot; + 0.003*&quot;中国&quot;0.005*&quot;中&quot; + 0.005*&quot;节目&quot; + 0.004*&quot;说&quot; + 0.004*&quot;表演&quot; + 0.003*&quot;岁&quot;0.007*&quot;电视剧&quot; + 0.004*&quot;中&quot; + 0.003*&quot;说&quot; + 0.003*&quot;飞行&quot; + 0.002*&quot;飞机&quot;0.007*&quot;中&quot; + 0.006*&quot;球队&quot; + 0.005*&quot;选手&quot; + 0.004*&quot;观众&quot; + 0.004*&quot;ｉ&quot;0.005*&quot;中&quot; + 0.005*&quot;天籁&quot; + 0.004*&quot;产品&quot; + 0.004*&quot;肌肤&quot; + 0.003*&quot;职场&quot;0.008*&quot;中国&quot; + 0.008*&quot;饰演&quot; + 0.007*&quot;中&quot; + 0.004*&quot;说&quot; + 0.004*&quot;节目&quot;0.021*&quot;ｅ&quot; + 0.021*&quot;ａ&quot; + 0.016*&quot;ｏ&quot; + 0.013*&quot;ｉ&quot; + 0.013*&quot;ｎ&quot;</code></pre><h3 id="贝叶斯算法进行新闻的分类"><a href="#贝叶斯算法进行新闻的分类" class="headerlink" title="贝叶斯算法进行新闻的分类"></a>贝叶斯算法进行新闻的分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_train=pd.DataFrame(&#123;<span class="string">&#x27;contents_clean&#x27;</span>:contents_clean,<span class="string">&#x27;label&#x27;</span>:df_news[<span class="string">&#x27;category&#x27;</span>]&#125;)</span><br><span class="line">df_train.tail()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>contents_clean</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>4995</th>      <td>[天气, 炎热, 补水, 变得, 美国, 跑步, 世界, 杂志, 报道, 喝水, 身体, 补...</td>      <td>时尚</td>    </tr>    <tr>      <th>4996</th>      <td>[不想, 说, 话, 刺激, 说, 做, 只能, 走, 离开, 伤心地, 想起, 一句, 话...</td>      <td>时尚</td>    </tr>    <tr>      <th>4997</th>      <td>[岁, 刘晓庆, 最新, 嫩照, Ｏ, 衷, 诘, 牧跸, 庆, 看不出, 岁, 秒杀, 刘...</td>      <td>时尚</td>    </tr>    <tr>      <th>4998</th>      <td>[导语, 做, 爸爸, 一种, 幸福, 无论是, 领养, 亲生, 更何况, 影视剧, 中, ...</td>      <td>时尚</td>    </tr>    <tr>      <th>4999</th>      <td>[全球, 最美, 女人, 合成图, 国, 整形外科, 教授, 李承哲, 国际, 学术, 杂志...</td>      <td>时尚</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_train.label.unique()</span><br></pre></td></tr></table></figure><pre><code>array([&#39;汽车&#39;, &#39;财经&#39;, &#39;科技&#39;, &#39;健康&#39;, &#39;体育&#39;, &#39;教育&#39;, &#39;文化&#39;, &#39;军事&#39;, &#39;娱乐&#39;, &#39;时尚&#39;], dtype=object)</code></pre><p><strong> pandas 容易可以很容易进行打标签 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">label_mapping = &#123;<span class="string">&quot;汽车&quot;</span>: <span class="number">1</span>, <span class="string">&quot;财经&quot;</span>: <span class="number">2</span>, <span class="string">&quot;科技&quot;</span>: <span class="number">3</span>, <span class="string">&quot;健康&quot;</span>: <span class="number">4</span>, <span class="string">&quot;体育&quot;</span>:<span class="number">5</span>, <span class="string">&quot;教育&quot;</span>: <span class="number">6</span>,<span class="string">&quot;文化&quot;</span>: <span class="number">7</span>,<span class="string">&quot;军事&quot;</span>: <span class="number">8</span>,<span class="string">&quot;娱乐&quot;</span>: <span class="number">9</span>,<span class="string">&quot;时尚&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">df_train[<span class="string">&#x27;label&#x27;</span>] = df_train[<span class="string">&#x27;label&#x27;</span>].<span class="built_in">map</span>(label_mapping) <span class="comment"># label的替换</span></span><br><span class="line">df_train.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>contents_clean</th>      <th>label</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>[经销商, 电话, 试驾, 订车, Ｕ, 憬, 杭州, 滨江区, 江陵, 路, 号, 转, ...</td>      <td>1</td>    </tr>    <tr>      <th>1</th>      <td>[呼叫, 热线, 服务, 邮箱, ｋ, ｆ, ｐ, ｅ, ｏ, ｐ, ｌ, ｅ, ｄ, ａ,...</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>[Ｍ, Ｉ, Ｎ, Ｉ, 品牌, 二月, 公布, 最新, Ｍ, Ｉ, Ｎ, Ｉ, 新, 概念...</td>      <td>1</td>    </tr>    <tr>      <th>3</th>      <td>[清仓, 甩卖, 一汽, 夏利, Ｎ, 威志, Ｖ, 低至, 万, 启新, 中国, 一汽, ...</td>      <td>1</td>    </tr>    <tr>      <th>4</th>      <td>[日内瓦, 车展, 见到, 高尔夫, 家族, 新, 成员, 高尔夫, 敞篷版, 款, 全新,...</td>      <td>1</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(df_train[<span class="string">&#x27;contents_clean&#x27;</span>].values, df_train[<span class="string">&#x27;label&#x27;</span>].values, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x_train = x_train.flatten()</span></span><br><span class="line">x_train[<span class="number">0</span>][<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>&#39;上海&#39;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">words = []  </span><br><span class="line"><span class="keyword">for</span> line_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x_train)):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># x_train[line_index][word_index] = str(x_train[line_index][word_index])</span></span><br><span class="line">        words.append(<span class="string">&#x27; &#x27;</span>.join(x_train[line_index])) <span class="comment"># python的list往字符串转化</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span> (line_index,word_index)</span><br><span class="line">words[<span class="number">0</span>]  <span class="comment"># 格式转换，不是list of list格式（下文的CoountVector的格式）      </span></span><br></pre></td></tr></table></figure><div style="overflow: scroll;">    '中新网 上海 日电 于俊 父亲节 网络 吃 一顿 电影 快餐 微 电影 爸 对不起 我爱你 定于 本月 父亲节 当天 各大 视频 网站 首映 葜 谱 鞣 剑 保慈 障蚣 钦 呓 樯 埽 ⒌ 缬 埃 ǎ 停 椋 悖 颍 铩 妫 椋 恚 称 微型 电影 新 媒体 平台 播放 状态 短时 休闲 状态 观看 完整 策划 系统 制作 体系 支持 显示 较完整 故事情节 电影 微 超短 放映 微 周期 制作 天 数周 微 规模 投资 人民币 几千 数万元 每部 内容 融合 幽默 搞怪 时尚 潮流 人文 言情 公益 教育 商业 定制 主题 单独 成篇 系列 成剧 唇 开播 微 电影 爸 对不起 我爱你 讲述 一对 父子 观念 缺少 沟通 导致 关系 父亲 传统 固执 钟情 传统 生活 方式 儿子 新派 音乐 达 习惯 晚出 早 生活 性格 张扬 叛逆 两种 截然不同 生活 方式 理念 差异 一场 父子 间 拉开序幕 子 失手 打破 父亲 心爱 物品 父亲 赶出 家门 剧情 演绎 父亲节 妹妹 哥哥 化解 父亲 这场 矛盾 映逋坏 嚼 斫 狻 ⒍ 粤 ⒌ 桨容 争执 退让 传统 尴尬 父子 尴尬 情 男人 表达 心中 那份 感恩 一杯 滤挂 咖啡 父亲节 变得 温馨 镁 缬 缮 虾 Ｎ 逄 煳 幕 传播 迪欧 咖啡 联合 出品 出品人 希望 观摩 扪心自问 父亲节 父亲 记得 父亲 生日 哪一天 父亲 爱喝 跨出 家门 那一刻 感觉 一颗 颤动 心 操劳 天下 儿女 父亲节 大声 喊出 父亲 家人 爱 完'</div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (<span class="built_in">len</span>(words))</span><br></pre></td></tr></table></figure><pre><code>3750</code></pre><p><strong>CountVectorizer的简要介绍</strong>↓——将词转换成向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">texts=[<span class="string">&quot;dog cat fish&quot;</span>,<span class="string">&quot;dog cat cat&quot;</span>,<span class="string">&quot;fish bird&quot;</span>, <span class="string">&#x27;bird&#x27;</span>] <span class="comment"># 四篇文章，注意其格式，不是list of list格式</span></span><br><span class="line">cv = CountVectorizer()</span><br><span class="line">cv_fit=cv.fit_transform(texts)</span><br><span class="line"></span><br><span class="line">print(cv.get_feature_names()) <span class="comment"># 获得语料库中不重复的词</span></span><br><span class="line">print(cv_fit.toarray())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(cv_fit.toarray().<span class="built_in">sum</span>(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>[&#39;bird&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;fish&#39;][[0 1 1 1] [0 2 1 0] [1 0 0 1] [1 0 0 0]][2 3 2 2]</code></pre><p>ngram_range=(1,4)可以将特征值进行组合，让向量更复杂，一般2就可以</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">texts=[<span class="string">&quot;dog cat fish&quot;</span>,<span class="string">&quot;dog cat cat&quot;</span>,<span class="string">&quot;fish bird&quot;</span>, <span class="string">&#x27;bird&#x27;</span>]</span><br><span class="line">cv = CountVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">4</span>))  <span class="comment"># 词可以组合。可以让向量更复杂！</span></span><br><span class="line">cv_fit=cv.fit_transform(texts)</span><br><span class="line"></span><br><span class="line">print(cv.get_feature_names())</span><br><span class="line">print(cv_fit.toarray())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(cv_fit.toarray().<span class="built_in">sum</span>(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>[&#39;bird&#39;, &#39;cat&#39;, &#39;cat cat&#39;, &#39;cat fish&#39;, &#39;dog&#39;, &#39;dog cat&#39;, &#39;dog cat cat&#39;, &#39;dog cat fish&#39;, &#39;fish&#39;, &#39;fish bird&#39;][[0 1 0 1 1 1 0 1 1 0] [0 2 1 0 1 1 1 0 0 0] [1 0 0 0 0 0 0 0 1 1] [1 0 0 0 0 0 0 0 0 0]][2 3 1 1 2 2 1 1 2 1]</code></pre><p><strong> 数据准备好后可以开始进行操作了 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">vec = CountVectorizer(analyzer=<span class="string">&#x27;word&#x27;</span>, max_features=<span class="number">4000</span>,  lowercase = <span class="literal">False</span>)</span><br><span class="line">vec.fit(words) <span class="comment"># fit,以某种规则传化</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong> 进行贝叶斯的计算 </strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">classifier = MultinomialNB()</span><br><span class="line">classifier.fit(vec.transform(words), y_train) <span class="comment"># transform,规则训练好，进行转换为向量。为特征</span></span><br></pre></td></tr></table></figure><pre><code>MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">test_words = []</span><br><span class="line"><span class="keyword">for</span> line_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x_test)):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment">#x_train[line_index][word_index] = str(x_train[line_index][word_index])</span></span><br><span class="line">        test_words.append(<span class="string">&#x27; &#x27;</span>.join(x_test[line_index]))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">         <span class="built_in">print</span> (line_index,word_index)</span><br><span class="line">test_words[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><div style="overflow: scroll;">     '国家 公务员 考试 申论 应用文 类 试题 实质 一道 集 概括 分析 提出 解决问题 一体 综合性 试题 说 一道 客观 凝练 申发 论述 文章 题目 分析 历年 国考 申论 真题 公文 类 试题 类型 多样 包括 公文 类 事务性 文书 类 题材 从题 干 作答 材料 内容 整合 分析 无需 太 创造性 发挥 纵观 历年 申论 真题 作答 应用文 类 试题 文种 格式 作出 特别 重在 内容 考查 行文 格式 考生 平常心 面对 应用文 类 试题 准确 把握 作答 领会 内在 含义 把握 题材 主旨 材料 结构 轻松 应对 应用文 类 试题 Ｒ 弧 ⒆ 钒 盐 展文 写作 原则 Ｔ 材料 中来 应用文 类 试题 材料 总体 把握 客观 考生 材料 中来 材料 中 把握 材料 准确 理解 题材 主旨 Ｔ 政府 角度 作答 应用文 类 试题 更应 注重 政府 角度 观点 政府 角度 出发 原则 表述 观点 提出 解决 之策 考生 作答 站 政府 人员 角度 看待 提出 解决问题 Ｔ 文体 结构 形式 考查 重点 文体 结构 大部分 评分 关键点 解答 方法 薄 ⒆ ス 丶 词 明 方向 作答 题目 题干 作答 作答 方向 作答 角度 关键 向导 考生 仔细阅读 题干 作答 抓住 关键词 作答 方向 相关 要点 整理 作答 思路 年国考 地市级 真 题为 例 潦惺姓 府 宣传 推进 近海 水域 污染 整治 工作 请 给定 资料 市政府 工作人员 身份 草拟 一份 宣传 纲要 Ｒ 求 保对 宣传 内容 要点 提纲挈领 陈述 玻 体现 政府 精神 全市 各界 关心 支持 污染 整治 工作 通俗易懂 超过 字 肮 丶 词 近海 水域 污染 整治 工作 市政府 工作人员 身份 宣传 纲要 提纲挈领 陈述 体现 政府 精神 全市 各界 关心 支持 污染 整治 工作 通俗易懂 提示 归结 作答 要点 包括 污染 情况 原因 解决 对策 作答 思路 情况 原因 对策 意义 逻辑 顺序 安排 文章 结构 病 ⒋ 缶殖 龇 ⅲ 明 结构 解答 应用文 类 试题 考生 材料 整体 出发 大局 出发 高屋建瓴 把握 材料 主题 思想 事件 起因 解决 对策 阅读文章 构建 文章 结构 直至 快速 解答 场 ⒗ 硭 乘悸 罚明 逻辑 应用文 类 试题 严密 逻辑思维 情况 原因 对策 意义 考生 作答 先 弄清楚 解答 思路 统筹安排 脉络 清晰 逻辑 表达 内容 表述 础 把握 明 详略 考生 仔细阅读 分析 揣摩 应用文 类 试题 内容 答题 时要 详略 得当 主次 分明 安排 内容 增加 文章 层次感 阅卷 老师 阅卷 时能 明白 清晰 一目了然 玻埃 保蹦旯 考 考试 申论 试卷 分为 省级 地市级 两套 试卷 能力 大有 省级 申论 试题 考生 宏观 角度看 注重 深度 广度 考生 深谋远虑 地市级 试题 考生 微观 视角 观察 侧重 考查 解决 能力 考生 贯彻执行 作答 区别对待'</div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classifier.score(vec.transform(test_words), y_test)</span><br></pre></td></tr></table></figure><pre><code>0.80400000000000005</code></pre><h3 id="TF-IDF的到导入计算"><a href="#TF-IDF的到导入计算" class="headerlink" title="TF-IDF的到导入计算"></a>TF-IDF的到导入计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line">vectorizer = TfidfVectorizer(analyzer=<span class="string">&#x27;word&#x27;</span>, max_features=<span class="number">4000</span>,  lowercase = <span class="literal">False</span>)</span><br><span class="line">vectorizer.fit(words)</span><br></pre></td></tr></table></figure><pre><code>TfidfVectorizer(analyzer=&#39;word&#39;, binary=False, decode_error=&#39;strict&#39;,        dtype=&lt;class &#39;numpy.int64&#39;&gt;, encoding=&#39;utf-8&#39;, input=&#39;content&#39;,        lowercase=False, max_df=1.0, max_features=4000, min_df=1,        ngram_range=(1, 1), norm=&#39;l2&#39;, preprocessor=None, smooth_idf=True,        stop_words=None, strip_accents=None, sublinear_tf=False,        token_pattern=&#39;(?u)\\b\\w\\w+\\b&#39;, tokenizer=None, use_idf=True,        vocabulary=None)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line">classifier = MultinomialNB()</span><br><span class="line">classifier.fit(vectorizer.transform(words), y_train)</span><br></pre></td></tr></table></figure><pre><code>MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classifier.score(vectorizer.transform(test_words), y_test)</span><br></pre></td></tr></table></figure><pre><code>0.81520000000000004</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;文本分析——新闻分类&quot;&gt;&lt;a href=&quot;#文本分析——新闻分类&quot; class=&quot;headerlink&quot; title=&quot;文本分析——新闻分类&quot;&gt;&lt;/a&gt;文本分析——新闻分类&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;</summary>
      
    
    
    
    <category term="机器学习基础实战" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="机器学习基础实战" scheme="https://xxren8218.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（五十四）：字符流中第一个不重复的字符</title>
    <link href="https://xxren8218.github.io/20210511/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E5%9B%9B%EF%BC%89%EF%BC%9A%E5%AD%97%E7%AC%A6%E6%B5%81%E4%B8%AD%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%B8%8D%E9%87%8D%E5%A4%8D%E7%9A%84%E5%AD%97%E7%AC%A6.html"/>
    <id>https://xxren8218.github.io/20210511/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%94%E5%8D%81%E5%9B%9B%EF%BC%89%EF%BC%9A%E5%AD%97%E7%AC%A6%E6%B5%81%E4%B8%AD%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%B8%8D%E9%87%8D%E5%A4%8D%E7%9A%84%E5%AD%97%E7%AC%A6.html</id>
    <published>2021-05-11T06:17:23.000Z</published>
    <updated>2021-05-11T06:21:39.150Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符&quot;go&quot;时，第一个只出现一次的字符是&quot;g&quot;。当从该字符流中读出前六个字符“google&quot;时，第一个只出现一次的字符是&quot;l&quot;。如果当前字符流没有存在出现一次的字符，返回#字符。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>可以创建一个列表进行字符的记录。然后按顺序进行遍历列表有count方法可以进行计数。</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回对应char</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>       </span><br><span class="line">        self.s = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Insert</span>(<span class="params">self, char</span>):</span></span><br><span class="line">        self.s.append(char)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FirstAppearingOnce</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.s:</span><br><span class="line">            <span class="keyword">if</span> self.s.count(i) == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> i</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;#&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符&amp;quot;go&amp;q</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（四十八）：不用加减乘除的加法</title>
    <link href="https://xxren8218.github.io/20210511/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9A%E4%B8%8D%E7%94%A8%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4%E7%9A%84%E5%8A%A0%E6%B3%95.html"/>
    <id>https://xxren8218.github.io/20210511/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AB%EF%BC%89%EF%BC%9A%E4%B8%8D%E7%94%A8%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4%E7%9A%84%E5%8A%A0%E6%B3%95.html</id>
    <published>2021-05-11T06:12:44.000Z</published>
    <updated>2021-05-11T06:16:07.727Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>写一个函数，求两个整数之和，要求在函数体内不得使用+、-、*、/四则运算符号。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>首先看十进制是如何做的： 5+7=12，可以使用三步走：第一步：相加各位的值，不算进位，得到2。第二步：计算进位值，得到10. 如果这一步的进位值为0，那么第一步得到的值就是最终结果。第三步：重复上述两步，只是相加的值变成上述两步的得到的结果2和10，得到12。 同样我们可以三步走的方式计算二进制值相加： 5-101，7-111第一步：相加各位的值，不算进位，得到010，二进制每位相加就相当于各位做异或操作，101^111。第二步：计算进位值，得到1010，相当于各位做与操作得到101，再向左移一位得到1010，(101&amp;111)&lt;&lt;1。第三步：重复上述两步， 各位相加 010^1010=1000，进位值为100=(010&amp;1010)&lt;&lt;1。继续重复上述两步：1000^100 = 1100，进位值为0，跳出循环，1100为最终结果。</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Add</span>(<span class="params">self, num1, num2</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="comment"># python2.7的int取值范围为：-2147483648至2147483647</span></span><br><span class="line">        <span class="comment"># 将数字&amp;0xffffffff，得到二进制。python的二进制不一样。其负数为 ~(num ^ mask)</span></span><br><span class="line">        MAX = <span class="number">0x7fffffff</span></span><br><span class="line">        mask = <span class="number">0xffffffff</span></span><br><span class="line">        <span class="keyword">while</span> num2 != <span class="number">0</span>:</span><br><span class="line">            num1, num2 = (num1 ^ num2), ((num1 &amp; num2) &lt;&lt; <span class="number">1</span>)</span><br><span class="line">            num1 = num1 &amp; mask</span><br><span class="line">            num2 = num2 &amp; mask</span><br><span class="line">        <span class="keyword">return</span> num1 <span class="keyword">if</span> num1 &lt;= MAX <span class="keyword">else</span> ~(num1 ^ mask)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;写一个函数，求两个整数之和，要求在函数体内不得使用+、-、*、/四则运算符号。
&lt;/code&gt;&lt;/pre&gt;&lt;</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="位运算" scheme="https://xxren8218.github.io/tags/%E4%BD%8D%E8%BF%90%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（四十七）：求1+2+3+…+n</title>
    <link href="https://xxren8218.github.io/20210511/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%83%EF%BC%89%EF%BC%9A%E6%B1%821-2-3-%E2%80%A6-n.html"/>
    <id>https://xxren8218.github.io/20210511/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%83%EF%BC%89%EF%BC%9A%E6%B1%821-2-3-%E2%80%A6-n.html</id>
    <published>2021-05-11T06:08:14.000Z</published>
    <updated>2021-05-11T06:11:26.586Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>求1+2+3+...+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>这是一道超级无敌送分题，使用递归即可。</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Sum_Solution</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        ans = n</span><br><span class="line">        <span class="keyword">if</span> ans:</span><br><span class="line">            ans += self.Sum_Solution(n-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;求1+2+3+...+n，要求不能使用乘除法、for、while、if、else、switch、case等关</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="递归" scheme="https://xxren8218.github.io/tags/%E9%80%92%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（四十六）：孩子们的游戏（圆圈中最后剩下的数）</title>
    <link href="https://xxren8218.github.io/20210510/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E5%AD%A9%E5%AD%90%E4%BB%AC%E7%9A%84%E6%B8%B8%E6%88%8F%EF%BC%88%E5%9C%86%E5%9C%88%E4%B8%AD%E6%9C%80%E5%90%8E%E5%89%A9%E4%B8%8B%E7%9A%84%E6%95%B0%EF%BC%89.html"/>
    <id>https://xxren8218.github.io/20210510/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E5%85%AD%EF%BC%89%EF%BC%9A%E5%AD%A9%E5%AD%90%E4%BB%AC%E7%9A%84%E6%B8%B8%E6%88%8F%EF%BC%88%E5%9C%86%E5%9C%88%E4%B8%AD%E6%9C%80%E5%90%8E%E5%89%A9%E4%B8%8B%E7%9A%84%E6%95%B0%EF%BC%89.html</id>
    <published>2021-05-10T12:16:29.000Z</published>
    <updated>2021-05-11T06:07:11.635Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>每年六一儿童节,牛客都会准备一些小礼物去看望孤儿院的小朋友,今年亦是如此。HF作为牛客的资深元老,自然也准备了一些小游戏。其中,有个游戏是这样的:首先,让小朋友们围成一个大圈。然后,他随机指定一个数m,让编号为0的小朋友开始报数。每次喊到m-1的那个小朋友要出列唱首歌,然后可以在礼品箱中任意的挑选礼物,并且不再回到圈中,从他的下一个小朋友开始,继续0...m-1报数....这样下去....直到剩下最后一个小朋友,可以不用表演,并且拿到牛客名贵的“名侦探柯南”典藏版(名额有限哦!!^_^)。请你试着想下,哪个小朋友会得到这份礼品呢？(注：小朋友的编号是从0到n-1)</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>这道题可以用数学归纳法解决。题目抽象：给定一个由[0...n-1]构成的数组，第一次从0开始数m个数，然后删除，以后每次都从删除的数下一个位置开始数m个数，然后删除，直到剩余一个数字，找出那个数字。比如：arr = [0 1 2 3 4]， m = 3第一次：删除2 ，变成 arr = [0 1 3 4]第二次，删除0，变成 arr = [1 3 4]第三次，删除4，变成 arr = [1 3]第四次，删除1，变成 arr = [3]f[1] = 0               f[2] = (f&#123;1] + m) % 2  f[3] = (f[2] + m) % 3  f[4] = (f[3] + m) % 4  f[5] = (f[4] + m) % 5  ...f[n] = (f[n-1] + m) % n</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">LastRemaining_Solution</span>(<span class="params">self, n, m</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> n==<span class="number">0</span>:<span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> n==<span class="number">1</span>:<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        f=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,n+<span class="number">1</span>):</span><br><span class="line">            f=(f+m)%i</span><br><span class="line">        <span class="keyword">return</span> f</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;每年六一儿童节,牛客都会准备一些小礼物去看望孤儿院的小朋友,今年亦是如此。HF作为牛客的资深元老,自然也准备</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（四十五）：扑克牌顺子</title>
    <link href="https://xxren8218.github.io/20210510/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9A%E6%89%91%E5%85%8B%E7%89%8C%E9%A1%BA%E5%AD%90.html"/>
    <id>https://xxren8218.github.io/20210510/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%94%EF%BC%89%EF%BC%9A%E6%89%91%E5%85%8B%E7%89%8C%E9%A1%BA%E5%AD%90.html</id>
    <published>2021-05-10T12:01:26.000Z</published>
    <updated>2021-05-10T12:37:53.062Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>LL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有2个大王,2个小王(一副牌原本是54张😊)...他随机从中抽出了5张牌,想测测自己的手气,看看能不能抽到顺子,如果抽到的话,他决定去买体育彩票,嘿嘿！！“红心A,黑桃3,小王,大王,方片5”,“Oh My God!”不是顺子.....LL不高兴了,他想了想,决定大\小 王可以看成任何数字,并且A看作1,J为11,Q为12,K为13。上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4),“So Lucky!”。LL决定去买体育彩票啦。 现在,要求你使用这幅牌模拟上面的过程,然后告诉我们LL的运气如何。为了方便起见,你可以认为大小王是0。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>这道题可以用另外一种思路解决：无非两种特殊情况需要考虑：    1.因为有四个鬼，所以最多有四个0，遇到0直接跳过    2.若含有重复的数字，那肯定不能成为顺子。可以用python的set()得以解决。    3.要组成顺子，这几张牌的max(max-min)只能是5-1=4（1，2，3，4，5）        若有零，则肯定更小于4了。</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">IsContinuous</span>(<span class="params">self, numbers</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        repeat = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> numbers:</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:<span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> repeat:</span><br><span class="line">                repeat.add(i)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">max</span>(repeat) - <span class="built_in">min</span>(repeat) &lt;= <span class="number">4</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;LL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有2个大王,2个小王(一副牌原本是54张😊)...</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（四十二）：和为S的两个数字</title>
    <link href="https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%92%8C%E4%B8%BAS%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%95%B0%E5%AD%97.html"/>
    <id>https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%92%8C%E4%B8%BAS%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%95%B0%E5%AD%97.html</id>
    <published>2021-05-08T10:27:38.000Z</published>
    <updated>2021-05-08T10:32:19.450Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>输入一个递增排序的数组和一个数字S，在数组中查找两个数，是的他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。输出描述：对应每个测试案例，输出两个数，小的先输出。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>对于一个数组，我们可以定义两个指针，一个从左往右遍历（left），另一个从右往左遍历（right）。首先，我们比较第一个数字和最后一个数字的和cursum与给定数字tsum，如果cursum &lt; tsum，那么我们就要加大输入值，所以，left向右移动一位，重复之前的计算；如果cursum &gt; tsum，那么我们就要减小输入值，所以，right向左移动一位，重复之前的计算；如果相等，那么这两个数字就是我们要找的数字，直接输出即可。这么做的好处是，也保证了乘积最小。</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FindNumbersWithSum</span>(<span class="params">self, array, tsum</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(array) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(array)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="keyword">if</span> array[left] + array[right] == tsum:</span><br><span class="line">                res.append(array[left])</span><br><span class="line">                res.append(array[right])</span><br><span class="line">                <span class="keyword">return</span> res</span><br><span class="line">            <span class="keyword">elif</span> array[left] + array[right] &lt; tsum:</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;输入一个递增排序的数组和一个数字S，在数组中查找两个数，是的他们的和正好是S，如果有多对数字的和等于S，输出</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（四十一）：和为S的连续正数序列</title>
    <link href="https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%80%EF%BC%89%EF%BC%9A%E5%92%8C%E4%B8%BAS%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97.html"/>
    <id>https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E5%9B%9B%E5%8D%81%E4%B8%80%EF%BC%89%EF%BC%9A%E5%92%8C%E4%B8%BAS%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97.html</id>
    <published>2021-05-08T10:23:27.000Z</published>
    <updated>2021-05-08T10:26:57.735Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满足于此,他在想究竟有多少种连续的正数序列的和为100(至少包括两个数)。没多久,他就得到另一组连续正数和为100的序列:18,19,20,21,22。现在把问题交给你,你能不能也很快的找出所有和为S的连续正数序列? Good Luck!输出描述：输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>设定两个指针，一个指向第一个数，一个指向最后一个数，在此之前需要设定第一个数和最后一个数的值，由于是正数序列，所以可以把第一个数设为1，最后一个数为2（因为是要求是连续正数序列，最后不可能和第一个数重合）。下一步就是不断改变第一个数和最后一个数的值，如果从第一个数到最后一个数的和刚好是要求的和，那么把所有的数都添加到一个序列中；如果大于要求的和，则说明从第一个数到最后一个数之间的范围太大，因此减小范围，需要把第一个数的值加1，同时把当前和减去原来的第一个数的值；如果小于要求的和，说明范围太小，因此把最后一个数加1，同时把当前的和加上改变之后的最后一个数的值。这样，不断修改第一个数和最后一个数的值，就能确定所有连续正数序列的和等于S的序列了。注意：初中的求和公式应该记得吧，首项加尾项的和乘以个数除以2，即sum = (a + b) * n / 2。</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FindContinuousSequence</span>(<span class="params">self, tsum</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        res = []</span><br><span class="line">        left, right = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="comment"># 求连续整数的和(a+b)*n/2</span></span><br><span class="line">            cursum = (left + right)*(right-left+<span class="number">1</span>)/<span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> cursum == tsum:</span><br><span class="line">                tmp = []</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(left, right+<span class="number">1</span>):</span><br><span class="line">                    tmp.append(i)</span><br><span class="line">                res.append(tmp)</span><br><span class="line">                <span class="comment"># 接着后移</span></span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> cursum &lt; tsum:</span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（三十三）：丑数</title>
    <link href="https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%89%EF%BC%89%EF%BC%9A%E4%B8%91%E6%95%B0.html"/>
    <id>https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%89%EF%BC%89%EF%BC%9A%E4%B8%91%E6%95%B0.html</id>
    <published>2021-05-08T10:02:57.000Z</published>
    <updated>2021-05-08T10:22:19.712Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>丑数其实可以看成是是下图的形式。即2、3、5的乘积，然后找出相乘后最小的数字放入列表(数组)a中即可。</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210508180923.JPG" alt=""></p><pre><code>可以设立三个指针。p2,p3,p5 = 0 如下图所示。</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210508181238.JPG" alt=""></p><pre><code>对于n=1 a[0],他们的值都是1.从a[2]开始(n=2)。如下图</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210508181529.JPG" alt=""></p><pre><code>最小的数是a[p2]x2,则将其放入数组a中，将p2指针后移一位。接下来 n=3 时候,以此类推。。。当 n = 6时，两个都是6，如下图，则需要移动两个指针。</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210508181951.JPG" alt="">    </p><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetUglyNumber_Solution</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        a = [<span class="number">1</span>]</span><br><span class="line">        p2 = p3 = p5 = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,index+<span class="number">1</span>):</span><br><span class="line">            newNum = <span class="built_in">min</span>(a[p2]*<span class="number">2</span>, a[p3]*<span class="number">3</span>, a[p5]*<span class="number">5</span>)</span><br><span class="line">            a.append(newNum)</span><br><span class="line">            <span class="comment"># 此处保证了，数值相等时都向后移动一位。</span></span><br><span class="line">            <span class="keyword">if</span> newNum == a[p2]*<span class="number">2</span>:p2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> newNum == a[p3]*<span class="number">3</span>:p3 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> newNum == a[p5]*<span class="number">5</span>:p5 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> a[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;把只包含因子2、3和5的数称作丑数（Ugly Number）。例如6、8都是丑数，但14不是，因为它包含因子</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（三十一）：整数中1出现的次数（从1到n整数中1出现的次数）</title>
    <link href="https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%80%EF%BC%89%EF%BC%9A%E6%95%B4%E6%95%B0%E4%B8%AD1%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0%EF%BC%88%E4%BB%8E1%E5%88%B0n%E6%95%B4%E6%95%B0%E4%B8%AD1%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0%EF%BC%89.html"/>
    <id>https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%89%E5%8D%81%E4%B8%80%EF%BC%89%EF%BC%9A%E6%95%B4%E6%95%B0%E4%B8%AD1%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0%EF%BC%88%E4%BB%8E1%E5%88%B0n%E6%95%B4%E6%95%B0%E4%B8%AD1%E5%87%BA%E7%8E%B0%E7%9A%84%E6%AC%A1%E6%95%B0%EF%BC%89.html</id>
    <published>2021-05-08T09:36:53.000Z</published>
    <updated>2021-05-08T10:02:11.605Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>输入一个整数n，求从1到n这n个整数的十进制表示中1出现的次数。例如输入12，从1到12这些整数中包含1的数字有1，10，11和12，1一共出现了5次。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>“1”出现次数实际上就是各个位置上1出现的次数的求和，以3101592为例。我们以cur表示目前所在的位数,例如在百位  base = 100, cur = n//base%10a表示左侧的数字，b表示右侧的位数. a = n//base//10, b = n%base</code></pre><p><strong>如下图所示</strong><br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210508174659.JPG" alt=""></p><p>接下来只需要考虑三种情况即可：</p><pre><code>1.cur &gt; 1: 共有(a+1)xbase2.cur == 1: 共有axbase+b+13.cur &lt; 1: 共有axbase</code></pre><p>最后求和即可。</p><p><strong>如下图所示</strong><br><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/20210508174706.JPG" alt=""></p><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">NumberOf1Between1AndN_Solution</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        base = <span class="number">1</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> base &lt;= n:</span><br><span class="line">            a = n//base</span><br><span class="line">            b = n%base</span><br><span class="line">            cur = a%<span class="number">10</span></span><br><span class="line">            a //= <span class="number">10</span></span><br><span class="line">            <span class="keyword">if</span> cur &gt; <span class="number">1</span>:res += (a+<span class="number">1</span>)*base</span><br><span class="line">            <span class="keyword">elif</span> cur == <span class="number">1</span>:res += (a*base+b+<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:res += a*base</span><br><span class="line">            base *= <span class="number">10</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;输入一个整数n，求从1到n这n个整数的十进制表示中1出现的次数。例如输入12，从1到12这些整数中包含1的数</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="其他" scheme="https://xxren8218.github.io/tags/%E5%85%B6%E4%BB%96/"/>
    
  </entry>
  
  <entry>
    <title>剑指Offer（二十九）：最小的K个数</title>
    <link href="https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B9%9D%EF%BC%89%EF%BC%9A%E6%9C%80%E5%B0%8F%E7%9A%84K%E4%B8%AA%E6%95%B0.html"/>
    <id>https://xxren8218.github.io/20210508/%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B9%9D%EF%BC%89%EF%BC%9A%E6%9C%80%E5%B0%8F%E7%9A%84K%E4%B8%AA%E6%95%B0.html</id>
    <published>2021-05-08T09:28:55.000Z</published>
    <updated>2021-05-15T12:28:02.747Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1.题目"></a>1.题目</h2><pre><code>输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4。</code></pre><h2 id="2-思路"><a href="#2-思路" class="headerlink" title="2.思路"></a>2.思路</h2><pre><code>可以通过python的排序对给定的数组进行排序，然后取值即可。</code></pre><h2 id="3-代码"><a href="#3-代码" class="headerlink" title="3.代码"></a>3.代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetLeastNumbers_Solution</span>(<span class="params">self, tinput, k</span>):</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> k==<span class="number">0</span> <span class="keyword">or</span> k&gt;<span class="built_in">len</span>(tinput):</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        tinput.sort()  <span class="comment"># list.sort()默认是升序排序。</span></span><br><span class="line">        <span class="keyword">return</span> tinput[:k]</span><br></pre></td></tr></table></figure><h2 id="解析：sorted-的时间复杂度为O-nlogn"><a href="#解析：sorted-的时间复杂度为O-nlogn" class="headerlink" title="解析：sorted()的时间复杂度为O(nlogn)"></a>解析：sorted()的时间复杂度为O(nlogn)</h2><h2 id="力扣的解题思路："><a href="#力扣的解题思路：" class="headerlink" title="力扣的解题思路："></a>力扣的解题思路：</h2><ul><li>最大堆(最小的k个元素)</li><li>最小堆(最大的k个元素)<ol><li>先存列表的前k个元素</li><li>原地转换为最大堆 heapq.heapify(),时间复杂度O(n)</li><li>循环取剩余的元素，若比最大堆的队顶元素小，则将最大堆的堆顶元素弹出，将此元素放入。heapq.heapreplace(heap,-num)<ul><li>它从堆中弹出最小的元素，再压入一个新元素。</li></ul></li></ol></li></ul><p>python没有最大堆，只有最小堆。我们可以对其取反就可以得到解决。</p><h2 id="代码："><a href="#代码：" class="headerlink" title="代码："></a>代码：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getLeastNumbers</span>(<span class="params">self, arr, k</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type arr: List[int]</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: List[int]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        heap = [-x <span class="keyword">for</span> x <span class="keyword">in</span> arr[:k]]</span><br><span class="line">        heapq.heapify(heap)</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> arr[k:]:</span><br><span class="line">            <span class="keyword">if</span> -num &gt; heap[<span class="number">0</span>]:</span><br><span class="line">                heapq.heapreplace(heap, -num)</span><br><span class="line">        <span class="keyword">return</span> [-x <span class="keyword">for</span> x <span class="keyword">in</span> heap]</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-题目&quot;&gt;&lt;a href=&quot;#1-题目&quot; class=&quot;headerlink&quot; title=&quot;1.题目&quot;&gt;&lt;/a&gt;1.题目&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,</summary>
      
    
    
    
    <category term="传统算法" scheme="https://xxren8218.github.io/categories/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="排序" scheme="https://xxren8218.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
    <category term="最小堆" scheme="https://xxren8218.github.io/tags/%E6%9C%80%E5%B0%8F%E5%A0%86/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯基础</title>
    <link href="https://xxren8218.github.io/20210429/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%9F%BA%E7%A1%80.html"/>
    <id>https://xxren8218.github.io/20210429/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%9F%BA%E7%A1%80.html</id>
    <published>2021-04-29T15:52:24.000Z</published>
    <updated>2021-04-29T15:54:44.328Z</updated>
    
    <content type="html"><![CDATA[<h3 id="贝叶斯拼写检查器"><a href="#贝叶斯拼写检查器" class="headerlink" title="贝叶斯拼写检查器"></a>贝叶斯拼写检查器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re, collections</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">words</span>(<span class="params">text</span>):</span> <span class="keyword">return</span> re.findall(<span class="string">&#x27;[a-z]+&#x27;</span>, text.lower()) </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">features</span>):</span></span><br><span class="line">    model = collections.defaultdict(<span class="keyword">lambda</span>: <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> features:</span><br><span class="line">        model[f] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"> </span><br><span class="line">NWORDS = train(words(<span class="built_in">open</span>(<span class="string">&#x27;big.txt&#x27;</span>).read()))</span><br><span class="line"> </span><br><span class="line">alphabet = <span class="string">&#x27;abcdefghijklmnopqrstuvwxyz&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edits1</span>(<span class="params">word</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(word)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>([word[<span class="number">0</span>:i]+word[i+<span class="number">1</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] +                     <span class="comment"># deletion</span></span><br><span class="line">               [word[<span class="number">0</span>:i]+word[i+<span class="number">1</span>]+word[i]+word[i+<span class="number">2</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>)] + <span class="comment"># transposition</span></span><br><span class="line">               [word[<span class="number">0</span>:i]+c+word[i+<span class="number">1</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">for</span> c <span class="keyword">in</span> alphabet] + <span class="comment"># alteration</span></span><br><span class="line">               [word[<span class="number">0</span>:i]+c+word[i:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>) <span class="keyword">for</span> c <span class="keyword">in</span> alphabet])  <span class="comment"># insertion</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">known_edits2</span>(<span class="params">word</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>(e2 <span class="keyword">for</span> e1 <span class="keyword">in</span> edits1(word) <span class="keyword">for</span> e2 <span class="keyword">in</span> edits1(e1) <span class="keyword">if</span> e2 <span class="keyword">in</span> NWORDS)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">known</span>(<span class="params">words</span>):</span> <span class="keyword">return</span> <span class="built_in">set</span>(w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> w <span class="keyword">in</span> NWORDS)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correct</span>(<span class="params">word</span>):</span></span><br><span class="line">    candidates = known([word]) <span class="keyword">or</span> known(edits1(word)) <span class="keyword">or</span> known_edits2(word) <span class="keyword">or</span> [word]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(candidates, key=<span class="keyword">lambda</span> w: NWORDS[w])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># appl #appla #learw #tess #morw</span></span><br><span class="line">correct(<span class="string">&#x27;tess&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>&#39;less&#39;</code></pre><h3 id="求解：argmaxc-P-c-w-gt-argmaxc-P-w-c-P-c-P-w"><a href="#求解：argmaxc-P-c-w-gt-argmaxc-P-w-c-P-c-P-w" class="headerlink" title="求解：argmaxc P(c|w) -&gt; argmaxc P(w|c) P(c) / P(w)"></a>求解：argmaxc P(c|w) -&gt; argmaxc P(w|c) P(c) / P(w)</h3><ul><li>P(c), <strong>先验概率</strong> 文章中出现一个正确拼写词 c 的概率, 也就是说, 在英语文章中, c 出现的概率有多大</li><li>P(w|c), 在用户想键入 c 的情况下敲成 w 的概率. 因为这个是代表用户会以多大的概率把 c 敲错成 w</li><li>argmaxc, 用来枚举所有可能的 c 并且选取概率最大的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把语料中的单词全部抽取出来, 转成小写, 并且去除单词中间的特殊符号</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">words</span>(<span class="params">text</span>):</span> <span class="keyword">return</span> re.findall(<span class="string">&#x27;[a-z]+&#x27;</span>, text.lower()) </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">features</span>):</span></span><br><span class="line">    <span class="comment"># 匿名函数：新出现的词，将其出现次数设置为1，符合实际，不然上面的公式可得，概率为0.太过绝对。另外出现一次就会加一</span></span><br><span class="line">    model = collections.defaultdict(<span class="keyword">lambda</span>: <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> features:</span><br><span class="line">        model[f] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"> </span><br><span class="line">NWORDS = train(words(<span class="built_in">open</span>(<span class="string">&#x27;big.txt&#x27;</span>).read()))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>要是遇到我们从来没有过见过的新词怎么办. 假如说一个词拼写完全正确, 但是语料库中没有包含这个词, 从而这个词也永远不会出现在训练集中. 于是, 我们就要返回出现这个词的概率是0. 这个情况不太妙, 因为概率为0这个代表了这个事件绝对不可能发生, 而在我们的概率模型中, 我们期望用一个很小的概率来代表这种情况. lambda: 1</p><h3 id="相当于先求先验概率"><a href="#相当于先求先验概率" class="headerlink" title="相当于先求先验概率"></a>相当于先求先验概率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NWORDS</span><br></pre></td></tr></table></figure><pre><code>defaultdict(&lt;function __main__.train.&lt;locals&gt;.&lt;lambda&gt;&gt;,            &#123;&#39;the&#39;: 80031,             &#39;project&#39;: 289,             &#39;gutenberg&#39;: 264,             &#39;ebook&#39;: 88,             &#39;of&#39;: 40026,             &#39;adventures&#39;: 18,             &#39;sherlock&#39;: 102,             &#39;holmes&#39;: 468,             &#39;by&#39;: 6739,             &#39;sir&#39;: 178,             &#39;arthur&#39;: 35,             &#39;conan&#39;: 5,             &#39;doyle&#39;: 6,             &#39;in&#39;: 22048,             &#39;our&#39;: 1067,             &#39;series&#39;: 129,             &#39;copyright&#39;: 70,             &#39;laws&#39;: 234,             &#39;are&#39;: 3631,             &#39;changing&#39;: 45,             &#39;all&#39;: 4145,             &#39;over&#39;: 1283,             &#39;world&#39;: 363,             &#39;be&#39;: 6156,             &#39;sure&#39;: 124,             ...&#125;)</code></pre><h3 id="编辑距离"><a href="#编辑距离" class="headerlink" title="编辑距离:"></a>编辑距离:</h3><p>两个词之间的编辑距离定义为使用了几次插入(在词中插入一个单字母), 删除(删除一个单字母), 交换(交换相邻两个字母), 替换(把一个字母换成另一个)的操作从一个词变到另一个词.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回所有与单词 w 编辑距离为 1 的集合.一次操作，能从A到B</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edits1</span>(<span class="params">word</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(word)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>([word[<span class="number">0</span>:i]+word[i+<span class="number">1</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] +                     <span class="comment"># deletion</span></span><br><span class="line">               [word[<span class="number">0</span>:i]+word[i+<span class="number">1</span>]+word[i]+word[i+<span class="number">2</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>)] + <span class="comment"># transposition</span></span><br><span class="line">               [word[<span class="number">0</span>:i]+c+word[i+<span class="number">1</span>:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n) <span class="keyword">for</span> c <span class="keyword">in</span> alphabet] + <span class="comment"># alteration</span></span><br><span class="line">               [word[<span class="number">0</span>:i]+c+word[i:] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>) <span class="keyword">for</span> c <span class="keyword">in</span> alphabet])  <span class="comment"># insertion</span></span><br></pre></td></tr></table></figure><p>与 something 编辑距离为2的单词居然达到了 114,324 个</p><p>优化:在这些编辑距离小于2的词中间, 只把那些正确的词作为候选词,只能返回 3 个单词: ‘smoothing’, ‘something’ 和 ‘soothing’</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回所有与单词 w 编辑距离为 2 的集合</span></span><br><span class="line"><span class="comment"># 在这些编辑距离小于2的词中间, 只把那些正确的词作为候选词</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edits2</span>(<span class="params">word</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">set</span>(e2 <span class="keyword">for</span> e1 <span class="keyword">in</span> edits1(word) <span class="keyword">for</span> e2 <span class="keyword">in</span> edits1(e1))</span><br></pre></td></tr></table></figure><p><strong> P(w|c)的计算 </strong></p><p>正常来说把一个元音拼成另一个的概率要大于辅音 (因为人常常把 hello 打成 hallo 这样); 把单词的第一个字母拼错的概率会相对小, 等等.但是为了简单起见, 选择了一个简单的方法: 编辑距离为1的正确单词比编辑距离为2的优先级高, 而编辑距离为0的正确单词优先级比编辑距离为1的高. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">known</span>(<span class="params">words</span>):</span> <span class="keyword">return</span> <span class="built_in">set</span>(w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> w <span class="keyword">in</span> NWORDS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果known(set)非空, candidate 就会选取这个集合, 而不继续计算后面的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correct</span>(<span class="params">word</span>):</span></span><br><span class="line">    candidates = known([word]) <span class="keyword">or</span> known(edits1(word)) <span class="keyword">or</span> known_edits2(word) <span class="keyword">or</span> [word]  <span class="comment"># 优先级，前面的能得到结果，不会算后面的。</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(candidates, key=<span class="keyword">lambda</span> w: NWORDS[w])</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;贝叶斯拼写检查器&quot;&gt;&lt;a href=&quot;#贝叶斯拼写检查器&quot; class=&quot;headerlink&quot; title=&quot;贝叶斯拼写检查器&quot;&gt;&lt;/a&gt;贝叶斯拼写检查器&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td c</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习基础" scheme="https://xxren8218.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>决策树基础</title>
    <link href="https://xxren8218.github.io/20210429/%E5%86%B3%E7%AD%96%E6%A0%91.html"/>
    <id>https://xxren8218.github.io/20210429/%E5%86%B3%E7%AD%96%E6%A0%91.html</id>
    <published>2021-04-29T15:45:59.000Z</published>
    <updated>2021-04-29T15:50:48.301Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets.california_housing <span class="keyword">import</span> fetch_california_housing  <span class="comment"># 内置的数据集</span></span><br><span class="line">housing = fetch_california_housing()</span><br><span class="line">print(housing.DESCR)</span><br></pre></td></tr></table></figure><pre><code>downloading Cal. housing from http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz to C:\Users\user\scikit_learn_dataCalifornia housing dataset.The original database is available from StatLib    http://lib.stat.cmu.edu/The data contains 20,640 observations on 9 variables.This dataset contains the average house value as target variableand the following input variables (features): average income,housing average age, average rooms, average bedrooms, population,average occupation, latitude, and longitude in that order.References----------Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,Statistics and Probability Letters, 33 (1997) 291-297.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.data.shape  <span class="comment"># 有两万多个数据，每个数据有8个特征</span></span><br></pre></td></tr></table></figure><pre><code>(20640, 8)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">housing.data[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>array([   8.3252    ,   41.        ,    6.98412698,    1.02380952,        322.        ,    2.55555556,   37.88      , -122.23      ])</code></pre><h2 id="sklearn运行决策树只需要两步"><a href="#sklearn运行决策树只需要两步" class="headerlink" title="sklearn运行决策树只需要两步"></a>sklearn运行决策树只需要两步</h2><ul><li><strong>1.实例化树模型，传参数(下面有部分API文档说明)——此处最大深度为2</strong></li><li><strong>2.用实例化的对象.fit（数据的X，数据的y）就可以了</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree  <span class="comment"># 导入需要指定的树模块</span></span><br><span class="line">dtr = tree.DecisionTreeRegressor(max_depth = <span class="number">2</span>)</span><br><span class="line">dtr.fit(housing.data[:, [<span class="number">6</span>, <span class="number">7</span>]], housing.target)   <span class="comment"># 只选择两个数据来用（试验而已）。——经度和纬度</span></span><br></pre></td></tr></table></figure><pre><code>DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=2, max_features=None,           max_leaf_nodes=None, min_impurity_split=1e-07,           min_samples_leaf=1, min_samples_split=2,           min_weight_fraction_leaf=0.0, presort=False, random_state=None,           splitter=&#39;best&#39;)</code></pre><h3 id="会自动输出一些默认的参数。"><a href="#会自动输出一些默认的参数。" class="headerlink" title="会自动输出一些默认的参数。"></a>会自动输出一些默认的参数。</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要可视化显示 首先需要安装 graphviz   http://www.graphviz.org/Download..php</span></span><br><span class="line">dot_data = \</span><br><span class="line">    tree.export_graphviz(</span><br><span class="line">        dtr,  <span class="comment"># 构造出来的决策树对象传入第一个参数</span></span><br><span class="line">        out_file = <span class="literal">None</span>,</span><br><span class="line">        feature_names = housing.feature_names[<span class="number">6</span>:<span class="number">8</span>], <span class="comment"># 用哪个特征，传哪个特征（含左不含右），其余不需要改了。</span></span><br><span class="line">        filled = <span class="literal">True</span>,</span><br><span class="line">        impurity = <span class="literal">False</span>,</span><br><span class="line">        rounded = <span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p><strong>执行完以后会生成一个.dat的文件</strong></p><p><strong>需要一个库来对其进行显示</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip install pydotplus</span></span><br><span class="line"><span class="keyword">import</span> pydotplus</span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data)</span><br><span class="line">graph.get_nodes()[<span class="number">7</span>].set_fillcolor(<span class="string">&quot;#FFF2DD&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line">Image(graph.create_png())</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/10_0.png" alt=""></p><p><strong>可以用下列的命令将构造好的图保存起来</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.write_png(<span class="string">&quot;dtr_white_background.png&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>True</code></pre><p><strong>数据的切分</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">data_train, data_test, target_train, target_test = \</span><br><span class="line">    train_test_split(housing.data, housing.target, test_size = <span class="number">0.1</span>, random_state = <span class="number">42</span>)</span><br><span class="line">dtr = tree.DecisionTreeRegressor(random_state = <span class="number">42</span>)  <span class="comment"># （切分时的随机性）为了方面复现，使得每一次随机的结果都是一致的。</span></span><br><span class="line">dtr.fit(data_train, target_train)</span><br><span class="line"></span><br><span class="line">dtr.score(data_test, target_test)</span><br></pre></td></tr></table></figure><pre><code>0.637318351331017</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">rfr = RandomForestRegressor( random_state = <span class="number">42</span>)</span><br><span class="line">rfr.fit(data_train, target_train)</span><br><span class="line">rfr.score(data_test, target_test)</span><br></pre></td></tr></table></figure><pre><code>0.79086492280964926</code></pre><h2 id="树模型参数-（为了防止过拟合）"><a href="#树模型参数-（为了防止过拟合）" class="headerlink" title="树模型参数:（为了防止过拟合）"></a>树模型参数:（为了防止过拟合）</h2><ul><li><p>1.衡量标准  gini系数  or  entropy（熵）</p></li><li><p>2.splitter  best or random 前者是在所有特征中找最好的切分点 后者是在部分特征中（数据量大的时候）——特征多的时候，从头到尾遍历特征比较耗时（best默认），随机选择几个特征（random）,很少去改，因为很少遇到几百个特征。</p></li><li><p>3.max_features  None（所有），log2，sqrt，N  特征小于50的时候一般使用所有的</p></li><li><p><strong>4.max_depth</strong>  数据少或者特征少的时候可以不管这个值，如果模型样本量多，特征也多的情况下，可以尝试限制下（没有定值，可以交叉验证得到最优值）</p></li><li><p><strong>5.min_samples_split</strong>  如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</p></li><li><p>6.min_samples_leaf  这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝，如果样本量不大，不需要管这个值，大些如10W可是尝试下5</p></li><li><p>7.min_weight_fraction_leaf 这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。</p></li><li><p>8.max_leaf_nodes 通过限制最大叶子节点数，可以防止过拟合，默认是”None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制具体的值可以通过交叉验证得到。</p></li><li><p>9.class_weight 指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多导致训练的决策树过于偏向这些类别。这里可以自己指定各个样本的权重如果使用“balanced”，则算法会自己计算权重，样本量少的类别所对应的样本权重会高。</p></li><li><p>10.min_impurity_split 这个值限制了决策树的增长，如果某节点的不纯度(基尼系数，信息增益，均方差，绝对差)小于这个阈值则该节点不再生成子节点。即为叶子节点 。</p></li><li>n_estimators:要建立树的个数</li></ul><h3 id="GridSearchCV-模块相当于循环遍历，方便对参数进行选择。"><a href="#GridSearchCV-模块相当于循环遍历，方便对参数进行选择。" class="headerlink" title="GridSearchCV 模块相当于循环遍历，方便对参数进行选择。"></a>GridSearchCV 模块相当于循环遍历，方便对参数进行选择。</h3><ul><li>实例化GridSearchCV后需要传的参数(算法，参数的候选值，VC交叉验证的次数)，一般候选的值写成字典的形式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</span><br><span class="line">tree_param_grid = &#123; <span class="string">&#x27;min_samples_split&#x27;</span>: <span class="built_in">list</span>((<span class="number">3</span>,<span class="number">6</span>,<span class="number">9</span>)),<span class="string">&#x27;n_estimators&#x27;</span>:<span class="built_in">list</span>((<span class="number">10</span>,<span class="number">50</span>,<span class="number">100</span>))&#125;</span><br><span class="line">grid = GridSearchCV(RandomForestRegressor(),param_grid=tree_param_grid, cv=<span class="number">5</span>)</span><br><span class="line">grid.fit(data_train, target_train)</span><br><span class="line">grid.grid_scores_, grid.best_params_, grid.best_score_</span><br></pre></td></tr></table></figure><pre><code>([mean: 0.78405, std: 0.00505, params: &#123;&#39;min_samples_split&#39;: 3, &#39;n_estimators&#39;: 10&#125;,  mean: 0.80529, std: 0.00448, params: &#123;&#39;min_samples_split&#39;: 3, &#39;n_estimators&#39;: 50&#125;,  mean: 0.80673, std: 0.00433, params: &#123;&#39;min_samples_split&#39;: 3, &#39;n_estimators&#39;: 100&#125;,  mean: 0.79016, std: 0.00124, params: &#123;&#39;min_samples_split&#39;: 6, &#39;n_estimators&#39;: 10&#125;,  mean: 0.80496, std: 0.00491, params: &#123;&#39;min_samples_split&#39;: 6, &#39;n_estimators&#39;: 50&#125;,  mean: 0.80671, std: 0.00408, params: &#123;&#39;min_samples_split&#39;: 6, &#39;n_estimators&#39;: 100&#125;,  mean: 0.78747, std: 0.00341, params: &#123;&#39;min_samples_split&#39;: 9, &#39;n_estimators&#39;: 10&#125;,  mean: 0.80481, std: 0.00322, params: &#123;&#39;min_samples_split&#39;: 9, &#39;n_estimators&#39;: 50&#125;,  mean: 0.80603, std: 0.00437, params: &#123;&#39;min_samples_split&#39;: 9, &#39;n_estimators&#39;: 100&#125;], &#123;&#39;min_samples_split&#39;: 3, &#39;n_estimators&#39;: 100&#125;, 0.8067250881273065)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rfr = RandomForestRegressor( min_samples_split=<span class="number">3</span>,n_estimators = <span class="number">100</span>,random_state = <span class="number">42</span>)</span><br><span class="line">rfr.fit(data_train, target_train)</span><br><span class="line">rfr.score(data_test, target_test)</span><br></pre></td></tr></table></figure><pre><code>0.80908290496531576</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.Series(rfr.feature_importances_, index = housing.feature_names).sort_values(ascending = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure><pre><code>MedInc        0.524257AveOccup      0.137947Latitude      0.090622Longitude     0.089414HouseAge      0.053970AveRooms      0.044443Population    0.030263AveBedrms     0.029084dtype: float64</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;</summary>
      
    
    
    
    <category term="机器学习" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习基础" scheme="https://xxren8218.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归实战--信用卡诈骗检测</title>
    <link href="https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html"/>
    <id>https://xxren8218.github.io/20210418/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98.html</id>
    <published>2021-04-17T17:26:48.000Z</published>
    <updated>2021-04-17T18:53:58.904Z</updated>
    
    <content type="html"><![CDATA[<h1 id="信用卡诈骗预测——二分类的问题"><a href="#信用卡诈骗预测——二分类的问题" class="headerlink" title="信用卡诈骗预测——二分类的问题"></a>信用卡诈骗预测——二分类的问题</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><h2 id="先来看看数据长什么样子吧"><a href="#先来看看数据长什么样子吧" class="headerlink" title="先来看看数据长什么样子吧"></a>先来看看数据长什么样子吧</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;creditcard.csv&quot;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Time</th>      <th>V1</th>      <th>V2</th>      <th>V3</th>      <th>V4</th>      <th>V5</th>      <th>V6</th>      <th>V7</th>      <th>V8</th>      <th>V9</th>      <th>...</th>      <th>V21</th>      <th>V22</th>      <th>V23</th>      <th>V24</th>      <th>V25</th>      <th>V26</th>      <th>V27</th>      <th>V28</th>      <th>Amount</th>      <th>Class</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0.0</td>      <td>-1.359807</td>      <td>-0.072781</td>      <td>2.536347</td>      <td>1.378155</td>      <td>-0.338321</td>      <td>0.462388</td>      <td>0.239599</td>      <td>0.098698</td>      <td>0.363787</td>      <td>...</td>      <td>-0.018307</td>      <td>0.277838</td>      <td>-0.110474</td>      <td>0.066928</td>      <td>0.128539</td>      <td>-0.189115</td>      <td>0.133558</td>      <td>-0.021053</td>      <td>149.62</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>0.0</td>      <td>1.191857</td>      <td>0.266151</td>      <td>0.166480</td>      <td>0.448154</td>      <td>0.060018</td>      <td>-0.082361</td>      <td>-0.078803</td>      <td>0.085102</td>      <td>-0.255425</td>      <td>...</td>      <td>-0.225775</td>      <td>-0.638672</td>      <td>0.101288</td>      <td>-0.339846</td>      <td>0.167170</td>      <td>0.125895</td>      <td>-0.008983</td>      <td>0.014724</td>      <td>2.69</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>1.0</td>      <td>-1.358354</td>      <td>-1.340163</td>      <td>1.773209</td>      <td>0.379780</td>      <td>-0.503198</td>      <td>1.800499</td>      <td>0.791461</td>      <td>0.247676</td>      <td>-1.514654</td>      <td>...</td>      <td>0.247998</td>      <td>0.771679</td>      <td>0.909412</td>      <td>-0.689281</td>      <td>-0.327642</td>      <td>-0.139097</td>      <td>-0.055353</td>      <td>-0.059752</td>      <td>378.66</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>1.0</td>      <td>-0.966272</td>      <td>-0.185226</td>      <td>1.792993</td>      <td>-0.863291</td>      <td>-0.010309</td>      <td>1.247203</td>      <td>0.237609</td>      <td>0.377436</td>      <td>-1.387024</td>      <td>...</td>      <td>-0.108300</td>      <td>0.005274</td>      <td>-0.190321</td>      <td>-1.175575</td>      <td>0.647376</td>      <td>-0.221929</td>      <td>0.062723</td>      <td>0.061458</td>      <td>123.50</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>2.0</td>      <td>-1.158233</td>      <td>0.877737</td>      <td>1.548718</td>      <td>0.403034</td>      <td>-0.407193</td>      <td>0.095921</td>      <td>0.592941</td>      <td>-0.270533</td>      <td>0.817739</td>      <td>...</td>      <td>-0.009431</td>      <td>0.798278</td>      <td>-0.137458</td>      <td>0.141267</td>      <td>-0.206010</td>      <td>0.502292</td>      <td>0.219422</td>      <td>0.215153</td>      <td>69.99</td>      <td>0</td>    </tr>  </tbody></table><p>5 rows × 31 columns</p></div><h2 id="先来看看正负样本的分布情况吧！"><a href="#先来看看正负样本的分布情况吧！" class="headerlink" title="先来看看正负样本的分布情况吧！"></a>先来看看正负样本的分布情况吧！</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">count_classes = pd.value_counts(data[<span class="string">&#x27;Class&#x27;</span>], sort = <span class="literal">True</span>).sort_index()  <span class="comment"># values_counts可以根据值进行计数。sort_index()按行索引排序</span></span><br><span class="line">count_classes.plot(kind = <span class="string">&#x27;bar&#x27;</span>)    <span class="comment"># 除了plt，pd也可以做一些简单的图</span></span><br><span class="line">plt.title(<span class="string">&quot;Fraud class histogram&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Class&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Frequency&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.text.Text at 0x216366d8860&gt;</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/5_11.png" alt=""></p><h2 id="样本数据极度不均匀，应该怎么做？"><a href="#样本数据极度不均匀，应该怎么做？" class="headerlink" title="样本数据极度不均匀，应该怎么做？"></a>样本数据极度不均匀，应该怎么做？</h2><ul><li><strong>下采样</strong>——对于不均衡的数据，让 1 和 0 的数据一样少</li><li><strong>过采样</strong>——对于不均衡的数据，生成一些数据，让生成的数据与 0 样本一样多</li></ul><h3 id="Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。"><a href="#Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。" class="headerlink" title="Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。"></a>Amount数据分布不均衡，为了保证特征之间的分布是差不多的。——即保证数据的重要性一样。</h3><ul><li><strong>标准化</strong> </li><li><strong>归一化</strong>  </li></ul><p>可以使用sklearn的预处理模块进行标准化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;normAmount&#x27;</span>] = StandardScaler().fit_transform(data[<span class="string">&#x27;Amount&#x27;</span>].reshape(-<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># reshape(-1,1)</span></span><br><span class="line">                                                                                   <span class="comment"># -1表示让python给它行数</span></span><br><span class="line">data = data.drop([<span class="string">&#x27;Time&#x27;</span>,<span class="string">&#x27;Amount&#x27;</span>],axis=<span class="number">1</span>)  <span class="comment"># 有了新特征后，将没用的特征去掉。</span></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><div style="overflow: scroll;"><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>V1</th>      <th>V2</th>      <th>V3</th>      <th>V4</th>      <th>V5</th>      <th>V6</th>      <th>V7</th>      <th>V8</th>      <th>V9</th>      <th>V10</th>      <th>...</th>      <th>V21</th>      <th>V22</th>      <th>V23</th>      <th>V24</th>      <th>V25</th>      <th>V26</th>      <th>V27</th>      <th>V28</th>      <th>Class</th>      <th>normAmount</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>-1.359807</td>      <td>-0.072781</td>      <td>2.536347</td>      <td>1.378155</td>      <td>-0.338321</td>      <td>0.462388</td>      <td>0.239599</td>      <td>0.098698</td>      <td>0.363787</td>      <td>0.090794</td>      <td>...</td>      <td>-0.018307</td>      <td>0.277838</td>      <td>-0.110474</td>      <td>0.066928</td>      <td>0.128539</td>      <td>-0.189115</td>      <td>0.133558</td>      <td>-0.021053</td>      <td>0</td>      <td>0.244964</td>    </tr>    <tr>      <th>1</th>      <td>1.191857</td>      <td>0.266151</td>      <td>0.166480</td>      <td>0.448154</td>      <td>0.060018</td>      <td>-0.082361</td>      <td>-0.078803</td>      <td>0.085102</td>      <td>-0.255425</td>      <td>-0.166974</td>      <td>...</td>      <td>-0.225775</td>      <td>-0.638672</td>      <td>0.101288</td>      <td>-0.339846</td>      <td>0.167170</td>      <td>0.125895</td>      <td>-0.008983</td>      <td>0.014724</td>      <td>0</td>      <td>-0.342475</td>    </tr>    <tr>      <th>2</th>      <td>-1.358354</td>      <td>-1.340163</td>      <td>1.773209</td>      <td>0.379780</td>      <td>-0.503198</td>      <td>1.800499</td>      <td>0.791461</td>      <td>0.247676</td>      <td>-1.514654</td>      <td>0.207643</td>      <td>...</td>      <td>0.247998</td>      <td>0.771679</td>      <td>0.909412</td>      <td>-0.689281</td>      <td>-0.327642</td>      <td>-0.139097</td>      <td>-0.055353</td>      <td>-0.059752</td>      <td>0</td>      <td>1.160686</td>    </tr>    <tr>      <th>3</th>      <td>-0.966272</td>      <td>-0.185226</td>      <td>1.792993</td>      <td>-0.863291</td>      <td>-0.010309</td>      <td>1.247203</td>      <td>0.237609</td>      <td>0.377436</td>      <td>-1.387024</td>      <td>-0.054952</td>      <td>...</td>      <td>-0.108300</td>      <td>0.005274</td>      <td>-0.190321</td>      <td>-1.175575</td>      <td>0.647376</td>      <td>-0.221929</td>      <td>0.062723</td>      <td>0.061458</td>      <td>0</td>      <td>0.140534</td>    </tr>    <tr>      <th>4</th>      <td>-1.158233</td>      <td>0.877737</td>      <td>1.548718</td>      <td>0.403034</td>      <td>-0.407193</td>      <td>0.095921</td>      <td>0.592941</td>      <td>-0.270533</td>      <td>0.817739</td>      <td>0.753074</td>      <td>...</td>      <td>-0.009431</td>      <td>0.798278</td>      <td>-0.137458</td>      <td>0.141267</td>      <td>-0.206010</td>      <td>0.502292</td>      <td>0.219422</td>      <td>0.215153</td>      <td>0</td>      <td>-0.073403</td>    </tr>  </tbody></table><p>5 rows × 30 columns</p></div><h2 id="先来进行下采样吧！"><a href="#先来进行下采样吧！" class="headerlink" title="先来进行下采样吧！"></a>先来进行下采样吧！</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">X = data.ix[:, data.columns != <span class="string">&#x27;Class&#x27;</span>] <span class="comment"># loc[标签] iloc[索引数字] 取值 ，ix[都可以]  </span></span><br><span class="line">y = data.ix[:, data.columns == <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of data points in the minority class</span></span><br><span class="line">number_records_fraud = <span class="built_in">len</span>(data[data.Class == <span class="number">1</span>])  <span class="comment"># 计算异常样本的数目——采用bool索引的方式进行</span></span><br><span class="line">fraud_indices = np.array(data[data.Class == <span class="number">1</span>].index) <span class="comment"># 通过.index函数拿出来异常样本的索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Picking the indices of the normal classes</span></span><br><span class="line">normal_indices = data[data.Class == <span class="number">0</span>].index  <span class="comment"># 拿出来所有正常样本的index，为了下面的随机选择。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Out of the indices we picked, randomly select &quot;x&quot; number (number_records_fraud)</span></span><br><span class="line">random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = <span class="literal">False</span>)<span class="comment">#  np.random.choice(样本，选择数目)进行随机选择</span></span><br><span class="line">random_normal_indices = np.array(random_normal_indices)  <span class="comment"># 将拿出来的索引转化为np.array的类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Appending the 2 indices  ##合并两个样本的index进行合并</span></span><br><span class="line">under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Under sample dataset  ## 经过下采样以后拿到的数据</span></span><br><span class="line">under_sample_data = data.iloc[under_sample_indices,:]</span><br><span class="line"></span><br><span class="line">X_undersample = under_sample_data.ix[:, under_sample_data.columns != <span class="string">&#x27;Class&#x27;</span>]  <span class="comment"># 下采样的数据分成两部分</span></span><br><span class="line">y_undersample = under_sample_data.ix[:, under_sample_data.columns == <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Showing ratio</span></span><br><span class="line">print(<span class="string">&quot;Percentage of normal transactions: &quot;</span>, <span class="built_in">len</span>(under_sample_data[under_sample_data.Class == <span class="number">0</span>])/<span class="built_in">len</span>(under_sample_data))</span><br><span class="line">print(<span class="string">&quot;Percentage of fraud transactions: &quot;</span>, <span class="built_in">len</span>(under_sample_data[under_sample_data.Class == <span class="number">1</span>])/<span class="built_in">len</span>(under_sample_data))</span><br><span class="line">print(<span class="string">&quot;Total number of transactions in resampled data: &quot;</span>, <span class="built_in">len</span>(under_sample_data))</span><br></pre></td></tr></table></figure><pre><code>Percentage of normal transactions:  0.5Percentage of fraud transactions:  0.5Total number of transactions in resampled data:  984</code></pre><h3 id="下采样的数据少了，会出现什么问题呢？-后面说。"><a href="#下采样的数据少了，会出现什么问题呢？-后面说。" class="headerlink" title="下采样的数据少了，会出现什么问题呢？ 后面说。"></a>下采样的数据少了，会出现什么问题呢？ 后面说。</h3><h2 id="先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！"><a href="#先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！" class="headerlink" title="先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！"></a>先来进行交叉验证的数据的切分。——交叉验证，说到底是为了选参！</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split  <span class="comment"># sklearn有交叉验证的工具，能镜像数据的划分。</span></span><br><span class="line"><span class="comment"># from sklearn.model_selection import train_test_split</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Whole dataset  #【1】对原始的数据进行切分——（为了使用它的测试集进行测试）</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>) <span class="comment">## 注意顺序！ 数据洗牌</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Number transactions train dataset: &quot;</span>, <span class="built_in">len</span>(X_train))</span><br><span class="line">print(<span class="string">&quot;Number transactions test dataset: &quot;</span>, <span class="built_in">len</span>(X_test))</span><br><span class="line">print(<span class="string">&quot;Total number of transactions: &quot;</span>, <span class="built_in">len</span>(X_train)+<span class="built_in">len</span>(X_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Undersampled dataset  # 【2】 对下采样的数据进行切分。（下采样的测试集小，不具备原始数据的分布规则。）</span></span><br><span class="line">X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample</span><br><span class="line">                                                                                                   ,y_undersample</span><br><span class="line">                                                                                                   ,test_size = <span class="number">0.3</span></span><br><span class="line">                                                                                                   ,random_state = <span class="number">0</span>)</span><br><span class="line">print(<span class="string">&quot;&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;Number transactions train dataset: &quot;</span>, <span class="built_in">len</span>(X_train_undersample))</span><br><span class="line">print(<span class="string">&quot;Number transactions test dataset: &quot;</span>, <span class="built_in">len</span>(X_test_undersample))</span><br><span class="line">print(<span class="string">&quot;Total number of transactions: &quot;</span>, <span class="built_in">len</span>(X_train_undersample)+<span class="built_in">len</span>(X_test_undersample))</span><br></pre></td></tr></table></figure><pre><code>C:\Anaconda3\lib\site-packages\sklearn\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.  &quot;This module will be removed in 0.20.&quot;, DeprecationWarning)Number transactions train dataset:  199364Number transactions test dataset:  85443Total number of transactions:  284807Number transactions train dataset:  688Number transactions test dataset:  296Total number of transactions:  984</code></pre><h2 id="现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归"><a href="#现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归" class="headerlink" title="现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归"></a>现在数据切分完了，已经有数据了，可以进行建模了！——逻辑回归</h2><h4 id="模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人"><a href="#模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人" class="headerlink" title="模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人!"></a>模型可以容易建立（如用sklearn），但是模型评估标准咋样呢？——精度骗人!</h4><ul><li>样本数目不均衡时，类偏移现象。100个人，99个正常(0)，1个得癌症(1)。那如果我的模型是y = 0,我的准确率是 99 %,但是检测不出来一个患有癌症的人。——所以希望我们的模型查的全一点。</li></ul><h3 id="查准率与查全率（召回率）"><a href="#查准率与查全率（召回率）" class="headerlink" title="查准率与查全率（召回率）"></a>查准率与查全率（召回率）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Recall = TP/(TP+FN)  # 我判断得癌症的人/实际得癌症的人</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> KFold, cross_val_score   <span class="comment"># KFold 做几倍的交叉验证， cross_val_score交叉验证的结果</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix,recall_score,classification_report </span><br></pre></td></tr></table></figure><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><ul><li>正则化惩罚项——解决<strong>高偏差</strong>（<strong>欠拟合</strong>，数据误差大）&amp; <strong>高方差</strong>（<strong>过拟合</strong>，泛化能力差）<ul><li>L1 惩罚项</li><li>L2 惩罚项</li></ul></li></ul><ul><li><p>直接使用sklearn的逻辑回归库进行拟合 </p><ul><li>先实例化一个逻辑回归对象（传入正则化参数C，惩罚方式即可）</li><li>然后进行fit拟合</li><li>sklearn会返回预测结果</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printing_Kfold_scores</span>(<span class="params">x_train_data,y_train_data</span>):</span></span><br><span class="line">    fold = KFold(<span class="number">5</span>,shuffle=<span class="literal">False</span>)   <span class="comment"># 对（训练的）测试集的五倍交叉验证。</span></span><br><span class="line">                                                      <span class="comment">### 返回值是一个列表是[[train1,test1],[train2,test2],...]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Different C parameters   # C越大惩罚力度越大，即heta的权重就越小。可以用交叉验证来检测到底等于多少好。</span></span><br><span class="line">    c_param_range = [<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1</span>,<span class="number">10</span>,<span class="number">100</span>]</span><br><span class="line"></span><br><span class="line">    results_table = pd.DataFrame(index = <span class="built_in">range</span>(<span class="built_in">len</span>(c_param_range),<span class="number">2</span>), columns = [<span class="string">&#x27;C_parameter&#x27;</span>,<span class="string">&#x27;Mean recall score&#x27;</span>])</span><br><span class="line">    results_table[<span class="string">&#x27;C_parameter&#x27;</span>] = c_param_range</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]  </span></span><br><span class="line">    <span class="comment">## k-fold会分成两个索引的列表：train_indices = indices[0], test_indices = indices[1]  </span></span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">&quot;&quot;&quot;来看哪个C好&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> c_param <span class="keyword">in</span> c_param_range:</span><br><span class="line">        print(<span class="string">&#x27;-------------------------------------------&#x27;</span>)</span><br><span class="line">        print(<span class="string">&#x27;C parameter: &#x27;</span>, c_param)</span><br><span class="line">        print(<span class="string">&#x27;-------------------------------------------&#x27;</span>)</span><br><span class="line">        print(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        recall_accs = []</span><br><span class="line">        <span class="string">&quot;&quot;&quot;来进行交叉验证，1 3 训练 2验证，1 2 训练，3验证...&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> iteration, indices <span class="keyword">in</span> <span class="built_in">enumerate</span>(fold,start=<span class="number">1</span>):  <span class="comment">## 一般情况下，如果要对一个列表或者数组既要遍历索引又要遍历元素时，可以用enumerate</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Call the logistic regression model with a certain C parameter</span></span><br><span class="line">            lr = LogisticRegression(C = c_param, penalty = <span class="string">&#x27;l1&#x27;</span>)  <span class="comment">## C正则化，惩罚方式 L1惩罚。</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Use the training data to fit the model. In this case, we use the portion of the fold to train the model</span></span><br><span class="line">            <span class="comment"># with indices[0]. We then predict on the portion assigned as the &#x27;test cross validation&#x27; with indices[1]</span></span><br><span class="line">            <span class="comment"># 进行数据的拟合</span></span><br><span class="line">            lr.fit(x_train_data.iloc[indices[<span class="number">0</span>],:],y_train_data.iloc[indices[<span class="number">0</span>],:].values.ravel())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Predict values using the test indices in the training data</span></span><br><span class="line">            <span class="comment">## 比如在C = 0.01情况下，效果咋样</span></span><br><span class="line">            y_pred_undersample = lr.predict(x_train_data.iloc[indices[<span class="number">1</span>],:].values)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Calculate the recall score and append it to a list for recall scores representing the current c_parameter</span></span><br><span class="line">            recall_acc = recall_score(y_train_data.iloc[indices[<span class="number">1</span>],:].values,y_pred_undersample)  <span class="comment">## 召回率库自己生成 recall_score(实际值，预测值)</span></span><br><span class="line">            recall_accs.append(recall_acc)</span><br><span class="line">            print(<span class="string">&#x27;Iteration &#x27;</span>, iteration,<span class="string">&#x27;: recall score = &#x27;</span>, recall_acc)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The mean value of those recall scores is the metric we want to save and get hold of.</span></span><br><span class="line">        results_table.ix[j,<span class="string">&#x27;Mean recall score&#x27;</span>] = np.mean(recall_accs)</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">        print(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        print(<span class="string">&#x27;Mean recall score &#x27;</span>, np.mean(recall_accs))</span><br><span class="line">        print(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    best_c = results_table.loc[results_table[<span class="string">&#x27;Mean recall score&#x27;</span>].idxmax()][<span class="string">&#x27;C_parameter&#x27;</span>]  <span class="comment"># 定义能取到最大值得索引位置，</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Finally, we can check which C parameter is the best amongst the chosen.</span></span><br><span class="line">    print(<span class="string">&#x27;*********************************************************************************&#x27;</span>)</span><br><span class="line">    print(<span class="string">&#x27;Best model to choose from cross validation is with C parameter = &#x27;</span>, best_c)</span><br><span class="line">    print(<span class="string">&#x27;*********************************************************************************&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_c</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)</span><br></pre></td></tr></table></figure><pre><code>-------------------------------------------C parameter:  0.01-------------------------------------------Iteration  1 : recall score =  0.958904109589Iteration  2 : recall score =  0.917808219178Iteration  3 : recall score =  1.0Iteration  4 : recall score =  0.972972972973Iteration  5 : recall score =  0.954545454545Mean recall score  0.960846151257-------------------------------------------C parameter:  0.1-------------------------------------------Iteration  1 : recall score =  0.835616438356Iteration  2 : recall score =  0.86301369863Iteration  3 : recall score =  0.915254237288Iteration  4 : recall score =  0.932432432432Iteration  5 : recall score =  0.878787878788Mean recall score  0.885020937099-------------------------------------------C parameter:  1-------------------------------------------Iteration  1 : recall score =  0.835616438356Iteration  2 : recall score =  0.86301369863Iteration  3 : recall score =  0.966101694915Iteration  4 : recall score =  0.945945945946Iteration  5 : recall score =  0.893939393939Mean recall score  0.900923434357-------------------------------------------C parameter:  10-------------------------------------------Iteration  1 : recall score =  0.849315068493Iteration  2 : recall score =  0.86301369863Iteration  3 : recall score =  0.966101694915Iteration  4 : recall score =  0.959459459459Iteration  5 : recall score =  0.893939393939Mean recall score  0.906365863087-------------------------------------------C parameter:  100-------------------------------------------Iteration  1 : recall score =  0.86301369863Iteration  2 : recall score =  0.86301369863Iteration  3 : recall score =  0.966101694915Iteration  4 : recall score =  0.959459459459Iteration  5 : recall score =  0.893939393939Mean recall score  0.909105589115*********************************************************************************Best model to choose from cross validation is with C parameter =  0.01*********************************************************************************</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span>(<span class="params">cm, classes,</span></span></span><br><span class="line"><span class="function"><span class="params">                          title=<span class="string">&#x27;Confusion matrix&#x27;</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                          cmap=plt.cm.Blues</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function prints and plots the confusion matrix.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    plt.imshow(cm, interpolation=<span class="string">&#x27;nearest&#x27;</span>, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(<span class="built_in">len</span>(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=<span class="number">0</span>)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line"></span><br><span class="line">    thresh = cm.<span class="built_in">max</span>() / <span class="number">2.</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(<span class="built_in">range</span>(cm.shape[<span class="number">0</span>]), <span class="built_in">range</span>(cm.shape[<span class="number">1</span>])):</span><br><span class="line">        plt.text(j, i, cm[i, j],</span><br><span class="line">                 horizontalalignment=<span class="string">&quot;center&quot;</span>,</span><br><span class="line">                 color=<span class="string">&quot;white&quot;</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">&quot;black&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred_undersample = lr.predict(X_test_undersample.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.931972789116</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/22_1.png" alt=""></p><h3 id="从下采样的测试集，可以看到召回率约为-137-10-137≈90"><a href="#从下采样的测试集，可以看到召回率约为-137-10-137≈90" class="headerlink" title="从下采样的测试集，可以看到召回率约为(137+10)/137≈90%"></a>从下采样的测试集，可以看到召回率约为(137+10)/137≈90%</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred = lr.predict(X_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test,y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.918367346939</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/24_1.png" alt=""></p><h3 id="可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90-，但有8581个误杀值，不是我们所希望的。"><a href="#可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90-，但有8581个误杀值，不是我们所希望的。" class="headerlink" title="可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90%，但有8581个误杀值，不是我们所希望的。"></a>可以看到下采样的预测应用到整体样本的测试集，虽然召回率约为90%，但有8581个误杀值，不是我们所希望的。</h3><h2 id="对于原始数据集进行验证。会得到什么结果呢？——不进行上-下-采样"><a href="#对于原始数据集进行验证。会得到什么结果呢？——不进行上-下-采样" class="headerlink" title="对于原始数据集进行验证。会得到什么结果呢？——不进行上(下)采样"></a>对于原始数据集进行验证。会得到什么结果呢？——不进行上(下)采样</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_c = printing_Kfold_scores(X_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>-------------------------------------------C parameter:  0.01-------------------------------------------Iteration  1 : recall score =  0.492537313433Iteration  2 : recall score =  0.602739726027Iteration  3 : recall score =  0.683333333333Iteration  4 : recall score =  0.569230769231Iteration  5 : recall score =  0.45Mean recall score  0.559568228405-------------------------------------------C parameter:  0.1-------------------------------------------Iteration  1 : recall score =  0.567164179104Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.683333333333Iteration  4 : recall score =  0.584615384615Iteration  5 : recall score =  0.525Mean recall score  0.595310250644-------------------------------------------C parameter:  1-------------------------------------------Iteration  1 : recall score =  0.55223880597Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.716666666667Iteration  4 : recall score =  0.615384615385Iteration  5 : recall score =  0.5625Mean recall score  0.612645688837-------------------------------------------C parameter:  10-------------------------------------------Iteration  1 : recall score =  0.55223880597Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.733333333333Iteration  4 : recall score =  0.615384615385Iteration  5 : recall score =  0.575Mean recall score  0.61847902217-------------------------------------------C parameter:  100-------------------------------------------Iteration  1 : recall score =  0.55223880597Iteration  2 : recall score =  0.616438356164Iteration  3 : recall score =  0.733333333333Iteration  4 : recall score =  0.615384615385Iteration  5 : recall score =  0.575Mean recall score  0.61847902217*********************************************************************************Best model to choose from cross validation is with C parameter =  10.0*********************************************************************************</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train,y_train.values.ravel())</span><br><span class="line">y_pred_undersample = lr.predict(X_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(y_test,y_pred_undersample)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.619047619048</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/28_1.png" alt=""></p><h3 id="可以看到拿原始数据进行预测得到的召回率是比较低的。"><a href="#可以看到拿原始数据进行预测得到的召回率是比较低的。" class="headerlink" title="可以看到拿原始数据进行预测得到的召回率是比较低的。"></a>可以看到拿原始数据进行预测得到的召回率是比较低的。</h3><h2 id="接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0-5了"><a href="#接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0-5了" class="headerlink" title="接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0.5了"></a>接下来看看不同的阈值对模型的影响——划分正负样本的标准不是默认的0.5了</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = <span class="number">0.01</span>, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(X_train_undersample,y_train_undersample.values.ravel())</span><br><span class="line">y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values) <span class="comment">## 之前拿的是predict()现在是另外一个函数了</span></span><br><span class="line">                                                                       <span class="comment"># 之前预测是类别的值，现在预测是概率值</span></span><br><span class="line"></span><br><span class="line">thresholds = [<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.3</span>,<span class="number">0.4</span>,<span class="number">0.5</span>,<span class="number">0.6</span>,<span class="number">0.7</span>,<span class="number">0.8</span>,<span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">j = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> thresholds:</span><br><span class="line">    y_test_predictions_high_recall = y_pred_undersample_proba[:,<span class="number">1</span>] &gt; i  <span class="comment">## 这是关键，拿到概率后直接拿它与设定阈值比较</span></span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">3</span>,j)</span><br><span class="line">    j += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Compute confusion matrix</span></span><br><span class="line">    cnf_matrix = confusion_matrix(y_test_undersample,y_test_predictions_high_recall)</span><br><span class="line">    np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">    class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">    plot_confusion_matrix(cnf_matrix</span><br><span class="line">                          , classes=class_names</span><br><span class="line">                          , title=<span class="string">&#x27;Threshold &gt;= %s&#x27;</span>%i) </span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  1.0Recall metric in the testing dataset:  1.0Recall metric in the testing dataset:  1.0Recall metric in the testing dataset:  0.986394557823Recall metric in the testing dataset:  0.931972789116Recall metric in the testing dataset:  0.884353741497Recall metric in the testing dataset:  0.836734693878Recall metric in the testing dataset:  0.748299319728Recall metric in the testing dataset:  0.571428571429</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/31_1.png" alt=""></p><h3 id="可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！"><a href="#可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！" class="headerlink" title="可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！"></a>可以看到随着阈值的上升，误杀值减小，但是召回率也是减小了。——实际建模时，应该根据实际情况来选择阈值！</h3><h2 id="看完下采样的分析，我们来看看上采样的结果吧！"><a href="#看完下采样的分析，我们来看看上采样的结果吧！" class="headerlink" title="看完下采样的分析，我们来看看上采样的结果吧！"></a>看完下采样的分析，我们来看看上采样的结果吧！</h2><ul><li>上采样需要额外的数据，这里我们采用 <strong><code>SMOTE</code></strong> 方法来生成少数样本的数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE   <span class="comment"># 需要安装 imblearn 库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">credit_cards=pd.read_csv(<span class="string">&#x27;creditcard.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">columns=credit_cards.columns</span><br><span class="line"><span class="comment"># The labels are in the last column (&#x27;Class&#x27;). Simply remove it to obtain features columns</span></span><br><span class="line">features_columns=columns.delete(<span class="built_in">len</span>(columns)-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">features=credit_cards[features_columns]</span><br><span class="line">labels=credit_cards[<span class="string">&#x27;Class&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">features_train, features_test, labels_train, labels_test = train_test_split(features, </span><br><span class="line">                                                                            labels, </span><br><span class="line">                                                                            test_size=<span class="number">0.2</span>, </span><br><span class="line">                                                                            random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oversampler=SMOTE(random_state=<span class="number">0</span>)  <span class="comment"># 每次生辰的随机数一样。</span></span><br><span class="line">os_features,os_labels=oversampler.fit_sample(features_train,labels_train)  <span class="comment"># 注意传入的是训练的x和y的值。没有测试部分的</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(os_labels[os_labels==<span class="number">1</span>])  <span class="comment"># 自动会进行平衡。1:1平衡</span></span><br></pre></td></tr></table></figure><pre><code>227454</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">os_features = pd.DataFrame(os_features)</span><br><span class="line">os_labels = pd.DataFrame(os_labels)</span><br><span class="line">best_c = printing_Kfold_scores(os_features,os_labels)</span><br></pre></td></tr></table></figure><pre><code>-------------------------------------------C parameter:  0.01-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.968861347792Iteration  4 : recall score =  0.957595541926Iteration  5 : recall score =  0.958430881173Mean recall score  0.933989438728-------------------------------------------C parameter:  0.1-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.970410534469Iteration  4 : recall score =  0.959980655302Iteration  5 : recall score =  0.960178498807Mean recall score  0.935125822266-------------------------------------------C parameter:  1-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.970454796946Iteration  4 : recall score =  0.96014552489Iteration  5 : recall score =  0.960596168431Mean recall score  0.935251182603-------------------------------------------C parameter:  10-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.97065397809Iteration  4 : recall score =  0.960343368396Iteration  5 : recall score =  0.960530220596Mean recall score  0.935317397966-------------------------------------------C parameter:  100-------------------------------------------Iteration  1 : recall score =  0.890322580645Iteration  2 : recall score =  0.894736842105Iteration  3 : recall score =  0.970543321899Iteration  4 : recall score =  0.960211472725Iteration  5 : recall score =  0.960903924995Mean recall score  0.935343628474*********************************************************************************Best model to choose from cross validation is with C parameter =  100.0*********************************************************************************</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C = best_c, penalty = <span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">lr.fit(os_features,os_labels.values.ravel())</span><br><span class="line">y_pred = lr.predict(features_test.values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute confusion matrix</span></span><br><span class="line">cnf_matrix = confusion_matrix(labels_test,y_pred)</span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Recall metric in the testing dataset: &quot;</span>, cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]/(cnf_matrix[<span class="number">1</span>,<span class="number">0</span>]+cnf_matrix[<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot non-normalized confusion matrix</span></span><br><span class="line">class_names = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">plt.figure()</span><br><span class="line">plot_confusion_matrix(cnf_matrix</span><br><span class="line">                      , classes=class_names</span><br><span class="line">                      , title=<span class="string">&#x27;Confusion matrix&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>Recall metric in the testing dataset:  0.90099009901</code></pre><p><img src="https://cdn.jsdelivr.net/gh/xxren8218/blogimages/img/40_1png" alt=""></p><h3 id="召回率还可以，误杀率降下来——模型的精度变高。-56344-91-569344-91-517-10"><a href="#召回率还可以，误杀率降下来——模型的精度变高。-56344-91-569344-91-517-10" class="headerlink" title="召回率还可以，误杀率降下来——模型的精度变高。(56344+91)/(569344+91+517+10)"></a>召回率还可以，误杀率降下来——模型的精度变高。(56344+91)/(569344+91+517+10)</h3><h3 id="总之，能用数据生成方式尽量用，上采样的结果更好！"><a href="#总之，能用数据生成方式尽量用，上采样的结果更好！" class="headerlink" title="总之，能用数据生成方式尽量用，上采样的结果更好！"></a>总之，能用数据生成方式尽量用，上采样的结果更好！</h3><h1 id="案例流程总结："><a href="#案例流程总结：" class="headerlink" title="案例流程总结："></a>案例流程总结：</h1><ul><li><p><strong>1. 数据的观察。</strong></p><ul><li>1.1 数据浮动情况：<ul><li>归一化</li><li>标准化<ul><li>1.2 数据分布均匀情况：</li></ul></li><li>下采样</li><li>上采样<ul><li>1.3 此处的案例的特征是处理过的，纯净的特征，不需要额外处理。很多时候需要特种工程处理特征数据—后面讲</li></ul></li></ul></li></ul></li><li><p><strong>2. 对于不同的模型有不同的参数，需要自己进行选择。</strong></p><ul><li>比如逻辑回归的正则化参数C的选择(解决过拟合【高方差】和欠拟合【高偏差】)。<ul><li>采用交叉验证的方式来确定参数C（交叉验证多次来确定C的合适大小）</li></ul></li></ul></li><li><p><strong>3. 混淆矩阵，召回率——解决类偏移问题</strong></p><ul><li>预测模型为 y=1 ,准确率达到90%这类问题。</li></ul></li><li><p><strong>4. 不同的阈值（评判分类的不概率标准）</strong></p><ul><li>对结果有一定的影响。如此题。阈值越大，误杀率越高，召回率降低。——实际建模的时候，根据需要来确定。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;信用卡诈骗预测——二分类的问题&quot;&gt;&lt;a href=&quot;#信用卡诈骗预测——二分类的问题&quot; class=&quot;headerlink&quot; title=&quot;信用卡诈骗预测——二分类的问题&quot;&gt;&lt;/a&gt;信用卡诈骗预测——二分类的问题&lt;/h1&gt;&lt;figure class=&quot;highli</summary>
      
    
    
    
    <category term="机器学习基础实战" scheme="https://xxren8218.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="机器学习基础实战" scheme="https://xxren8218.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98/"/>
    
  </entry>
  
</feed>
